{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1554,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import time\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mogankumarnarsozhan/Documents/NN_Project/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(['f', 'e', 'd', 'b', 'c', 'a'], np.nan, inplace=True)\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1557,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "\n",
    "#Sampling the data\n",
    "df_majority = df[df.target == 0]\n",
    "df_minority = df[df.target == 1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "X_upsampled = df_upsampled.drop(columns='target')\n",
    "y_upsampled = df_upsampled['target']\n",
    "\n",
    "#Splitting into training, testing and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_upsampled, y_upsampled, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "#Scaling the values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.fit_transform(X_val)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of entire df: (760, 8)\n",
      "Shape of X_train: (800, 7)\n",
      "Shape of y_train: (800,)\n",
      "Shape of X_test: (99, 7)\n",
      "Shape of y_test: (99,)\n",
      "Shape of X_val: (89, 7)\n",
      "Shape of y_val: (89,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of entire df:\", df.shape)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train).float()\n",
    "y_train_tensor = torch.tensor(y_train.values).int()\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val).float()\n",
    "y_val_tensor = torch.tensor(y_val.values).int()\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test).float()\n",
    "y_test_tensor = torch.tensor(y_test.values).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork                            [1, 1]                    --\n",
       "├─Linear: 1-1                            [1, 256]                  2,048\n",
       "├─ReLU: 1-2                              [1, 256]                  --\n",
       "├─Dropout: 1-3                           [1, 256]                  --\n",
       "├─Linear: 1-4                            [1, 128]                  32,896\n",
       "├─ReLU: 1-5                              [1, 128]                  --\n",
       "├─Dropout: 1-6                           [1, 128]                  --\n",
       "├─Linear: 1-7                            [1, 64]                   8,256\n",
       "├─ReLU: 1-8                              [1, 64]                   --\n",
       "├─Dropout: 1-9                           [1, 64]                   --\n",
       "├─Linear: 1-10                           [1, 32]                   2,080\n",
       "├─ReLU: 1-11                             [1, 32]                   --\n",
       "├─Dropout: 1-12                          [1, 32]                   --\n",
       "├─Linear: 1-13                           [1, 1]                    33\n",
       "├─Sigmoid: 1-14                          [1, 1]                    --\n",
       "==========================================================================================\n",
       "Total params: 45,313\n",
       "Trainable params: 45,313\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.05\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.18\n",
       "Estimated Total Size (MB): 0.19\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 1560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "    \n",
    "        self.fc1 = nn.Linear(7, 256)  # Input layer\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)  # Hidden layers\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc5 = nn.Linear(32, 1)  # Output layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Using sigmoid because of Binary Target\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "summary(model, input_size=(1, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1561,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch= 16\n",
    "learning_rate = 0.01\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1562,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size= batch, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size= batch, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropout rates as hyper parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 0.5621, Validation Loss: 0.5688, Training Accuracy: 0.7087, Validation Accuracy: 0.7528\n",
      "Epoch [2/500], Training Loss: 0.5528, Validation Loss: 0.5068, Training Accuracy: 0.7262, Validation Accuracy: 0.7528\n",
      "Epoch [3/500], Training Loss: 0.5231, Validation Loss: 0.4932, Training Accuracy: 0.7475, Validation Accuracy: 0.7416\n",
      "Epoch [4/500], Training Loss: 0.5039, Validation Loss: 0.5245, Training Accuracy: 0.7425, Validation Accuracy: 0.7640\n",
      "Epoch [5/500], Training Loss: 0.5098, Validation Loss: 0.5106, Training Accuracy: 0.7512, Validation Accuracy: 0.7191\n",
      "Epoch [6/500], Training Loss: 0.4824, Validation Loss: 0.5597, Training Accuracy: 0.7688, Validation Accuracy: 0.6742\n",
      "Epoch [7/500], Training Loss: 0.4982, Validation Loss: 0.4980, Training Accuracy: 0.7525, Validation Accuracy: 0.7865\n",
      "Epoch [8/500], Training Loss: 0.4520, Validation Loss: 0.4579, Training Accuracy: 0.7725, Validation Accuracy: 0.8202\n",
      "Epoch [9/500], Training Loss: 0.5069, Validation Loss: 0.6444, Training Accuracy: 0.7650, Validation Accuracy: 0.7191\n",
      "Epoch [10/500], Training Loss: 0.4939, Validation Loss: 0.4984, Training Accuracy: 0.7525, Validation Accuracy: 0.7753\n",
      "Epoch [11/500], Training Loss: 0.4421, Validation Loss: 0.5221, Training Accuracy: 0.7775, Validation Accuracy: 0.7640\n",
      "Epoch [12/500], Training Loss: 0.4279, Validation Loss: 0.4733, Training Accuracy: 0.7738, Validation Accuracy: 0.7416\n",
      "Epoch [13/500], Training Loss: 0.4427, Validation Loss: 0.5443, Training Accuracy: 0.7850, Validation Accuracy: 0.6854\n",
      "Epoch [14/500], Training Loss: 0.4551, Validation Loss: 0.5034, Training Accuracy: 0.7762, Validation Accuracy: 0.8090\n",
      "Epoch [15/500], Training Loss: 0.4480, Validation Loss: 0.4495, Training Accuracy: 0.7900, Validation Accuracy: 0.7753\n",
      "Epoch [16/500], Training Loss: 0.4610, Validation Loss: 0.4868, Training Accuracy: 0.7950, Validation Accuracy: 0.7640\n",
      "Epoch [17/500], Training Loss: 0.4694, Validation Loss: 0.4950, Training Accuracy: 0.7688, Validation Accuracy: 0.7640\n",
      "Epoch [18/500], Training Loss: 0.4343, Validation Loss: 0.5359, Training Accuracy: 0.7825, Validation Accuracy: 0.7865\n",
      "Epoch [19/500], Training Loss: 0.3880, Validation Loss: 0.5056, Training Accuracy: 0.8075, Validation Accuracy: 0.7865\n",
      "Epoch [20/500], Training Loss: 0.4343, Validation Loss: 0.4820, Training Accuracy: 0.8013, Validation Accuracy: 0.7978\n",
      "Epoch [21/500], Training Loss: 0.4210, Validation Loss: 0.4621, Training Accuracy: 0.8137, Validation Accuracy: 0.8090\n",
      "Epoch [22/500], Training Loss: 0.4271, Validation Loss: 0.4674, Training Accuracy: 0.8187, Validation Accuracy: 0.7753\n",
      "Epoch [23/500], Training Loss: 0.4009, Validation Loss: 0.4748, Training Accuracy: 0.8063, Validation Accuracy: 0.8090\n",
      "Epoch [24/500], Training Loss: 0.3942, Validation Loss: 0.6373, Training Accuracy: 0.8150, Validation Accuracy: 0.7640\n",
      "Epoch [25/500], Training Loss: 0.3782, Validation Loss: 0.4571, Training Accuracy: 0.8250, Validation Accuracy: 0.7753\n",
      "Epoch [26/500], Training Loss: 0.3986, Validation Loss: 0.4580, Training Accuracy: 0.8163, Validation Accuracy: 0.7865\n",
      "Epoch [27/500], Training Loss: 0.3903, Validation Loss: 0.4441, Training Accuracy: 0.8250, Validation Accuracy: 0.7640\n",
      "Epoch [28/500], Training Loss: 0.3421, Validation Loss: 0.4485, Training Accuracy: 0.8300, Validation Accuracy: 0.7865\n",
      "Epoch [29/500], Training Loss: 0.3566, Validation Loss: 0.5194, Training Accuracy: 0.8375, Validation Accuracy: 0.7416\n",
      "Epoch [30/500], Training Loss: 0.4022, Validation Loss: 0.4816, Training Accuracy: 0.8200, Validation Accuracy: 0.7640\n",
      "Epoch [31/500], Training Loss: 0.3568, Validation Loss: 0.5795, Training Accuracy: 0.8450, Validation Accuracy: 0.7753\n",
      "Epoch [32/500], Training Loss: 0.3489, Validation Loss: 0.4588, Training Accuracy: 0.8475, Validation Accuracy: 0.7865\n",
      "Epoch [33/500], Training Loss: 0.3600, Validation Loss: 0.4364, Training Accuracy: 0.8363, Validation Accuracy: 0.7865\n",
      "Epoch [34/500], Training Loss: 0.3582, Validation Loss: 0.4393, Training Accuracy: 0.8488, Validation Accuracy: 0.8090\n",
      "Epoch [35/500], Training Loss: 0.3760, Validation Loss: 0.4424, Training Accuracy: 0.8400, Validation Accuracy: 0.7865\n",
      "Epoch [36/500], Training Loss: 0.3771, Validation Loss: 0.4252, Training Accuracy: 0.8400, Validation Accuracy: 0.7528\n",
      "Epoch [37/500], Training Loss: 0.3725, Validation Loss: 0.4815, Training Accuracy: 0.8425, Validation Accuracy: 0.8090\n",
      "Epoch [38/500], Training Loss: 0.3400, Validation Loss: 0.4754, Training Accuracy: 0.8512, Validation Accuracy: 0.8090\n",
      "Epoch [39/500], Training Loss: 0.3524, Validation Loss: 0.4808, Training Accuracy: 0.8450, Validation Accuracy: 0.8202\n",
      "Epoch [40/500], Training Loss: 0.3116, Validation Loss: 0.4542, Training Accuracy: 0.8650, Validation Accuracy: 0.8315\n",
      "Epoch [41/500], Training Loss: 0.3185, Validation Loss: 0.4552, Training Accuracy: 0.8562, Validation Accuracy: 0.7865\n",
      "Epoch [42/500], Training Loss: 0.3269, Validation Loss: 0.4764, Training Accuracy: 0.8488, Validation Accuracy: 0.7753\n",
      "Epoch [43/500], Training Loss: 0.2484, Validation Loss: 0.5640, Training Accuracy: 0.8838, Validation Accuracy: 0.8315\n",
      "Epoch [44/500], Training Loss: 0.3256, Validation Loss: 0.5007, Training Accuracy: 0.8700, Validation Accuracy: 0.8202\n",
      "Epoch [45/500], Training Loss: 0.3358, Validation Loss: 0.4906, Training Accuracy: 0.8638, Validation Accuracy: 0.8090\n",
      "Epoch [46/500], Training Loss: 0.3115, Validation Loss: 0.4704, Training Accuracy: 0.8725, Validation Accuracy: 0.8202\n",
      "Epoch [47/500], Training Loss: 0.3045, Validation Loss: 0.5028, Training Accuracy: 0.8788, Validation Accuracy: 0.8090\n",
      "Epoch [48/500], Training Loss: 0.2647, Validation Loss: 0.4405, Training Accuracy: 0.8862, Validation Accuracy: 0.8202\n",
      "Epoch [49/500], Training Loss: 0.2668, Validation Loss: 0.4734, Training Accuracy: 0.8912, Validation Accuracy: 0.7865\n",
      "Epoch [50/500], Training Loss: 0.2753, Validation Loss: 0.4784, Training Accuracy: 0.8700, Validation Accuracy: 0.8090\n",
      "Epoch [51/500], Training Loss: 0.2820, Validation Loss: 0.3969, Training Accuracy: 0.8688, Validation Accuracy: 0.8202\n",
      "Epoch [52/500], Training Loss: 0.2818, Validation Loss: 0.4752, Training Accuracy: 0.8675, Validation Accuracy: 0.8090\n",
      "Epoch [53/500], Training Loss: 0.2315, Validation Loss: 0.5229, Training Accuracy: 0.8975, Validation Accuracy: 0.8090\n",
      "Epoch [54/500], Training Loss: 0.2361, Validation Loss: 0.5063, Training Accuracy: 0.9012, Validation Accuracy: 0.8202\n",
      "Epoch [55/500], Training Loss: 0.3197, Validation Loss: 0.5237, Training Accuracy: 0.8838, Validation Accuracy: 0.8202\n",
      "Epoch [56/500], Training Loss: 0.3137, Validation Loss: 0.4672, Training Accuracy: 0.8638, Validation Accuracy: 0.8090\n",
      "Epoch [57/500], Training Loss: 0.2941, Validation Loss: 0.4460, Training Accuracy: 0.8688, Validation Accuracy: 0.7753\n",
      "Epoch [58/500], Training Loss: 0.3095, Validation Loss: 0.5400, Training Accuracy: 0.8675, Validation Accuracy: 0.7753\n",
      "Epoch [59/500], Training Loss: 0.3271, Validation Loss: 0.4519, Training Accuracy: 0.8612, Validation Accuracy: 0.7753\n",
      "Epoch [60/500], Training Loss: 0.2709, Validation Loss: 0.5512, Training Accuracy: 0.8762, Validation Accuracy: 0.8090\n",
      "Epoch [61/500], Training Loss: 0.3107, Validation Loss: 0.4628, Training Accuracy: 0.8838, Validation Accuracy: 0.7978\n",
      "Epoch [62/500], Training Loss: 0.2363, Validation Loss: 0.4637, Training Accuracy: 0.8950, Validation Accuracy: 0.7978\n",
      "Epoch [63/500], Training Loss: 0.2714, Validation Loss: 0.6759, Training Accuracy: 0.8950, Validation Accuracy: 0.7865\n",
      "Epoch [64/500], Training Loss: 0.2421, Validation Loss: 0.4806, Training Accuracy: 0.8938, Validation Accuracy: 0.7753\n",
      "Epoch [65/500], Training Loss: 0.2294, Validation Loss: 0.5902, Training Accuracy: 0.9075, Validation Accuracy: 0.8202\n",
      "Epoch [66/500], Training Loss: 0.2482, Validation Loss: 0.5000, Training Accuracy: 0.8975, Validation Accuracy: 0.7753\n",
      "Epoch [67/500], Training Loss: 0.2104, Validation Loss: 0.6661, Training Accuracy: 0.9137, Validation Accuracy: 0.7640\n",
      "Epoch [68/500], Training Loss: 0.3537, Validation Loss: 0.5742, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [69/500], Training Loss: 0.2455, Validation Loss: 0.4868, Training Accuracy: 0.9025, Validation Accuracy: 0.7640\n",
      "Epoch [70/500], Training Loss: 0.2382, Validation Loss: 0.4853, Training Accuracy: 0.8950, Validation Accuracy: 0.8202\n",
      "Epoch [71/500], Training Loss: 0.2167, Validation Loss: 0.5223, Training Accuracy: 0.9163, Validation Accuracy: 0.7865\n",
      "Epoch [72/500], Training Loss: 0.1990, Validation Loss: 0.4664, Training Accuracy: 0.9100, Validation Accuracy: 0.8202\n",
      "Epoch [73/500], Training Loss: 0.2431, Validation Loss: 0.4392, Training Accuracy: 0.9087, Validation Accuracy: 0.7865\n",
      "Epoch [74/500], Training Loss: 0.2974, Validation Loss: 0.4926, Training Accuracy: 0.8925, Validation Accuracy: 0.8202\n",
      "Epoch [75/500], Training Loss: 0.2528, Validation Loss: 0.6043, Training Accuracy: 0.8850, Validation Accuracy: 0.7753\n",
      "Epoch [76/500], Training Loss: 0.2652, Validation Loss: 0.6527, Training Accuracy: 0.8938, Validation Accuracy: 0.8090\n",
      "Epoch [77/500], Training Loss: 0.2243, Validation Loss: 0.7318, Training Accuracy: 0.9050, Validation Accuracy: 0.8202\n",
      "Epoch [78/500], Training Loss: 0.2216, Validation Loss: 0.5613, Training Accuracy: 0.9113, Validation Accuracy: 0.8090\n",
      "Epoch [79/500], Training Loss: 0.1952, Validation Loss: 0.6789, Training Accuracy: 0.9125, Validation Accuracy: 0.8202\n",
      "Epoch [80/500], Training Loss: 0.1873, Validation Loss: 0.6669, Training Accuracy: 0.9113, Validation Accuracy: 0.8202\n",
      "Epoch [81/500], Training Loss: 0.2345, Validation Loss: 0.3839, Training Accuracy: 0.9062, Validation Accuracy: 0.7978\n",
      "Epoch [82/500], Training Loss: 0.1984, Validation Loss: 0.5983, Training Accuracy: 0.9125, Validation Accuracy: 0.7978\n",
      "Epoch [83/500], Training Loss: 0.1932, Validation Loss: 0.5504, Training Accuracy: 0.9200, Validation Accuracy: 0.8315\n",
      "Epoch [84/500], Training Loss: 0.2111, Validation Loss: 0.5921, Training Accuracy: 0.9187, Validation Accuracy: 0.8315\n",
      "Epoch [85/500], Training Loss: 0.1944, Validation Loss: 0.9185, Training Accuracy: 0.9187, Validation Accuracy: 0.8202\n",
      "Epoch [86/500], Training Loss: 0.1650, Validation Loss: 0.6742, Training Accuracy: 0.9213, Validation Accuracy: 0.8090\n",
      "Epoch [87/500], Training Loss: 0.1954, Validation Loss: 0.5670, Training Accuracy: 0.9225, Validation Accuracy: 0.8090\n",
      "Epoch [88/500], Training Loss: 0.1645, Validation Loss: 0.7325, Training Accuracy: 0.9313, Validation Accuracy: 0.7865\n",
      "Epoch [89/500], Training Loss: 0.1968, Validation Loss: 1.5640, Training Accuracy: 0.9200, Validation Accuracy: 0.7865\n",
      "Epoch [90/500], Training Loss: 0.1701, Validation Loss: 1.7385, Training Accuracy: 0.9325, Validation Accuracy: 0.7640\n",
      "Epoch [91/500], Training Loss: 0.1851, Validation Loss: 0.7614, Training Accuracy: 0.9300, Validation Accuracy: 0.7753\n",
      "Epoch [92/500], Training Loss: 0.1958, Validation Loss: 0.7087, Training Accuracy: 0.9187, Validation Accuracy: 0.7753\n",
      "Epoch [93/500], Training Loss: 0.1967, Validation Loss: 0.5413, Training Accuracy: 0.9113, Validation Accuracy: 0.8090\n",
      "Epoch [94/500], Training Loss: 0.2027, Validation Loss: 0.6221, Training Accuracy: 0.9263, Validation Accuracy: 0.7978\n",
      "Epoch [95/500], Training Loss: 0.1710, Validation Loss: 0.7454, Training Accuracy: 0.9325, Validation Accuracy: 0.7978\n",
      "Epoch [96/500], Training Loss: 0.1820, Validation Loss: 0.6817, Training Accuracy: 0.9150, Validation Accuracy: 0.7978\n",
      "Epoch [97/500], Training Loss: 0.1731, Validation Loss: 0.9134, Training Accuracy: 0.9313, Validation Accuracy: 0.7753\n",
      "Epoch [98/500], Training Loss: 0.2588, Validation Loss: 0.6665, Training Accuracy: 0.9287, Validation Accuracy: 0.8090\n",
      "Epoch [99/500], Training Loss: 0.2015, Validation Loss: 0.6545, Training Accuracy: 0.9113, Validation Accuracy: 0.7528\n",
      "Epoch [100/500], Training Loss: 0.2011, Validation Loss: 0.3895, Training Accuracy: 0.9113, Validation Accuracy: 0.7865\n",
      "Epoch [101/500], Training Loss: 0.1648, Validation Loss: 0.7870, Training Accuracy: 0.9350, Validation Accuracy: 0.7978\n",
      "Epoch [102/500], Training Loss: 0.3351, Validation Loss: 0.6027, Training Accuracy: 0.9113, Validation Accuracy: 0.8090\n",
      "Epoch [103/500], Training Loss: 0.2290, Validation Loss: 0.6252, Training Accuracy: 0.9038, Validation Accuracy: 0.7865\n",
      "Epoch [104/500], Training Loss: 0.2261, Validation Loss: 0.4176, Training Accuracy: 0.9025, Validation Accuracy: 0.7640\n",
      "Epoch [105/500], Training Loss: 0.2379, Validation Loss: 0.4722, Training Accuracy: 0.8988, Validation Accuracy: 0.7753\n",
      "Epoch [106/500], Training Loss: 0.1892, Validation Loss: 0.6312, Training Accuracy: 0.9125, Validation Accuracy: 0.8202\n",
      "Epoch [107/500], Training Loss: 0.2120, Validation Loss: 0.8317, Training Accuracy: 0.9187, Validation Accuracy: 0.7978\n",
      "Epoch [108/500], Training Loss: 0.2298, Validation Loss: 0.5909, Training Accuracy: 0.8950, Validation Accuracy: 0.7865\n",
      "Epoch [109/500], Training Loss: 0.1956, Validation Loss: 0.7331, Training Accuracy: 0.9213, Validation Accuracy: 0.8202\n",
      "Epoch [110/500], Training Loss: 0.2312, Validation Loss: 1.9952, Training Accuracy: 0.9213, Validation Accuracy: 0.7528\n",
      "Epoch [111/500], Training Loss: 0.1998, Validation Loss: 0.8123, Training Accuracy: 0.9137, Validation Accuracy: 0.7865\n",
      "Epoch [112/500], Training Loss: 0.2054, Validation Loss: 0.7539, Training Accuracy: 0.9250, Validation Accuracy: 0.8315\n",
      "Epoch [113/500], Training Loss: 0.1708, Validation Loss: 0.8878, Training Accuracy: 0.9150, Validation Accuracy: 0.7978\n",
      "Epoch [114/500], Training Loss: 0.1583, Validation Loss: 0.8353, Training Accuracy: 0.9350, Validation Accuracy: 0.7978\n",
      "Epoch [115/500], Training Loss: 0.1455, Validation Loss: 0.6227, Training Accuracy: 0.9363, Validation Accuracy: 0.8315\n",
      "Epoch [116/500], Training Loss: 0.1406, Validation Loss: 0.7445, Training Accuracy: 0.9363, Validation Accuracy: 0.7753\n",
      "Epoch [117/500], Training Loss: 0.1396, Validation Loss: 0.8625, Training Accuracy: 0.9300, Validation Accuracy: 0.7865\n",
      "Epoch [118/500], Training Loss: 0.1799, Validation Loss: 0.8141, Training Accuracy: 0.9287, Validation Accuracy: 0.7865\n",
      "Epoch [119/500], Training Loss: 0.1712, Validation Loss: 2.8267, Training Accuracy: 0.9275, Validation Accuracy: 0.8090\n",
      "Epoch [120/500], Training Loss: 0.2189, Validation Loss: 0.4888, Training Accuracy: 0.9038, Validation Accuracy: 0.7978\n",
      "Epoch [121/500], Training Loss: 0.1954, Validation Loss: 1.7758, Training Accuracy: 0.9287, Validation Accuracy: 0.7753\n",
      "Epoch [122/500], Training Loss: 0.1874, Validation Loss: 0.7006, Training Accuracy: 0.9400, Validation Accuracy: 0.8090\n",
      "Epoch [123/500], Training Loss: 0.1931, Validation Loss: 0.6774, Training Accuracy: 0.9237, Validation Accuracy: 0.8090\n",
      "Epoch [124/500], Training Loss: 0.1683, Validation Loss: 0.8098, Training Accuracy: 0.9337, Validation Accuracy: 0.7978\n",
      "Epoch [125/500], Training Loss: 0.1679, Validation Loss: 0.6803, Training Accuracy: 0.9263, Validation Accuracy: 0.7978\n",
      "Epoch [126/500], Training Loss: 0.1739, Validation Loss: 0.6054, Training Accuracy: 0.9250, Validation Accuracy: 0.8315\n",
      "Epoch [127/500], Training Loss: 0.3726, Validation Loss: 0.5144, Training Accuracy: 0.8975, Validation Accuracy: 0.7865\n",
      "Epoch [128/500], Training Loss: 0.1808, Validation Loss: 0.7060, Training Accuracy: 0.9163, Validation Accuracy: 0.7865\n",
      "Epoch [129/500], Training Loss: 0.2109, Validation Loss: 0.6620, Training Accuracy: 0.9050, Validation Accuracy: 0.8315\n",
      "Epoch [130/500], Training Loss: 0.1686, Validation Loss: 0.4693, Training Accuracy: 0.9275, Validation Accuracy: 0.8539\n",
      "Epoch [131/500], Training Loss: 0.3182, Validation Loss: 0.4220, Training Accuracy: 0.9313, Validation Accuracy: 0.8427\n",
      "Epoch [132/500], Training Loss: 0.1952, Validation Loss: 0.6216, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [133/500], Training Loss: 0.1592, Validation Loss: 0.5576, Training Accuracy: 0.9275, Validation Accuracy: 0.8315\n",
      "Epoch [134/500], Training Loss: 0.1511, Validation Loss: 2.6388, Training Accuracy: 0.9500, Validation Accuracy: 0.7865\n",
      "Epoch [135/500], Training Loss: 0.1458, Validation Loss: 2.5536, Training Accuracy: 0.9263, Validation Accuracy: 0.8090\n",
      "Epoch [136/500], Training Loss: 0.1511, Validation Loss: 0.8211, Training Accuracy: 0.9400, Validation Accuracy: 0.7978\n",
      "Epoch [137/500], Training Loss: 0.1933, Validation Loss: 1.7989, Training Accuracy: 0.9275, Validation Accuracy: 0.7753\n",
      "Epoch [138/500], Training Loss: 0.1629, Validation Loss: 1.7407, Training Accuracy: 0.9337, Validation Accuracy: 0.8315\n",
      "Epoch [139/500], Training Loss: 0.1414, Validation Loss: 2.6123, Training Accuracy: 0.9500, Validation Accuracy: 0.8202\n",
      "Epoch [140/500], Training Loss: 0.1451, Validation Loss: 0.7336, Training Accuracy: 0.9387, Validation Accuracy: 0.8539\n",
      "Epoch [141/500], Training Loss: 0.1701, Validation Loss: 0.6823, Training Accuracy: 0.9300, Validation Accuracy: 0.8202\n",
      "Epoch [142/500], Training Loss: 0.1635, Validation Loss: 2.5417, Training Accuracy: 0.9300, Validation Accuracy: 0.8090\n",
      "Epoch [143/500], Training Loss: 0.1757, Validation Loss: 0.7425, Training Accuracy: 0.9337, Validation Accuracy: 0.8427\n",
      "Epoch [144/500], Training Loss: 0.1410, Validation Loss: 0.9276, Training Accuracy: 0.9425, Validation Accuracy: 0.8315\n",
      "Epoch [145/500], Training Loss: 0.1832, Validation Loss: 0.7067, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [146/500], Training Loss: 0.1671, Validation Loss: 1.6596, Training Accuracy: 0.9387, Validation Accuracy: 0.7978\n",
      "Epoch [147/500], Training Loss: 0.1338, Validation Loss: 1.7214, Training Accuracy: 0.9475, Validation Accuracy: 0.7640\n",
      "Epoch [148/500], Training Loss: 0.1500, Validation Loss: 0.6611, Training Accuracy: 0.9387, Validation Accuracy: 0.8090\n",
      "Epoch [149/500], Training Loss: 0.1824, Validation Loss: 1.6879, Training Accuracy: 0.9375, Validation Accuracy: 0.8539\n",
      "Epoch [150/500], Training Loss: 0.1786, Validation Loss: 1.6646, Training Accuracy: 0.9350, Validation Accuracy: 0.8315\n",
      "Epoch [151/500], Training Loss: 0.1663, Validation Loss: 0.8416, Training Accuracy: 0.9237, Validation Accuracy: 0.8202\n",
      "Epoch [152/500], Training Loss: 0.1487, Validation Loss: 2.7224, Training Accuracy: 0.9325, Validation Accuracy: 0.7978\n",
      "Epoch [153/500], Training Loss: 0.1743, Validation Loss: 0.7940, Training Accuracy: 0.9350, Validation Accuracy: 0.8202\n",
      "Epoch [154/500], Training Loss: 0.1561, Validation Loss: 0.6477, Training Accuracy: 0.9325, Validation Accuracy: 0.8202\n",
      "Epoch [155/500], Training Loss: 0.1838, Validation Loss: 0.8801, Training Accuracy: 0.9200, Validation Accuracy: 0.8090\n",
      "Epoch [156/500], Training Loss: 0.3374, Validation Loss: 0.5716, Training Accuracy: 0.9250, Validation Accuracy: 0.8090\n",
      "Epoch [157/500], Training Loss: 0.1558, Validation Loss: 1.7430, Training Accuracy: 0.9313, Validation Accuracy: 0.8427\n",
      "Epoch [158/500], Training Loss: 0.2130, Validation Loss: 0.6360, Training Accuracy: 0.9250, Validation Accuracy: 0.7753\n",
      "Epoch [159/500], Training Loss: 0.4058, Validation Loss: 0.8139, Training Accuracy: 0.9237, Validation Accuracy: 0.8090\n",
      "Epoch [160/500], Training Loss: 0.2012, Validation Loss: 0.4443, Training Accuracy: 0.9225, Validation Accuracy: 0.8315\n",
      "Epoch [161/500], Training Loss: 0.1846, Validation Loss: 0.5878, Training Accuracy: 0.9263, Validation Accuracy: 0.7978\n",
      "Epoch [162/500], Training Loss: 0.1672, Validation Loss: 0.8138, Training Accuracy: 0.9387, Validation Accuracy: 0.7978\n",
      "Epoch [163/500], Training Loss: 0.2009, Validation Loss: 0.7194, Training Accuracy: 0.9175, Validation Accuracy: 0.8427\n",
      "Epoch [164/500], Training Loss: 0.1327, Validation Loss: 0.8764, Training Accuracy: 0.9337, Validation Accuracy: 0.7978\n",
      "Epoch [165/500], Training Loss: 0.1480, Validation Loss: 0.6381, Training Accuracy: 0.9337, Validation Accuracy: 0.8539\n",
      "Epoch [166/500], Training Loss: 0.1887, Validation Loss: 0.5856, Training Accuracy: 0.9200, Validation Accuracy: 0.8090\n",
      "Epoch [167/500], Training Loss: 0.1458, Validation Loss: 0.7574, Training Accuracy: 0.9325, Validation Accuracy: 0.7978\n",
      "Epoch [168/500], Training Loss: 0.1324, Validation Loss: 2.6899, Training Accuracy: 0.9450, Validation Accuracy: 0.8315\n",
      "Epoch [169/500], Training Loss: 0.1290, Validation Loss: 0.9159, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [170/500], Training Loss: 0.1253, Validation Loss: 3.0846, Training Accuracy: 0.9537, Validation Accuracy: 0.7865\n",
      "Epoch [171/500], Training Loss: 0.2023, Validation Loss: 0.7639, Training Accuracy: 0.9237, Validation Accuracy: 0.7865\n",
      "Epoch [172/500], Training Loss: 0.2031, Validation Loss: 4.7342, Training Accuracy: 0.9275, Validation Accuracy: 0.7865\n",
      "Epoch [173/500], Training Loss: 0.3405, Validation Loss: 1.8363, Training Accuracy: 0.9125, Validation Accuracy: 0.7416\n",
      "Epoch [174/500], Training Loss: 0.1847, Validation Loss: 1.7789, Training Accuracy: 0.9213, Validation Accuracy: 0.7640\n",
      "Epoch [175/500], Training Loss: 0.1839, Validation Loss: 0.6133, Training Accuracy: 0.9187, Validation Accuracy: 0.7865\n",
      "Epoch [176/500], Training Loss: 0.1618, Validation Loss: 0.8612, Training Accuracy: 0.9400, Validation Accuracy: 0.7978\n",
      "Epoch [177/500], Training Loss: 0.1481, Validation Loss: 0.7521, Training Accuracy: 0.9487, Validation Accuracy: 0.8090\n",
      "Epoch [178/500], Training Loss: 0.3085, Validation Loss: 6.0020, Training Accuracy: 0.9350, Validation Accuracy: 0.8090\n",
      "Epoch [179/500], Training Loss: 0.4326, Validation Loss: 3.0486, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [180/500], Training Loss: 0.4678, Validation Loss: 1.0640, Training Accuracy: 0.9175, Validation Accuracy: 0.7753\n",
      "Epoch [181/500], Training Loss: 0.2834, Validation Loss: 0.7733, Training Accuracy: 0.9000, Validation Accuracy: 0.8202\n",
      "Epoch [182/500], Training Loss: 0.1876, Validation Loss: 1.8560, Training Accuracy: 0.9187, Validation Accuracy: 0.8090\n",
      "Epoch [183/500], Training Loss: 0.2257, Validation Loss: 2.8593, Training Accuracy: 0.9375, Validation Accuracy: 0.8090\n",
      "Epoch [184/500], Training Loss: 0.2109, Validation Loss: 0.7771, Training Accuracy: 0.9200, Validation Accuracy: 0.7865\n",
      "Epoch [185/500], Training Loss: 0.1369, Validation Loss: 1.9961, Training Accuracy: 0.9375, Validation Accuracy: 0.7978\n",
      "Epoch [186/500], Training Loss: 0.3395, Validation Loss: 1.8243, Training Accuracy: 0.9337, Validation Accuracy: 0.7978\n",
      "Epoch [187/500], Training Loss: 0.2489, Validation Loss: 0.5965, Training Accuracy: 0.9375, Validation Accuracy: 0.8315\n",
      "Epoch [188/500], Training Loss: 0.0987, Validation Loss: 2.0371, Training Accuracy: 0.9425, Validation Accuracy: 0.8090\n",
      "Epoch [189/500], Training Loss: 0.1856, Validation Loss: 0.8788, Training Accuracy: 0.9287, Validation Accuracy: 0.7528\n",
      "Epoch [190/500], Training Loss: 0.1477, Validation Loss: 0.7848, Training Accuracy: 0.9350, Validation Accuracy: 0.7640\n",
      "Epoch [191/500], Training Loss: 0.1546, Validation Loss: 0.7100, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [192/500], Training Loss: 0.1295, Validation Loss: 0.8836, Training Accuracy: 0.9437, Validation Accuracy: 0.7978\n",
      "Epoch [193/500], Training Loss: 0.1238, Validation Loss: 0.7760, Training Accuracy: 0.9500, Validation Accuracy: 0.8202\n",
      "Epoch [194/500], Training Loss: 0.1573, Validation Loss: 0.7071, Training Accuracy: 0.9425, Validation Accuracy: 0.7978\n",
      "Epoch [195/500], Training Loss: 0.1020, Validation Loss: 2.9285, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [196/500], Training Loss: 0.1074, Validation Loss: 3.7018, Training Accuracy: 0.9437, Validation Accuracy: 0.8090\n",
      "Epoch [197/500], Training Loss: 0.2293, Validation Loss: 2.7957, Training Accuracy: 0.9413, Validation Accuracy: 0.8090\n",
      "Epoch [198/500], Training Loss: 0.0921, Validation Loss: 0.7969, Training Accuracy: 0.9563, Validation Accuracy: 0.8202\n",
      "Epoch [199/500], Training Loss: 0.0730, Validation Loss: 3.8464, Training Accuracy: 0.9587, Validation Accuracy: 0.8090\n",
      "Epoch [200/500], Training Loss: 0.2037, Validation Loss: 2.8153, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [201/500], Training Loss: 0.2304, Validation Loss: 1.8283, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [202/500], Training Loss: 0.1142, Validation Loss: 0.7524, Training Accuracy: 0.9513, Validation Accuracy: 0.8315\n",
      "Epoch [203/500], Training Loss: 0.1252, Validation Loss: 4.7326, Training Accuracy: 0.9563, Validation Accuracy: 0.8315\n",
      "Epoch [204/500], Training Loss: 0.1785, Validation Loss: 0.4288, Training Accuracy: 0.9313, Validation Accuracy: 0.8202\n",
      "Epoch [205/500], Training Loss: 0.5354, Validation Loss: 5.4096, Training Accuracy: 0.9313, Validation Accuracy: 0.8202\n",
      "Epoch [206/500], Training Loss: 0.3817, Validation Loss: 7.8487, Training Accuracy: 0.9113, Validation Accuracy: 0.7528\n",
      "Epoch [207/500], Training Loss: 0.6369, Validation Loss: 0.8361, Training Accuracy: 0.9113, Validation Accuracy: 0.7753\n",
      "Epoch [208/500], Training Loss: 0.2449, Validation Loss: 1.7077, Training Accuracy: 0.8988, Validation Accuracy: 0.7978\n",
      "Epoch [209/500], Training Loss: 0.1944, Validation Loss: 1.8778, Training Accuracy: 0.9163, Validation Accuracy: 0.8090\n",
      "Epoch [210/500], Training Loss: 0.3373, Validation Loss: 0.9800, Training Accuracy: 0.9075, Validation Accuracy: 0.7753\n",
      "Epoch [211/500], Training Loss: 0.3170, Validation Loss: 0.8408, Training Accuracy: 0.9250, Validation Accuracy: 0.7753\n",
      "Epoch [212/500], Training Loss: 0.2439, Validation Loss: 0.6043, Training Accuracy: 0.9100, Validation Accuracy: 0.7978\n",
      "Epoch [213/500], Training Loss: 0.1859, Validation Loss: 0.6945, Training Accuracy: 0.9175, Validation Accuracy: 0.7978\n",
      "Epoch [214/500], Training Loss: 0.1552, Validation Loss: 0.8076, Training Accuracy: 0.9300, Validation Accuracy: 0.8090\n",
      "Epoch [215/500], Training Loss: 0.1671, Validation Loss: 0.6574, Training Accuracy: 0.9350, Validation Accuracy: 0.8427\n",
      "Epoch [216/500], Training Loss: 0.1575, Validation Loss: 0.6502, Training Accuracy: 0.9363, Validation Accuracy: 0.8315\n",
      "Epoch [217/500], Training Loss: 0.1676, Validation Loss: 0.6459, Training Accuracy: 0.9337, Validation Accuracy: 0.7978\n",
      "Epoch [218/500], Training Loss: 0.1829, Validation Loss: 0.5951, Training Accuracy: 0.9275, Validation Accuracy: 0.8427\n",
      "Epoch [219/500], Training Loss: 0.1781, Validation Loss: 0.5134, Training Accuracy: 0.9400, Validation Accuracy: 0.8090\n",
      "Epoch [220/500], Training Loss: 0.1942, Validation Loss: 0.6254, Training Accuracy: 0.9300, Validation Accuracy: 0.7528\n",
      "Epoch [221/500], Training Loss: 0.1421, Validation Loss: 0.6562, Training Accuracy: 0.9313, Validation Accuracy: 0.8090\n",
      "Epoch [222/500], Training Loss: 0.1323, Validation Loss: 0.5796, Training Accuracy: 0.9413, Validation Accuracy: 0.7978\n",
      "Epoch [223/500], Training Loss: 0.1123, Validation Loss: 1.6479, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [224/500], Training Loss: 0.2709, Validation Loss: 1.7022, Training Accuracy: 0.9387, Validation Accuracy: 0.7978\n",
      "Epoch [225/500], Training Loss: 0.0984, Validation Loss: 2.6138, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [226/500], Training Loss: 0.1041, Validation Loss: 2.6607, Training Accuracy: 0.9625, Validation Accuracy: 0.7753\n",
      "Epoch [227/500], Training Loss: 0.1475, Validation Loss: 1.6696, Training Accuracy: 0.9437, Validation Accuracy: 0.7753\n",
      "Epoch [228/500], Training Loss: 0.1396, Validation Loss: 2.7241, Training Accuracy: 0.9600, Validation Accuracy: 0.7416\n",
      "Epoch [229/500], Training Loss: 0.1671, Validation Loss: 1.4359, Training Accuracy: 0.9375, Validation Accuracy: 0.7978\n",
      "Epoch [230/500], Training Loss: 0.1055, Validation Loss: 1.6218, Training Accuracy: 0.9525, Validation Accuracy: 0.7528\n",
      "Epoch [231/500], Training Loss: 0.1388, Validation Loss: 1.6930, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [232/500], Training Loss: 0.1376, Validation Loss: 1.4883, Training Accuracy: 0.9425, Validation Accuracy: 0.7640\n",
      "Epoch [233/500], Training Loss: 0.1084, Validation Loss: 1.5757, Training Accuracy: 0.9525, Validation Accuracy: 0.7753\n",
      "Epoch [234/500], Training Loss: 0.1305, Validation Loss: 1.6194, Training Accuracy: 0.9525, Validation Accuracy: 0.7640\n",
      "Epoch [235/500], Training Loss: 0.1190, Validation Loss: 1.7450, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [236/500], Training Loss: 0.1301, Validation Loss: 0.6550, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [237/500], Training Loss: 0.1058, Validation Loss: 0.6734, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [238/500], Training Loss: 0.0948, Validation Loss: 1.5508, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [239/500], Training Loss: 0.1064, Validation Loss: 1.6112, Training Accuracy: 0.9613, Validation Accuracy: 0.8090\n",
      "Epoch [240/500], Training Loss: 0.1204, Validation Loss: 2.8223, Training Accuracy: 0.9563, Validation Accuracy: 0.7753\n",
      "Epoch [241/500], Training Loss: 0.1432, Validation Loss: 2.8314, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [242/500], Training Loss: 0.1077, Validation Loss: 1.5957, Training Accuracy: 0.9575, Validation Accuracy: 0.8202\n",
      "Epoch [243/500], Training Loss: 0.1177, Validation Loss: 1.7040, Training Accuracy: 0.9513, Validation Accuracy: 0.7978\n",
      "Epoch [244/500], Training Loss: 0.1403, Validation Loss: 1.6594, Training Accuracy: 0.9475, Validation Accuracy: 0.8202\n",
      "Epoch [245/500], Training Loss: 0.1210, Validation Loss: 2.5772, Training Accuracy: 0.9513, Validation Accuracy: 0.7978\n",
      "Epoch [246/500], Training Loss: 0.1128, Validation Loss: 4.6372, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [247/500], Training Loss: 0.3421, Validation Loss: 2.5558, Training Accuracy: 0.9300, Validation Accuracy: 0.7640\n",
      "Epoch [248/500], Training Loss: 0.4515, Validation Loss: 1.4799, Training Accuracy: 0.9125, Validation Accuracy: 0.8315\n",
      "Epoch [249/500], Training Loss: 0.4365, Validation Loss: 3.6747, Training Accuracy: 0.9375, Validation Accuracy: 0.8090\n",
      "Epoch [250/500], Training Loss: 0.5159, Validation Loss: 1.7010, Training Accuracy: 0.9425, Validation Accuracy: 0.7753\n",
      "Epoch [251/500], Training Loss: 0.5039, Validation Loss: 2.7938, Training Accuracy: 0.9425, Validation Accuracy: 0.7865\n",
      "Epoch [252/500], Training Loss: 0.2182, Validation Loss: 2.8880, Training Accuracy: 0.9250, Validation Accuracy: 0.7865\n",
      "Epoch [253/500], Training Loss: 0.2224, Validation Loss: 2.5742, Training Accuracy: 0.9137, Validation Accuracy: 0.8090\n",
      "Epoch [254/500], Training Loss: 0.1515, Validation Loss: 3.7152, Training Accuracy: 0.9387, Validation Accuracy: 0.7865\n",
      "Epoch [255/500], Training Loss: 0.1330, Validation Loss: 1.7720, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [256/500], Training Loss: 0.1341, Validation Loss: 3.6524, Training Accuracy: 0.9437, Validation Accuracy: 0.8090\n",
      "Epoch [257/500], Training Loss: 0.1247, Validation Loss: 4.6788, Training Accuracy: 0.9413, Validation Accuracy: 0.8202\n",
      "Epoch [258/500], Training Loss: 0.1493, Validation Loss: 3.6843, Training Accuracy: 0.9500, Validation Accuracy: 0.8202\n",
      "Epoch [259/500], Training Loss: 0.2599, Validation Loss: 1.7691, Training Accuracy: 0.9450, Validation Accuracy: 0.8090\n",
      "Epoch [260/500], Training Loss: 0.1064, Validation Loss: 1.7767, Training Accuracy: 0.9563, Validation Accuracy: 0.7640\n",
      "Epoch [261/500], Training Loss: 0.1256, Validation Loss: 1.5744, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [262/500], Training Loss: 0.1414, Validation Loss: 1.8373, Training Accuracy: 0.9363, Validation Accuracy: 0.7978\n",
      "Epoch [263/500], Training Loss: 0.1313, Validation Loss: 1.9642, Training Accuracy: 0.9525, Validation Accuracy: 0.8090\n",
      "Epoch [264/500], Training Loss: 0.1409, Validation Loss: 2.7878, Training Accuracy: 0.9487, Validation Accuracy: 0.8202\n",
      "Epoch [265/500], Training Loss: 0.1474, Validation Loss: 0.6180, Training Accuracy: 0.9487, Validation Accuracy: 0.8090\n",
      "Epoch [266/500], Training Loss: 0.1251, Validation Loss: 4.7421, Training Accuracy: 0.9575, Validation Accuracy: 0.8090\n",
      "Epoch [267/500], Training Loss: 0.1295, Validation Loss: 2.6512, Training Accuracy: 0.9513, Validation Accuracy: 0.8090\n",
      "Epoch [268/500], Training Loss: 0.1364, Validation Loss: 1.8852, Training Accuracy: 0.9437, Validation Accuracy: 0.7978\n",
      "Epoch [269/500], Training Loss: 0.1118, Validation Loss: 4.7936, Training Accuracy: 0.9513, Validation Accuracy: 0.8427\n",
      "Epoch [270/500], Training Loss: 0.1458, Validation Loss: 2.9761, Training Accuracy: 0.9437, Validation Accuracy: 0.8202\n",
      "Epoch [271/500], Training Loss: 0.1248, Validation Loss: 2.6312, Training Accuracy: 0.9500, Validation Accuracy: 0.8090\n",
      "Epoch [272/500], Training Loss: 0.1010, Validation Loss: 1.8991, Training Accuracy: 0.9613, Validation Accuracy: 0.8315\n",
      "Epoch [273/500], Training Loss: 0.2845, Validation Loss: 1.9151, Training Accuracy: 0.9163, Validation Accuracy: 0.7640\n",
      "Epoch [274/500], Training Loss: 0.1630, Validation Loss: 1.7234, Training Accuracy: 0.9287, Validation Accuracy: 0.8090\n",
      "Epoch [275/500], Training Loss: 0.1336, Validation Loss: 1.9711, Training Accuracy: 0.9487, Validation Accuracy: 0.8090\n",
      "Epoch [276/500], Training Loss: 0.1133, Validation Loss: 1.9061, Training Accuracy: 0.9475, Validation Accuracy: 0.8090\n",
      "Epoch [277/500], Training Loss: 0.1275, Validation Loss: 4.7005, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [278/500], Training Loss: 0.1037, Validation Loss: 6.5488, Training Accuracy: 0.9587, Validation Accuracy: 0.8090\n",
      "Epoch [279/500], Training Loss: 0.1270, Validation Loss: 3.9088, Training Accuracy: 0.9487, Validation Accuracy: 0.8202\n",
      "Epoch [280/500], Training Loss: 0.1366, Validation Loss: 3.8505, Training Accuracy: 0.9513, Validation Accuracy: 0.8202\n",
      "Epoch [281/500], Training Loss: 0.1714, Validation Loss: 3.7307, Training Accuracy: 0.9337, Validation Accuracy: 0.8539\n",
      "Epoch [282/500], Training Loss: 0.1408, Validation Loss: 4.6231, Training Accuracy: 0.9325, Validation Accuracy: 0.8202\n",
      "Epoch [283/500], Training Loss: 0.1259, Validation Loss: 6.5015, Training Accuracy: 0.9563, Validation Accuracy: 0.8315\n",
      "Epoch [284/500], Training Loss: 0.5201, Validation Loss: 2.8293, Training Accuracy: 0.9375, Validation Accuracy: 0.8315\n",
      "Epoch [285/500], Training Loss: 0.5061, Validation Loss: 0.6803, Training Accuracy: 0.9237, Validation Accuracy: 0.8202\n",
      "Epoch [286/500], Training Loss: 0.2138, Validation Loss: 2.6175, Training Accuracy: 0.9287, Validation Accuracy: 0.8315\n",
      "Epoch [287/500], Training Loss: 0.2791, Validation Loss: 3.4532, Training Accuracy: 0.9313, Validation Accuracy: 0.8090\n",
      "Epoch [288/500], Training Loss: 0.3146, Validation Loss: 2.8298, Training Accuracy: 0.9287, Validation Accuracy: 0.8315\n",
      "Epoch [289/500], Training Loss: 0.2340, Validation Loss: 2.7553, Training Accuracy: 0.9050, Validation Accuracy: 0.7753\n",
      "Epoch [290/500], Training Loss: 0.2659, Validation Loss: 3.5120, Training Accuracy: 0.9337, Validation Accuracy: 0.7978\n",
      "Epoch [291/500], Training Loss: 0.2869, Validation Loss: 1.6826, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [292/500], Training Loss: 0.5505, Validation Loss: 2.8878, Training Accuracy: 0.9125, Validation Accuracy: 0.7865\n",
      "Epoch [293/500], Training Loss: 0.1135, Validation Loss: 4.7058, Training Accuracy: 0.9437, Validation Accuracy: 0.8427\n",
      "Epoch [294/500], Training Loss: 0.4915, Validation Loss: 1.7112, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [295/500], Training Loss: 0.2681, Validation Loss: 2.5884, Training Accuracy: 0.9475, Validation Accuracy: 0.8202\n",
      "Epoch [296/500], Training Loss: 0.2224, Validation Loss: 3.5991, Training Accuracy: 0.9600, Validation Accuracy: 0.7865\n",
      "Epoch [297/500], Training Loss: 0.2559, Validation Loss: 2.6547, Training Accuracy: 0.9425, Validation Accuracy: 0.7865\n",
      "Epoch [298/500], Training Loss: 0.2314, Validation Loss: 2.6844, Training Accuracy: 0.9525, Validation Accuracy: 0.7865\n",
      "Epoch [299/500], Training Loss: 0.2379, Validation Loss: 1.8675, Training Accuracy: 0.9550, Validation Accuracy: 0.7865\n",
      "Epoch [300/500], Training Loss: 0.1488, Validation Loss: 2.6762, Training Accuracy: 0.9550, Validation Accuracy: 0.7640\n",
      "Epoch [301/500], Training Loss: 0.1222, Validation Loss: 2.6132, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [302/500], Training Loss: 0.0897, Validation Loss: 2.8055, Training Accuracy: 0.9675, Validation Accuracy: 0.7978\n",
      "Epoch [303/500], Training Loss: 0.0944, Validation Loss: 1.9161, Training Accuracy: 0.9675, Validation Accuracy: 0.7978\n",
      "Epoch [304/500], Training Loss: 0.1193, Validation Loss: 2.6469, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [305/500], Training Loss: 0.0966, Validation Loss: 0.8754, Training Accuracy: 0.9613, Validation Accuracy: 0.8090\n",
      "Epoch [306/500], Training Loss: 0.1115, Validation Loss: 0.5578, Training Accuracy: 0.9587, Validation Accuracy: 0.7865\n",
      "Epoch [307/500], Training Loss: 0.0964, Validation Loss: 0.8441, Training Accuracy: 0.9625, Validation Accuracy: 0.7640\n",
      "Epoch [308/500], Training Loss: 0.1941, Validation Loss: 2.8909, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [309/500], Training Loss: 0.1051, Validation Loss: 2.7488, Training Accuracy: 0.9600, Validation Accuracy: 0.8090\n",
      "Epoch [310/500], Training Loss: 0.1224, Validation Loss: 1.7226, Training Accuracy: 0.9688, Validation Accuracy: 0.8315\n",
      "Epoch [311/500], Training Loss: 0.2705, Validation Loss: 1.9157, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [312/500], Training Loss: 0.1730, Validation Loss: 3.0528, Training Accuracy: 0.9650, Validation Accuracy: 0.7865\n",
      "Epoch [313/500], Training Loss: 0.1215, Validation Loss: 1.8612, Training Accuracy: 0.9550, Validation Accuracy: 0.7753\n",
      "Epoch [314/500], Training Loss: 0.1520, Validation Loss: 1.8296, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [315/500], Training Loss: 0.1297, Validation Loss: 1.7072, Training Accuracy: 0.9563, Validation Accuracy: 0.8202\n",
      "Epoch [316/500], Training Loss: 0.0930, Validation Loss: 0.9030, Training Accuracy: 0.9575, Validation Accuracy: 0.8090\n",
      "Epoch [317/500], Training Loss: 0.1029, Validation Loss: 3.8341, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [318/500], Training Loss: 0.0713, Validation Loss: 3.8421, Training Accuracy: 0.9738, Validation Accuracy: 0.8202\n",
      "Epoch [319/500], Training Loss: 0.0726, Validation Loss: 3.8818, Training Accuracy: 0.9725, Validation Accuracy: 0.8202\n",
      "Epoch [320/500], Training Loss: 0.2763, Validation Loss: 3.5996, Training Accuracy: 0.9575, Validation Accuracy: 0.7753\n",
      "Epoch [321/500], Training Loss: 0.0861, Validation Loss: 3.7783, Training Accuracy: 0.9637, Validation Accuracy: 0.7640\n",
      "Epoch [322/500], Training Loss: 0.4019, Validation Loss: 2.5949, Training Accuracy: 0.9575, Validation Accuracy: 0.6966\n",
      "Epoch [323/500], Training Loss: 0.1295, Validation Loss: 2.7105, Training Accuracy: 0.9487, Validation Accuracy: 0.7865\n",
      "Epoch [324/500], Training Loss: 0.2309, Validation Loss: 0.9600, Training Accuracy: 0.9550, Validation Accuracy: 0.7753\n",
      "Epoch [325/500], Training Loss: 0.2198, Validation Loss: 2.1152, Training Accuracy: 0.9613, Validation Accuracy: 0.7753\n",
      "Epoch [326/500], Training Loss: 0.2162, Validation Loss: 4.6149, Training Accuracy: 0.9600, Validation Accuracy: 0.7753\n",
      "Epoch [327/500], Training Loss: 0.1374, Validation Loss: 2.6384, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [328/500], Training Loss: 0.1369, Validation Loss: 0.7153, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [329/500], Training Loss: 0.1006, Validation Loss: 1.8221, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [330/500], Training Loss: 0.0782, Validation Loss: 4.6397, Training Accuracy: 0.9738, Validation Accuracy: 0.8202\n",
      "Epoch [331/500], Training Loss: 0.4102, Validation Loss: 5.7338, Training Accuracy: 0.9563, Validation Accuracy: 0.8090\n",
      "Epoch [332/500], Training Loss: 0.2688, Validation Loss: 2.9628, Training Accuracy: 0.9475, Validation Accuracy: 0.7753\n",
      "Epoch [333/500], Training Loss: 0.2648, Validation Loss: 5.7411, Training Accuracy: 0.9350, Validation Accuracy: 0.7640\n",
      "Epoch [334/500], Training Loss: 0.2907, Validation Loss: 5.0577, Training Accuracy: 0.9513, Validation Accuracy: 0.7640\n",
      "Epoch [335/500], Training Loss: 0.1433, Validation Loss: 7.6810, Training Accuracy: 0.9450, Validation Accuracy: 0.7416\n",
      "Epoch [336/500], Training Loss: 0.1842, Validation Loss: 3.8458, Training Accuracy: 0.9325, Validation Accuracy: 0.7753\n",
      "Epoch [337/500], Training Loss: 0.1565, Validation Loss: 3.7456, Training Accuracy: 0.9250, Validation Accuracy: 0.7978\n",
      "Epoch [338/500], Training Loss: 0.2315, Validation Loss: 5.8467, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [339/500], Training Loss: 0.4133, Validation Loss: 3.6563, Training Accuracy: 0.9275, Validation Accuracy: 0.8202\n",
      "Epoch [340/500], Training Loss: 0.2772, Validation Loss: 5.5995, Training Accuracy: 0.9187, Validation Accuracy: 0.8202\n",
      "Epoch [341/500], Training Loss: 0.1520, Validation Loss: 5.7140, Training Accuracy: 0.9300, Validation Accuracy: 0.8202\n",
      "Epoch [342/500], Training Loss: 0.7596, Validation Loss: 5.7713, Training Accuracy: 0.9437, Validation Accuracy: 0.8202\n",
      "Epoch [343/500], Training Loss: 0.4631, Validation Loss: 2.7576, Training Accuracy: 0.9125, Validation Accuracy: 0.7865\n",
      "Epoch [344/500], Training Loss: 0.4146, Validation Loss: 0.8163, Training Accuracy: 0.9363, Validation Accuracy: 0.7865\n",
      "Epoch [345/500], Training Loss: 0.2265, Validation Loss: 0.8552, Training Accuracy: 0.9250, Validation Accuracy: 0.7753\n",
      "Epoch [346/500], Training Loss: 0.2804, Validation Loss: 3.7613, Training Accuracy: 0.9150, Validation Accuracy: 0.7640\n",
      "Epoch [347/500], Training Loss: 0.2385, Validation Loss: 3.7017, Training Accuracy: 0.9313, Validation Accuracy: 0.7865\n",
      "Epoch [348/500], Training Loss: 0.3005, Validation Loss: 4.6228, Training Accuracy: 0.9237, Validation Accuracy: 0.7865\n",
      "Epoch [349/500], Training Loss: 0.1495, Validation Loss: 2.8774, Training Accuracy: 0.9375, Validation Accuracy: 0.7640\n",
      "Epoch [350/500], Training Loss: 0.2552, Validation Loss: 3.7555, Training Accuracy: 0.9363, Validation Accuracy: 0.7978\n",
      "Epoch [351/500], Training Loss: 0.3990, Validation Loss: 3.5128, Training Accuracy: 0.9463, Validation Accuracy: 0.8090\n",
      "Epoch [352/500], Training Loss: 0.1620, Validation Loss: 2.9960, Training Accuracy: 0.9363, Validation Accuracy: 0.7303\n",
      "Epoch [353/500], Training Loss: 0.1438, Validation Loss: 2.7178, Training Accuracy: 0.9387, Validation Accuracy: 0.8202\n",
      "Epoch [354/500], Training Loss: 0.2648, Validation Loss: 4.6609, Training Accuracy: 0.9437, Validation Accuracy: 0.8090\n",
      "Epoch [355/500], Training Loss: 0.1139, Validation Loss: 1.9213, Training Accuracy: 0.9625, Validation Accuracy: 0.7978\n",
      "Epoch [356/500], Training Loss: 0.3248, Validation Loss: 5.5943, Training Accuracy: 0.9537, Validation Accuracy: 0.7865\n",
      "Epoch [357/500], Training Loss: 0.2629, Validation Loss: 4.6672, Training Accuracy: 0.9413, Validation Accuracy: 0.7865\n",
      "Epoch [358/500], Training Loss: 0.1826, Validation Loss: 3.7304, Training Accuracy: 0.9513, Validation Accuracy: 0.8090\n",
      "Epoch [359/500], Training Loss: 0.1050, Validation Loss: 4.5988, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [360/500], Training Loss: 0.1206, Validation Loss: 3.8509, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [361/500], Training Loss: 0.1291, Validation Loss: 3.8373, Training Accuracy: 0.9537, Validation Accuracy: 0.8090\n",
      "Epoch [362/500], Training Loss: 0.1577, Validation Loss: 2.6565, Training Accuracy: 0.9537, Validation Accuracy: 0.8090\n",
      "Epoch [363/500], Training Loss: 0.3418, Validation Loss: 2.5507, Training Accuracy: 0.9437, Validation Accuracy: 0.8090\n",
      "Epoch [364/500], Training Loss: 0.1675, Validation Loss: 2.6719, Training Accuracy: 0.9387, Validation Accuracy: 0.8090\n",
      "Epoch [365/500], Training Loss: 0.3959, Validation Loss: 2.7265, Training Accuracy: 0.9425, Validation Accuracy: 0.8090\n",
      "Epoch [366/500], Training Loss: 0.2218, Validation Loss: 2.8192, Training Accuracy: 0.9563, Validation Accuracy: 0.7865\n",
      "Epoch [367/500], Training Loss: 0.0927, Validation Loss: 3.0245, Training Accuracy: 0.9613, Validation Accuracy: 0.7865\n",
      "Epoch [368/500], Training Loss: 0.0809, Validation Loss: 3.9276, Training Accuracy: 0.9663, Validation Accuracy: 0.8090\n",
      "Epoch [369/500], Training Loss: 0.0666, Validation Loss: 3.9479, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [370/500], Training Loss: 0.0891, Validation Loss: 2.8666, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [371/500], Training Loss: 0.0914, Validation Loss: 3.0417, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [372/500], Training Loss: 0.0918, Validation Loss: 3.9079, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [373/500], Training Loss: 0.1129, Validation Loss: 2.8915, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [374/500], Training Loss: 0.1179, Validation Loss: 1.8708, Training Accuracy: 0.9487, Validation Accuracy: 0.8090\n",
      "Epoch [375/500], Training Loss: 0.0871, Validation Loss: 3.1145, Training Accuracy: 0.9688, Validation Accuracy: 0.7640\n",
      "Epoch [376/500], Training Loss: 0.0903, Validation Loss: 3.2112, Training Accuracy: 0.9613, Validation Accuracy: 0.7865\n",
      "Epoch [377/500], Training Loss: 0.1449, Validation Loss: 5.8376, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [378/500], Training Loss: 0.0924, Validation Loss: 1.9095, Training Accuracy: 0.9613, Validation Accuracy: 0.8090\n",
      "Epoch [379/500], Training Loss: 0.1161, Validation Loss: 4.7085, Training Accuracy: 0.9600, Validation Accuracy: 0.8202\n",
      "Epoch [380/500], Training Loss: 0.1767, Validation Loss: 4.7538, Training Accuracy: 0.9400, Validation Accuracy: 0.8090\n",
      "Epoch [381/500], Training Loss: 0.3249, Validation Loss: 3.5099, Training Accuracy: 0.9413, Validation Accuracy: 0.8202\n",
      "Epoch [382/500], Training Loss: 0.1441, Validation Loss: 3.0227, Training Accuracy: 0.9487, Validation Accuracy: 0.8202\n",
      "Epoch [383/500], Training Loss: 0.1189, Validation Loss: 3.8671, Training Accuracy: 0.9537, Validation Accuracy: 0.8202\n",
      "Epoch [384/500], Training Loss: 0.1271, Validation Loss: 4.7502, Training Accuracy: 0.9513, Validation Accuracy: 0.8202\n",
      "Epoch [385/500], Training Loss: 0.1287, Validation Loss: 3.9482, Training Accuracy: 0.9587, Validation Accuracy: 0.8090\n",
      "Epoch [386/500], Training Loss: 0.1203, Validation Loss: 5.6674, Training Accuracy: 0.9475, Validation Accuracy: 0.8202\n",
      "Epoch [387/500], Training Loss: 0.1826, Validation Loss: 5.7661, Training Accuracy: 0.9350, Validation Accuracy: 0.7753\n",
      "Epoch [388/500], Training Loss: 0.1000, Validation Loss: 5.7855, Training Accuracy: 0.9587, Validation Accuracy: 0.7865\n",
      "Epoch [389/500], Training Loss: 0.1286, Validation Loss: 4.9409, Training Accuracy: 0.9613, Validation Accuracy: 0.8090\n",
      "Epoch [390/500], Training Loss: 0.1113, Validation Loss: 4.2755, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [391/500], Training Loss: 0.0985, Validation Loss: 3.0861, Training Accuracy: 0.9537, Validation Accuracy: 0.7978\n",
      "Epoch [392/500], Training Loss: 0.1215, Validation Loss: 3.9868, Training Accuracy: 0.9413, Validation Accuracy: 0.8427\n",
      "Epoch [393/500], Training Loss: 0.1917, Validation Loss: 6.0961, Training Accuracy: 0.9575, Validation Accuracy: 0.8202\n",
      "Epoch [394/500], Training Loss: 0.1020, Validation Loss: 4.1257, Training Accuracy: 0.9637, Validation Accuracy: 0.8202\n",
      "Epoch [395/500], Training Loss: 0.2156, Validation Loss: 3.9814, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [396/500], Training Loss: 0.2434, Validation Loss: 6.4837, Training Accuracy: 0.9563, Validation Accuracy: 0.8090\n",
      "Epoch [397/500], Training Loss: 0.4180, Validation Loss: 3.7801, Training Accuracy: 0.9450, Validation Accuracy: 0.7978\n",
      "Epoch [398/500], Training Loss: 0.2065, Validation Loss: 2.9902, Training Accuracy: 0.9237, Validation Accuracy: 0.7978\n",
      "Epoch [399/500], Training Loss: 0.2976, Validation Loss: 1.6480, Training Accuracy: 0.9363, Validation Accuracy: 0.7865\n",
      "Epoch [400/500], Training Loss: 0.1725, Validation Loss: 1.8531, Training Accuracy: 0.9437, Validation Accuracy: 0.7753\n",
      "Epoch [401/500], Training Loss: 0.0945, Validation Loss: 2.9216, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [402/500], Training Loss: 0.2094, Validation Loss: 5.8967, Training Accuracy: 0.9613, Validation Accuracy: 0.7640\n",
      "Epoch [403/500], Training Loss: 0.1133, Validation Loss: 5.2109, Training Accuracy: 0.9513, Validation Accuracy: 0.7978\n",
      "Epoch [404/500], Training Loss: 0.2489, Validation Loss: 1.7475, Training Accuracy: 0.9563, Validation Accuracy: 0.8090\n",
      "Epoch [405/500], Training Loss: 0.1090, Validation Loss: 2.9923, Training Accuracy: 0.9625, Validation Accuracy: 0.8202\n",
      "Epoch [406/500], Training Loss: 0.0925, Validation Loss: 3.1849, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [407/500], Training Loss: 0.1181, Validation Loss: 2.8083, Training Accuracy: 0.9513, Validation Accuracy: 0.7978\n",
      "Epoch [408/500], Training Loss: 0.1231, Validation Loss: 4.0123, Training Accuracy: 0.9537, Validation Accuracy: 0.8090\n",
      "Epoch [409/500], Training Loss: 0.2668, Validation Loss: 1.8074, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [410/500], Training Loss: 0.1018, Validation Loss: 1.9233, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [411/500], Training Loss: 0.1197, Validation Loss: 2.7534, Training Accuracy: 0.9563, Validation Accuracy: 0.7865\n",
      "Epoch [412/500], Training Loss: 0.0827, Validation Loss: 5.8484, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [413/500], Training Loss: 0.0800, Validation Loss: 3.7602, Training Accuracy: 0.9663, Validation Accuracy: 0.7753\n",
      "Epoch [414/500], Training Loss: 0.1146, Validation Loss: 2.7551, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [415/500], Training Loss: 0.2185, Validation Loss: 3.8804, Training Accuracy: 0.9625, Validation Accuracy: 0.7978\n",
      "Epoch [416/500], Training Loss: 0.0798, Validation Loss: 3.9632, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [417/500], Training Loss: 0.0937, Validation Loss: 3.7310, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [418/500], Training Loss: 0.0776, Validation Loss: 4.8662, Training Accuracy: 0.9663, Validation Accuracy: 0.7865\n",
      "Epoch [419/500], Training Loss: 0.0672, Validation Loss: 5.8854, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [420/500], Training Loss: 0.0797, Validation Loss: 4.8936, Training Accuracy: 0.9712, Validation Accuracy: 0.7753\n",
      "Epoch [421/500], Training Loss: 0.0862, Validation Loss: 4.5024, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [422/500], Training Loss: 0.2260, Validation Loss: 4.0658, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [423/500], Training Loss: 0.1367, Validation Loss: 5.8541, Training Accuracy: 0.9587, Validation Accuracy: 0.7640\n",
      "Epoch [424/500], Training Loss: 0.2900, Validation Loss: 4.7124, Training Accuracy: 0.9475, Validation Accuracy: 0.7865\n",
      "Epoch [425/500], Training Loss: 0.1214, Validation Loss: 2.7870, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [426/500], Training Loss: 0.1221, Validation Loss: 2.7297, Training Accuracy: 0.9437, Validation Accuracy: 0.7753\n",
      "Epoch [427/500], Training Loss: 0.1186, Validation Loss: 2.8743, Training Accuracy: 0.9587, Validation Accuracy: 0.7753\n",
      "Epoch [428/500], Training Loss: 0.2175, Validation Loss: 2.7350, Training Accuracy: 0.9725, Validation Accuracy: 0.8090\n",
      "Epoch [429/500], Training Loss: 0.1537, Validation Loss: 1.6419, Training Accuracy: 0.9513, Validation Accuracy: 0.7640\n",
      "Epoch [430/500], Training Loss: 0.2126, Validation Loss: 1.8871, Training Accuracy: 0.9688, Validation Accuracy: 0.8090\n",
      "Epoch [431/500], Training Loss: 0.1186, Validation Loss: 3.8194, Training Accuracy: 0.9587, Validation Accuracy: 0.8090\n",
      "Epoch [432/500], Training Loss: 0.1240, Validation Loss: 2.8265, Training Accuracy: 0.9500, Validation Accuracy: 0.8202\n",
      "Epoch [433/500], Training Loss: 0.1081, Validation Loss: 3.7795, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [434/500], Training Loss: 0.1459, Validation Loss: 2.7378, Training Accuracy: 0.9537, Validation Accuracy: 0.7978\n",
      "Epoch [435/500], Training Loss: 0.1778, Validation Loss: 2.6544, Training Accuracy: 0.9375, Validation Accuracy: 0.7978\n",
      "Epoch [436/500], Training Loss: 0.1617, Validation Loss: 3.6914, Training Accuracy: 0.9425, Validation Accuracy: 0.8090\n",
      "Epoch [437/500], Training Loss: 0.1822, Validation Loss: 4.7368, Training Accuracy: 0.9463, Validation Accuracy: 0.8202\n",
      "Epoch [438/500], Training Loss: 0.1673, Validation Loss: 3.9799, Training Accuracy: 0.9513, Validation Accuracy: 0.7640\n",
      "Epoch [439/500], Training Loss: 0.2808, Validation Loss: 5.0835, Training Accuracy: 0.9500, Validation Accuracy: 0.7753\n",
      "Epoch [440/500], Training Loss: 0.1538, Validation Loss: 4.8005, Training Accuracy: 0.9437, Validation Accuracy: 0.7753\n",
      "Epoch [441/500], Training Loss: 0.1351, Validation Loss: 4.0744, Training Accuracy: 0.9413, Validation Accuracy: 0.8090\n",
      "Epoch [442/500], Training Loss: 0.3472, Validation Loss: 4.1716, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [443/500], Training Loss: 0.1122, Validation Loss: 4.1803, Training Accuracy: 0.9587, Validation Accuracy: 0.8090\n",
      "Epoch [444/500], Training Loss: 0.1330, Validation Loss: 5.8122, Training Accuracy: 0.9450, Validation Accuracy: 0.7865\n",
      "Epoch [445/500], Training Loss: 0.1028, Validation Loss: 3.8760, Training Accuracy: 0.9587, Validation Accuracy: 0.7753\n",
      "Epoch [446/500], Training Loss: 0.1324, Validation Loss: 3.3362, Training Accuracy: 0.9600, Validation Accuracy: 0.7753\n",
      "Epoch [447/500], Training Loss: 0.3312, Validation Loss: 1.9759, Training Accuracy: 0.9375, Validation Accuracy: 0.7753\n",
      "Epoch [448/500], Training Loss: 0.2453, Validation Loss: 4.8368, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [449/500], Training Loss: 0.2358, Validation Loss: 3.1228, Training Accuracy: 0.9575, Validation Accuracy: 0.8202\n",
      "Epoch [450/500], Training Loss: 0.1565, Validation Loss: 2.0880, Training Accuracy: 0.9575, Validation Accuracy: 0.8202\n",
      "Epoch [451/500], Training Loss: 0.1032, Validation Loss: 4.0514, Training Accuracy: 0.9637, Validation Accuracy: 0.8315\n",
      "Epoch [452/500], Training Loss: 0.1674, Validation Loss: 4.0511, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [453/500], Training Loss: 0.1428, Validation Loss: 2.9144, Training Accuracy: 0.9425, Validation Accuracy: 0.8202\n",
      "Epoch [454/500], Training Loss: 0.2568, Validation Loss: 2.9054, Training Accuracy: 0.9487, Validation Accuracy: 0.8202\n",
      "Epoch [455/500], Training Loss: 0.2411, Validation Loss: 4.8197, Training Accuracy: 0.9513, Validation Accuracy: 0.8090\n",
      "Epoch [456/500], Training Loss: 0.0958, Validation Loss: 4.2012, Training Accuracy: 0.9563, Validation Accuracy: 0.8202\n",
      "Epoch [457/500], Training Loss: 0.1998, Validation Loss: 4.7505, Training Accuracy: 0.9563, Validation Accuracy: 0.7865\n",
      "Epoch [458/500], Training Loss: 0.1453, Validation Loss: 2.8378, Training Accuracy: 0.9525, Validation Accuracy: 0.8090\n",
      "Epoch [459/500], Training Loss: 0.1205, Validation Loss: 4.7608, Training Accuracy: 0.9463, Validation Accuracy: 0.8202\n",
      "Epoch [460/500], Training Loss: 0.1197, Validation Loss: 3.7967, Training Accuracy: 0.9587, Validation Accuracy: 0.8202\n",
      "Epoch [461/500], Training Loss: 0.3891, Validation Loss: 0.9051, Training Accuracy: 0.9487, Validation Accuracy: 0.8202\n",
      "Epoch [462/500], Training Loss: 0.6179, Validation Loss: 2.7732, Training Accuracy: 0.9363, Validation Accuracy: 0.8090\n",
      "Epoch [463/500], Training Loss: 0.5224, Validation Loss: 1.8146, Training Accuracy: 0.9513, Validation Accuracy: 0.8315\n",
      "Epoch [464/500], Training Loss: 0.2347, Validation Loss: 3.5448, Training Accuracy: 0.9525, Validation Accuracy: 0.8427\n",
      "Epoch [465/500], Training Loss: 0.5856, Validation Loss: 3.7281, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [466/500], Training Loss: 0.3243, Validation Loss: 4.9391, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [467/500], Training Loss: 0.4161, Validation Loss: 2.7822, Training Accuracy: 0.9613, Validation Accuracy: 0.8315\n",
      "Epoch [468/500], Training Loss: 0.2246, Validation Loss: 3.2772, Training Accuracy: 0.9487, Validation Accuracy: 0.7865\n",
      "Epoch [469/500], Training Loss: 0.1935, Validation Loss: 4.1344, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [470/500], Training Loss: 0.1930, Validation Loss: 3.2531, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [471/500], Training Loss: 0.2290, Validation Loss: 2.4155, Training Accuracy: 0.9613, Validation Accuracy: 0.8090\n",
      "Epoch [472/500], Training Loss: 0.1218, Validation Loss: 2.0507, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [473/500], Training Loss: 0.0723, Validation Loss: 5.3617, Training Accuracy: 0.9712, Validation Accuracy: 0.8315\n",
      "Epoch [474/500], Training Loss: 0.0812, Validation Loss: 1.2895, Training Accuracy: 0.9738, Validation Accuracy: 0.8315\n",
      "Epoch [475/500], Training Loss: 0.1060, Validation Loss: 0.8119, Training Accuracy: 0.9625, Validation Accuracy: 0.8202\n",
      "Epoch [476/500], Training Loss: 0.1100, Validation Loss: 6.0593, Training Accuracy: 0.9663, Validation Accuracy: 0.8315\n",
      "Epoch [477/500], Training Loss: 0.0922, Validation Loss: 7.8011, Training Accuracy: 0.9650, Validation Accuracy: 0.8202\n",
      "Epoch [478/500], Training Loss: 0.0914, Validation Loss: 2.6030, Training Accuracy: 0.9675, Validation Accuracy: 0.8315\n",
      "Epoch [479/500], Training Loss: 0.1276, Validation Loss: 3.7014, Training Accuracy: 0.9613, Validation Accuracy: 0.8315\n",
      "Epoch [480/500], Training Loss: 0.0956, Validation Loss: 4.8523, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [481/500], Training Loss: 0.2580, Validation Loss: 1.0063, Training Accuracy: 0.9550, Validation Accuracy: 0.8315\n",
      "Epoch [482/500], Training Loss: 0.1390, Validation Loss: 1.7056, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [483/500], Training Loss: 0.2914, Validation Loss: 1.2440, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [484/500], Training Loss: 0.2108, Validation Loss: 1.9113, Training Accuracy: 0.9363, Validation Accuracy: 0.7865\n",
      "Epoch [485/500], Training Loss: 0.0925, Validation Loss: 4.1470, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [486/500], Training Loss: 0.0915, Validation Loss: 6.1213, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [487/500], Training Loss: 0.1292, Validation Loss: 5.1373, Training Accuracy: 0.9500, Validation Accuracy: 0.8090\n",
      "Epoch [488/500], Training Loss: 0.3301, Validation Loss: 0.5151, Training Accuracy: 0.9450, Validation Accuracy: 0.7978\n",
      "Epoch [489/500], Training Loss: 0.1474, Validation Loss: 3.0422, Training Accuracy: 0.9387, Validation Accuracy: 0.8090\n",
      "Epoch [490/500], Training Loss: 0.1791, Validation Loss: 1.7410, Training Accuracy: 0.9513, Validation Accuracy: 0.7978\n",
      "Epoch [491/500], Training Loss: 0.1195, Validation Loss: 5.6355, Training Accuracy: 0.9525, Validation Accuracy: 0.8202\n",
      "Epoch [492/500], Training Loss: 0.1457, Validation Loss: 3.6391, Training Accuracy: 0.9513, Validation Accuracy: 0.8315\n",
      "Epoch [493/500], Training Loss: 0.1443, Validation Loss: 1.2075, Training Accuracy: 0.9513, Validation Accuracy: 0.8427\n",
      "Epoch [494/500], Training Loss: 0.1136, Validation Loss: 2.1040, Training Accuracy: 0.9537, Validation Accuracy: 0.8202\n",
      "Epoch [495/500], Training Loss: 0.0833, Validation Loss: 5.1554, Training Accuracy: 0.9675, Validation Accuracy: 0.8202\n",
      "Epoch [496/500], Training Loss: 0.1849, Validation Loss: 3.1848, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [497/500], Training Loss: 0.0868, Validation Loss: 4.9208, Training Accuracy: 0.9663, Validation Accuracy: 0.8090\n",
      "Epoch [498/500], Training Loss: 0.1404, Validation Loss: 4.5686, Training Accuracy: 0.9563, Validation Accuracy: 0.8315\n",
      "Epoch [499/500], Training Loss: 0.1138, Validation Loss: 1.8422, Training Accuracy: 0.9537, Validation Accuracy: 0.8315\n",
      "Epoch [500/500], Training Loss: 0.1081, Validation Loss: 1.8656, Training Accuracy: 0.9463, Validation Accuracy: 0.7865\n",
      "Training Time: 11.92 seconds\n",
      "Epoch [1/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [2/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [3/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [4/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [5/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [6/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [7/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [8/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [9/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [10/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [11/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [12/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [13/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [14/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [15/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [16/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [17/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [18/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [19/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [20/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [21/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [22/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [23/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [24/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [25/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [26/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [27/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [28/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [29/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [30/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [31/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [32/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [33/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [34/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [35/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [36/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [37/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [38/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [39/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [40/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [41/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [42/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [43/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [44/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [45/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [46/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [47/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [48/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [49/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [50/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [51/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [52/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [53/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [54/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [55/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [56/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [57/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [58/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [59/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [60/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [61/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [62/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [63/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [64/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [65/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [66/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [67/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [68/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [69/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [70/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [71/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [72/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [73/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [74/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [75/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [76/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [77/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [78/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [79/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [80/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [81/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [82/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [83/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [84/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [85/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [86/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [87/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [88/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [89/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [90/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [91/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [92/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [93/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [94/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [95/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [96/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [97/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [98/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [99/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [100/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [101/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [102/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [103/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [104/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [105/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [106/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [107/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [108/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [109/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [110/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [111/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [112/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [113/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [114/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [115/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [116/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [117/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [118/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [119/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [120/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [121/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [122/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [123/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [124/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [125/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [126/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [127/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [128/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [129/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [130/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [131/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [132/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [133/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [134/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [135/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [136/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [137/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [138/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [139/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [140/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [141/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [142/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [143/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [144/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [145/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [146/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [147/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [148/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [149/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [150/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [151/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [152/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [153/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [154/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [155/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [156/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [157/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [158/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [159/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [160/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [161/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [162/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [163/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [164/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [165/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [166/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [167/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [168/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [169/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [170/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [171/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [172/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [173/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [174/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [175/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [176/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [177/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [178/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [179/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [180/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [181/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [182/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [183/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [184/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [185/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [186/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [187/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [188/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [189/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [190/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [191/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [192/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [193/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [194/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [195/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [196/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [197/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [198/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [199/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [200/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [201/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [202/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [203/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [204/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [205/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [206/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [207/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [208/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [209/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [210/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [211/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [212/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [213/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [214/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [215/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [216/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [217/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [218/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [219/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [220/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [221/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [222/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [223/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [224/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [225/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [226/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [227/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [228/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [229/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [230/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [231/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [232/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [233/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [234/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [235/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [236/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [237/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [238/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [239/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [240/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [241/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [242/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [243/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [244/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [245/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [246/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [247/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [248/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [249/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [250/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [251/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/v5ysl19s0hbdkdprhb3xqd4r0000gn/T/ipykernel_34536/2267140078.py:119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_weights.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [252/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [253/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [254/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [255/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [256/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [257/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [258/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [259/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [260/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [261/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [262/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [263/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [264/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [265/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [266/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [267/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [268/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [269/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [270/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [271/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [272/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [273/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [274/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [275/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [276/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [277/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [278/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [279/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [280/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [281/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [282/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [283/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [284/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [285/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [286/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [287/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [288/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [289/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [290/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [291/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [292/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [293/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [294/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [295/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [296/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [297/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [298/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [299/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [300/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [301/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [302/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [303/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [304/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [305/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [306/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [307/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [308/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [309/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [310/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [311/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [312/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [313/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [314/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [315/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [316/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [317/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [318/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [319/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [320/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [321/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [322/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [323/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [324/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [325/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [326/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [327/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [328/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [329/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [330/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [331/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [332/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [333/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [334/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [335/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [336/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [337/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [338/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [339/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [340/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [341/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [342/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [343/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [344/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [345/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [346/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [347/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [348/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [349/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [350/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [351/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [352/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [353/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [354/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [355/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [356/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [357/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [358/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [359/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [360/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [361/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [362/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [363/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [364/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [365/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [366/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [367/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [368/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [369/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [370/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [371/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [372/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [373/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [374/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [375/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [376/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [377/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [378/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [379/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [380/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [381/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [382/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [383/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [384/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [385/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [386/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [387/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [388/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [389/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [390/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [391/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [392/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [393/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [394/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [395/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [396/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [397/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [398/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [399/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [400/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [401/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [402/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [403/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [404/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [405/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [406/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [407/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [408/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [409/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [410/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [411/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [412/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [413/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [414/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [415/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [416/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [417/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [418/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [419/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [420/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [421/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [422/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [423/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [424/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [425/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [426/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [427/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [428/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [429/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [430/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [431/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [432/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [433/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [434/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [435/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [436/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [437/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [438/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [439/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [440/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [441/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [442/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [443/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [444/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [445/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [446/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [447/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [448/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [449/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [450/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [451/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [452/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [453/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [454/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [455/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [456/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [457/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [458/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [459/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [460/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [461/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [462/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [463/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [464/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [465/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [466/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [467/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [468/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [469/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [470/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [471/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [472/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [473/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [474/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [475/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [476/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [477/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [478/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [479/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [480/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [481/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [482/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [483/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [484/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [485/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [486/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [487/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [488/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [489/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [490/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [491/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [492/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [493/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [494/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [495/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [496/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [497/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [498/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [499/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [500/500], Test Loss: 0.8876, Testing Accuracy: 0.7778, \n",
      "Epoch [1/500], Training Loss: 0.5964, Validation Loss: 0.5620, Training Accuracy: 0.6900, Validation Accuracy: 0.7303\n",
      "Epoch [2/500], Training Loss: 0.5399, Validation Loss: 0.5315, Training Accuracy: 0.7375, Validation Accuracy: 0.7303\n",
      "Epoch [3/500], Training Loss: 0.5318, Validation Loss: 0.5584, Training Accuracy: 0.7450, Validation Accuracy: 0.6966\n",
      "Epoch [4/500], Training Loss: 0.5501, Validation Loss: 0.4946, Training Accuracy: 0.7412, Validation Accuracy: 0.7528\n",
      "Epoch [5/500], Training Loss: 0.5170, Validation Loss: 0.4775, Training Accuracy: 0.7512, Validation Accuracy: 0.7191\n",
      "Epoch [6/500], Training Loss: 0.5176, Validation Loss: 0.5036, Training Accuracy: 0.7738, Validation Accuracy: 0.7978\n",
      "Epoch [7/500], Training Loss: 0.5446, Validation Loss: 0.4767, Training Accuracy: 0.7325, Validation Accuracy: 0.7416\n",
      "Epoch [8/500], Training Loss: 0.5581, Validation Loss: 0.4595, Training Accuracy: 0.7550, Validation Accuracy: 0.7978\n",
      "Epoch [9/500], Training Loss: 0.5483, Validation Loss: 0.5308, Training Accuracy: 0.7338, Validation Accuracy: 0.7640\n",
      "Epoch [10/500], Training Loss: 0.5384, Validation Loss: 0.5044, Training Accuracy: 0.7588, Validation Accuracy: 0.7416\n",
      "Epoch [11/500], Training Loss: 0.5528, Validation Loss: 0.5392, Training Accuracy: 0.7362, Validation Accuracy: 0.7416\n",
      "Epoch [12/500], Training Loss: 0.5167, Validation Loss: 0.5272, Training Accuracy: 0.7575, Validation Accuracy: 0.7079\n",
      "Epoch [13/500], Training Loss: 0.4866, Validation Loss: 0.5619, Training Accuracy: 0.7712, Validation Accuracy: 0.6517\n",
      "Epoch [14/500], Training Loss: 0.5142, Validation Loss: 0.5282, Training Accuracy: 0.7412, Validation Accuracy: 0.7528\n",
      "Epoch [15/500], Training Loss: 0.4925, Validation Loss: 0.5592, Training Accuracy: 0.7600, Validation Accuracy: 0.7191\n",
      "Epoch [16/500], Training Loss: 0.5254, Validation Loss: 0.5515, Training Accuracy: 0.7588, Validation Accuracy: 0.7191\n",
      "Epoch [17/500], Training Loss: 0.4878, Validation Loss: 0.5430, Training Accuracy: 0.7700, Validation Accuracy: 0.7191\n",
      "Epoch [18/500], Training Loss: 0.5005, Validation Loss: 0.5279, Training Accuracy: 0.7662, Validation Accuracy: 0.7191\n",
      "Epoch [19/500], Training Loss: 0.6162, Validation Loss: 0.5395, Training Accuracy: 0.7600, Validation Accuracy: 0.7528\n",
      "Epoch [20/500], Training Loss: 0.5688, Validation Loss: 0.5227, Training Accuracy: 0.7362, Validation Accuracy: 0.7640\n",
      "Epoch [21/500], Training Loss: 0.5009, Validation Loss: 0.5697, Training Accuracy: 0.7550, Validation Accuracy: 0.7528\n",
      "Epoch [22/500], Training Loss: 0.6310, Validation Loss: 0.5281, Training Accuracy: 0.7638, Validation Accuracy: 0.7079\n",
      "Epoch [23/500], Training Loss: 0.5282, Validation Loss: 0.5471, Training Accuracy: 0.7412, Validation Accuracy: 0.7528\n",
      "Epoch [24/500], Training Loss: 0.4986, Validation Loss: 0.5393, Training Accuracy: 0.7575, Validation Accuracy: 0.7865\n",
      "Epoch [25/500], Training Loss: 0.4925, Validation Loss: 0.5387, Training Accuracy: 0.7462, Validation Accuracy: 0.7865\n",
      "Epoch [26/500], Training Loss: 0.4636, Validation Loss: 0.5998, Training Accuracy: 0.7700, Validation Accuracy: 0.7640\n",
      "Epoch [27/500], Training Loss: 0.5174, Validation Loss: 0.4668, Training Accuracy: 0.7650, Validation Accuracy: 0.7416\n",
      "Epoch [28/500], Training Loss: 0.4856, Validation Loss: 0.4804, Training Accuracy: 0.7538, Validation Accuracy: 0.7528\n",
      "Epoch [29/500], Training Loss: 0.4710, Validation Loss: 0.5267, Training Accuracy: 0.7812, Validation Accuracy: 0.7978\n",
      "Epoch [30/500], Training Loss: 0.5112, Validation Loss: 0.5459, Training Accuracy: 0.7750, Validation Accuracy: 0.7416\n",
      "Epoch [31/500], Training Loss: 0.4715, Validation Loss: 0.4780, Training Accuracy: 0.7762, Validation Accuracy: 0.7640\n",
      "Epoch [32/500], Training Loss: 0.4687, Validation Loss: 0.5113, Training Accuracy: 0.7650, Validation Accuracy: 0.7416\n",
      "Epoch [33/500], Training Loss: 0.4477, Validation Loss: 0.4998, Training Accuracy: 0.7963, Validation Accuracy: 0.7753\n",
      "Epoch [34/500], Training Loss: 0.4460, Validation Loss: 0.4672, Training Accuracy: 0.7800, Validation Accuracy: 0.7416\n",
      "Epoch [35/500], Training Loss: 0.4953, Validation Loss: 0.4936, Training Accuracy: 0.7788, Validation Accuracy: 0.7753\n",
      "Epoch [36/500], Training Loss: 0.4537, Validation Loss: 0.5423, Training Accuracy: 0.7788, Validation Accuracy: 0.7191\n",
      "Epoch [37/500], Training Loss: 0.4669, Validation Loss: 0.5226, Training Accuracy: 0.7812, Validation Accuracy: 0.7416\n",
      "Epoch [38/500], Training Loss: 0.4933, Validation Loss: 0.5198, Training Accuracy: 0.7512, Validation Accuracy: 0.7303\n",
      "Epoch [39/500], Training Loss: 0.4532, Validation Loss: 0.5334, Training Accuracy: 0.7712, Validation Accuracy: 0.7865\n",
      "Epoch [40/500], Training Loss: 0.4392, Validation Loss: 0.5466, Training Accuracy: 0.7887, Validation Accuracy: 0.7640\n",
      "Epoch [41/500], Training Loss: 0.4589, Validation Loss: 0.5185, Training Accuracy: 0.7738, Validation Accuracy: 0.7528\n",
      "Epoch [42/500], Training Loss: 0.4573, Validation Loss: 0.4799, Training Accuracy: 0.7825, Validation Accuracy: 0.7753\n",
      "Epoch [43/500], Training Loss: 0.4362, Validation Loss: 0.4629, Training Accuracy: 0.7863, Validation Accuracy: 0.8090\n",
      "Epoch [44/500], Training Loss: 0.4474, Validation Loss: 0.5240, Training Accuracy: 0.7963, Validation Accuracy: 0.7303\n",
      "Epoch [45/500], Training Loss: 0.4366, Validation Loss: 0.5712, Training Accuracy: 0.7812, Validation Accuracy: 0.7416\n",
      "Epoch [46/500], Training Loss: 0.4424, Validation Loss: 0.5922, Training Accuracy: 0.7800, Validation Accuracy: 0.7640\n",
      "Epoch [47/500], Training Loss: 0.4424, Validation Loss: 0.4644, Training Accuracy: 0.7837, Validation Accuracy: 0.7753\n",
      "Epoch [48/500], Training Loss: 0.4370, Validation Loss: 0.5058, Training Accuracy: 0.7800, Validation Accuracy: 0.7865\n",
      "Epoch [49/500], Training Loss: 0.4336, Validation Loss: 0.4863, Training Accuracy: 0.7875, Validation Accuracy: 0.7753\n",
      "Epoch [50/500], Training Loss: 0.4328, Validation Loss: 0.4601, Training Accuracy: 0.7987, Validation Accuracy: 0.7978\n",
      "Epoch [51/500], Training Loss: 0.4151, Validation Loss: 0.5000, Training Accuracy: 0.8000, Validation Accuracy: 0.8090\n",
      "Epoch [52/500], Training Loss: 0.4231, Validation Loss: 0.6234, Training Accuracy: 0.8113, Validation Accuracy: 0.7753\n",
      "Epoch [53/500], Training Loss: 0.4050, Validation Loss: 0.5144, Training Accuracy: 0.8087, Validation Accuracy: 0.8090\n",
      "Epoch [54/500], Training Loss: 0.3988, Validation Loss: 0.6073, Training Accuracy: 0.8187, Validation Accuracy: 0.7753\n",
      "Epoch [55/500], Training Loss: 0.4685, Validation Loss: 0.5434, Training Accuracy: 0.7775, Validation Accuracy: 0.7303\n",
      "Epoch [56/500], Training Loss: 0.4689, Validation Loss: 0.7261, Training Accuracy: 0.7688, Validation Accuracy: 0.7416\n",
      "Epoch [57/500], Training Loss: 0.4759, Validation Loss: 0.6528, Training Accuracy: 0.7963, Validation Accuracy: 0.7416\n",
      "Epoch [58/500], Training Loss: 0.4349, Validation Loss: 0.5411, Training Accuracy: 0.7812, Validation Accuracy: 0.7753\n",
      "Epoch [59/500], Training Loss: 0.4473, Validation Loss: 0.5473, Training Accuracy: 0.8050, Validation Accuracy: 0.7640\n",
      "Epoch [60/500], Training Loss: 0.4804, Validation Loss: 0.5657, Training Accuracy: 0.7812, Validation Accuracy: 0.7303\n",
      "Epoch [61/500], Training Loss: 0.4155, Validation Loss: 0.5933, Training Accuracy: 0.8025, Validation Accuracy: 0.7528\n",
      "Epoch [62/500], Training Loss: 0.4639, Validation Loss: 0.5395, Training Accuracy: 0.8100, Validation Accuracy: 0.7416\n",
      "Epoch [63/500], Training Loss: 0.4426, Validation Loss: 0.5051, Training Accuracy: 0.7950, Validation Accuracy: 0.7978\n",
      "Epoch [64/500], Training Loss: 0.4381, Validation Loss: 0.4856, Training Accuracy: 0.8013, Validation Accuracy: 0.8090\n",
      "Epoch [65/500], Training Loss: 0.3943, Validation Loss: 0.4723, Training Accuracy: 0.8150, Validation Accuracy: 0.8202\n",
      "Epoch [66/500], Training Loss: 0.3988, Validation Loss: 0.6164, Training Accuracy: 0.8125, Validation Accuracy: 0.7978\n",
      "Epoch [67/500], Training Loss: 0.3898, Validation Loss: 0.4590, Training Accuracy: 0.8213, Validation Accuracy: 0.7978\n",
      "Epoch [68/500], Training Loss: 0.4105, Validation Loss: 0.5122, Training Accuracy: 0.8013, Validation Accuracy: 0.7528\n",
      "Epoch [69/500], Training Loss: 0.4321, Validation Loss: 0.4567, Training Accuracy: 0.8050, Validation Accuracy: 0.8202\n",
      "Epoch [70/500], Training Loss: 0.4022, Validation Loss: 0.4920, Training Accuracy: 0.7987, Validation Accuracy: 0.8090\n",
      "Epoch [71/500], Training Loss: 0.3740, Validation Loss: 0.6135, Training Accuracy: 0.8225, Validation Accuracy: 0.7753\n",
      "Epoch [72/500], Training Loss: 0.4315, Validation Loss: 0.5360, Training Accuracy: 0.7913, Validation Accuracy: 0.7303\n",
      "Epoch [73/500], Training Loss: 0.4224, Validation Loss: 0.5318, Training Accuracy: 0.8050, Validation Accuracy: 0.7416\n",
      "Epoch [74/500], Training Loss: 0.5425, Validation Loss: 1.5448, Training Accuracy: 0.8087, Validation Accuracy: 0.7303\n",
      "Epoch [75/500], Training Loss: 0.5474, Validation Loss: 0.4599, Training Accuracy: 0.8125, Validation Accuracy: 0.7865\n",
      "Epoch [76/500], Training Loss: 0.4460, Validation Loss: 0.6179, Training Accuracy: 0.7837, Validation Accuracy: 0.8090\n",
      "Epoch [77/500], Training Loss: 0.4113, Validation Loss: 0.4531, Training Accuracy: 0.8075, Validation Accuracy: 0.8202\n",
      "Epoch [78/500], Training Loss: 0.4411, Validation Loss: 0.5143, Training Accuracy: 0.8087, Validation Accuracy: 0.7865\n",
      "Epoch [79/500], Training Loss: 0.3977, Validation Loss: 0.5667, Training Accuracy: 0.8025, Validation Accuracy: 0.7640\n",
      "Epoch [80/500], Training Loss: 0.4103, Validation Loss: 1.5134, Training Accuracy: 0.8125, Validation Accuracy: 0.8202\n",
      "Epoch [81/500], Training Loss: 0.4433, Validation Loss: 0.5544, Training Accuracy: 0.8113, Validation Accuracy: 0.8090\n",
      "Epoch [82/500], Training Loss: 0.4214, Validation Loss: 0.4321, Training Accuracy: 0.8113, Validation Accuracy: 0.8202\n",
      "Epoch [83/500], Training Loss: 0.4354, Validation Loss: 0.4721, Training Accuracy: 0.7900, Validation Accuracy: 0.7978\n",
      "Epoch [84/500], Training Loss: 0.4361, Validation Loss: 0.4610, Training Accuracy: 0.8013, Validation Accuracy: 0.7978\n",
      "Epoch [85/500], Training Loss: 0.4037, Validation Loss: 0.4964, Training Accuracy: 0.8137, Validation Accuracy: 0.7978\n",
      "Epoch [86/500], Training Loss: 0.3805, Validation Loss: 0.5259, Training Accuracy: 0.8275, Validation Accuracy: 0.7865\n",
      "Epoch [87/500], Training Loss: 0.3958, Validation Loss: 0.5909, Training Accuracy: 0.8113, Validation Accuracy: 0.7528\n",
      "Epoch [88/500], Training Loss: 0.3963, Validation Loss: 0.4851, Training Accuracy: 0.8087, Validation Accuracy: 0.7865\n",
      "Epoch [89/500], Training Loss: 0.3746, Validation Loss: 1.5093, Training Accuracy: 0.8325, Validation Accuracy: 0.7753\n",
      "Epoch [90/500], Training Loss: 0.4108, Validation Loss: 0.5697, Training Accuracy: 0.8050, Validation Accuracy: 0.7753\n",
      "Epoch [91/500], Training Loss: 0.3851, Validation Loss: 0.6029, Training Accuracy: 0.8100, Validation Accuracy: 0.7978\n",
      "Epoch [92/500], Training Loss: 0.3870, Validation Loss: 1.5996, Training Accuracy: 0.8200, Validation Accuracy: 0.7753\n",
      "Epoch [93/500], Training Loss: 0.4870, Validation Loss: 0.6384, Training Accuracy: 0.8063, Validation Accuracy: 0.7528\n",
      "Epoch [94/500], Training Loss: 0.4132, Validation Loss: 0.4889, Training Accuracy: 0.8000, Validation Accuracy: 0.7753\n",
      "Epoch [95/500], Training Loss: 0.4047, Validation Loss: 0.4725, Training Accuracy: 0.8087, Validation Accuracy: 0.7978\n",
      "Epoch [96/500], Training Loss: 0.3947, Validation Loss: 1.4556, Training Accuracy: 0.8050, Validation Accuracy: 0.7753\n",
      "Epoch [97/500], Training Loss: 0.3958, Validation Loss: 0.5951, Training Accuracy: 0.8363, Validation Accuracy: 0.7528\n",
      "Epoch [98/500], Training Loss: 0.4434, Validation Loss: 0.6272, Training Accuracy: 0.8100, Validation Accuracy: 0.7528\n",
      "Epoch [99/500], Training Loss: 0.4534, Validation Loss: 0.5441, Training Accuracy: 0.7863, Validation Accuracy: 0.8427\n",
      "Epoch [100/500], Training Loss: 0.4094, Validation Loss: 0.5627, Training Accuracy: 0.8200, Validation Accuracy: 0.7528\n",
      "Epoch [101/500], Training Loss: 0.4388, Validation Loss: 0.5424, Training Accuracy: 0.8025, Validation Accuracy: 0.7865\n",
      "Epoch [102/500], Training Loss: 0.5103, Validation Loss: 0.5888, Training Accuracy: 0.8175, Validation Accuracy: 0.8202\n",
      "Epoch [103/500], Training Loss: 0.4101, Validation Loss: 0.5365, Training Accuracy: 0.7963, Validation Accuracy: 0.7640\n",
      "Epoch [104/500], Training Loss: 0.3836, Validation Loss: 0.5750, Training Accuracy: 0.8237, Validation Accuracy: 0.7753\n",
      "Epoch [105/500], Training Loss: 0.3767, Validation Loss: 0.5559, Training Accuracy: 0.8237, Validation Accuracy: 0.8090\n",
      "Epoch [106/500], Training Loss: 0.3864, Validation Loss: 0.5843, Training Accuracy: 0.8263, Validation Accuracy: 0.7978\n",
      "Epoch [107/500], Training Loss: 0.4238, Validation Loss: 0.4809, Training Accuracy: 0.8013, Validation Accuracy: 0.7978\n",
      "Epoch [108/500], Training Loss: 0.4241, Validation Loss: 0.4435, Training Accuracy: 0.8037, Validation Accuracy: 0.8202\n",
      "Epoch [109/500], Training Loss: 0.4460, Validation Loss: 0.5928, Training Accuracy: 0.7700, Validation Accuracy: 0.7528\n",
      "Epoch [110/500], Training Loss: 0.4197, Validation Loss: 0.5604, Training Accuracy: 0.7900, Validation Accuracy: 0.7191\n",
      "Epoch [111/500], Training Loss: 0.4068, Validation Loss: 0.5651, Training Accuracy: 0.8125, Validation Accuracy: 0.7865\n",
      "Epoch [112/500], Training Loss: 0.4110, Validation Loss: 0.4931, Training Accuracy: 0.8037, Validation Accuracy: 0.8202\n",
      "Epoch [113/500], Training Loss: 0.4140, Validation Loss: 0.5041, Training Accuracy: 0.8037, Validation Accuracy: 0.7978\n",
      "Epoch [114/500], Training Loss: 0.3873, Validation Loss: 0.4815, Training Accuracy: 0.8150, Validation Accuracy: 0.8202\n",
      "Epoch [115/500], Training Loss: 0.3745, Validation Loss: 0.5219, Training Accuracy: 0.8375, Validation Accuracy: 0.8202\n",
      "Epoch [116/500], Training Loss: 0.4973, Validation Loss: 0.4903, Training Accuracy: 0.8137, Validation Accuracy: 0.7978\n",
      "Epoch [117/500], Training Loss: 0.3726, Validation Loss: 0.5626, Training Accuracy: 0.8413, Validation Accuracy: 0.7528\n",
      "Epoch [118/500], Training Loss: 0.3654, Validation Loss: 0.6528, Training Accuracy: 0.8100, Validation Accuracy: 0.7416\n",
      "Epoch [119/500], Training Loss: 0.4123, Validation Loss: 1.5352, Training Accuracy: 0.8063, Validation Accuracy: 0.7753\n",
      "Epoch [120/500], Training Loss: 0.3978, Validation Loss: 0.5128, Training Accuracy: 0.8263, Validation Accuracy: 0.7416\n",
      "Epoch [121/500], Training Loss: 0.5500, Validation Loss: 0.5599, Training Accuracy: 0.7950, Validation Accuracy: 0.7753\n",
      "Epoch [122/500], Training Loss: 0.7593, Validation Loss: 0.6069, Training Accuracy: 0.8013, Validation Accuracy: 0.6966\n",
      "Epoch [123/500], Training Loss: 0.4936, Validation Loss: 0.5751, Training Accuracy: 0.7212, Validation Accuracy: 0.7528\n",
      "Epoch [124/500], Training Loss: 0.4364, Validation Loss: 0.5427, Training Accuracy: 0.7638, Validation Accuracy: 0.7528\n",
      "Epoch [125/500], Training Loss: 0.4339, Validation Loss: 0.5169, Training Accuracy: 0.7800, Validation Accuracy: 0.7416\n",
      "Epoch [126/500], Training Loss: 0.4219, Validation Loss: 0.6501, Training Accuracy: 0.7738, Validation Accuracy: 0.7303\n",
      "Epoch [127/500], Training Loss: 0.4580, Validation Loss: 0.5248, Training Accuracy: 0.7712, Validation Accuracy: 0.7640\n",
      "Epoch [128/500], Training Loss: 0.6223, Validation Loss: 0.6494, Training Accuracy: 0.8063, Validation Accuracy: 0.7640\n",
      "Epoch [129/500], Training Loss: 0.4167, Validation Loss: 0.5238, Training Accuracy: 0.8100, Validation Accuracy: 0.7303\n",
      "Epoch [130/500], Training Loss: 0.5646, Validation Loss: 0.5613, Training Accuracy: 0.8175, Validation Accuracy: 0.7978\n",
      "Epoch [131/500], Training Loss: 0.4276, Validation Loss: 0.5875, Training Accuracy: 0.8075, Validation Accuracy: 0.7865\n",
      "Epoch [132/500], Training Loss: 0.3907, Validation Loss: 0.5542, Training Accuracy: 0.8275, Validation Accuracy: 0.7978\n",
      "Epoch [133/500], Training Loss: 0.3698, Validation Loss: 0.6104, Training Accuracy: 0.8363, Validation Accuracy: 0.7978\n",
      "Epoch [134/500], Training Loss: 0.3863, Validation Loss: 0.7158, Training Accuracy: 0.8250, Validation Accuracy: 0.7865\n",
      "Epoch [135/500], Training Loss: 0.5525, Validation Loss: 0.6810, Training Accuracy: 0.8175, Validation Accuracy: 0.7753\n",
      "Epoch [136/500], Training Loss: 0.5440, Validation Loss: 1.4693, Training Accuracy: 0.8000, Validation Accuracy: 0.7640\n",
      "Epoch [137/500], Training Loss: 0.4010, Validation Loss: 0.6062, Training Accuracy: 0.8113, Validation Accuracy: 0.7753\n",
      "Epoch [138/500], Training Loss: 0.4346, Validation Loss: 0.6005, Training Accuracy: 0.7925, Validation Accuracy: 0.7865\n",
      "Epoch [139/500], Training Loss: 0.4661, Validation Loss: 0.6443, Training Accuracy: 0.7925, Validation Accuracy: 0.7303\n",
      "Epoch [140/500], Training Loss: 0.4072, Validation Loss: 1.4794, Training Accuracy: 0.8200, Validation Accuracy: 0.8090\n",
      "Epoch [141/500], Training Loss: 0.3899, Validation Loss: 0.5474, Training Accuracy: 0.8100, Validation Accuracy: 0.8427\n",
      "Epoch [142/500], Training Loss: 0.4087, Validation Loss: 0.5630, Training Accuracy: 0.8037, Validation Accuracy: 0.7978\n",
      "Epoch [143/500], Training Loss: 0.3592, Validation Loss: 0.5328, Training Accuracy: 0.8113, Validation Accuracy: 0.7978\n",
      "Epoch [144/500], Training Loss: 0.3828, Validation Loss: 0.5619, Training Accuracy: 0.8150, Validation Accuracy: 0.8427\n",
      "Epoch [145/500], Training Loss: 0.3567, Validation Loss: 0.6428, Training Accuracy: 0.8213, Validation Accuracy: 0.8090\n",
      "Epoch [146/500], Training Loss: 0.3826, Validation Loss: 0.7098, Training Accuracy: 0.8250, Validation Accuracy: 0.8090\n",
      "Epoch [147/500], Training Loss: 0.3837, Validation Loss: 0.4824, Training Accuracy: 0.8150, Validation Accuracy: 0.7865\n",
      "Epoch [148/500], Training Loss: 0.5467, Validation Loss: 0.4852, Training Accuracy: 0.8263, Validation Accuracy: 0.7978\n",
      "Epoch [149/500], Training Loss: 0.3486, Validation Loss: 0.5845, Training Accuracy: 0.8337, Validation Accuracy: 0.8090\n",
      "Epoch [150/500], Training Loss: 0.3957, Validation Loss: 0.5071, Training Accuracy: 0.8213, Validation Accuracy: 0.7978\n",
      "Epoch [151/500], Training Loss: 0.3973, Validation Loss: 0.3905, Training Accuracy: 0.8287, Validation Accuracy: 0.8315\n",
      "Epoch [152/500], Training Loss: 0.3996, Validation Loss: 0.4146, Training Accuracy: 0.8237, Validation Accuracy: 0.7753\n",
      "Epoch [153/500], Training Loss: 0.3555, Validation Loss: 0.4293, Training Accuracy: 0.8137, Validation Accuracy: 0.8315\n",
      "Epoch [154/500], Training Loss: 0.3960, Validation Loss: 0.5270, Training Accuracy: 0.8025, Validation Accuracy: 0.7865\n",
      "Epoch [155/500], Training Loss: 0.4086, Validation Loss: 0.5894, Training Accuracy: 0.8150, Validation Accuracy: 0.7753\n",
      "Epoch [156/500], Training Loss: 0.4513, Validation Loss: 0.4984, Training Accuracy: 0.8037, Validation Accuracy: 0.7640\n",
      "Epoch [157/500], Training Loss: 0.4208, Validation Loss: 0.5407, Training Accuracy: 0.7987, Validation Accuracy: 0.8090\n",
      "Epoch [158/500], Training Loss: 0.3959, Validation Loss: 0.4643, Training Accuracy: 0.8175, Validation Accuracy: 0.8202\n",
      "Epoch [159/500], Training Loss: 0.3499, Validation Loss: 0.4733, Training Accuracy: 0.8562, Validation Accuracy: 0.7978\n",
      "Epoch [160/500], Training Loss: 0.3776, Validation Loss: 0.4399, Training Accuracy: 0.8313, Validation Accuracy: 0.7753\n",
      "Epoch [161/500], Training Loss: 0.3705, Validation Loss: 0.5125, Training Accuracy: 0.8250, Validation Accuracy: 0.7865\n",
      "Epoch [162/500], Training Loss: 0.3952, Validation Loss: 0.5613, Training Accuracy: 0.8263, Validation Accuracy: 0.8090\n",
      "Epoch [163/500], Training Loss: 0.4086, Validation Loss: 0.4514, Training Accuracy: 0.8263, Validation Accuracy: 0.8090\n",
      "Epoch [164/500], Training Loss: 0.4044, Validation Loss: 0.5263, Training Accuracy: 0.8163, Validation Accuracy: 0.8315\n",
      "Epoch [165/500], Training Loss: 0.3912, Validation Loss: 0.4665, Training Accuracy: 0.8263, Validation Accuracy: 0.8202\n",
      "Epoch [166/500], Training Loss: 0.3606, Validation Loss: 0.4907, Training Accuracy: 0.8313, Validation Accuracy: 0.7753\n",
      "Epoch [167/500], Training Loss: 0.3905, Validation Loss: 0.4934, Training Accuracy: 0.8213, Validation Accuracy: 0.8090\n",
      "Epoch [168/500], Training Loss: 0.3783, Validation Loss: 0.4542, Training Accuracy: 0.8237, Validation Accuracy: 0.8315\n",
      "Epoch [169/500], Training Loss: 0.4045, Validation Loss: 0.4758, Training Accuracy: 0.8263, Validation Accuracy: 0.7978\n",
      "Epoch [170/500], Training Loss: 0.3577, Validation Loss: 0.4064, Training Accuracy: 0.8275, Validation Accuracy: 0.8315\n",
      "Epoch [171/500], Training Loss: 0.3454, Validation Loss: 0.4646, Training Accuracy: 0.8225, Validation Accuracy: 0.8202\n",
      "Epoch [172/500], Training Loss: 0.3661, Validation Loss: 0.3918, Training Accuracy: 0.8363, Validation Accuracy: 0.8202\n",
      "Epoch [173/500], Training Loss: 0.3631, Validation Loss: 0.4146, Training Accuracy: 0.8337, Validation Accuracy: 0.8090\n",
      "Epoch [174/500], Training Loss: 0.3414, Validation Loss: 0.5086, Training Accuracy: 0.8287, Validation Accuracy: 0.8315\n",
      "Epoch [175/500], Training Loss: 0.3738, Validation Loss: 0.5354, Training Accuracy: 0.8287, Validation Accuracy: 0.8090\n",
      "Epoch [176/500], Training Loss: 0.3006, Validation Loss: 0.5346, Training Accuracy: 0.8575, Validation Accuracy: 0.8090\n",
      "Epoch [177/500], Training Loss: 0.3702, Validation Loss: 0.4000, Training Accuracy: 0.8413, Validation Accuracy: 0.8090\n",
      "Epoch [178/500], Training Loss: 0.4098, Validation Loss: 0.4722, Training Accuracy: 0.8200, Validation Accuracy: 0.8090\n",
      "Epoch [179/500], Training Loss: 0.3430, Validation Loss: 0.4336, Training Accuracy: 0.8313, Validation Accuracy: 0.8315\n",
      "Epoch [180/500], Training Loss: 0.3699, Validation Loss: 0.4607, Training Accuracy: 0.8313, Validation Accuracy: 0.7978\n",
      "Epoch [181/500], Training Loss: 0.3875, Validation Loss: 0.4949, Training Accuracy: 0.8175, Validation Accuracy: 0.8202\n",
      "Epoch [182/500], Training Loss: 0.3737, Validation Loss: 0.4848, Training Accuracy: 0.8313, Validation Accuracy: 0.8427\n",
      "Epoch [183/500], Training Loss: 0.3248, Validation Loss: 1.4242, Training Accuracy: 0.8500, Validation Accuracy: 0.7978\n",
      "Epoch [184/500], Training Loss: 0.3444, Validation Loss: 1.4144, Training Accuracy: 0.8425, Validation Accuracy: 0.7865\n",
      "Epoch [185/500], Training Loss: 0.3417, Validation Loss: 0.4938, Training Accuracy: 0.8400, Validation Accuracy: 0.7978\n",
      "Epoch [186/500], Training Loss: 0.3410, Validation Loss: 0.4326, Training Accuracy: 0.8400, Validation Accuracy: 0.8090\n",
      "Epoch [187/500], Training Loss: 0.3531, Validation Loss: 0.4905, Training Accuracy: 0.8400, Validation Accuracy: 0.7865\n",
      "Epoch [188/500], Training Loss: 0.4106, Validation Loss: 0.4695, Training Accuracy: 0.8287, Validation Accuracy: 0.8090\n",
      "Epoch [189/500], Training Loss: 0.3725, Validation Loss: 0.4895, Training Accuracy: 0.8325, Validation Accuracy: 0.7865\n",
      "Epoch [190/500], Training Loss: 0.3440, Validation Loss: 0.4790, Training Accuracy: 0.8462, Validation Accuracy: 0.7865\n",
      "Epoch [191/500], Training Loss: 0.3644, Validation Loss: 0.4087, Training Accuracy: 0.8438, Validation Accuracy: 0.7978\n",
      "Epoch [192/500], Training Loss: 0.3791, Validation Loss: 0.4570, Training Accuracy: 0.8325, Validation Accuracy: 0.7978\n",
      "Epoch [193/500], Training Loss: 0.4426, Validation Loss: 0.4540, Training Accuracy: 0.8363, Validation Accuracy: 0.7865\n",
      "Epoch [194/500], Training Loss: 0.3522, Validation Loss: 0.4877, Training Accuracy: 0.8475, Validation Accuracy: 0.8090\n",
      "Epoch [195/500], Training Loss: 0.3402, Validation Loss: 0.4291, Training Accuracy: 0.8350, Validation Accuracy: 0.7978\n",
      "Epoch [196/500], Training Loss: 0.3238, Validation Loss: 0.4651, Training Accuracy: 0.8525, Validation Accuracy: 0.8315\n",
      "Epoch [197/500], Training Loss: 0.3473, Validation Loss: 0.5894, Training Accuracy: 0.8525, Validation Accuracy: 0.8090\n",
      "Epoch [198/500], Training Loss: 0.3608, Validation Loss: 0.5590, Training Accuracy: 0.8500, Validation Accuracy: 0.7753\n",
      "Epoch [199/500], Training Loss: 0.4939, Validation Loss: 1.5125, Training Accuracy: 0.8375, Validation Accuracy: 0.7978\n",
      "Epoch [200/500], Training Loss: 0.3047, Validation Loss: 1.4273, Training Accuracy: 0.8562, Validation Accuracy: 0.8090\n",
      "Epoch [201/500], Training Loss: 0.3334, Validation Loss: 0.5300, Training Accuracy: 0.8450, Validation Accuracy: 0.8202\n",
      "Epoch [202/500], Training Loss: 0.3109, Validation Loss: 0.5497, Training Accuracy: 0.8575, Validation Accuracy: 0.8202\n",
      "Epoch [203/500], Training Loss: 0.3013, Validation Loss: 0.5306, Training Accuracy: 0.8662, Validation Accuracy: 0.7753\n",
      "Epoch [204/500], Training Loss: 0.4715, Validation Loss: 1.3868, Training Accuracy: 0.8325, Validation Accuracy: 0.7978\n",
      "Epoch [205/500], Training Loss: 0.3138, Validation Loss: 1.4009, Training Accuracy: 0.8488, Validation Accuracy: 0.7978\n",
      "Epoch [206/500], Training Loss: 0.3847, Validation Loss: 0.5539, Training Accuracy: 0.8350, Validation Accuracy: 0.7978\n",
      "Epoch [207/500], Training Loss: 0.3473, Validation Loss: 1.4529, Training Accuracy: 0.8400, Validation Accuracy: 0.8315\n",
      "Epoch [208/500], Training Loss: 0.3613, Validation Loss: 0.4231, Training Accuracy: 0.8263, Validation Accuracy: 0.8090\n",
      "Epoch [209/500], Training Loss: 0.3541, Validation Loss: 0.4602, Training Accuracy: 0.8275, Validation Accuracy: 0.8090\n",
      "Epoch [210/500], Training Loss: 0.3639, Validation Loss: 0.5379, Training Accuracy: 0.8500, Validation Accuracy: 0.8090\n",
      "Epoch [211/500], Training Loss: 0.3656, Validation Loss: 0.5754, Training Accuracy: 0.8263, Validation Accuracy: 0.7978\n",
      "Epoch [212/500], Training Loss: 0.3388, Validation Loss: 0.6134, Training Accuracy: 0.8375, Validation Accuracy: 0.7865\n",
      "Epoch [213/500], Training Loss: 0.3674, Validation Loss: 1.4738, Training Accuracy: 0.8237, Validation Accuracy: 0.7978\n",
      "Epoch [214/500], Training Loss: 0.3346, Validation Loss: 1.5378, Training Accuracy: 0.8400, Validation Accuracy: 0.7978\n",
      "Epoch [215/500], Training Loss: 0.3509, Validation Loss: 1.5701, Training Accuracy: 0.8287, Validation Accuracy: 0.7978\n",
      "Epoch [216/500], Training Loss: 0.4050, Validation Loss: 0.4953, Training Accuracy: 0.8163, Validation Accuracy: 0.8090\n",
      "Epoch [217/500], Training Loss: 0.3617, Validation Loss: 0.4544, Training Accuracy: 0.8488, Validation Accuracy: 0.8315\n",
      "Epoch [218/500], Training Loss: 0.3418, Validation Loss: 0.5703, Training Accuracy: 0.8538, Validation Accuracy: 0.8202\n",
      "Epoch [219/500], Training Loss: 0.5704, Validation Loss: 0.5048, Training Accuracy: 0.8612, Validation Accuracy: 0.8315\n",
      "Epoch [220/500], Training Loss: 0.3384, Validation Loss: 1.5087, Training Accuracy: 0.8450, Validation Accuracy: 0.8427\n",
      "Epoch [221/500], Training Loss: 0.3392, Validation Loss: 0.4347, Training Accuracy: 0.8600, Validation Accuracy: 0.8202\n",
      "Epoch [222/500], Training Loss: 0.3074, Validation Loss: 0.5506, Training Accuracy: 0.8638, Validation Accuracy: 0.8090\n",
      "Epoch [223/500], Training Loss: 0.3411, Validation Loss: 0.5376, Training Accuracy: 0.8413, Validation Accuracy: 0.7978\n",
      "Epoch [224/500], Training Loss: 0.3329, Validation Loss: 1.4111, Training Accuracy: 0.8550, Validation Accuracy: 0.8315\n",
      "Epoch [225/500], Training Loss: 0.3672, Validation Loss: 0.4356, Training Accuracy: 0.8425, Validation Accuracy: 0.8539\n",
      "Epoch [226/500], Training Loss: 0.3689, Validation Loss: 0.5492, Training Accuracy: 0.8450, Validation Accuracy: 0.8090\n",
      "Epoch [227/500], Training Loss: 0.3189, Validation Loss: 0.5664, Training Accuracy: 0.8525, Validation Accuracy: 0.8090\n",
      "Epoch [228/500], Training Loss: 0.3638, Validation Loss: 0.4667, Training Accuracy: 0.8425, Validation Accuracy: 0.7978\n",
      "Epoch [229/500], Training Loss: 0.3518, Validation Loss: 0.4560, Training Accuracy: 0.8363, Validation Accuracy: 0.7978\n",
      "Epoch [230/500], Training Loss: 0.3548, Validation Loss: 1.4613, Training Accuracy: 0.8488, Validation Accuracy: 0.8202\n",
      "Epoch [231/500], Training Loss: 0.4423, Validation Loss: 0.4960, Training Accuracy: 0.8438, Validation Accuracy: 0.8090\n",
      "Epoch [232/500], Training Loss: 0.3682, Validation Loss: 0.5953, Training Accuracy: 0.8363, Validation Accuracy: 0.8090\n",
      "Epoch [233/500], Training Loss: 0.3255, Validation Loss: 1.4297, Training Accuracy: 0.8625, Validation Accuracy: 0.7978\n",
      "Epoch [234/500], Training Loss: 0.3287, Validation Loss: 1.3861, Training Accuracy: 0.8462, Validation Accuracy: 0.8427\n",
      "Epoch [235/500], Training Loss: 0.3762, Validation Loss: 0.4606, Training Accuracy: 0.8550, Validation Accuracy: 0.8090\n",
      "Epoch [236/500], Training Loss: 0.3562, Validation Loss: 0.5709, Training Accuracy: 0.8438, Validation Accuracy: 0.7978\n",
      "Epoch [237/500], Training Loss: 0.3505, Validation Loss: 0.4912, Training Accuracy: 0.8450, Validation Accuracy: 0.8539\n",
      "Epoch [238/500], Training Loss: 0.2995, Validation Loss: 0.6155, Training Accuracy: 0.8600, Validation Accuracy: 0.8652\n",
      "Epoch [239/500], Training Loss: 0.3151, Validation Loss: 1.5934, Training Accuracy: 0.8525, Validation Accuracy: 0.8090\n",
      "Epoch [240/500], Training Loss: 0.3525, Validation Loss: 0.5373, Training Accuracy: 0.8400, Validation Accuracy: 0.8090\n",
      "Epoch [241/500], Training Loss: 0.3370, Validation Loss: 0.4951, Training Accuracy: 0.8475, Validation Accuracy: 0.8202\n",
      "Epoch [242/500], Training Loss: 0.3237, Validation Loss: 1.5549, Training Accuracy: 0.8612, Validation Accuracy: 0.8090\n",
      "Epoch [243/500], Training Loss: 0.3514, Validation Loss: 1.4695, Training Accuracy: 0.8313, Validation Accuracy: 0.7640\n",
      "Epoch [244/500], Training Loss: 0.3510, Validation Loss: 0.5097, Training Accuracy: 0.8488, Validation Accuracy: 0.8202\n",
      "Epoch [245/500], Training Loss: 0.3396, Validation Loss: 0.5308, Training Accuracy: 0.8313, Validation Accuracy: 0.7978\n",
      "Epoch [246/500], Training Loss: 0.3602, Validation Loss: 0.5643, Training Accuracy: 0.8438, Validation Accuracy: 0.8090\n",
      "Epoch [247/500], Training Loss: 0.3492, Validation Loss: 0.5649, Training Accuracy: 0.8462, Validation Accuracy: 0.7978\n",
      "Epoch [248/500], Training Loss: 0.3295, Validation Loss: 0.6057, Training Accuracy: 0.8425, Validation Accuracy: 0.7978\n",
      "Epoch [249/500], Training Loss: 0.3463, Validation Loss: 1.5805, Training Accuracy: 0.8488, Validation Accuracy: 0.7753\n",
      "Epoch [250/500], Training Loss: 0.4375, Validation Loss: 0.4258, Training Accuracy: 0.8313, Validation Accuracy: 0.7978\n",
      "Epoch [251/500], Training Loss: 0.3199, Validation Loss: 0.4653, Training Accuracy: 0.8550, Validation Accuracy: 0.8315\n",
      "Epoch [252/500], Training Loss: 0.3813, Validation Loss: 1.5716, Training Accuracy: 0.8337, Validation Accuracy: 0.8090\n",
      "Epoch [253/500], Training Loss: 0.3527, Validation Loss: 0.4935, Training Accuracy: 0.8462, Validation Accuracy: 0.7753\n",
      "Epoch [254/500], Training Loss: 0.3817, Validation Loss: 1.5355, Training Accuracy: 0.8175, Validation Accuracy: 0.7753\n",
      "Epoch [255/500], Training Loss: 0.3671, Validation Loss: 1.4447, Training Accuracy: 0.8125, Validation Accuracy: 0.8090\n",
      "Epoch [256/500], Training Loss: 0.5215, Validation Loss: 1.4516, Training Accuracy: 0.8137, Validation Accuracy: 0.8539\n",
      "Epoch [257/500], Training Loss: 0.4201, Validation Loss: 1.3611, Training Accuracy: 0.8538, Validation Accuracy: 0.8539\n",
      "Epoch [258/500], Training Loss: 0.3227, Validation Loss: 0.5152, Training Accuracy: 0.8438, Validation Accuracy: 0.8539\n",
      "Epoch [259/500], Training Loss: 0.4118, Validation Loss: 0.4538, Training Accuracy: 0.8300, Validation Accuracy: 0.8427\n",
      "Epoch [260/500], Training Loss: 0.3614, Validation Loss: 0.4615, Training Accuracy: 0.8525, Validation Accuracy: 0.8315\n",
      "Epoch [261/500], Training Loss: 0.3564, Validation Loss: 0.5468, Training Accuracy: 0.8475, Validation Accuracy: 0.8202\n",
      "Epoch [262/500], Training Loss: 0.3484, Validation Loss: 1.6555, Training Accuracy: 0.8350, Validation Accuracy: 0.7753\n",
      "Epoch [263/500], Training Loss: 0.3606, Validation Loss: 1.6846, Training Accuracy: 0.8387, Validation Accuracy: 0.7978\n",
      "Epoch [264/500], Training Loss: 0.3380, Validation Loss: 1.4903, Training Accuracy: 0.8337, Validation Accuracy: 0.8315\n",
      "Epoch [265/500], Training Loss: 0.3856, Validation Loss: 0.5253, Training Accuracy: 0.8425, Validation Accuracy: 0.8090\n",
      "Epoch [266/500], Training Loss: 0.3689, Validation Loss: 1.4914, Training Accuracy: 0.8300, Validation Accuracy: 0.8090\n",
      "Epoch [267/500], Training Loss: 0.4593, Validation Loss: 1.5306, Training Accuracy: 0.8475, Validation Accuracy: 0.8090\n",
      "Epoch [268/500], Training Loss: 0.3010, Validation Loss: 1.4448, Training Accuracy: 0.8612, Validation Accuracy: 0.8090\n",
      "Epoch [269/500], Training Loss: 0.5319, Validation Loss: 1.3968, Training Accuracy: 0.8400, Validation Accuracy: 0.8427\n",
      "Epoch [270/500], Training Loss: 0.4826, Validation Loss: 1.3523, Training Accuracy: 0.8313, Validation Accuracy: 0.8427\n",
      "Epoch [271/500], Training Loss: 0.3385, Validation Loss: 1.3967, Training Accuracy: 0.8462, Validation Accuracy: 0.8427\n",
      "Epoch [272/500], Training Loss: 0.6338, Validation Loss: 0.4967, Training Accuracy: 0.8425, Validation Accuracy: 0.7753\n",
      "Epoch [273/500], Training Loss: 0.4992, Validation Loss: 2.4768, Training Accuracy: 0.8337, Validation Accuracy: 0.7865\n",
      "Epoch [274/500], Training Loss: 0.3875, Validation Loss: 0.6237, Training Accuracy: 0.8287, Validation Accuracy: 0.8090\n",
      "Epoch [275/500], Training Loss: 0.3734, Validation Loss: 0.4374, Training Accuracy: 0.8488, Validation Accuracy: 0.8202\n",
      "Epoch [276/500], Training Loss: 0.3281, Validation Loss: 0.5227, Training Accuracy: 0.8475, Validation Accuracy: 0.8427\n",
      "Epoch [277/500], Training Loss: 0.4734, Validation Loss: 0.4881, Training Accuracy: 0.8387, Validation Accuracy: 0.8090\n",
      "Epoch [278/500], Training Loss: 0.3637, Validation Loss: 0.4517, Training Accuracy: 0.8475, Validation Accuracy: 0.8202\n",
      "Epoch [279/500], Training Loss: 0.4278, Validation Loss: 0.4362, Training Accuracy: 0.8237, Validation Accuracy: 0.7640\n",
      "Epoch [280/500], Training Loss: 0.3318, Validation Loss: 0.4346, Training Accuracy: 0.8350, Validation Accuracy: 0.7978\n",
      "Epoch [281/500], Training Loss: 0.3276, Validation Loss: 0.4732, Training Accuracy: 0.8363, Validation Accuracy: 0.7978\n",
      "Epoch [282/500], Training Loss: 0.4352, Validation Loss: 1.3823, Training Accuracy: 0.8287, Validation Accuracy: 0.7753\n",
      "Epoch [283/500], Training Loss: 0.4148, Validation Loss: 0.8075, Training Accuracy: 0.8275, Validation Accuracy: 0.7528\n",
      "Epoch [284/500], Training Loss: 0.4903, Validation Loss: 1.4174, Training Accuracy: 0.8363, Validation Accuracy: 0.7865\n",
      "Epoch [285/500], Training Loss: 0.3835, Validation Loss: 1.4331, Training Accuracy: 0.8400, Validation Accuracy: 0.7865\n",
      "Epoch [286/500], Training Loss: 0.5129, Validation Loss: 1.4323, Training Accuracy: 0.8275, Validation Accuracy: 0.7978\n",
      "Epoch [287/500], Training Loss: 0.3856, Validation Loss: 0.4501, Training Accuracy: 0.8275, Validation Accuracy: 0.7978\n",
      "Epoch [288/500], Training Loss: 0.3490, Validation Loss: 0.4836, Training Accuracy: 0.8425, Validation Accuracy: 0.7978\n",
      "Epoch [289/500], Training Loss: 0.3817, Validation Loss: 0.5435, Training Accuracy: 0.8287, Validation Accuracy: 0.7528\n",
      "Epoch [290/500], Training Loss: 0.3914, Validation Loss: 0.4769, Training Accuracy: 0.8375, Validation Accuracy: 0.7640\n",
      "Epoch [291/500], Training Loss: 0.5466, Validation Loss: 0.5158, Training Accuracy: 0.8175, Validation Accuracy: 0.7865\n",
      "Epoch [292/500], Training Loss: 0.3807, Validation Loss: 0.4366, Training Accuracy: 0.8313, Validation Accuracy: 0.7753\n",
      "Epoch [293/500], Training Loss: 0.3294, Validation Loss: 0.4537, Training Accuracy: 0.8438, Validation Accuracy: 0.8090\n",
      "Epoch [294/500], Training Loss: 0.3881, Validation Loss: 0.3701, Training Accuracy: 0.8313, Validation Accuracy: 0.8090\n",
      "Epoch [295/500], Training Loss: 0.3789, Validation Loss: 0.3526, Training Accuracy: 0.8462, Validation Accuracy: 0.8202\n",
      "Epoch [296/500], Training Loss: 0.3447, Validation Loss: 0.3827, Training Accuracy: 0.8488, Validation Accuracy: 0.8202\n",
      "Epoch [297/500], Training Loss: 0.5511, Validation Loss: 0.4556, Training Accuracy: 0.8250, Validation Accuracy: 0.8090\n",
      "Epoch [298/500], Training Loss: 0.3995, Validation Loss: 0.4366, Training Accuracy: 0.8250, Validation Accuracy: 0.8427\n",
      "Epoch [299/500], Training Loss: 0.3566, Validation Loss: 0.4092, Training Accuracy: 0.8512, Validation Accuracy: 0.8315\n",
      "Epoch [300/500], Training Loss: 0.3799, Validation Loss: 0.3883, Training Accuracy: 0.8387, Validation Accuracy: 0.8427\n",
      "Epoch [301/500], Training Loss: 0.3349, Validation Loss: 0.3735, Training Accuracy: 0.8438, Validation Accuracy: 0.8315\n",
      "Epoch [302/500], Training Loss: 0.3524, Validation Loss: 0.5335, Training Accuracy: 0.8287, Validation Accuracy: 0.8427\n",
      "Epoch [303/500], Training Loss: 0.3630, Validation Loss: 0.3557, Training Accuracy: 0.8512, Validation Accuracy: 0.8427\n",
      "Epoch [304/500], Training Loss: 0.3328, Validation Loss: 0.3814, Training Accuracy: 0.8475, Validation Accuracy: 0.8427\n",
      "Epoch [305/500], Training Loss: 0.3747, Validation Loss: 0.5038, Training Accuracy: 0.8300, Validation Accuracy: 0.8202\n",
      "Epoch [306/500], Training Loss: 0.4993, Validation Loss: 2.4089, Training Accuracy: 0.8237, Validation Accuracy: 0.8539\n",
      "Epoch [307/500], Training Loss: 0.3423, Validation Loss: 0.5324, Training Accuracy: 0.8538, Validation Accuracy: 0.8539\n",
      "Epoch [308/500], Training Loss: 0.4621, Validation Loss: 0.5080, Training Accuracy: 0.8462, Validation Accuracy: 0.8539\n",
      "Epoch [309/500], Training Loss: 0.4972, Validation Loss: 0.5382, Training Accuracy: 0.8575, Validation Accuracy: 0.8539\n",
      "Epoch [310/500], Training Loss: 0.3744, Validation Loss: 1.3571, Training Accuracy: 0.8450, Validation Accuracy: 0.8427\n",
      "Epoch [311/500], Training Loss: 0.3549, Validation Loss: 0.5087, Training Accuracy: 0.8413, Validation Accuracy: 0.8427\n",
      "Epoch [312/500], Training Loss: 0.3329, Validation Loss: 0.5794, Training Accuracy: 0.8488, Validation Accuracy: 0.8539\n",
      "Epoch [313/500], Training Loss: 0.4717, Validation Loss: 0.3916, Training Accuracy: 0.8363, Validation Accuracy: 0.8539\n",
      "Epoch [314/500], Training Loss: 0.4230, Validation Loss: 0.4994, Training Accuracy: 0.8400, Validation Accuracy: 0.8202\n",
      "Epoch [315/500], Training Loss: 0.4057, Validation Loss: 0.4540, Training Accuracy: 0.8363, Validation Accuracy: 0.8315\n",
      "Epoch [316/500], Training Loss: 0.3366, Validation Loss: 0.4815, Training Accuracy: 0.8538, Validation Accuracy: 0.8090\n",
      "Epoch [317/500], Training Loss: 0.3300, Validation Loss: 0.4297, Training Accuracy: 0.8462, Validation Accuracy: 0.8090\n",
      "Epoch [318/500], Training Loss: 0.3681, Validation Loss: 0.4155, Training Accuracy: 0.8450, Validation Accuracy: 0.8427\n",
      "Epoch [319/500], Training Loss: 0.3356, Validation Loss: 0.3588, Training Accuracy: 0.8625, Validation Accuracy: 0.8539\n",
      "Epoch [320/500], Training Loss: 0.5987, Validation Loss: 1.3883, Training Accuracy: 0.8462, Validation Accuracy: 0.8427\n",
      "Epoch [321/500], Training Loss: 0.4833, Validation Loss: 1.4499, Training Accuracy: 0.8363, Validation Accuracy: 0.8315\n",
      "Epoch [322/500], Training Loss: 0.5960, Validation Loss: 1.4068, Training Accuracy: 0.8462, Validation Accuracy: 0.8427\n",
      "Epoch [323/500], Training Loss: 0.5466, Validation Loss: 1.4154, Training Accuracy: 0.8400, Validation Accuracy: 0.8427\n",
      "Epoch [324/500], Training Loss: 0.4698, Validation Loss: 0.4226, Training Accuracy: 0.8500, Validation Accuracy: 0.8539\n",
      "Epoch [325/500], Training Loss: 0.3253, Validation Loss: 0.4406, Training Accuracy: 0.8450, Validation Accuracy: 0.8539\n",
      "Epoch [326/500], Training Loss: 0.4395, Validation Loss: 0.5096, Training Accuracy: 0.8525, Validation Accuracy: 0.8315\n",
      "Epoch [327/500], Training Loss: 0.2971, Validation Loss: 0.4843, Training Accuracy: 0.8500, Validation Accuracy: 0.8315\n",
      "Epoch [328/500], Training Loss: 0.4418, Validation Loss: 2.4354, Training Accuracy: 0.8588, Validation Accuracy: 0.8539\n",
      "Epoch [329/500], Training Loss: 0.3484, Validation Loss: 0.5499, Training Accuracy: 0.8588, Validation Accuracy: 0.8315\n",
      "Epoch [330/500], Training Loss: 0.3336, Validation Loss: 1.4550, Training Accuracy: 0.8562, Validation Accuracy: 0.8427\n",
      "Epoch [331/500], Training Loss: 0.5419, Validation Loss: 2.4151, Training Accuracy: 0.8625, Validation Accuracy: 0.8315\n",
      "Epoch [332/500], Training Loss: 0.7364, Validation Loss: 1.5115, Training Accuracy: 0.8425, Validation Accuracy: 0.7978\n",
      "Epoch [333/500], Training Loss: 0.3708, Validation Loss: 1.3918, Training Accuracy: 0.8512, Validation Accuracy: 0.8315\n",
      "Epoch [334/500], Training Loss: 0.6378, Validation Loss: 1.4745, Training Accuracy: 0.8438, Validation Accuracy: 0.8315\n",
      "Epoch [335/500], Training Loss: 0.6946, Validation Loss: 1.4082, Training Accuracy: 0.8413, Validation Accuracy: 0.8315\n",
      "Epoch [336/500], Training Loss: 0.3771, Validation Loss: 2.5090, Training Accuracy: 0.8413, Validation Accuracy: 0.8202\n",
      "Epoch [337/500], Training Loss: 0.6282, Validation Loss: 0.5518, Training Accuracy: 0.8488, Validation Accuracy: 0.8202\n",
      "Epoch [338/500], Training Loss: 0.5159, Validation Loss: 0.4721, Training Accuracy: 0.8350, Validation Accuracy: 0.8202\n",
      "Epoch [339/500], Training Loss: 0.3861, Validation Loss: 1.6221, Training Accuracy: 0.8325, Validation Accuracy: 0.7978\n",
      "Epoch [340/500], Training Loss: 0.3416, Validation Loss: 1.5233, Training Accuracy: 0.8250, Validation Accuracy: 0.8202\n",
      "Epoch [341/500], Training Loss: 0.4535, Validation Loss: 2.5136, Training Accuracy: 0.8600, Validation Accuracy: 0.7978\n",
      "Epoch [342/500], Training Loss: 0.6162, Validation Loss: 0.6225, Training Accuracy: 0.8350, Validation Accuracy: 0.7978\n",
      "Epoch [343/500], Training Loss: 0.3878, Validation Loss: 0.5222, Training Accuracy: 0.8387, Validation Accuracy: 0.8090\n",
      "Epoch [344/500], Training Loss: 0.4604, Validation Loss: 0.5539, Training Accuracy: 0.8538, Validation Accuracy: 0.8090\n",
      "Epoch [345/500], Training Loss: 0.3359, Validation Loss: 0.4617, Training Accuracy: 0.8575, Validation Accuracy: 0.8315\n",
      "Epoch [346/500], Training Loss: 0.4773, Validation Loss: 0.4822, Training Accuracy: 0.8475, Validation Accuracy: 0.8315\n",
      "Epoch [347/500], Training Loss: 0.5254, Validation Loss: 0.5113, Training Accuracy: 0.8512, Validation Accuracy: 0.8202\n",
      "Epoch [348/500], Training Loss: 0.4347, Validation Loss: 1.4097, Training Accuracy: 0.8625, Validation Accuracy: 0.8202\n",
      "Epoch [349/500], Training Loss: 0.5098, Validation Loss: 0.5432, Training Accuracy: 0.8450, Validation Accuracy: 0.7865\n",
      "Epoch [350/500], Training Loss: 0.3759, Validation Loss: 0.5859, Training Accuracy: 0.8400, Validation Accuracy: 0.7865\n",
      "Epoch [351/500], Training Loss: 0.4516, Validation Loss: 0.5242, Training Accuracy: 0.8488, Validation Accuracy: 0.7978\n",
      "Epoch [352/500], Training Loss: 0.3103, Validation Loss: 0.5910, Training Accuracy: 0.8525, Validation Accuracy: 0.8202\n",
      "Epoch [353/500], Training Loss: 0.3896, Validation Loss: 0.5691, Training Accuracy: 0.8413, Validation Accuracy: 0.7978\n",
      "Epoch [354/500], Training Loss: 0.4408, Validation Loss: 0.4929, Training Accuracy: 0.8450, Validation Accuracy: 0.8202\n",
      "Epoch [355/500], Training Loss: 0.5379, Validation Loss: 0.5564, Training Accuracy: 0.8625, Validation Accuracy: 0.8090\n",
      "Epoch [356/500], Training Loss: 0.3877, Validation Loss: 0.4863, Training Accuracy: 0.8313, Validation Accuracy: 0.7865\n",
      "Epoch [357/500], Training Loss: 0.3831, Validation Loss: 0.5013, Training Accuracy: 0.8538, Validation Accuracy: 0.7753\n",
      "Epoch [358/500], Training Loss: 0.3456, Validation Loss: 0.5561, Training Accuracy: 0.8287, Validation Accuracy: 0.7978\n",
      "Epoch [359/500], Training Loss: 0.3345, Validation Loss: 0.5024, Training Accuracy: 0.8450, Validation Accuracy: 0.8202\n",
      "Epoch [360/500], Training Loss: 0.4422, Validation Loss: 0.5430, Training Accuracy: 0.8488, Validation Accuracy: 0.8315\n",
      "Epoch [361/500], Training Loss: 0.4565, Validation Loss: 0.5441, Training Accuracy: 0.8538, Validation Accuracy: 0.8090\n",
      "Epoch [362/500], Training Loss: 0.3345, Validation Loss: 0.4405, Training Accuracy: 0.8512, Validation Accuracy: 0.8652\n",
      "Epoch [363/500], Training Loss: 0.3663, Validation Loss: 0.4645, Training Accuracy: 0.8475, Validation Accuracy: 0.8427\n",
      "Epoch [364/500], Training Loss: 0.4299, Validation Loss: 1.4654, Training Accuracy: 0.8588, Validation Accuracy: 0.8090\n",
      "Epoch [365/500], Training Loss: 0.3029, Validation Loss: 0.4963, Training Accuracy: 0.8575, Validation Accuracy: 0.8202\n",
      "Epoch [366/500], Training Loss: 0.3424, Validation Loss: 0.4733, Training Accuracy: 0.8400, Validation Accuracy: 0.8427\n",
      "Epoch [367/500], Training Loss: 0.3186, Validation Loss: 1.4270, Training Accuracy: 0.8538, Validation Accuracy: 0.8427\n",
      "Epoch [368/500], Training Loss: 0.3411, Validation Loss: 0.4768, Training Accuracy: 0.8525, Validation Accuracy: 0.8539\n",
      "Epoch [369/500], Training Loss: 0.3928, Validation Loss: 0.4127, Training Accuracy: 0.8300, Validation Accuracy: 0.7978\n",
      "Epoch [370/500], Training Loss: 0.3450, Validation Loss: 0.3619, Training Accuracy: 0.8375, Validation Accuracy: 0.8427\n",
      "Epoch [371/500], Training Loss: 0.3399, Validation Loss: 0.4172, Training Accuracy: 0.8488, Validation Accuracy: 0.8427\n",
      "Epoch [372/500], Training Loss: 0.5116, Validation Loss: 0.4955, Training Accuracy: 0.8337, Validation Accuracy: 0.8202\n",
      "Epoch [373/500], Training Loss: 0.3535, Validation Loss: 0.4063, Training Accuracy: 0.8462, Validation Accuracy: 0.8427\n",
      "Epoch [374/500], Training Loss: 0.3098, Validation Loss: 0.5511, Training Accuracy: 0.8612, Validation Accuracy: 0.8202\n",
      "Epoch [375/500], Training Loss: 0.3217, Validation Loss: 0.4126, Training Accuracy: 0.8575, Validation Accuracy: 0.8427\n",
      "Epoch [376/500], Training Loss: 0.3325, Validation Loss: 0.3778, Training Accuracy: 0.8475, Validation Accuracy: 0.8315\n",
      "Epoch [377/500], Training Loss: 0.4761, Validation Loss: 0.3940, Training Accuracy: 0.8538, Validation Accuracy: 0.8539\n",
      "Epoch [378/500], Training Loss: 0.3494, Validation Loss: 0.4072, Training Accuracy: 0.8337, Validation Accuracy: 0.8539\n",
      "Epoch [379/500], Training Loss: 0.3515, Validation Loss: 0.3948, Training Accuracy: 0.8488, Validation Accuracy: 0.8202\n",
      "Epoch [380/500], Training Loss: 0.3252, Validation Loss: 0.3341, Training Accuracy: 0.8638, Validation Accuracy: 0.8652\n",
      "Epoch [381/500], Training Loss: 0.4658, Validation Loss: 0.3775, Training Accuracy: 0.8525, Validation Accuracy: 0.8202\n",
      "Epoch [382/500], Training Loss: 0.2823, Validation Loss: 0.3934, Training Accuracy: 0.8650, Validation Accuracy: 0.8427\n",
      "Epoch [383/500], Training Loss: 0.3083, Validation Loss: 0.5498, Training Accuracy: 0.8600, Validation Accuracy: 0.8090\n",
      "Epoch [384/500], Training Loss: 0.2938, Validation Loss: 0.5304, Training Accuracy: 0.8612, Validation Accuracy: 0.7978\n",
      "Epoch [385/500], Training Loss: 0.3169, Validation Loss: 0.4923, Training Accuracy: 0.8588, Validation Accuracy: 0.8202\n",
      "Epoch [386/500], Training Loss: 0.2974, Validation Loss: 0.4568, Training Accuracy: 0.8625, Validation Accuracy: 0.8202\n",
      "Epoch [387/500], Training Loss: 0.3003, Validation Loss: 0.4834, Training Accuracy: 0.8600, Validation Accuracy: 0.8315\n",
      "Epoch [388/500], Training Loss: 0.3776, Validation Loss: 0.5145, Training Accuracy: 0.8512, Validation Accuracy: 0.8202\n",
      "Epoch [389/500], Training Loss: 0.5534, Validation Loss: 0.5845, Training Accuracy: 0.8512, Validation Accuracy: 0.8539\n",
      "Epoch [390/500], Training Loss: 0.3441, Validation Loss: 0.5028, Training Accuracy: 0.8525, Validation Accuracy: 0.8315\n",
      "Epoch [391/500], Training Loss: 0.4456, Validation Loss: 0.4296, Training Accuracy: 0.8638, Validation Accuracy: 0.8539\n",
      "Epoch [392/500], Training Loss: 0.3092, Validation Loss: 0.4380, Training Accuracy: 0.8688, Validation Accuracy: 0.8652\n",
      "Epoch [393/500], Training Loss: 0.3368, Validation Loss: 0.4132, Training Accuracy: 0.8625, Validation Accuracy: 0.8315\n",
      "Epoch [394/500], Training Loss: 0.3649, Validation Loss: 0.4447, Training Accuracy: 0.8562, Validation Accuracy: 0.8090\n",
      "Epoch [395/500], Training Loss: 0.2936, Validation Loss: 0.4706, Training Accuracy: 0.8612, Validation Accuracy: 0.8090\n",
      "Epoch [396/500], Training Loss: 0.3424, Validation Loss: 0.5601, Training Accuracy: 0.8450, Validation Accuracy: 0.8315\n",
      "Epoch [397/500], Training Loss: 0.4707, Validation Loss: 1.4120, Training Accuracy: 0.8313, Validation Accuracy: 0.8427\n",
      "Epoch [398/500], Training Loss: 0.5938, Validation Loss: 1.5434, Training Accuracy: 0.8275, Validation Accuracy: 0.8202\n",
      "Epoch [399/500], Training Loss: 0.3791, Validation Loss: 0.4364, Training Accuracy: 0.8400, Validation Accuracy: 0.8090\n",
      "Epoch [400/500], Training Loss: 0.3445, Validation Loss: 0.5382, Training Accuracy: 0.8413, Validation Accuracy: 0.8315\n",
      "Epoch [401/500], Training Loss: 0.3716, Validation Loss: 0.3918, Training Accuracy: 0.8363, Validation Accuracy: 0.8427\n",
      "Epoch [402/500], Training Loss: 0.3741, Validation Loss: 0.4530, Training Accuracy: 0.8300, Validation Accuracy: 0.8315\n",
      "Epoch [403/500], Training Loss: 0.3318, Validation Loss: 0.4264, Training Accuracy: 0.8375, Validation Accuracy: 0.8427\n",
      "Epoch [404/500], Training Loss: 0.3746, Validation Loss: 0.5556, Training Accuracy: 0.8500, Validation Accuracy: 0.8202\n",
      "Epoch [405/500], Training Loss: 0.4695, Validation Loss: 0.4973, Training Accuracy: 0.8325, Validation Accuracy: 0.8427\n",
      "Epoch [406/500], Training Loss: 0.3611, Validation Loss: 0.5536, Training Accuracy: 0.8313, Validation Accuracy: 0.8090\n",
      "Epoch [407/500], Training Loss: 0.4749, Validation Loss: 0.5230, Training Accuracy: 0.8237, Validation Accuracy: 0.8090\n",
      "Epoch [408/500], Training Loss: 0.3688, Validation Loss: 0.4716, Training Accuracy: 0.8400, Validation Accuracy: 0.7865\n",
      "Epoch [409/500], Training Loss: 0.3811, Validation Loss: 0.4828, Training Accuracy: 0.8363, Validation Accuracy: 0.8090\n",
      "Epoch [410/500], Training Loss: 0.4579, Validation Loss: 0.5094, Training Accuracy: 0.8400, Validation Accuracy: 0.7978\n",
      "Epoch [411/500], Training Loss: 0.3153, Validation Loss: 0.5585, Training Accuracy: 0.8600, Validation Accuracy: 0.8202\n",
      "Epoch [412/500], Training Loss: 0.3401, Validation Loss: 0.4816, Training Accuracy: 0.8538, Validation Accuracy: 0.8090\n",
      "Epoch [413/500], Training Loss: 0.4449, Validation Loss: 1.4579, Training Accuracy: 0.8588, Validation Accuracy: 0.7978\n",
      "Epoch [414/500], Training Loss: 0.3775, Validation Loss: 0.5379, Training Accuracy: 0.8287, Validation Accuracy: 0.8090\n",
      "Epoch [415/500], Training Loss: 0.4553, Validation Loss: 1.5395, Training Accuracy: 0.8512, Validation Accuracy: 0.7978\n",
      "Epoch [416/500], Training Loss: 0.4919, Validation Loss: 1.4593, Training Accuracy: 0.8363, Validation Accuracy: 0.8315\n",
      "Epoch [417/500], Training Loss: 0.3775, Validation Loss: 1.5051, Training Accuracy: 0.8337, Validation Accuracy: 0.8090\n",
      "Epoch [418/500], Training Loss: 0.3665, Validation Loss: 0.4009, Training Accuracy: 0.8425, Validation Accuracy: 0.8315\n",
      "Epoch [419/500], Training Loss: 0.3446, Validation Loss: 0.3582, Training Accuracy: 0.8538, Validation Accuracy: 0.8202\n",
      "Epoch [420/500], Training Loss: 0.4670, Validation Loss: 1.3559, Training Accuracy: 0.8275, Validation Accuracy: 0.8315\n",
      "Epoch [421/500], Training Loss: 0.4225, Validation Loss: 1.3721, Training Accuracy: 0.8500, Validation Accuracy: 0.8090\n",
      "Epoch [422/500], Training Loss: 0.3350, Validation Loss: 0.4802, Training Accuracy: 0.8425, Validation Accuracy: 0.8315\n",
      "Epoch [423/500], Training Loss: 0.3244, Validation Loss: 1.3798, Training Accuracy: 0.8538, Validation Accuracy: 0.8315\n",
      "Epoch [424/500], Training Loss: 0.4359, Validation Loss: 0.3579, Training Accuracy: 0.8662, Validation Accuracy: 0.8315\n",
      "Epoch [425/500], Training Loss: 0.2965, Validation Loss: 0.3448, Training Accuracy: 0.8650, Validation Accuracy: 0.8202\n",
      "Epoch [426/500], Training Loss: 0.2625, Validation Loss: 0.3782, Training Accuracy: 0.8712, Validation Accuracy: 0.8427\n",
      "Epoch [427/500], Training Loss: 0.3361, Validation Loss: 0.4119, Training Accuracy: 0.8475, Validation Accuracy: 0.8315\n",
      "Epoch [428/500], Training Loss: 0.3233, Validation Loss: 0.4225, Training Accuracy: 0.8500, Validation Accuracy: 0.8427\n",
      "Epoch [429/500], Training Loss: 0.3175, Validation Loss: 1.3213, Training Accuracy: 0.8650, Validation Accuracy: 0.8427\n",
      "Epoch [430/500], Training Loss: 0.3495, Validation Loss: 0.3789, Training Accuracy: 0.8575, Validation Accuracy: 0.8315\n",
      "Epoch [431/500], Training Loss: 0.4717, Validation Loss: 0.4609, Training Accuracy: 0.8550, Validation Accuracy: 0.8315\n",
      "Epoch [432/500], Training Loss: 0.3308, Validation Loss: 0.3911, Training Accuracy: 0.8538, Validation Accuracy: 0.8539\n",
      "Epoch [433/500], Training Loss: 0.4604, Validation Loss: 0.3958, Training Accuracy: 0.8500, Validation Accuracy: 0.8427\n",
      "Epoch [434/500], Training Loss: 0.4061, Validation Loss: 0.4003, Training Accuracy: 0.8475, Validation Accuracy: 0.8315\n",
      "Epoch [435/500], Training Loss: 0.3753, Validation Loss: 0.3776, Training Accuracy: 0.8387, Validation Accuracy: 0.8427\n",
      "Epoch [436/500], Training Loss: 0.3824, Validation Loss: 0.4799, Training Accuracy: 0.8337, Validation Accuracy: 0.8315\n",
      "Epoch [437/500], Training Loss: 0.3600, Validation Loss: 0.4123, Training Accuracy: 0.8363, Validation Accuracy: 0.8427\n",
      "Epoch [438/500], Training Loss: 0.4500, Validation Loss: 1.4584, Training Accuracy: 0.8525, Validation Accuracy: 0.8202\n",
      "Epoch [439/500], Training Loss: 0.4575, Validation Loss: 0.5218, Training Accuracy: 0.8575, Validation Accuracy: 0.8315\n",
      "Epoch [440/500], Training Loss: 0.3248, Validation Loss: 1.4219, Training Accuracy: 0.8588, Validation Accuracy: 0.8090\n",
      "Epoch [441/500], Training Loss: 0.3567, Validation Loss: 0.4512, Training Accuracy: 0.8438, Validation Accuracy: 0.8427\n",
      "Epoch [442/500], Training Loss: 0.3571, Validation Loss: 0.4999, Training Accuracy: 0.8413, Validation Accuracy: 0.8202\n",
      "Epoch [443/500], Training Loss: 0.3587, Validation Loss: 1.3955, Training Accuracy: 0.8450, Validation Accuracy: 0.8315\n",
      "Epoch [444/500], Training Loss: 0.3667, Validation Loss: 1.3924, Training Accuracy: 0.8462, Validation Accuracy: 0.8315\n",
      "Epoch [445/500], Training Loss: 0.4687, Validation Loss: 1.3918, Training Accuracy: 0.8325, Validation Accuracy: 0.8090\n",
      "Epoch [446/500], Training Loss: 0.5539, Validation Loss: 1.3807, Training Accuracy: 0.8512, Validation Accuracy: 0.8202\n",
      "Epoch [447/500], Training Loss: 0.3009, Validation Loss: 1.3584, Training Accuracy: 0.8600, Validation Accuracy: 0.8427\n",
      "Epoch [448/500], Training Loss: 0.5566, Validation Loss: 1.3839, Training Accuracy: 0.8450, Validation Accuracy: 0.8315\n",
      "Epoch [449/500], Training Loss: 0.4897, Validation Loss: 1.3832, Training Accuracy: 0.8575, Validation Accuracy: 0.8202\n",
      "Epoch [450/500], Training Loss: 0.5876, Validation Loss: 1.5114, Training Accuracy: 0.8612, Validation Accuracy: 0.8427\n",
      "Epoch [451/500], Training Loss: 0.5419, Validation Loss: 1.4769, Training Accuracy: 0.8363, Validation Accuracy: 0.8315\n",
      "Epoch [452/500], Training Loss: 0.3311, Validation Loss: 0.5325, Training Accuracy: 0.8500, Validation Accuracy: 0.8090\n",
      "Epoch [453/500], Training Loss: 0.4624, Validation Loss: 0.5789, Training Accuracy: 0.8462, Validation Accuracy: 0.8202\n",
      "Epoch [454/500], Training Loss: 0.5852, Validation Loss: 1.5425, Training Accuracy: 0.8313, Validation Accuracy: 0.8202\n",
      "Epoch [455/500], Training Loss: 0.4408, Validation Loss: 0.5560, Training Accuracy: 0.8538, Validation Accuracy: 0.8315\n",
      "Epoch [456/500], Training Loss: 0.3519, Validation Loss: 0.5163, Training Accuracy: 0.8413, Validation Accuracy: 0.8202\n",
      "Epoch [457/500], Training Loss: 0.5748, Validation Loss: 1.5562, Training Accuracy: 0.8263, Validation Accuracy: 0.8315\n",
      "Epoch [458/500], Training Loss: 0.6125, Validation Loss: 1.3937, Training Accuracy: 0.8538, Validation Accuracy: 0.8090\n",
      "Epoch [459/500], Training Loss: 0.5783, Validation Loss: 1.4791, Training Accuracy: 0.8425, Validation Accuracy: 0.8315\n",
      "Epoch [460/500], Training Loss: 0.3240, Validation Loss: 1.3573, Training Accuracy: 0.8612, Validation Accuracy: 0.8427\n",
      "Epoch [461/500], Training Loss: 0.3435, Validation Loss: 1.3519, Training Accuracy: 0.8550, Validation Accuracy: 0.8315\n",
      "Epoch [462/500], Training Loss: 0.3575, Validation Loss: 1.3451, Training Accuracy: 0.8500, Validation Accuracy: 0.8427\n",
      "Epoch [463/500], Training Loss: 0.4296, Validation Loss: 1.4272, Training Accuracy: 0.8375, Validation Accuracy: 0.8315\n",
      "Epoch [464/500], Training Loss: 0.3246, Validation Loss: 1.6063, Training Accuracy: 0.8413, Validation Accuracy: 0.8427\n",
      "Epoch [465/500], Training Loss: 0.5350, Validation Loss: 1.6120, Training Accuracy: 0.8287, Validation Accuracy: 0.8090\n",
      "Epoch [466/500], Training Loss: 0.3854, Validation Loss: 1.4767, Training Accuracy: 0.8187, Validation Accuracy: 0.8315\n",
      "Epoch [467/500], Training Loss: 0.3892, Validation Loss: 0.5789, Training Accuracy: 0.8375, Validation Accuracy: 0.8202\n",
      "Epoch [468/500], Training Loss: 0.2986, Validation Loss: 2.5298, Training Accuracy: 0.8575, Validation Accuracy: 0.8315\n",
      "Epoch [469/500], Training Loss: 0.2953, Validation Loss: 2.5062, Training Accuracy: 0.8638, Validation Accuracy: 0.8427\n",
      "Epoch [470/500], Training Loss: 0.3877, Validation Loss: 1.5212, Training Accuracy: 0.8462, Validation Accuracy: 0.8315\n",
      "Epoch [471/500], Training Loss: 0.3206, Validation Loss: 1.5096, Training Accuracy: 0.8612, Validation Accuracy: 0.8427\n",
      "Epoch [472/500], Training Loss: 0.3240, Validation Loss: 2.4389, Training Accuracy: 0.8562, Validation Accuracy: 0.8539\n",
      "Epoch [473/500], Training Loss: 0.3000, Validation Loss: 0.5228, Training Accuracy: 0.8512, Validation Accuracy: 0.8202\n",
      "Epoch [474/500], Training Loss: 0.2877, Validation Loss: 0.5999, Training Accuracy: 0.8575, Validation Accuracy: 0.8315\n",
      "Epoch [475/500], Training Loss: 0.4005, Validation Loss: 1.4949, Training Accuracy: 0.8662, Validation Accuracy: 0.8652\n",
      "Epoch [476/500], Training Loss: 0.2929, Validation Loss: 0.5399, Training Accuracy: 0.8625, Validation Accuracy: 0.8315\n",
      "Epoch [477/500], Training Loss: 0.5182, Validation Loss: 1.5266, Training Accuracy: 0.8662, Validation Accuracy: 0.8427\n",
      "Epoch [478/500], Training Loss: 0.3120, Validation Loss: 1.5649, Training Accuracy: 0.8638, Validation Accuracy: 0.8427\n",
      "Epoch [479/500], Training Loss: 0.2979, Validation Loss: 0.5091, Training Accuracy: 0.8712, Validation Accuracy: 0.8427\n",
      "Epoch [480/500], Training Loss: 0.3299, Validation Loss: 0.4832, Training Accuracy: 0.8562, Validation Accuracy: 0.8202\n",
      "Epoch [481/500], Training Loss: 0.3910, Validation Loss: 0.5041, Training Accuracy: 0.8512, Validation Accuracy: 0.8427\n",
      "Epoch [482/500], Training Loss: 0.3058, Validation Loss: 0.5243, Training Accuracy: 0.8538, Validation Accuracy: 0.8427\n",
      "Epoch [483/500], Training Loss: 0.3457, Validation Loss: 1.5716, Training Accuracy: 0.8562, Validation Accuracy: 0.8315\n",
      "Epoch [484/500], Training Loss: 0.2787, Validation Loss: 0.5128, Training Accuracy: 0.8700, Validation Accuracy: 0.8315\n",
      "Epoch [485/500], Training Loss: 0.3542, Validation Loss: 0.4842, Training Accuracy: 0.8662, Validation Accuracy: 0.8652\n",
      "Epoch [486/500], Training Loss: 0.3184, Validation Loss: 0.5674, Training Accuracy: 0.8600, Validation Accuracy: 0.8315\n",
      "Epoch [487/500], Training Loss: 0.3033, Validation Loss: 1.6299, Training Accuracy: 0.8625, Validation Accuracy: 0.8427\n",
      "Epoch [488/500], Training Loss: 0.2983, Validation Loss: 0.4804, Training Accuracy: 0.8675, Validation Accuracy: 0.8427\n",
      "Epoch [489/500], Training Loss: 0.3474, Validation Loss: 1.4624, Training Accuracy: 0.8550, Validation Accuracy: 0.8315\n",
      "Epoch [490/500], Training Loss: 0.2997, Validation Loss: 1.4325, Training Accuracy: 0.8588, Validation Accuracy: 0.8427\n",
      "Epoch [491/500], Training Loss: 0.3236, Validation Loss: 0.3816, Training Accuracy: 0.8588, Validation Accuracy: 0.8539\n",
      "Epoch [492/500], Training Loss: 0.3083, Validation Loss: 0.3905, Training Accuracy: 0.8700, Validation Accuracy: 0.8427\n",
      "Epoch [493/500], Training Loss: 0.4359, Validation Loss: 0.5803, Training Accuracy: 0.8538, Validation Accuracy: 0.8315\n",
      "Epoch [494/500], Training Loss: 0.3328, Validation Loss: 1.4718, Training Accuracy: 0.8838, Validation Accuracy: 0.8427\n",
      "Epoch [495/500], Training Loss: 0.3662, Validation Loss: 0.4745, Training Accuracy: 0.8588, Validation Accuracy: 0.8202\n",
      "Epoch [496/500], Training Loss: 0.4193, Validation Loss: 1.4285, Training Accuracy: 0.8812, Validation Accuracy: 0.8202\n",
      "Epoch [497/500], Training Loss: 0.3405, Validation Loss: 0.3949, Training Accuracy: 0.8650, Validation Accuracy: 0.7978\n",
      "Epoch [498/500], Training Loss: 0.3266, Validation Loss: 1.4788, Training Accuracy: 0.8625, Validation Accuracy: 0.8090\n",
      "Epoch [499/500], Training Loss: 0.2938, Validation Loss: 0.4099, Training Accuracy: 0.8575, Validation Accuracy: 0.8315\n",
      "Epoch [500/500], Training Loss: 0.3155, Validation Loss: 1.3978, Training Accuracy: 0.8600, Validation Accuracy: 0.8202\n",
      "Training Time: 11.81 seconds\n",
      "Epoch [1/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [2/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [3/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [4/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [5/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [6/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [7/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [8/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [9/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [10/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [11/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [12/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [13/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [14/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [15/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [16/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [17/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [18/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [19/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [20/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [21/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [22/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [23/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [24/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [25/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [26/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [27/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [28/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [29/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [30/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [31/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [32/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [33/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [34/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [35/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [36/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [37/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [38/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [39/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [40/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [41/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [42/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [43/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [44/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [45/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [46/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [47/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [48/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [49/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [50/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [51/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [52/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [53/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [54/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [55/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [56/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [57/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [58/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [59/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [60/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [61/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [62/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [63/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [64/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [65/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [66/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [67/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [68/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [69/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [70/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [71/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [72/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [73/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [74/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [75/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [76/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [77/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [78/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [79/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [80/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [81/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [82/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [83/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [84/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [85/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [86/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [87/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [88/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [89/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [90/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [91/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [92/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [93/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [94/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [95/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [96/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [97/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [98/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [99/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [100/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [101/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [102/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [103/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [104/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [105/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [106/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [107/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [108/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [109/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [110/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [111/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [112/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [113/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [114/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [115/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [116/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [117/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [118/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [119/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [120/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [121/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [122/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [123/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [124/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [125/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [126/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [127/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [128/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [129/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [130/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [131/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [132/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [133/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [134/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [135/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [136/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [137/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [138/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [139/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [140/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [141/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [142/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [143/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [144/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [145/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [146/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [147/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [148/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [149/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [150/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [151/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [152/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [153/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [154/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [155/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [156/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [157/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [158/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [159/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [160/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [161/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [162/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [163/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [164/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [165/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [166/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [167/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [168/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [169/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [170/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [171/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [172/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [173/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [174/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [175/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [176/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [177/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [178/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [179/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [180/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [181/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [182/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [183/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [184/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [185/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [186/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [187/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [188/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [189/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [190/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [191/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [192/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [193/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [194/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [195/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [196/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [197/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [198/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [199/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [200/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [201/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [202/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [203/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [204/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [205/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [206/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [207/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [208/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [209/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [210/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [211/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [212/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [213/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [214/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [215/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [216/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [217/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [218/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [219/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [220/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [221/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [222/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [223/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [224/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [225/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [226/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [227/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [228/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [229/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [230/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [231/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [232/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [233/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [234/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [235/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [236/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [237/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [238/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [239/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [240/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [241/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [242/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [243/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [244/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [245/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [246/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [247/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [248/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [249/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [250/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [251/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [252/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [253/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [254/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [255/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [256/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [257/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [258/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [259/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [260/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [261/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [262/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [263/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [264/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [265/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [266/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [267/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [268/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [269/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [270/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [271/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [272/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [273/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [274/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [275/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [276/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [277/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [278/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [279/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [280/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [281/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [282/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [283/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [284/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [285/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [286/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [287/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [288/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [289/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [290/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [291/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [292/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [293/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [294/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [295/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [296/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [297/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [298/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [299/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [300/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [301/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [302/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [303/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [304/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [305/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [306/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [307/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [308/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [309/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [310/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [311/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [312/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [313/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [314/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [315/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [316/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [317/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [318/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [319/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [320/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [321/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [322/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [323/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [324/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [325/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [326/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [327/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [328/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [329/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [330/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [331/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [332/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [333/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [334/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [335/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [336/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [337/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [338/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [339/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [340/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [341/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [342/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [343/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [344/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [345/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [346/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [347/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [348/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [349/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [350/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [351/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [352/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [353/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [354/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [355/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [356/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [357/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [358/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [359/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [360/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [361/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [362/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [363/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [364/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [365/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [366/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [367/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [368/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [369/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [370/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [371/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [372/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [373/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [374/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [375/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [376/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [377/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [378/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [379/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [380/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [381/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [382/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [383/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [384/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [385/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [386/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [387/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [388/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [389/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [390/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [391/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [392/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [393/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [394/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [395/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [396/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [397/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [398/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [399/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [400/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [401/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [402/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [403/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [404/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [405/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [406/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [407/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [408/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [409/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [410/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [411/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [412/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [413/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [414/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [415/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [416/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [417/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [418/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [419/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [420/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [421/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [422/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [423/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [424/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [425/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [426/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [427/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [428/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [429/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [430/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [431/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [432/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [433/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [434/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [435/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [436/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [437/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [438/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [439/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [440/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [441/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [442/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [443/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [444/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [445/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [446/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [447/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [448/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [449/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [450/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [451/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [452/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [453/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [454/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [455/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [456/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [457/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [458/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [459/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [460/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [461/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [462/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [463/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [464/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [465/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [466/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [467/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [468/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [469/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [470/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [471/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [472/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [473/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [474/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [475/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [476/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [477/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [478/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [479/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [480/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [481/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [482/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [483/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [484/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [485/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [486/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [487/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [488/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [489/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [490/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [491/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [492/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [493/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [494/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [495/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [496/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [497/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [498/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [499/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [500/500], Test Loss: 1.5495, Testing Accuracy: 0.7879, \n",
      "Epoch [1/500], Training Loss: 0.6379, Validation Loss: 0.5086, Training Accuracy: 0.6600, Validation Accuracy: 0.7528\n",
      "Epoch [2/500], Training Loss: 0.5737, Validation Loss: 0.4887, Training Accuracy: 0.7113, Validation Accuracy: 0.7528\n",
      "Epoch [3/500], Training Loss: 0.5921, Validation Loss: 0.5069, Training Accuracy: 0.6813, Validation Accuracy: 0.7640\n",
      "Epoch [4/500], Training Loss: 0.5842, Validation Loss: 0.5017, Training Accuracy: 0.6950, Validation Accuracy: 0.7978\n",
      "Epoch [5/500], Training Loss: 0.6321, Validation Loss: 0.5459, Training Accuracy: 0.6887, Validation Accuracy: 0.7191\n",
      "Epoch [6/500], Training Loss: 0.6093, Validation Loss: 0.5107, Training Accuracy: 0.7300, Validation Accuracy: 0.7416\n",
      "Epoch [7/500], Training Loss: 0.6570, Validation Loss: 0.4907, Training Accuracy: 0.6850, Validation Accuracy: 0.7978\n",
      "Epoch [8/500], Training Loss: 0.7212, Validation Loss: 0.5212, Training Accuracy: 0.7238, Validation Accuracy: 0.7640\n",
      "Epoch [9/500], Training Loss: 0.5842, Validation Loss: 0.5289, Training Accuracy: 0.7037, Validation Accuracy: 0.7528\n",
      "Epoch [10/500], Training Loss: 0.5592, Validation Loss: 0.5197, Training Accuracy: 0.7150, Validation Accuracy: 0.7416\n",
      "Epoch [11/500], Training Loss: 0.5477, Validation Loss: 0.5157, Training Accuracy: 0.7262, Validation Accuracy: 0.7416\n",
      "Epoch [12/500], Training Loss: 0.6090, Validation Loss: 0.5163, Training Accuracy: 0.7013, Validation Accuracy: 0.7640\n",
      "Epoch [13/500], Training Loss: 0.5710, Validation Loss: 0.4557, Training Accuracy: 0.7188, Validation Accuracy: 0.7865\n",
      "Epoch [14/500], Training Loss: 0.5995, Validation Loss: 0.4766, Training Accuracy: 0.7262, Validation Accuracy: 0.7303\n",
      "Epoch [15/500], Training Loss: 0.6034, Validation Loss: 0.5253, Training Accuracy: 0.6863, Validation Accuracy: 0.7079\n",
      "Epoch [16/500], Training Loss: 0.6000, Validation Loss: 0.5167, Training Accuracy: 0.6825, Validation Accuracy: 0.7416\n",
      "Epoch [17/500], Training Loss: 0.5655, Validation Loss: 0.4929, Training Accuracy: 0.7212, Validation Accuracy: 0.6966\n",
      "Epoch [18/500], Training Loss: 0.6488, Validation Loss: 0.5492, Training Accuracy: 0.6975, Validation Accuracy: 0.7640\n",
      "Epoch [19/500], Training Loss: 0.6229, Validation Loss: 0.5364, Training Accuracy: 0.6875, Validation Accuracy: 0.7191\n",
      "Epoch [20/500], Training Loss: 0.5682, Validation Loss: 0.4843, Training Accuracy: 0.7013, Validation Accuracy: 0.7753\n",
      "Epoch [21/500], Training Loss: 0.6314, Validation Loss: 0.4960, Training Accuracy: 0.6950, Validation Accuracy: 0.7079\n",
      "Epoch [22/500], Training Loss: 0.5695, Validation Loss: 0.4911, Training Accuracy: 0.6950, Validation Accuracy: 0.7416\n",
      "Epoch [23/500], Training Loss: 0.5938, Validation Loss: 0.4970, Training Accuracy: 0.6813, Validation Accuracy: 0.7303\n",
      "Epoch [24/500], Training Loss: 0.5732, Validation Loss: 0.5186, Training Accuracy: 0.7262, Validation Accuracy: 0.6966\n",
      "Epoch [25/500], Training Loss: 0.5817, Validation Loss: 0.5424, Training Accuracy: 0.7238, Validation Accuracy: 0.6854\n",
      "Epoch [26/500], Training Loss: 0.5624, Validation Loss: 0.4930, Training Accuracy: 0.7238, Validation Accuracy: 0.7528\n",
      "Epoch [27/500], Training Loss: 0.5785, Validation Loss: 0.5016, Training Accuracy: 0.7025, Validation Accuracy: 0.7191\n",
      "Epoch [28/500], Training Loss: 0.5651, Validation Loss: 0.5543, Training Accuracy: 0.7000, Validation Accuracy: 0.7191\n",
      "Epoch [29/500], Training Loss: 0.5683, Validation Loss: 0.5795, Training Accuracy: 0.7288, Validation Accuracy: 0.6404\n",
      "Epoch [30/500], Training Loss: 0.5722, Validation Loss: 0.5249, Training Accuracy: 0.6850, Validation Accuracy: 0.7191\n",
      "Epoch [31/500], Training Loss: 0.5721, Validation Loss: 0.4867, Training Accuracy: 0.7013, Validation Accuracy: 0.7191\n",
      "Epoch [32/500], Training Loss: 0.4978, Validation Loss: 0.4932, Training Accuracy: 0.7400, Validation Accuracy: 0.7191\n",
      "Epoch [33/500], Training Loss: 0.5594, Validation Loss: 0.5652, Training Accuracy: 0.7325, Validation Accuracy: 0.6742\n",
      "Epoch [34/500], Training Loss: 0.5838, Validation Loss: 0.4801, Training Accuracy: 0.7013, Validation Accuracy: 0.6966\n",
      "Epoch [35/500], Training Loss: 0.5500, Validation Loss: 0.5020, Training Accuracy: 0.7325, Validation Accuracy: 0.6854\n",
      "Epoch [36/500], Training Loss: 0.5601, Validation Loss: 0.5389, Training Accuracy: 0.7262, Validation Accuracy: 0.6854\n",
      "Epoch [37/500], Training Loss: 0.5834, Validation Loss: 0.5315, Training Accuracy: 0.7037, Validation Accuracy: 0.6966\n",
      "Epoch [38/500], Training Loss: 0.6082, Validation Loss: 0.5909, Training Accuracy: 0.6875, Validation Accuracy: 0.6292\n",
      "Epoch [39/500], Training Loss: 0.6017, Validation Loss: 0.5323, Training Accuracy: 0.6913, Validation Accuracy: 0.6854\n",
      "Epoch [40/500], Training Loss: 0.6248, Validation Loss: 0.5498, Training Accuracy: 0.6863, Validation Accuracy: 0.6966\n",
      "Epoch [41/500], Training Loss: 0.5999, Validation Loss: 0.5267, Training Accuracy: 0.6913, Validation Accuracy: 0.7303\n",
      "Epoch [42/500], Training Loss: 0.5798, Validation Loss: 0.6000, Training Accuracy: 0.6975, Validation Accuracy: 0.6517\n",
      "Epoch [43/500], Training Loss: 0.5776, Validation Loss: 0.5186, Training Accuracy: 0.6950, Validation Accuracy: 0.6966\n",
      "Epoch [44/500], Training Loss: 0.6101, Validation Loss: 0.5380, Training Accuracy: 0.6925, Validation Accuracy: 0.7191\n",
      "Epoch [45/500], Training Loss: 0.5677, Validation Loss: 0.5292, Training Accuracy: 0.7150, Validation Accuracy: 0.6854\n",
      "Epoch [46/500], Training Loss: 0.5758, Validation Loss: 0.5890, Training Accuracy: 0.6875, Validation Accuracy: 0.7079\n",
      "Epoch [47/500], Training Loss: 0.7158, Validation Loss: 0.5152, Training Accuracy: 0.6837, Validation Accuracy: 0.7303\n",
      "Epoch [48/500], Training Loss: 0.5566, Validation Loss: 0.5112, Training Accuracy: 0.7100, Validation Accuracy: 0.7191\n",
      "Epoch [49/500], Training Loss: 0.5434, Validation Loss: 0.4936, Training Accuracy: 0.7137, Validation Accuracy: 0.7416\n",
      "Epoch [50/500], Training Loss: 0.5394, Validation Loss: 0.5179, Training Accuracy: 0.7350, Validation Accuracy: 0.7528\n",
      "Epoch [51/500], Training Loss: 0.5768, Validation Loss: 0.5280, Training Accuracy: 0.7025, Validation Accuracy: 0.6854\n",
      "Epoch [52/500], Training Loss: 0.7790, Validation Loss: 0.6072, Training Accuracy: 0.6887, Validation Accuracy: 0.6180\n",
      "Epoch [53/500], Training Loss: 0.6583, Validation Loss: 0.5678, Training Accuracy: 0.6162, Validation Accuracy: 0.6517\n",
      "Epoch [54/500], Training Loss: 0.5740, Validation Loss: 0.5237, Training Accuracy: 0.6825, Validation Accuracy: 0.6742\n",
      "Epoch [55/500], Training Loss: 0.6874, Validation Loss: 0.5405, Training Accuracy: 0.6875, Validation Accuracy: 0.6742\n",
      "Epoch [56/500], Training Loss: 0.5905, Validation Loss: 0.5527, Training Accuracy: 0.6763, Validation Accuracy: 0.6966\n",
      "Epoch [57/500], Training Loss: 0.5733, Validation Loss: 0.5605, Training Accuracy: 0.6875, Validation Accuracy: 0.6629\n",
      "Epoch [58/500], Training Loss: 0.6178, Validation Loss: 0.5683, Training Accuracy: 0.6800, Validation Accuracy: 0.6742\n",
      "Epoch [59/500], Training Loss: 0.5830, Validation Loss: 0.5319, Training Accuracy: 0.6950, Validation Accuracy: 0.7079\n",
      "Epoch [60/500], Training Loss: 0.6006, Validation Loss: 0.5137, Training Accuracy: 0.7288, Validation Accuracy: 0.7528\n",
      "Epoch [61/500], Training Loss: 0.7797, Validation Loss: 0.5636, Training Accuracy: 0.6700, Validation Accuracy: 0.6517\n",
      "Epoch [62/500], Training Loss: 0.6208, Validation Loss: 0.5336, Training Accuracy: 0.6875, Validation Accuracy: 0.6742\n",
      "Epoch [63/500], Training Loss: 0.5727, Validation Loss: 0.5444, Training Accuracy: 0.7037, Validation Accuracy: 0.6742\n",
      "Epoch [64/500], Training Loss: 0.7819, Validation Loss: 0.5069, Training Accuracy: 0.6775, Validation Accuracy: 0.7303\n",
      "Epoch [65/500], Training Loss: 0.6384, Validation Loss: 0.5865, Training Accuracy: 0.6562, Validation Accuracy: 0.6404\n",
      "Epoch [66/500], Training Loss: 0.6036, Validation Loss: 0.5832, Training Accuracy: 0.6763, Validation Accuracy: 0.6517\n",
      "Epoch [67/500], Training Loss: 0.5944, Validation Loss: 0.5667, Training Accuracy: 0.7000, Validation Accuracy: 0.6404\n",
      "Epoch [68/500], Training Loss: 0.6080, Validation Loss: 0.5875, Training Accuracy: 0.6837, Validation Accuracy: 0.6517\n",
      "Epoch [69/500], Training Loss: 0.5788, Validation Loss: 0.5245, Training Accuracy: 0.6987, Validation Accuracy: 0.7303\n",
      "Epoch [70/500], Training Loss: 0.5867, Validation Loss: 0.5668, Training Accuracy: 0.6713, Validation Accuracy: 0.6742\n",
      "Epoch [71/500], Training Loss: 0.6940, Validation Loss: 0.5534, Training Accuracy: 0.7013, Validation Accuracy: 0.6742\n",
      "Epoch [72/500], Training Loss: 0.5683, Validation Loss: 0.5510, Training Accuracy: 0.7050, Validation Accuracy: 0.7303\n",
      "Epoch [73/500], Training Loss: 0.7131, Validation Loss: 0.5156, Training Accuracy: 0.7362, Validation Accuracy: 0.7303\n",
      "Epoch [74/500], Training Loss: 0.6424, Validation Loss: 0.5376, Training Accuracy: 0.6987, Validation Accuracy: 0.7079\n",
      "Epoch [75/500], Training Loss: 0.6134, Validation Loss: 0.5470, Training Accuracy: 0.6913, Validation Accuracy: 0.7079\n",
      "Epoch [76/500], Training Loss: 0.7329, Validation Loss: 0.5778, Training Accuracy: 0.6937, Validation Accuracy: 0.6742\n",
      "Epoch [77/500], Training Loss: 0.6057, Validation Loss: 0.5723, Training Accuracy: 0.6925, Validation Accuracy: 0.6517\n",
      "Epoch [78/500], Training Loss: 0.6858, Validation Loss: 0.5876, Training Accuracy: 0.6937, Validation Accuracy: 0.6517\n",
      "Epoch [79/500], Training Loss: 0.6125, Validation Loss: 0.4603, Training Accuracy: 0.7113, Validation Accuracy: 0.7753\n",
      "Epoch [80/500], Training Loss: 0.6762, Validation Loss: 0.5068, Training Accuracy: 0.7238, Validation Accuracy: 0.7640\n",
      "Epoch [81/500], Training Loss: 0.6660, Validation Loss: 0.5702, Training Accuracy: 0.6650, Validation Accuracy: 0.6629\n",
      "Epoch [82/500], Training Loss: 0.6477, Validation Loss: 0.6068, Training Accuracy: 0.6562, Validation Accuracy: 0.6180\n",
      "Epoch [83/500], Training Loss: 0.5914, Validation Loss: 0.5915, Training Accuracy: 0.6625, Validation Accuracy: 0.6292\n",
      "Epoch [84/500], Training Loss: 0.6096, Validation Loss: 0.5668, Training Accuracy: 0.6763, Validation Accuracy: 0.6629\n",
      "Epoch [85/500], Training Loss: 0.7117, Validation Loss: 0.5973, Training Accuracy: 0.6725, Validation Accuracy: 0.6292\n",
      "Epoch [86/500], Training Loss: 0.6547, Validation Loss: 0.5748, Training Accuracy: 0.6887, Validation Accuracy: 0.6629\n",
      "Epoch [87/500], Training Loss: 0.6028, Validation Loss: 0.5882, Training Accuracy: 0.6650, Validation Accuracy: 0.6404\n",
      "Epoch [88/500], Training Loss: 0.5761, Validation Loss: 0.5745, Training Accuracy: 0.6900, Validation Accuracy: 0.6517\n",
      "Epoch [89/500], Training Loss: 0.9758, Validation Loss: 0.5716, Training Accuracy: 0.6800, Validation Accuracy: 0.6629\n",
      "Epoch [90/500], Training Loss: 0.6041, Validation Loss: 0.5762, Training Accuracy: 0.6663, Validation Accuracy: 0.6517\n",
      "Epoch [91/500], Training Loss: 0.6196, Validation Loss: 0.5946, Training Accuracy: 0.6837, Validation Accuracy: 0.6404\n",
      "Epoch [92/500], Training Loss: 0.6247, Validation Loss: 0.5713, Training Accuracy: 0.6637, Validation Accuracy: 0.6517\n",
      "Epoch [93/500], Training Loss: 0.6015, Validation Loss: 0.5654, Training Accuracy: 0.6750, Validation Accuracy: 0.6854\n",
      "Epoch [94/500], Training Loss: 0.5972, Validation Loss: 0.5680, Training Accuracy: 0.6800, Validation Accuracy: 0.6742\n",
      "Epoch [95/500], Training Loss: 0.6015, Validation Loss: 0.5682, Training Accuracy: 0.6887, Validation Accuracy: 0.6742\n",
      "Epoch [96/500], Training Loss: 0.5772, Validation Loss: 0.5380, Training Accuracy: 0.6963, Validation Accuracy: 0.6966\n",
      "Epoch [97/500], Training Loss: 0.7258, Validation Loss: 0.5141, Training Accuracy: 0.6975, Validation Accuracy: 0.7191\n",
      "Epoch [98/500], Training Loss: 0.8442, Validation Loss: 0.5499, Training Accuracy: 0.6937, Validation Accuracy: 0.6742\n",
      "Epoch [99/500], Training Loss: 0.6115, Validation Loss: 0.5829, Training Accuracy: 0.6963, Validation Accuracy: 0.6854\n",
      "Epoch [100/500], Training Loss: 0.7161, Validation Loss: 0.5603, Training Accuracy: 0.6837, Validation Accuracy: 0.6742\n",
      "Epoch [101/500], Training Loss: 0.6052, Validation Loss: 0.5569, Training Accuracy: 0.7013, Validation Accuracy: 0.6854\n",
      "Epoch [102/500], Training Loss: 0.6280, Validation Loss: 0.5661, Training Accuracy: 0.6863, Validation Accuracy: 0.6742\n",
      "Epoch [103/500], Training Loss: 0.5980, Validation Loss: 0.5614, Training Accuracy: 0.6750, Validation Accuracy: 0.6629\n",
      "Epoch [104/500], Training Loss: 0.5737, Validation Loss: 0.5636, Training Accuracy: 0.6850, Validation Accuracy: 0.6854\n",
      "Epoch [105/500], Training Loss: 0.5990, Validation Loss: 0.5812, Training Accuracy: 0.6775, Validation Accuracy: 0.6742\n",
      "Epoch [106/500], Training Loss: 0.7761, Validation Loss: 0.5684, Training Accuracy: 0.6488, Validation Accuracy: 0.6742\n",
      "Epoch [107/500], Training Loss: 0.7097, Validation Loss: 0.5575, Training Accuracy: 0.6650, Validation Accuracy: 0.6966\n",
      "Epoch [108/500], Training Loss: 0.6481, Validation Loss: 0.6193, Training Accuracy: 0.6438, Validation Accuracy: 0.6067\n",
      "Epoch [109/500], Training Loss: 0.6288, Validation Loss: 0.6194, Training Accuracy: 0.6462, Validation Accuracy: 0.6067\n",
      "Epoch [110/500], Training Loss: 0.5879, Validation Loss: 0.5861, Training Accuracy: 0.6663, Validation Accuracy: 0.6517\n",
      "Epoch [111/500], Training Loss: 0.7265, Validation Loss: 0.5390, Training Accuracy: 0.6825, Validation Accuracy: 0.7191\n",
      "Epoch [112/500], Training Loss: 0.7586, Validation Loss: 0.5599, Training Accuracy: 0.6825, Validation Accuracy: 0.6854\n",
      "Epoch [113/500], Training Loss: 0.7079, Validation Loss: 0.5127, Training Accuracy: 0.6963, Validation Accuracy: 0.7191\n",
      "Epoch [114/500], Training Loss: 0.6444, Validation Loss: 0.5610, Training Accuracy: 0.6863, Validation Accuracy: 0.6966\n",
      "Epoch [115/500], Training Loss: 0.6382, Validation Loss: 0.5525, Training Accuracy: 0.6863, Validation Accuracy: 0.7191\n",
      "Epoch [116/500], Training Loss: 0.8768, Validation Loss: 0.5128, Training Accuracy: 0.6887, Validation Accuracy: 0.7191\n",
      "Epoch [117/500], Training Loss: 0.6191, Validation Loss: 0.5321, Training Accuracy: 0.6825, Validation Accuracy: 0.7191\n",
      "Epoch [118/500], Training Loss: 1.2110, Validation Loss: 0.5289, Training Accuracy: 0.6713, Validation Accuracy: 0.7191\n",
      "Epoch [119/500], Training Loss: 0.6042, Validation Loss: 0.5271, Training Accuracy: 0.6987, Validation Accuracy: 0.7079\n",
      "Epoch [120/500], Training Loss: 0.5874, Validation Loss: 0.5122, Training Accuracy: 0.6975, Validation Accuracy: 0.7303\n",
      "Epoch [121/500], Training Loss: 0.6935, Validation Loss: 0.5280, Training Accuracy: 0.6963, Validation Accuracy: 0.7303\n",
      "Epoch [122/500], Training Loss: 0.5732, Validation Loss: 0.5726, Training Accuracy: 0.6937, Validation Accuracy: 0.6517\n",
      "Epoch [123/500], Training Loss: 0.5950, Validation Loss: 0.5683, Training Accuracy: 0.6913, Validation Accuracy: 0.6854\n",
      "Epoch [124/500], Training Loss: 0.5911, Validation Loss: 0.5406, Training Accuracy: 0.6813, Validation Accuracy: 0.7191\n",
      "Epoch [125/500], Training Loss: 0.6154, Validation Loss: 0.5141, Training Accuracy: 0.6963, Validation Accuracy: 0.7191\n",
      "Epoch [126/500], Training Loss: 0.6749, Validation Loss: 0.5520, Training Accuracy: 0.6887, Validation Accuracy: 0.6966\n",
      "Epoch [127/500], Training Loss: 0.5858, Validation Loss: 0.5778, Training Accuracy: 0.6675, Validation Accuracy: 0.6404\n",
      "Epoch [128/500], Training Loss: 0.5947, Validation Loss: 0.5774, Training Accuracy: 0.6625, Validation Accuracy: 0.6404\n",
      "Epoch [129/500], Training Loss: 0.5885, Validation Loss: 0.5830, Training Accuracy: 0.6650, Validation Accuracy: 0.6404\n",
      "Epoch [130/500], Training Loss: 0.6397, Validation Loss: 0.5624, Training Accuracy: 0.6813, Validation Accuracy: 0.6854\n",
      "Epoch [131/500], Training Loss: 0.6993, Validation Loss: 0.5735, Training Accuracy: 0.6713, Validation Accuracy: 0.6629\n",
      "Epoch [132/500], Training Loss: 0.7766, Validation Loss: 0.6051, Training Accuracy: 0.6600, Validation Accuracy: 0.6292\n",
      "Epoch [133/500], Training Loss: 0.7527, Validation Loss: 0.5955, Training Accuracy: 0.6475, Validation Accuracy: 0.6404\n",
      "Epoch [134/500], Training Loss: 0.6416, Validation Loss: 0.6351, Training Accuracy: 0.6400, Validation Accuracy: 0.5843\n",
      "Epoch [135/500], Training Loss: 0.6344, Validation Loss: 0.6342, Training Accuracy: 0.6375, Validation Accuracy: 0.5843\n",
      "Epoch [136/500], Training Loss: 0.5795, Validation Loss: 0.5689, Training Accuracy: 0.6587, Validation Accuracy: 0.6629\n",
      "Epoch [137/500], Training Loss: 0.6378, Validation Loss: 0.5571, Training Accuracy: 0.6600, Validation Accuracy: 0.6742\n",
      "Epoch [138/500], Training Loss: 0.6307, Validation Loss: 0.5711, Training Accuracy: 0.6700, Validation Accuracy: 0.6517\n",
      "Epoch [139/500], Training Loss: 0.5834, Validation Loss: 0.5733, Training Accuracy: 0.6625, Validation Accuracy: 0.6517\n",
      "Epoch [140/500], Training Loss: 0.7224, Validation Loss: 0.5736, Training Accuracy: 0.6600, Validation Accuracy: 0.6517\n",
      "Epoch [141/500], Training Loss: 0.6882, Validation Loss: 0.5603, Training Accuracy: 0.6687, Validation Accuracy: 0.6629\n",
      "Epoch [142/500], Training Loss: 0.5978, Validation Loss: 0.5602, Training Accuracy: 0.6863, Validation Accuracy: 0.6742\n",
      "Epoch [143/500], Training Loss: 0.6091, Validation Loss: 0.5877, Training Accuracy: 0.6550, Validation Accuracy: 0.6404\n",
      "Epoch [144/500], Training Loss: 0.6179, Validation Loss: 0.5972, Training Accuracy: 0.6550, Validation Accuracy: 0.6292\n",
      "Epoch [145/500], Training Loss: 0.5812, Validation Loss: 0.5941, Training Accuracy: 0.6600, Validation Accuracy: 0.6404\n",
      "Epoch [146/500], Training Loss: 0.5794, Validation Loss: 0.5568, Training Accuracy: 0.6562, Validation Accuracy: 0.6742\n",
      "Epoch [147/500], Training Loss: 0.6175, Validation Loss: 0.5533, Training Accuracy: 0.6700, Validation Accuracy: 0.6742\n",
      "Epoch [148/500], Training Loss: 0.7581, Validation Loss: 0.5472, Training Accuracy: 0.6687, Validation Accuracy: 0.6742\n",
      "Epoch [149/500], Training Loss: 0.7213, Validation Loss: 0.5615, Training Accuracy: 0.6800, Validation Accuracy: 0.6629\n",
      "Epoch [150/500], Training Loss: 0.6765, Validation Loss: 0.5956, Training Accuracy: 0.6625, Validation Accuracy: 0.6404\n",
      "Epoch [151/500], Training Loss: 0.6369, Validation Loss: 0.5964, Training Accuracy: 0.6675, Validation Accuracy: 0.6404\n",
      "Epoch [152/500], Training Loss: 0.5802, Validation Loss: 0.6637, Training Accuracy: 0.6538, Validation Accuracy: 0.6404\n",
      "Epoch [153/500], Training Loss: 0.5825, Validation Loss: 0.5824, Training Accuracy: 0.6650, Validation Accuracy: 0.6517\n",
      "Epoch [154/500], Training Loss: 0.7481, Validation Loss: 0.6133, Training Accuracy: 0.6512, Validation Accuracy: 0.6180\n",
      "Epoch [155/500], Training Loss: 0.5891, Validation Loss: 0.6043, Training Accuracy: 0.6450, Validation Accuracy: 0.6292\n",
      "Epoch [156/500], Training Loss: 0.5672, Validation Loss: 0.6199, Training Accuracy: 0.6687, Validation Accuracy: 0.6180\n",
      "Epoch [157/500], Training Loss: 0.5876, Validation Loss: 0.6361, Training Accuracy: 0.6488, Validation Accuracy: 0.5843\n",
      "Epoch [158/500], Training Loss: 0.6180, Validation Loss: 0.5950, Training Accuracy: 0.6625, Validation Accuracy: 0.6180\n",
      "Epoch [159/500], Training Loss: 0.7229, Validation Loss: 0.5834, Training Accuracy: 0.6650, Validation Accuracy: 0.6292\n",
      "Epoch [160/500], Training Loss: 0.8325, Validation Loss: 0.5844, Training Accuracy: 0.6650, Validation Accuracy: 0.6292\n",
      "Epoch [161/500], Training Loss: 0.6954, Validation Loss: 0.5848, Training Accuracy: 0.6613, Validation Accuracy: 0.6292\n",
      "Epoch [162/500], Training Loss: 0.9887, Validation Loss: 0.6119, Training Accuracy: 0.6438, Validation Accuracy: 0.6067\n",
      "Epoch [163/500], Training Loss: 0.7297, Validation Loss: 0.6106, Training Accuracy: 0.6362, Validation Accuracy: 0.6067\n",
      "Epoch [164/500], Training Loss: 0.9159, Validation Loss: 0.5996, Training Accuracy: 0.6488, Validation Accuracy: 0.6180\n",
      "Epoch [165/500], Training Loss: 0.6311, Validation Loss: 0.5952, Training Accuracy: 0.6488, Validation Accuracy: 0.6180\n",
      "Epoch [166/500], Training Loss: 0.9720, Validation Loss: 0.6092, Training Accuracy: 0.6462, Validation Accuracy: 0.6067\n",
      "Epoch [167/500], Training Loss: 0.8410, Validation Loss: 0.5895, Training Accuracy: 0.6450, Validation Accuracy: 0.6292\n",
      "Epoch [168/500], Training Loss: 0.7227, Validation Loss: 0.6100, Training Accuracy: 0.6488, Validation Accuracy: 0.6067\n",
      "Epoch [169/500], Training Loss: 0.7088, Validation Loss: 0.6096, Training Accuracy: 0.6450, Validation Accuracy: 0.6067\n",
      "Epoch [170/500], Training Loss: 0.9718, Validation Loss: 0.6103, Training Accuracy: 0.6512, Validation Accuracy: 0.6067\n",
      "Epoch [171/500], Training Loss: 1.2952, Validation Loss: 0.5935, Training Accuracy: 0.6275, Validation Accuracy: 0.6292\n",
      "Epoch [172/500], Training Loss: 0.6197, Validation Loss: 0.6013, Training Accuracy: 0.6562, Validation Accuracy: 0.6180\n",
      "Epoch [173/500], Training Loss: 0.8732, Validation Loss: 0.5697, Training Accuracy: 0.6450, Validation Accuracy: 0.6517\n",
      "Epoch [174/500], Training Loss: 0.8951, Validation Loss: 0.5764, Training Accuracy: 0.6625, Validation Accuracy: 0.6404\n",
      "Epoch [175/500], Training Loss: 0.8636, Validation Loss: 0.5757, Training Accuracy: 0.6613, Validation Accuracy: 0.6404\n",
      "Epoch [176/500], Training Loss: 1.3880, Validation Loss: 0.5664, Training Accuracy: 0.6587, Validation Accuracy: 0.6517\n",
      "Epoch [177/500], Training Loss: 1.0864, Validation Loss: 0.5785, Training Accuracy: 0.6637, Validation Accuracy: 0.6517\n",
      "Epoch [178/500], Training Loss: 1.0099, Validation Loss: 0.5797, Training Accuracy: 0.6425, Validation Accuracy: 0.6404\n",
      "Epoch [179/500], Training Loss: 0.5902, Validation Loss: 0.5877, Training Accuracy: 0.6462, Validation Accuracy: 0.6404\n",
      "Epoch [180/500], Training Loss: 0.7622, Validation Loss: 0.6005, Training Accuracy: 0.6500, Validation Accuracy: 0.6180\n",
      "Epoch [181/500], Training Loss: 0.9216, Validation Loss: 0.5999, Training Accuracy: 0.6275, Validation Accuracy: 0.6180\n",
      "Epoch [182/500], Training Loss: 0.7113, Validation Loss: 0.5750, Training Accuracy: 0.6525, Validation Accuracy: 0.6404\n",
      "Epoch [183/500], Training Loss: 0.9441, Validation Loss: 0.6005, Training Accuracy: 0.6300, Validation Accuracy: 0.6180\n",
      "Epoch [184/500], Training Loss: 0.6628, Validation Loss: 0.6001, Training Accuracy: 0.6262, Validation Accuracy: 0.6180\n",
      "Epoch [185/500], Training Loss: 0.5933, Validation Loss: 0.6000, Training Accuracy: 0.6338, Validation Accuracy: 0.6180\n",
      "Epoch [186/500], Training Loss: 0.5882, Validation Loss: 0.5921, Training Accuracy: 0.6388, Validation Accuracy: 0.6292\n",
      "Epoch [187/500], Training Loss: 0.9577, Validation Loss: 0.5910, Training Accuracy: 0.6412, Validation Accuracy: 0.6292\n",
      "Epoch [188/500], Training Loss: 0.7777, Validation Loss: 0.6003, Training Accuracy: 0.6375, Validation Accuracy: 0.6180\n",
      "Epoch [189/500], Training Loss: 0.6628, Validation Loss: 0.5998, Training Accuracy: 0.6325, Validation Accuracy: 0.6180\n",
      "Epoch [190/500], Training Loss: 0.7485, Validation Loss: 0.6002, Training Accuracy: 0.6400, Validation Accuracy: 0.6180\n",
      "Epoch [191/500], Training Loss: 0.6091, Validation Loss: 0.5999, Training Accuracy: 0.6162, Validation Accuracy: 0.6180\n",
      "Epoch [192/500], Training Loss: 0.7774, Validation Loss: 0.5910, Training Accuracy: 0.6412, Validation Accuracy: 0.6292\n",
      "Epoch [193/500], Training Loss: 0.6938, Validation Loss: 0.5999, Training Accuracy: 0.6400, Validation Accuracy: 0.6180\n",
      "Epoch [194/500], Training Loss: 0.8772, Validation Loss: 0.5999, Training Accuracy: 0.6238, Validation Accuracy: 0.6180\n",
      "Epoch [195/500], Training Loss: 0.7404, Validation Loss: 0.5999, Training Accuracy: 0.6250, Validation Accuracy: 0.6180\n",
      "Epoch [196/500], Training Loss: 0.7769, Validation Loss: 0.5998, Training Accuracy: 0.6312, Validation Accuracy: 0.6180\n",
      "Epoch [197/500], Training Loss: 0.6735, Validation Loss: 0.5998, Training Accuracy: 0.6250, Validation Accuracy: 0.6180\n",
      "Epoch [198/500], Training Loss: 0.9151, Validation Loss: 0.5998, Training Accuracy: 0.6212, Validation Accuracy: 0.6180\n",
      "Epoch [199/500], Training Loss: 0.9992, Validation Loss: 0.6085, Training Accuracy: 0.6050, Validation Accuracy: 0.6067\n",
      "Epoch [200/500], Training Loss: 0.7982, Validation Loss: 0.6085, Training Accuracy: 0.6062, Validation Accuracy: 0.6067\n",
      "Epoch [201/500], Training Loss: 0.6078, Validation Loss: 0.6085, Training Accuracy: 0.6138, Validation Accuracy: 0.6067\n",
      "Epoch [202/500], Training Loss: 0.5956, Validation Loss: 0.6000, Training Accuracy: 0.6288, Validation Accuracy: 0.6180\n",
      "Epoch [203/500], Training Loss: 0.7523, Validation Loss: 0.6000, Training Accuracy: 0.6300, Validation Accuracy: 0.6180\n",
      "Epoch [204/500], Training Loss: 0.7008, Validation Loss: 0.6177, Training Accuracy: 0.6325, Validation Accuracy: 0.5955\n",
      "Epoch [205/500], Training Loss: 0.6104, Validation Loss: 0.6218, Training Accuracy: 0.6125, Validation Accuracy: 0.5955\n",
      "Epoch [206/500], Training Loss: 0.7124, Validation Loss: 0.6402, Training Accuracy: 0.5950, Validation Accuracy: 0.5730\n",
      "Epoch [207/500], Training Loss: 0.6376, Validation Loss: 0.6263, Training Accuracy: 0.5988, Validation Accuracy: 0.5955\n",
      "Epoch [208/500], Training Loss: 0.5945, Validation Loss: 0.6103, Training Accuracy: 0.6300, Validation Accuracy: 0.6067\n",
      "Epoch [209/500], Training Loss: 0.6254, Validation Loss: 0.6105, Training Accuracy: 0.6212, Validation Accuracy: 0.6067\n",
      "Epoch [210/500], Training Loss: 0.6708, Validation Loss: 0.6111, Training Accuracy: 0.6088, Validation Accuracy: 0.6067\n",
      "Epoch [211/500], Training Loss: 0.7395, Validation Loss: 0.6161, Training Accuracy: 0.6150, Validation Accuracy: 0.5955\n",
      "Epoch [212/500], Training Loss: 0.7869, Validation Loss: 0.6102, Training Accuracy: 0.6138, Validation Accuracy: 0.6067\n",
      "Epoch [213/500], Training Loss: 0.6499, Validation Loss: 0.6172, Training Accuracy: 0.6125, Validation Accuracy: 0.5955\n",
      "Epoch [214/500], Training Loss: 0.6128, Validation Loss: 0.6087, Training Accuracy: 0.6212, Validation Accuracy: 0.6067\n",
      "Epoch [215/500], Training Loss: 0.6123, Validation Loss: 0.5999, Training Accuracy: 0.6275, Validation Accuracy: 0.6180\n",
      "Epoch [216/500], Training Loss: 0.7248, Validation Loss: 0.5998, Training Accuracy: 0.6238, Validation Accuracy: 0.6180\n",
      "Epoch [217/500], Training Loss: 0.6506, Validation Loss: 0.5999, Training Accuracy: 0.6375, Validation Accuracy: 0.6180\n",
      "Epoch [218/500], Training Loss: 0.6327, Validation Loss: 0.6092, Training Accuracy: 0.6475, Validation Accuracy: 0.6067\n",
      "Epoch [219/500], Training Loss: 0.6009, Validation Loss: 0.6089, Training Accuracy: 0.6262, Validation Accuracy: 0.6067\n",
      "Epoch [220/500], Training Loss: 0.7820, Validation Loss: 0.6085, Training Accuracy: 0.6175, Validation Accuracy: 0.6067\n",
      "Epoch [221/500], Training Loss: 0.7389, Validation Loss: 0.6173, Training Accuracy: 0.6125, Validation Accuracy: 0.5955\n",
      "Epoch [222/500], Training Loss: 0.6410, Validation Loss: 0.6172, Training Accuracy: 0.5962, Validation Accuracy: 0.5955\n",
      "Epoch [223/500], Training Loss: 0.6095, Validation Loss: 0.6172, Training Accuracy: 0.6138, Validation Accuracy: 0.5955\n",
      "Epoch [224/500], Training Loss: 0.6073, Validation Loss: 0.6170, Training Accuracy: 0.6162, Validation Accuracy: 0.5955\n",
      "Epoch [225/500], Training Loss: 0.6162, Validation Loss: 0.6173, Training Accuracy: 0.6238, Validation Accuracy: 0.5955\n",
      "Epoch [226/500], Training Loss: 0.6250, Validation Loss: 0.6171, Training Accuracy: 0.6238, Validation Accuracy: 0.5955\n",
      "Epoch [227/500], Training Loss: 0.6056, Validation Loss: 0.6172, Training Accuracy: 0.6188, Validation Accuracy: 0.5955\n",
      "Epoch [228/500], Training Loss: 0.5979, Validation Loss: 0.5998, Training Accuracy: 0.6275, Validation Accuracy: 0.6180\n",
      "Epoch [229/500], Training Loss: 0.6270, Validation Loss: 0.5910, Training Accuracy: 0.6412, Validation Accuracy: 0.6292\n",
      "Epoch [230/500], Training Loss: 0.7500, Validation Loss: 0.5750, Training Accuracy: 0.6538, Validation Accuracy: 0.6404\n",
      "Epoch [231/500], Training Loss: 0.6660, Validation Loss: 0.5749, Training Accuracy: 0.6525, Validation Accuracy: 0.6404\n",
      "Epoch [232/500], Training Loss: 0.9640, Validation Loss: 0.6010, Training Accuracy: 0.6512, Validation Accuracy: 0.6180\n",
      "Epoch [233/500], Training Loss: 0.7913, Validation Loss: 0.6002, Training Accuracy: 0.6312, Validation Accuracy: 0.6180\n",
      "Epoch [234/500], Training Loss: 0.7135, Validation Loss: 0.5999, Training Accuracy: 0.6350, Validation Accuracy: 0.6180\n",
      "Epoch [235/500], Training Loss: 0.5902, Validation Loss: 0.6000, Training Accuracy: 0.6438, Validation Accuracy: 0.6180\n",
      "Epoch [236/500], Training Loss: 0.7171, Validation Loss: 0.6001, Training Accuracy: 0.6288, Validation Accuracy: 0.6180\n",
      "Epoch [237/500], Training Loss: 0.6126, Validation Loss: 0.6089, Training Accuracy: 0.6250, Validation Accuracy: 0.6067\n",
      "Epoch [238/500], Training Loss: 0.8430, Validation Loss: 0.6086, Training Accuracy: 0.6275, Validation Accuracy: 0.6067\n",
      "Epoch [239/500], Training Loss: 0.7025, Validation Loss: 0.6002, Training Accuracy: 0.6475, Validation Accuracy: 0.6180\n",
      "Epoch [240/500], Training Loss: 0.7165, Validation Loss: 0.6000, Training Accuracy: 0.6462, Validation Accuracy: 0.6180\n",
      "Epoch [241/500], Training Loss: 0.7198, Validation Loss: 0.5917, Training Accuracy: 0.6637, Validation Accuracy: 0.6292\n",
      "Epoch [242/500], Training Loss: 1.1045, Validation Loss: 0.5915, Training Accuracy: 0.6575, Validation Accuracy: 0.6292\n",
      "Epoch [243/500], Training Loss: 0.9146, Validation Loss: 0.6107, Training Accuracy: 0.6575, Validation Accuracy: 0.6067\n",
      "Epoch [244/500], Training Loss: 2.0268, Validation Loss: 0.6095, Training Accuracy: 0.6225, Validation Accuracy: 0.6067\n",
      "Epoch [245/500], Training Loss: 1.4837, Validation Loss: 0.6090, Training Accuracy: 0.6225, Validation Accuracy: 0.6067\n",
      "Epoch [246/500], Training Loss: 0.7893, Validation Loss: 0.6085, Training Accuracy: 0.6150, Validation Accuracy: 0.6067\n",
      "Epoch [247/500], Training Loss: 0.6660, Validation Loss: 0.6321, Training Accuracy: 0.6112, Validation Accuracy: 0.5843\n",
      "Epoch [248/500], Training Loss: 0.6847, Validation Loss: 0.6321, Training Accuracy: 0.5875, Validation Accuracy: 0.5843\n",
      "Epoch [249/500], Training Loss: 0.7446, Validation Loss: 0.6318, Training Accuracy: 0.5950, Validation Accuracy: 0.5843\n",
      "Epoch [250/500], Training Loss: 0.6611, Validation Loss: 0.6318, Training Accuracy: 0.5975, Validation Accuracy: 0.5843\n",
      "Epoch [251/500], Training Loss: 0.6189, Validation Loss: 0.6319, Training Accuracy: 0.6000, Validation Accuracy: 0.5843\n",
      "Epoch [252/500], Training Loss: 0.6107, Validation Loss: 0.6118, Training Accuracy: 0.6100, Validation Accuracy: 0.6067\n",
      "Epoch [253/500], Training Loss: 0.6744, Validation Loss: 0.6324, Training Accuracy: 0.6175, Validation Accuracy: 0.5843\n",
      "Epoch [254/500], Training Loss: 0.8142, Validation Loss: 0.6326, Training Accuracy: 0.6088, Validation Accuracy: 0.5843\n",
      "Epoch [255/500], Training Loss: 0.8548, Validation Loss: 0.6473, Training Accuracy: 0.5863, Validation Accuracy: 0.5730\n",
      "Epoch [256/500], Training Loss: 0.6244, Validation Loss: 0.6404, Training Accuracy: 0.5925, Validation Accuracy: 0.5730\n",
      "Epoch [257/500], Training Loss: 0.6297, Validation Loss: 0.6350, Training Accuracy: 0.5925, Validation Accuracy: 0.5843\n",
      "Epoch [258/500], Training Loss: 0.7518, Validation Loss: 0.6193, Training Accuracy: 0.5887, Validation Accuracy: 0.5955\n",
      "Epoch [259/500], Training Loss: 0.7075, Validation Loss: 0.6318, Training Accuracy: 0.5950, Validation Accuracy: 0.5843\n",
      "Epoch [260/500], Training Loss: 0.9100, Validation Loss: 0.6180, Training Accuracy: 0.6150, Validation Accuracy: 0.5955\n",
      "Epoch [261/500], Training Loss: 0.7202, Validation Loss: 0.6004, Training Accuracy: 0.6262, Validation Accuracy: 0.6067\n",
      "Epoch [262/500], Training Loss: 0.8808, Validation Loss: 0.5930, Training Accuracy: 0.6250, Validation Accuracy: 0.6180\n",
      "Epoch [263/500], Training Loss: 1.2077, Validation Loss: 0.5954, Training Accuracy: 0.6162, Validation Accuracy: 0.6180\n",
      "Epoch [264/500], Training Loss: 0.9128, Validation Loss: 0.6088, Training Accuracy: 0.6125, Validation Accuracy: 0.6180\n",
      "Epoch [265/500], Training Loss: 1.0730, Validation Loss: 0.6401, Training Accuracy: 0.6112, Validation Accuracy: 0.5843\n",
      "Epoch [266/500], Training Loss: 0.7881, Validation Loss: 0.6487, Training Accuracy: 0.5775, Validation Accuracy: 0.5618\n",
      "Epoch [267/500], Training Loss: 1.0276, Validation Loss: 0.6459, Training Accuracy: 0.5800, Validation Accuracy: 0.5730\n",
      "Epoch [268/500], Training Loss: 0.6797, Validation Loss: 0.6484, Training Accuracy: 0.5850, Validation Accuracy: 0.5618\n",
      "Epoch [269/500], Training Loss: 0.6708, Validation Loss: 0.6481, Training Accuracy: 0.5775, Validation Accuracy: 0.5618\n",
      "Epoch [270/500], Training Loss: 0.6309, Validation Loss: 0.6480, Training Accuracy: 0.5900, Validation Accuracy: 0.5618\n",
      "Epoch [271/500], Training Loss: 0.6165, Validation Loss: 0.6302, Training Accuracy: 0.6025, Validation Accuracy: 0.5843\n",
      "Epoch [272/500], Training Loss: 0.7650, Validation Loss: 0.6256, Training Accuracy: 0.5938, Validation Accuracy: 0.5843\n",
      "Epoch [273/500], Training Loss: 0.7076, Validation Loss: 0.6256, Training Accuracy: 0.6138, Validation Accuracy: 0.5843\n",
      "Epoch [274/500], Training Loss: 0.9361, Validation Loss: 0.6199, Training Accuracy: 0.6162, Validation Accuracy: 0.5955\n",
      "Epoch [275/500], Training Loss: 0.7871, Validation Loss: 0.5910, Training Accuracy: 0.6300, Validation Accuracy: 0.6292\n",
      "Epoch [276/500], Training Loss: 0.8290, Validation Loss: 0.6332, Training Accuracy: 0.6138, Validation Accuracy: 0.5843\n",
      "Epoch [277/500], Training Loss: 1.0146, Validation Loss: 0.6663, Training Accuracy: 0.5837, Validation Accuracy: 0.5393\n",
      "Epoch [278/500], Training Loss: 1.1938, Validation Loss: 0.7622, Training Accuracy: 0.5875, Validation Accuracy: 0.5506\n",
      "Epoch [279/500], Training Loss: 1.4711, Validation Loss: 0.6564, Training Accuracy: 0.5813, Validation Accuracy: 0.5506\n",
      "Epoch [280/500], Training Loss: 0.7592, Validation Loss: 0.6560, Training Accuracy: 0.5787, Validation Accuracy: 0.5506\n",
      "Epoch [281/500], Training Loss: 0.7622, Validation Loss: 0.6481, Training Accuracy: 0.5737, Validation Accuracy: 0.5618\n",
      "Epoch [282/500], Training Loss: 0.8851, Validation Loss: 0.6496, Training Accuracy: 0.5750, Validation Accuracy: 0.5618\n",
      "Epoch [283/500], Training Loss: 0.7633, Validation Loss: 0.6565, Training Accuracy: 0.5850, Validation Accuracy: 0.5506\n",
      "Epoch [284/500], Training Loss: 0.7633, Validation Loss: 0.6640, Training Accuracy: 0.5713, Validation Accuracy: 0.5393\n",
      "Epoch [285/500], Training Loss: 0.7702, Validation Loss: 0.6645, Training Accuracy: 0.5687, Validation Accuracy: 0.5393\n",
      "Epoch [286/500], Training Loss: 0.8764, Validation Loss: 0.6640, Training Accuracy: 0.5687, Validation Accuracy: 0.5393\n",
      "Epoch [287/500], Training Loss: 0.7718, Validation Loss: 0.6484, Training Accuracy: 0.5900, Validation Accuracy: 0.5618\n",
      "Epoch [288/500], Training Loss: 1.5027, Validation Loss: 0.6486, Training Accuracy: 0.5988, Validation Accuracy: 0.5618\n",
      "Epoch [289/500], Training Loss: 1.3645, Validation Loss: 0.6483, Training Accuracy: 0.5800, Validation Accuracy: 0.5618\n",
      "Epoch [290/500], Training Loss: 0.8891, Validation Loss: 0.6481, Training Accuracy: 0.5850, Validation Accuracy: 0.5618\n",
      "Epoch [291/500], Training Loss: 0.8741, Validation Loss: 0.6482, Training Accuracy: 0.5887, Validation Accuracy: 0.5618\n",
      "Epoch [292/500], Training Loss: 0.8339, Validation Loss: 0.6574, Training Accuracy: 0.5813, Validation Accuracy: 0.5506\n",
      "Epoch [293/500], Training Loss: 0.8039, Validation Loss: 0.6481, Training Accuracy: 0.5875, Validation Accuracy: 0.5618\n",
      "Epoch [294/500], Training Loss: 1.0139, Validation Loss: 0.6479, Training Accuracy: 0.5763, Validation Accuracy: 0.5618\n",
      "Epoch [295/500], Training Loss: 1.0081, Validation Loss: 0.6482, Training Accuracy: 0.5813, Validation Accuracy: 0.5618\n",
      "Epoch [296/500], Training Loss: 0.6243, Validation Loss: 0.6490, Training Accuracy: 0.5925, Validation Accuracy: 0.5618\n",
      "Epoch [297/500], Training Loss: 0.9645, Validation Loss: 0.6480, Training Accuracy: 0.5825, Validation Accuracy: 0.5618\n",
      "Epoch [298/500], Training Loss: 1.1053, Validation Loss: 0.6401, Training Accuracy: 0.5837, Validation Accuracy: 0.5730\n",
      "Epoch [299/500], Training Loss: 1.0242, Validation Loss: 0.6401, Training Accuracy: 0.6000, Validation Accuracy: 0.5730\n",
      "Epoch [300/500], Training Loss: 1.1167, Validation Loss: 0.6405, Training Accuracy: 0.5950, Validation Accuracy: 0.5730\n",
      "Epoch [301/500], Training Loss: 0.8679, Validation Loss: 0.6407, Training Accuracy: 0.6088, Validation Accuracy: 0.5730\n",
      "Epoch [302/500], Training Loss: 0.7371, Validation Loss: 0.6420, Training Accuracy: 0.6088, Validation Accuracy: 0.5730\n",
      "Epoch [303/500], Training Loss: 0.8546, Validation Loss: 0.6417, Training Accuracy: 0.6112, Validation Accuracy: 0.5730\n",
      "Epoch [304/500], Training Loss: 0.8001, Validation Loss: 0.6324, Training Accuracy: 0.6012, Validation Accuracy: 0.5843\n",
      "Epoch [305/500], Training Loss: 0.7628, Validation Loss: 0.6404, Training Accuracy: 0.5913, Validation Accuracy: 0.5730\n",
      "Epoch [306/500], Training Loss: 0.9689, Validation Loss: 0.6319, Training Accuracy: 0.5938, Validation Accuracy: 0.5843\n",
      "Epoch [307/500], Training Loss: 0.6078, Validation Loss: 0.6236, Training Accuracy: 0.6162, Validation Accuracy: 0.5955\n",
      "Epoch [308/500], Training Loss: 0.9917, Validation Loss: 0.6238, Training Accuracy: 0.6175, Validation Accuracy: 0.5955\n",
      "Epoch [309/500], Training Loss: 0.7787, Validation Loss: 0.6239, Training Accuracy: 0.6162, Validation Accuracy: 0.5955\n",
      "Epoch [310/500], Training Loss: 1.8861, Validation Loss: 0.6239, Training Accuracy: 0.6025, Validation Accuracy: 0.5955\n",
      "Epoch [311/500], Training Loss: 1.0021, Validation Loss: 0.6237, Training Accuracy: 0.6062, Validation Accuracy: 0.5955\n",
      "Epoch [312/500], Training Loss: 0.8027, Validation Loss: 0.6238, Training Accuracy: 0.6000, Validation Accuracy: 0.5955\n",
      "Epoch [313/500], Training Loss: 0.6207, Validation Loss: 0.6490, Training Accuracy: 0.5975, Validation Accuracy: 0.5618\n",
      "Epoch [314/500], Training Loss: 0.6301, Validation Loss: 0.6484, Training Accuracy: 0.5837, Validation Accuracy: 0.5618\n",
      "Epoch [315/500], Training Loss: 0.8429, Validation Loss: 0.6481, Training Accuracy: 0.5863, Validation Accuracy: 0.5618\n",
      "Epoch [316/500], Training Loss: 0.6490, Validation Loss: 0.6488, Training Accuracy: 0.5850, Validation Accuracy: 0.5618\n",
      "Epoch [317/500], Training Loss: 0.7643, Validation Loss: 0.6520, Training Accuracy: 0.5725, Validation Accuracy: 0.5618\n",
      "Epoch [318/500], Training Loss: 0.6352, Validation Loss: 0.6518, Training Accuracy: 0.5775, Validation Accuracy: 0.5618\n",
      "Epoch [319/500], Training Loss: 0.8993, Validation Loss: 0.6482, Training Accuracy: 0.5750, Validation Accuracy: 0.5618\n",
      "Epoch [320/500], Training Loss: 0.7389, Validation Loss: 0.6254, Training Accuracy: 0.6025, Validation Accuracy: 0.5843\n",
      "Epoch [321/500], Training Loss: 0.6186, Validation Loss: 0.6254, Training Accuracy: 0.5988, Validation Accuracy: 0.5843\n",
      "Epoch [322/500], Training Loss: 0.7825, Validation Loss: 0.6254, Training Accuracy: 0.5962, Validation Accuracy: 0.5843\n",
      "Epoch [323/500], Training Loss: 0.6180, Validation Loss: 0.6254, Training Accuracy: 0.5988, Validation Accuracy: 0.5843\n",
      "Epoch [324/500], Training Loss: 0.6168, Validation Loss: 0.6254, Training Accuracy: 0.6012, Validation Accuracy: 0.5843\n",
      "Epoch [325/500], Training Loss: 0.7083, Validation Loss: 0.6255, Training Accuracy: 0.6050, Validation Accuracy: 0.5843\n",
      "Epoch [326/500], Training Loss: 0.7481, Validation Loss: 0.6255, Training Accuracy: 0.6012, Validation Accuracy: 0.5843\n",
      "Epoch [327/500], Training Loss: 0.6077, Validation Loss: 0.6170, Training Accuracy: 0.6112, Validation Accuracy: 0.5955\n",
      "Epoch [328/500], Training Loss: 0.7251, Validation Loss: 0.6085, Training Accuracy: 0.6200, Validation Accuracy: 0.6067\n",
      "Epoch [329/500], Training Loss: 0.5999, Validation Loss: 0.6000, Training Accuracy: 0.6212, Validation Accuracy: 0.6180\n",
      "Epoch [330/500], Training Loss: 0.9025, Validation Loss: 0.5999, Training Accuracy: 0.6225, Validation Accuracy: 0.6180\n",
      "Epoch [331/500], Training Loss: 0.9225, Validation Loss: 0.5998, Training Accuracy: 0.6188, Validation Accuracy: 0.6180\n",
      "Epoch [332/500], Training Loss: 0.9323, Validation Loss: 0.5998, Training Accuracy: 0.6188, Validation Accuracy: 0.6180\n",
      "Epoch [333/500], Training Loss: 0.8624, Validation Loss: 0.6170, Training Accuracy: 0.6088, Validation Accuracy: 0.5955\n",
      "Epoch [334/500], Training Loss: 0.9874, Validation Loss: 0.6171, Training Accuracy: 0.6012, Validation Accuracy: 0.5955\n",
      "Epoch [335/500], Training Loss: 1.2577, Validation Loss: 0.6171, Training Accuracy: 0.6012, Validation Accuracy: 0.5955\n",
      "Epoch [336/500], Training Loss: 1.3599, Validation Loss: 0.6171, Training Accuracy: 0.6000, Validation Accuracy: 0.5955\n",
      "Epoch [337/500], Training Loss: 1.4525, Validation Loss: 0.6176, Training Accuracy: 0.6100, Validation Accuracy: 0.5955\n",
      "Epoch [338/500], Training Loss: 1.6121, Validation Loss: 0.6085, Training Accuracy: 0.6125, Validation Accuracy: 0.6067\n",
      "Epoch [339/500], Training Loss: 1.0617, Validation Loss: 0.5998, Training Accuracy: 0.6088, Validation Accuracy: 0.6180\n",
      "Epoch [340/500], Training Loss: 1.0476, Validation Loss: 0.6499, Training Accuracy: 0.6062, Validation Accuracy: 0.5618\n",
      "Epoch [341/500], Training Loss: 0.8468, Validation Loss: 0.6485, Training Accuracy: 0.5900, Validation Accuracy: 0.5618\n",
      "Epoch [342/500], Training Loss: 0.6273, Validation Loss: 0.6560, Training Accuracy: 0.5950, Validation Accuracy: 0.5506\n",
      "Epoch [343/500], Training Loss: 0.9279, Validation Loss: 0.6402, Training Accuracy: 0.5938, Validation Accuracy: 0.5730\n",
      "Epoch [344/500], Training Loss: 0.9817, Validation Loss: 0.6322, Training Accuracy: 0.6088, Validation Accuracy: 0.5843\n",
      "Epoch [345/500], Training Loss: 0.6441, Validation Loss: 0.6568, Training Accuracy: 0.5913, Validation Accuracy: 0.5506\n",
      "Epoch [346/500], Training Loss: 0.7585, Validation Loss: 0.6566, Training Accuracy: 0.5775, Validation Accuracy: 0.5506\n",
      "Epoch [347/500], Training Loss: 0.7540, Validation Loss: 0.6481, Training Accuracy: 0.5863, Validation Accuracy: 0.5618\n",
      "Epoch [348/500], Training Loss: 0.7148, Validation Loss: 0.6487, Training Accuracy: 0.5962, Validation Accuracy: 0.5618\n",
      "Epoch [349/500], Training Loss: 1.0260, Validation Loss: 0.6483, Training Accuracy: 0.5813, Validation Accuracy: 0.5618\n",
      "Epoch [350/500], Training Loss: 0.6925, Validation Loss: 0.6420, Training Accuracy: 0.5988, Validation Accuracy: 0.5730\n",
      "Epoch [351/500], Training Loss: 0.8655, Validation Loss: 0.6413, Training Accuracy: 0.5975, Validation Accuracy: 0.5730\n",
      "Epoch [352/500], Training Loss: 0.9941, Validation Loss: 0.6447, Training Accuracy: 0.5913, Validation Accuracy: 0.5730\n",
      "Epoch [353/500], Training Loss: 0.8725, Validation Loss: 0.6457, Training Accuracy: 0.5887, Validation Accuracy: 0.5730\n",
      "Epoch [354/500], Training Loss: 0.8333, Validation Loss: 0.6401, Training Accuracy: 0.5938, Validation Accuracy: 0.5730\n",
      "Epoch [355/500], Training Loss: 0.7365, Validation Loss: 0.6170, Training Accuracy: 0.6075, Validation Accuracy: 0.5955\n",
      "Epoch [356/500], Training Loss: 1.2364, Validation Loss: 0.6086, Training Accuracy: 0.6138, Validation Accuracy: 0.6067\n",
      "Epoch [357/500], Training Loss: 1.5673, Validation Loss: 0.6085, Training Accuracy: 0.6150, Validation Accuracy: 0.6067\n",
      "Epoch [358/500], Training Loss: 1.1866, Validation Loss: 0.6171, Training Accuracy: 0.5988, Validation Accuracy: 0.5955\n",
      "Epoch [359/500], Training Loss: 0.7335, Validation Loss: 0.6321, Training Accuracy: 0.5950, Validation Accuracy: 0.5843\n",
      "Epoch [360/500], Training Loss: 0.8477, Validation Loss: 0.6319, Training Accuracy: 0.5988, Validation Accuracy: 0.5843\n",
      "Epoch [361/500], Training Loss: 0.6223, Validation Loss: 0.6319, Training Accuracy: 0.5938, Validation Accuracy: 0.5843\n",
      "Epoch [362/500], Training Loss: 1.0687, Validation Loss: 0.6319, Training Accuracy: 0.5950, Validation Accuracy: 0.5843\n",
      "Epoch [363/500], Training Loss: 0.6183, Validation Loss: 0.6319, Training Accuracy: 0.5988, Validation Accuracy: 0.5843\n",
      "Epoch [364/500], Training Loss: 0.8081, Validation Loss: 0.6318, Training Accuracy: 0.5925, Validation Accuracy: 0.5843\n",
      "Epoch [365/500], Training Loss: 0.8594, Validation Loss: 0.6319, Training Accuracy: 0.6062, Validation Accuracy: 0.5843\n",
      "Epoch [366/500], Training Loss: 0.8596, Validation Loss: 0.6324, Training Accuracy: 0.6062, Validation Accuracy: 0.5843\n",
      "Epoch [367/500], Training Loss: 0.9655, Validation Loss: 0.6320, Training Accuracy: 0.6038, Validation Accuracy: 0.5843\n",
      "Epoch [368/500], Training Loss: 0.8315, Validation Loss: 0.6326, Training Accuracy: 0.6150, Validation Accuracy: 0.5843\n",
      "Epoch [369/500], Training Loss: 0.9756, Validation Loss: 0.6323, Training Accuracy: 0.6150, Validation Accuracy: 0.5843\n",
      "Epoch [370/500], Training Loss: 0.9759, Validation Loss: 0.6325, Training Accuracy: 0.6138, Validation Accuracy: 0.5843\n",
      "Epoch [371/500], Training Loss: 0.7558, Validation Loss: 0.6330, Training Accuracy: 0.6212, Validation Accuracy: 0.5843\n",
      "Epoch [372/500], Training Loss: 1.2120, Validation Loss: 0.6177, Training Accuracy: 0.6262, Validation Accuracy: 0.5955\n",
      "Epoch [373/500], Training Loss: 1.0658, Validation Loss: 0.6174, Training Accuracy: 0.6238, Validation Accuracy: 0.5955\n",
      "Epoch [374/500], Training Loss: 0.8595, Validation Loss: 0.6175, Training Accuracy: 0.6188, Validation Accuracy: 0.5955\n",
      "Epoch [375/500], Training Loss: 0.8734, Validation Loss: 0.6172, Training Accuracy: 0.6150, Validation Accuracy: 0.5955\n",
      "Epoch [376/500], Training Loss: 1.0758, Validation Loss: 0.6170, Training Accuracy: 0.6075, Validation Accuracy: 0.5955\n",
      "Epoch [377/500], Training Loss: 1.2214, Validation Loss: 0.6172, Training Accuracy: 0.6200, Validation Accuracy: 0.5955\n",
      "Epoch [378/500], Training Loss: 0.9660, Validation Loss: 0.6175, Training Accuracy: 0.6162, Validation Accuracy: 0.5955\n",
      "Epoch [379/500], Training Loss: 1.0716, Validation Loss: 0.6172, Training Accuracy: 0.6075, Validation Accuracy: 0.5955\n",
      "Epoch [380/500], Training Loss: 0.8531, Validation Loss: 0.6087, Training Accuracy: 0.6150, Validation Accuracy: 0.6067\n",
      "Epoch [381/500], Training Loss: 2.6482, Validation Loss: 0.6086, Training Accuracy: 0.6100, Validation Accuracy: 0.6067\n",
      "Epoch [382/500], Training Loss: 2.4412, Validation Loss: 0.6172, Training Accuracy: 0.6175, Validation Accuracy: 0.5955\n",
      "Epoch [383/500], Training Loss: 1.9413, Validation Loss: 0.6173, Training Accuracy: 0.6162, Validation Accuracy: 0.5955\n",
      "Epoch [384/500], Training Loss: 0.9758, Validation Loss: 0.6173, Training Accuracy: 0.6138, Validation Accuracy: 0.5955\n",
      "Epoch [385/500], Training Loss: 0.8026, Validation Loss: 0.6170, Training Accuracy: 0.6112, Validation Accuracy: 0.5955\n",
      "Epoch [386/500], Training Loss: 1.1619, Validation Loss: 0.6086, Training Accuracy: 0.6125, Validation Accuracy: 0.6067\n",
      "Epoch [387/500], Training Loss: 1.0856, Validation Loss: 0.6170, Training Accuracy: 0.6100, Validation Accuracy: 0.5955\n",
      "Epoch [388/500], Training Loss: 1.0069, Validation Loss: 0.6085, Training Accuracy: 0.5988, Validation Accuracy: 0.6067\n",
      "Epoch [389/500], Training Loss: 1.0650, Validation Loss: 0.6085, Training Accuracy: 0.6162, Validation Accuracy: 0.6067\n",
      "Epoch [390/500], Training Loss: 0.7256, Validation Loss: 0.6086, Training Accuracy: 0.6188, Validation Accuracy: 0.6067\n",
      "Epoch [391/500], Training Loss: 0.6165, Validation Loss: 0.6085, Training Accuracy: 0.6012, Validation Accuracy: 0.6067\n",
      "Epoch [392/500], Training Loss: 0.7312, Validation Loss: 0.6085, Training Accuracy: 0.6112, Validation Accuracy: 0.6067\n",
      "Epoch [393/500], Training Loss: 1.0469, Validation Loss: 0.6085, Training Accuracy: 0.6062, Validation Accuracy: 0.6067\n",
      "Epoch [394/500], Training Loss: 1.0903, Validation Loss: 0.6085, Training Accuracy: 0.6000, Validation Accuracy: 0.6067\n",
      "Epoch [395/500], Training Loss: 0.8917, Validation Loss: 0.6085, Training Accuracy: 0.6150, Validation Accuracy: 0.6067\n",
      "Epoch [396/500], Training Loss: 0.9800, Validation Loss: 0.6085, Training Accuracy: 0.6212, Validation Accuracy: 0.6067\n",
      "Epoch [397/500], Training Loss: 1.4416, Validation Loss: 0.6085, Training Accuracy: 0.6225, Validation Accuracy: 0.6067\n",
      "Epoch [398/500], Training Loss: 0.9045, Validation Loss: 0.6087, Training Accuracy: 0.6275, Validation Accuracy: 0.6067\n",
      "Epoch [399/500], Training Loss: 1.0650, Validation Loss: 0.6085, Training Accuracy: 0.6212, Validation Accuracy: 0.6067\n",
      "Epoch [400/500], Training Loss: 1.0462, Validation Loss: 0.6086, Training Accuracy: 0.6212, Validation Accuracy: 0.6067\n",
      "Epoch [401/500], Training Loss: 0.8580, Validation Loss: 0.6091, Training Accuracy: 0.6275, Validation Accuracy: 0.6067\n",
      "Epoch [402/500], Training Loss: 0.9653, Validation Loss: 0.6086, Training Accuracy: 0.6262, Validation Accuracy: 0.6067\n",
      "Epoch [403/500], Training Loss: 1.5906, Validation Loss: 0.6086, Training Accuracy: 0.6162, Validation Accuracy: 0.6067\n",
      "Epoch [404/500], Training Loss: 1.3152, Validation Loss: 0.6086, Training Accuracy: 0.6300, Validation Accuracy: 0.6067\n",
      "Epoch [405/500], Training Loss: 1.1420, Validation Loss: 0.6088, Training Accuracy: 0.6338, Validation Accuracy: 0.6067\n",
      "Epoch [406/500], Training Loss: 1.0416, Validation Loss: 0.6086, Training Accuracy: 0.6325, Validation Accuracy: 0.6067\n",
      "Epoch [407/500], Training Loss: 1.3305, Validation Loss: 0.6090, Training Accuracy: 0.6388, Validation Accuracy: 0.6067\n",
      "Epoch [408/500], Training Loss: 1.1652, Validation Loss: 0.6089, Training Accuracy: 0.6338, Validation Accuracy: 0.6067\n",
      "Epoch [409/500], Training Loss: 0.8482, Validation Loss: 0.6177, Training Accuracy: 0.6188, Validation Accuracy: 0.5955\n",
      "Epoch [410/500], Training Loss: 0.8745, Validation Loss: 0.6219, Training Accuracy: 0.6038, Validation Accuracy: 0.5955\n",
      "Epoch [411/500], Training Loss: 0.6734, Validation Loss: 0.6321, Training Accuracy: 0.5975, Validation Accuracy: 0.5843\n",
      "Epoch [412/500], Training Loss: 0.6098, Validation Loss: 0.6321, Training Accuracy: 0.6100, Validation Accuracy: 0.5843\n",
      "Epoch [413/500], Training Loss: 1.0332, Validation Loss: 0.6323, Training Accuracy: 0.5988, Validation Accuracy: 0.5843\n",
      "Epoch [414/500], Training Loss: 0.8986, Validation Loss: 0.6321, Training Accuracy: 0.5913, Validation Accuracy: 0.5843\n",
      "Epoch [415/500], Training Loss: 1.0071, Validation Loss: 0.6091, Training Accuracy: 0.5913, Validation Accuracy: 0.6067\n",
      "Epoch [416/500], Training Loss: 0.7469, Validation Loss: 0.6085, Training Accuracy: 0.6088, Validation Accuracy: 0.6067\n",
      "Epoch [417/500], Training Loss: 0.9769, Validation Loss: 0.6085, Training Accuracy: 0.6125, Validation Accuracy: 0.6067\n",
      "Epoch [418/500], Training Loss: 0.9212, Validation Loss: 0.6088, Training Accuracy: 0.6262, Validation Accuracy: 0.6067\n",
      "Epoch [419/500], Training Loss: 1.8064, Validation Loss: 0.6086, Training Accuracy: 0.6250, Validation Accuracy: 0.6067\n",
      "Epoch [420/500], Training Loss: 1.1308, Validation Loss: 0.6088, Training Accuracy: 0.6275, Validation Accuracy: 0.6067\n",
      "Epoch [421/500], Training Loss: 1.7931, Validation Loss: 0.6086, Training Accuracy: 0.6125, Validation Accuracy: 0.6067\n",
      "Epoch [422/500], Training Loss: 2.5924, Validation Loss: 0.6086, Training Accuracy: 0.6150, Validation Accuracy: 0.6067\n",
      "Epoch [423/500], Training Loss: 2.5818, Validation Loss: 0.6098, Training Accuracy: 0.6438, Validation Accuracy: 0.6067\n",
      "Epoch [424/500], Training Loss: 2.3355, Validation Loss: 0.6099, Training Accuracy: 0.6400, Validation Accuracy: 0.6067\n",
      "Epoch [425/500], Training Loss: 2.2124, Validation Loss: 0.6098, Training Accuracy: 0.6300, Validation Accuracy: 0.6067\n",
      "Epoch [426/500], Training Loss: 1.9521, Validation Loss: 0.6088, Training Accuracy: 0.6138, Validation Accuracy: 0.6067\n",
      "Epoch [427/500], Training Loss: 1.4970, Validation Loss: 0.6087, Training Accuracy: 0.6200, Validation Accuracy: 0.6067\n",
      "Epoch [428/500], Training Loss: 2.5072, Validation Loss: 0.6087, Training Accuracy: 0.6150, Validation Accuracy: 0.6067\n",
      "Epoch [429/500], Training Loss: 1.7374, Validation Loss: 0.6172, Training Accuracy: 0.6000, Validation Accuracy: 0.5955\n",
      "Epoch [430/500], Training Loss: 1.5951, Validation Loss: 0.6327, Training Accuracy: 0.6125, Validation Accuracy: 0.5843\n",
      "Epoch [431/500], Training Loss: 1.9782, Validation Loss: 0.6172, Training Accuracy: 0.6000, Validation Accuracy: 0.5955\n",
      "Epoch [432/500], Training Loss: 1.4439, Validation Loss: 0.6086, Training Accuracy: 0.6200, Validation Accuracy: 0.6067\n",
      "Epoch [433/500], Training Loss: 1.6291, Validation Loss: 0.6418, Training Accuracy: 0.6125, Validation Accuracy: 0.5730\n",
      "Epoch [434/500], Training Loss: 1.3395, Validation Loss: 0.6404, Training Accuracy: 0.5850, Validation Accuracy: 0.5730\n",
      "Epoch [435/500], Training Loss: 0.9175, Validation Loss: 0.6640, Training Accuracy: 0.5537, Validation Accuracy: 0.5393\n",
      "Epoch [436/500], Training Loss: 1.0273, Validation Loss: 0.6636, Training Accuracy: 0.5500, Validation Accuracy: 0.5393\n",
      "Epoch [437/500], Training Loss: 0.8242, Validation Loss: 0.6401, Training Accuracy: 0.5587, Validation Accuracy: 0.5730\n",
      "Epoch [438/500], Training Loss: 0.9677, Validation Loss: 0.6399, Training Accuracy: 0.5737, Validation Accuracy: 0.5730\n",
      "Epoch [439/500], Training Loss: 0.6374, Validation Loss: 0.6399, Training Accuracy: 0.5750, Validation Accuracy: 0.5730\n",
      "Epoch [440/500], Training Loss: 1.2527, Validation Loss: 0.6400, Training Accuracy: 0.5787, Validation Accuracy: 0.5730\n",
      "Epoch [441/500], Training Loss: 0.9165, Validation Loss: 0.6561, Training Accuracy: 0.5687, Validation Accuracy: 0.5506\n",
      "Epoch [442/500], Training Loss: 0.6768, Validation Loss: 0.6559, Training Accuracy: 0.5450, Validation Accuracy: 0.5506\n",
      "Epoch [443/500], Training Loss: 0.6834, Validation Loss: 0.6558, Training Accuracy: 0.5450, Validation Accuracy: 0.5506\n",
      "Epoch [444/500], Training Loss: 0.8742, Validation Loss: 0.6558, Training Accuracy: 0.5387, Validation Accuracy: 0.5506\n",
      "Epoch [445/500], Training Loss: 0.6873, Validation Loss: 0.6635, Training Accuracy: 0.5387, Validation Accuracy: 0.5393\n",
      "Epoch [446/500], Training Loss: 0.6855, Validation Loss: 0.6712, Training Accuracy: 0.5175, Validation Accuracy: 0.5281\n",
      "Epoch [447/500], Training Loss: 0.7987, Validation Loss: 0.6712, Training Accuracy: 0.5238, Validation Accuracy: 0.5281\n",
      "Epoch [448/500], Training Loss: 0.6785, Validation Loss: 0.6711, Training Accuracy: 0.5188, Validation Accuracy: 0.5281\n",
      "Epoch [449/500], Training Loss: 0.6715, Validation Loss: 0.6711, Training Accuracy: 0.5288, Validation Accuracy: 0.5281\n",
      "Epoch [450/500], Training Loss: 0.6744, Validation Loss: 0.6636, Training Accuracy: 0.5250, Validation Accuracy: 0.5393\n",
      "Epoch [451/500], Training Loss: 0.6662, Validation Loss: 0.6635, Training Accuracy: 0.5363, Validation Accuracy: 0.5393\n",
      "Epoch [452/500], Training Loss: 0.8020, Validation Loss: 0.6635, Training Accuracy: 0.5188, Validation Accuracy: 0.5393\n",
      "Epoch [453/500], Training Loss: 0.7986, Validation Loss: 0.6641, Training Accuracy: 0.5238, Validation Accuracy: 0.5393\n",
      "Epoch [454/500], Training Loss: 0.7896, Validation Loss: 0.6646, Training Accuracy: 0.5363, Validation Accuracy: 0.5393\n",
      "Epoch [455/500], Training Loss: 0.7875, Validation Loss: 0.6644, Training Accuracy: 0.5387, Validation Accuracy: 0.5393\n",
      "Epoch [456/500], Training Loss: 0.7968, Validation Loss: 0.6645, Training Accuracy: 0.5262, Validation Accuracy: 0.5393\n",
      "Epoch [457/500], Training Loss: 0.6667, Validation Loss: 0.6643, Training Accuracy: 0.5350, Validation Accuracy: 0.5393\n",
      "Epoch [458/500], Training Loss: 0.7326, Validation Loss: 0.6642, Training Accuracy: 0.5250, Validation Accuracy: 0.5393\n",
      "Epoch [459/500], Training Loss: 0.7864, Validation Loss: 0.6635, Training Accuracy: 0.5413, Validation Accuracy: 0.5393\n",
      "Epoch [460/500], Training Loss: 0.7902, Validation Loss: 0.6635, Training Accuracy: 0.5350, Validation Accuracy: 0.5393\n",
      "Epoch [461/500], Training Loss: 0.6670, Validation Loss: 0.6635, Training Accuracy: 0.5350, Validation Accuracy: 0.5393\n",
      "Epoch [462/500], Training Loss: 0.6705, Validation Loss: 0.6635, Training Accuracy: 0.5300, Validation Accuracy: 0.5393\n",
      "Epoch [463/500], Training Loss: 0.6615, Validation Loss: 0.6635, Training Accuracy: 0.5425, Validation Accuracy: 0.5393\n",
      "Epoch [464/500], Training Loss: 0.7891, Validation Loss: 0.6635, Training Accuracy: 0.5363, Validation Accuracy: 0.5393\n",
      "Epoch [465/500], Training Loss: 0.7870, Validation Loss: 0.6409, Training Accuracy: 0.5400, Validation Accuracy: 0.5730\n",
      "Epoch [466/500], Training Loss: 0.8960, Validation Loss: 0.6401, Training Accuracy: 0.5587, Validation Accuracy: 0.5730\n",
      "Epoch [467/500], Training Loss: 0.8552, Validation Loss: 0.6400, Training Accuracy: 0.5613, Validation Accuracy: 0.5730\n",
      "Epoch [468/500], Training Loss: 0.7207, Validation Loss: 0.6399, Training Accuracy: 0.5863, Validation Accuracy: 0.5730\n",
      "Epoch [469/500], Training Loss: 0.6318, Validation Loss: 0.6401, Training Accuracy: 0.5962, Validation Accuracy: 0.5730\n",
      "Epoch [470/500], Training Loss: 0.8505, Validation Loss: 0.6399, Training Accuracy: 0.5800, Validation Accuracy: 0.5730\n",
      "Epoch [471/500], Training Loss: 0.8797, Validation Loss: 0.6402, Training Accuracy: 0.5813, Validation Accuracy: 0.5730\n",
      "Epoch [472/500], Training Loss: 0.8988, Validation Loss: 0.5931, Training Accuracy: 0.6250, Validation Accuracy: 0.6180\n",
      "Epoch [473/500], Training Loss: 0.9757, Validation Loss: 0.7750, Training Accuracy: 0.6138, Validation Accuracy: 0.5843\n",
      "Epoch [474/500], Training Loss: 1.5136, Validation Loss: 0.6321, Training Accuracy: 0.5988, Validation Accuracy: 0.5843\n",
      "Epoch [475/500], Training Loss: 0.6276, Validation Loss: 0.6319, Training Accuracy: 0.5875, Validation Accuracy: 0.5843\n",
      "Epoch [476/500], Training Loss: 1.4496, Validation Loss: 0.6170, Training Accuracy: 0.6025, Validation Accuracy: 0.5955\n",
      "Epoch [477/500], Training Loss: 1.0859, Validation Loss: 0.6170, Training Accuracy: 0.5950, Validation Accuracy: 0.5955\n",
      "Epoch [478/500], Training Loss: 1.4782, Validation Loss: 0.6170, Training Accuracy: 0.5837, Validation Accuracy: 0.5955\n",
      "Epoch [479/500], Training Loss: 0.6672, Validation Loss: 0.6171, Training Accuracy: 0.6025, Validation Accuracy: 0.5955\n",
      "Epoch [480/500], Training Loss: 0.9819, Validation Loss: 0.6170, Training Accuracy: 0.6062, Validation Accuracy: 0.5955\n",
      "Epoch [481/500], Training Loss: 1.1101, Validation Loss: 0.6170, Training Accuracy: 0.6000, Validation Accuracy: 0.5955\n",
      "Epoch [482/500], Training Loss: 1.3552, Validation Loss: 0.6170, Training Accuracy: 0.6025, Validation Accuracy: 0.5955\n",
      "Epoch [483/500], Training Loss: 0.8420, Validation Loss: 0.6170, Training Accuracy: 0.5988, Validation Accuracy: 0.5955\n",
      "Epoch [484/500], Training Loss: 0.9786, Validation Loss: 0.6171, Training Accuracy: 0.6100, Validation Accuracy: 0.5955\n",
      "Epoch [485/500], Training Loss: 0.8504, Validation Loss: 0.6171, Training Accuracy: 0.6162, Validation Accuracy: 0.5955\n",
      "Epoch [486/500], Training Loss: 1.1081, Validation Loss: 0.6170, Training Accuracy: 0.6025, Validation Accuracy: 0.5955\n",
      "Epoch [487/500], Training Loss: 1.0304, Validation Loss: 0.6320, Training Accuracy: 0.5825, Validation Accuracy: 0.5843\n",
      "Epoch [488/500], Training Loss: 0.9952, Validation Loss: 0.6318, Training Accuracy: 0.5900, Validation Accuracy: 0.5843\n",
      "Epoch [489/500], Training Loss: 0.7455, Validation Loss: 0.6319, Training Accuracy: 0.5938, Validation Accuracy: 0.5843\n",
      "Epoch [490/500], Training Loss: 0.8397, Validation Loss: 0.6172, Training Accuracy: 0.5813, Validation Accuracy: 0.5955\n",
      "Epoch [491/500], Training Loss: 0.7404, Validation Loss: 0.6170, Training Accuracy: 0.6000, Validation Accuracy: 0.5955\n",
      "Epoch [492/500], Training Loss: 0.7196, Validation Loss: 0.6170, Training Accuracy: 0.6038, Validation Accuracy: 0.5955\n",
      "Epoch [493/500], Training Loss: 0.6174, Validation Loss: 0.6170, Training Accuracy: 0.6000, Validation Accuracy: 0.5955\n",
      "Epoch [494/500], Training Loss: 1.1250, Validation Loss: 0.6171, Training Accuracy: 0.5825, Validation Accuracy: 0.5955\n",
      "Epoch [495/500], Training Loss: 0.8668, Validation Loss: 0.6170, Training Accuracy: 0.5962, Validation Accuracy: 0.5955\n",
      "Epoch [496/500], Training Loss: 0.8677, Validation Loss: 0.6170, Training Accuracy: 0.6025, Validation Accuracy: 0.5955\n",
      "Epoch [497/500], Training Loss: 0.8498, Validation Loss: 0.6171, Training Accuracy: 0.5925, Validation Accuracy: 0.5955\n",
      "Epoch [498/500], Training Loss: 1.1150, Validation Loss: 0.6319, Training Accuracy: 0.5938, Validation Accuracy: 0.5843\n",
      "Epoch [499/500], Training Loss: 0.8844, Validation Loss: 0.6319, Training Accuracy: 0.5950, Validation Accuracy: 0.5843\n",
      "Epoch [500/500], Training Loss: 0.6251, Validation Loss: 0.6319, Training Accuracy: 0.5900, Validation Accuracy: 0.5843\n",
      "Training Time: 11.82 seconds\n",
      "Epoch [1/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [2/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [3/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [4/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [5/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [6/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [7/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [8/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [9/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [10/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [11/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [12/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [13/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [14/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [15/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [16/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [17/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [18/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [19/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [20/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [21/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [22/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [23/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [24/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [25/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [26/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [27/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [28/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [29/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [30/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [31/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [32/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [33/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [34/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [35/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [36/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [37/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [38/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [39/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [40/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [41/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [42/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [43/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [44/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [45/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [46/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [47/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [48/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [49/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [50/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [51/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [52/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [53/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [54/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [55/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [56/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [57/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [58/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [59/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [60/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [61/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [62/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [63/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [64/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [65/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [66/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [67/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [68/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [69/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [70/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [71/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [72/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [73/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [74/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [75/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [76/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [77/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [78/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [79/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [80/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [81/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [82/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [83/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [84/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [85/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [86/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [87/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [88/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [89/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [90/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [91/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [92/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [93/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [94/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [95/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [96/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [97/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [98/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [99/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [100/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [101/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [102/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [103/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [104/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [105/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [106/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [107/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [108/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [109/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [110/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [111/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [112/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [113/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [114/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [115/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [116/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [117/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [118/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [119/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [120/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [121/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [122/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [123/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [124/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [125/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [126/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [127/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [128/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [129/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [130/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [131/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [132/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [133/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [134/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [135/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [136/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [137/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [138/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [139/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [140/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [141/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [142/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [143/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [144/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [145/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [146/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [147/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [148/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [149/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [150/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [151/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [152/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [153/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [154/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [155/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [156/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [157/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [158/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [159/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [160/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [161/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [162/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [163/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [164/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [165/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [166/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [167/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [168/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [169/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [170/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [171/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [172/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [173/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [174/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [175/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [176/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [177/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [178/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [179/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [180/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [181/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [182/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [183/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [184/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [185/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [186/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [187/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [188/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [189/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [190/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [191/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [192/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [193/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [194/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [195/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [196/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [197/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [198/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [199/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [200/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [201/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [202/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [203/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [204/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [205/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [206/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [207/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [208/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [209/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [210/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [211/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [212/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [213/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [214/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [215/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [216/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [217/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [218/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [219/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [220/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [221/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [222/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [223/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [224/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [225/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [226/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [227/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [228/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [229/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [230/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [231/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [232/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [233/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [234/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [235/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [236/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [237/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [238/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [239/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [240/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [241/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [242/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [243/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [244/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [245/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [246/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [247/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [248/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [249/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [250/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [251/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [252/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [253/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [254/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [255/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [256/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [257/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [258/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [259/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [260/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [261/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [262/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [263/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [264/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [265/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [266/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [267/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [268/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [269/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [270/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [271/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [272/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [273/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [274/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [275/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [276/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [277/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [278/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [279/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [280/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [281/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [282/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [283/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [284/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [285/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [286/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [287/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [288/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [289/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [290/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [291/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [292/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [293/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [294/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [295/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [296/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [297/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [298/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [299/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [300/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [301/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [302/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [303/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [304/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [305/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [306/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [307/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [308/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [309/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [310/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [311/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [312/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [313/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [314/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [315/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [316/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [317/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [318/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [319/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [320/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [321/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [322/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [323/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [324/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [325/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [326/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [327/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [328/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [329/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [330/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [331/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [332/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [333/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [334/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [335/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [336/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [337/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [338/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [339/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [340/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [341/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [342/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [343/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [344/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [345/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [346/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [347/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [348/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [349/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [350/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [351/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [352/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [353/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [354/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [355/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [356/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [357/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [358/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [359/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [360/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [361/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [362/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [363/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [364/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [365/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [366/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [367/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [368/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [369/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [370/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [371/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [372/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [373/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [374/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [375/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [376/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [377/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [378/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [379/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [380/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [381/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [382/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [383/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [384/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [385/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [386/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [387/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [388/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [389/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [390/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [391/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [392/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [393/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [394/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [395/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [396/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [397/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [398/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [399/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [400/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [401/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [402/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [403/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [404/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [405/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [406/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [407/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [408/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [409/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [410/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [411/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [412/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [413/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [414/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [415/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [416/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [417/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [418/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [419/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [420/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [421/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [422/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [423/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [424/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [425/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [426/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [427/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [428/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [429/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [430/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [431/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [432/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [433/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [434/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [435/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [436/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [437/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [438/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [439/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [440/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [441/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [442/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [443/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [444/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [445/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [446/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [447/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [448/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [449/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [450/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [451/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [452/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [453/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [454/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [455/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [456/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [457/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [458/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [459/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [460/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [461/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [462/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [463/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [464/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [465/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [466/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [467/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [468/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [469/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [470/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [471/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [472/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [473/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [474/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [475/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [476/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [477/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [478/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [479/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [480/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [481/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [482/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [483/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [484/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [485/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [486/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [487/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [488/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [489/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [490/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [491/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [492/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [493/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [494/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [495/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [496/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [497/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [498/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [499/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [500/500], Test Loss: 0.7260, Testing Accuracy: 0.6768, \n",
      "Epoch [1/500], Training Loss: 0.7329, Validation Loss: 0.6145, Training Accuracy: 0.5600, Validation Accuracy: 0.7753\n",
      "Epoch [2/500], Training Loss: 0.6795, Validation Loss: 0.5428, Training Accuracy: 0.6262, Validation Accuracy: 0.7191\n",
      "Epoch [3/500], Training Loss: 0.6381, Validation Loss: 0.5296, Training Accuracy: 0.6362, Validation Accuracy: 0.7528\n",
      "Epoch [4/500], Training Loss: 0.6836, Validation Loss: 0.5988, Training Accuracy: 0.6100, Validation Accuracy: 0.5730\n",
      "Epoch [5/500], Training Loss: 0.6825, Validation Loss: 0.5351, Training Accuracy: 0.6200, Validation Accuracy: 0.7303\n",
      "Epoch [6/500], Training Loss: 0.7044, Validation Loss: 0.5606, Training Accuracy: 0.6362, Validation Accuracy: 0.7303\n",
      "Epoch [7/500], Training Loss: 0.6796, Validation Loss: 0.5471, Training Accuracy: 0.6562, Validation Accuracy: 0.7416\n",
      "Epoch [8/500], Training Loss: 0.8256, Validation Loss: 0.5798, Training Accuracy: 0.6338, Validation Accuracy: 0.6742\n",
      "Epoch [9/500], Training Loss: 0.7466, Validation Loss: 0.6295, Training Accuracy: 0.6000, Validation Accuracy: 0.6180\n",
      "Epoch [10/500], Training Loss: 0.6884, Validation Loss: 0.5232, Training Accuracy: 0.6212, Validation Accuracy: 0.7191\n",
      "Epoch [11/500], Training Loss: 0.7080, Validation Loss: 0.5451, Training Accuracy: 0.6150, Validation Accuracy: 0.7191\n",
      "Epoch [12/500], Training Loss: 0.6619, Validation Loss: 0.5467, Training Accuracy: 0.6262, Validation Accuracy: 0.7303\n",
      "Epoch [13/500], Training Loss: 0.6245, Validation Loss: 0.5663, Training Accuracy: 0.6650, Validation Accuracy: 0.7191\n",
      "Epoch [14/500], Training Loss: 0.7056, Validation Loss: 0.6426, Training Accuracy: 0.6462, Validation Accuracy: 0.5843\n",
      "Epoch [15/500], Training Loss: 0.6572, Validation Loss: 0.5979, Training Accuracy: 0.5863, Validation Accuracy: 0.6854\n",
      "Epoch [16/500], Training Loss: 0.7068, Validation Loss: 0.6012, Training Accuracy: 0.6225, Validation Accuracy: 0.6966\n",
      "Epoch [17/500], Training Loss: 0.7104, Validation Loss: 0.5879, Training Accuracy: 0.6225, Validation Accuracy: 0.7303\n",
      "Epoch [18/500], Training Loss: 0.7453, Validation Loss: 0.6302, Training Accuracy: 0.6162, Validation Accuracy: 0.6292\n",
      "Epoch [19/500], Training Loss: 0.7036, Validation Loss: 0.6196, Training Accuracy: 0.6050, Validation Accuracy: 0.6404\n",
      "Epoch [20/500], Training Loss: 0.7351, Validation Loss: 0.6357, Training Accuracy: 0.5900, Validation Accuracy: 0.6292\n",
      "Epoch [21/500], Training Loss: 0.8393, Validation Loss: 0.6278, Training Accuracy: 0.5825, Validation Accuracy: 0.6292\n",
      "Epoch [22/500], Training Loss: 0.8667, Validation Loss: 0.6573, Training Accuracy: 0.5837, Validation Accuracy: 0.5843\n",
      "Epoch [23/500], Training Loss: 0.7488, Validation Loss: 0.6374, Training Accuracy: 0.5663, Validation Accuracy: 0.6292\n",
      "Epoch [24/500], Training Loss: 0.8920, Validation Loss: 0.6316, Training Accuracy: 0.5663, Validation Accuracy: 0.6292\n",
      "Epoch [25/500], Training Loss: 0.7526, Validation Loss: 0.6252, Training Accuracy: 0.5763, Validation Accuracy: 0.6067\n",
      "Epoch [26/500], Training Loss: 0.7263, Validation Loss: 0.6301, Training Accuracy: 0.5700, Validation Accuracy: 0.6180\n",
      "Epoch [27/500], Training Loss: 0.9969, Validation Loss: 0.6682, Training Accuracy: 0.5450, Validation Accuracy: 0.5843\n",
      "Epoch [28/500], Training Loss: 0.7135, Validation Loss: 0.6588, Training Accuracy: 0.5737, Validation Accuracy: 0.5955\n",
      "Epoch [29/500], Training Loss: 0.7575, Validation Loss: 0.6095, Training Accuracy: 0.5988, Validation Accuracy: 0.6517\n",
      "Epoch [30/500], Training Loss: 0.7698, Validation Loss: 0.6147, Training Accuracy: 0.5900, Validation Accuracy: 0.6404\n",
      "Epoch [31/500], Training Loss: 0.7670, Validation Loss: 0.6486, Training Accuracy: 0.5600, Validation Accuracy: 0.6067\n",
      "Epoch [32/500], Training Loss: 0.9213, Validation Loss: 0.6366, Training Accuracy: 0.5450, Validation Accuracy: 0.5843\n",
      "Epoch [33/500], Training Loss: 0.7805, Validation Loss: 0.6889, Training Accuracy: 0.5375, Validation Accuracy: 0.5281\n",
      "Epoch [34/500], Training Loss: 0.7752, Validation Loss: 0.6896, Training Accuracy: 0.5188, Validation Accuracy: 0.5281\n",
      "Epoch [35/500], Training Loss: 0.6956, Validation Loss: 0.6877, Training Accuracy: 0.5238, Validation Accuracy: 0.5393\n",
      "Epoch [36/500], Training Loss: 0.7216, Validation Loss: 0.6934, Training Accuracy: 0.5100, Validation Accuracy: 0.4944\n",
      "Epoch [37/500], Training Loss: 0.6914, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [38/500], Training Loss: 0.6974, Validation Loss: 0.6932, Training Accuracy: 0.5062, Validation Accuracy: 0.5056\n",
      "Epoch [39/500], Training Loss: 0.6974, Validation Loss: 0.6932, Training Accuracy: 0.4913, Validation Accuracy: 0.4944\n",
      "Epoch [40/500], Training Loss: 0.7149, Validation Loss: 0.6932, Training Accuracy: 0.5300, Validation Accuracy: 0.4944\n",
      "Epoch [41/500], Training Loss: 0.7359, Validation Loss: 0.6934, Training Accuracy: 0.5162, Validation Accuracy: 0.4944\n",
      "Epoch [42/500], Training Loss: 0.6978, Validation Loss: 0.6931, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [43/500], Training Loss: 0.7205, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [44/500], Training Loss: 0.8235, Validation Loss: 0.6932, Training Accuracy: 0.4600, Validation Accuracy: 0.4944\n",
      "Epoch [45/500], Training Loss: 0.7311, Validation Loss: 0.6933, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [46/500], Training Loss: 0.7224, Validation Loss: 0.6932, Training Accuracy: 0.4913, Validation Accuracy: 0.4944\n",
      "Epoch [47/500], Training Loss: 0.7044, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [48/500], Training Loss: 0.7113, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.4944\n",
      "Epoch [49/500], Training Loss: 0.8288, Validation Loss: 0.6932, Training Accuracy: 0.4863, Validation Accuracy: 0.4944\n",
      "Epoch [50/500], Training Loss: 0.8518, Validation Loss: 0.6932, Training Accuracy: 0.4813, Validation Accuracy: 0.4944\n",
      "Epoch [51/500], Training Loss: 0.6938, Validation Loss: 0.6931, Training Accuracy: 0.4913, Validation Accuracy: 0.5056\n",
      "Epoch [52/500], Training Loss: 0.6944, Validation Loss: 0.6931, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [53/500], Training Loss: 0.7042, Validation Loss: 0.6931, Training Accuracy: 0.4788, Validation Accuracy: 0.4944\n",
      "Epoch [54/500], Training Loss: 0.6914, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.4944\n",
      "Epoch [55/500], Training Loss: 0.7120, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [56/500], Training Loss: 0.7071, Validation Loss: 0.6932, Training Accuracy: 0.5050, Validation Accuracy: 0.4944\n",
      "Epoch [57/500], Training Loss: 0.7133, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [58/500], Training Loss: 0.6892, Validation Loss: 0.6932, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [59/500], Training Loss: 0.6884, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [60/500], Training Loss: 0.7126, Validation Loss: 0.6931, Training Accuracy: 0.5088, Validation Accuracy: 0.5056\n",
      "Epoch [61/500], Training Loss: 0.7101, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [62/500], Training Loss: 0.8539, Validation Loss: 0.6931, Training Accuracy: 0.4763, Validation Accuracy: 0.5056\n",
      "Epoch [63/500], Training Loss: 0.8404, Validation Loss: 0.6932, Training Accuracy: 0.4713, Validation Accuracy: 0.4944\n",
      "Epoch [64/500], Training Loss: 0.7175, Validation Loss: 0.6932, Training Accuracy: 0.4788, Validation Accuracy: 0.4944\n",
      "Epoch [65/500], Training Loss: 0.8889, Validation Loss: 0.6931, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [66/500], Training Loss: 0.8490, Validation Loss: 0.6932, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [67/500], Training Loss: 0.8868, Validation Loss: 0.6931, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [68/500], Training Loss: 0.7155, Validation Loss: 0.6932, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [69/500], Training Loss: 0.6958, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [70/500], Training Loss: 0.8177, Validation Loss: 0.6931, Training Accuracy: 0.4813, Validation Accuracy: 0.5056\n",
      "Epoch [71/500], Training Loss: 0.7261, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [72/500], Training Loss: 1.2127, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [73/500], Training Loss: 0.9572, Validation Loss: 0.6931, Training Accuracy: 0.4763, Validation Accuracy: 0.5056\n",
      "Epoch [74/500], Training Loss: 0.6917, Validation Loss: 0.6932, Training Accuracy: 0.4863, Validation Accuracy: 0.4944\n",
      "Epoch [75/500], Training Loss: 1.0766, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [76/500], Training Loss: 0.6954, Validation Loss: 0.6933, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [77/500], Training Loss: 0.7026, Validation Loss: 0.6932, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [78/500], Training Loss: 0.7034, Validation Loss: 0.6931, Training Accuracy: 0.4688, Validation Accuracy: 0.4944\n",
      "Epoch [79/500], Training Loss: 0.6916, Validation Loss: 0.6933, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [80/500], Training Loss: 0.6912, Validation Loss: 0.6932, Training Accuracy: 0.5062, Validation Accuracy: 0.5056\n",
      "Epoch [81/500], Training Loss: 0.6950, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [82/500], Training Loss: 0.8281, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [83/500], Training Loss: 0.7019, Validation Loss: 0.6931, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [84/500], Training Loss: 0.6931, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [85/500], Training Loss: 0.6999, Validation Loss: 0.6933, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [86/500], Training Loss: 0.7048, Validation Loss: 0.6932, Training Accuracy: 0.4888, Validation Accuracy: 0.5056\n",
      "Epoch [87/500], Training Loss: 0.6931, Validation Loss: 0.6932, Training Accuracy: 0.4700, Validation Accuracy: 0.4944\n",
      "Epoch [88/500], Training Loss: 0.6931, Validation Loss: 0.6932, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [89/500], Training Loss: 0.9593, Validation Loss: 0.6933, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [90/500], Training Loss: 0.9587, Validation Loss: 0.6932, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [91/500], Training Loss: 0.8281, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [92/500], Training Loss: 0.7068, Validation Loss: 0.6934, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [93/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.4944\n",
      "Epoch [94/500], Training Loss: 0.7078, Validation Loss: 0.6931, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [95/500], Training Loss: 0.8306, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.4944\n",
      "Epoch [96/500], Training Loss: 0.8235, Validation Loss: 0.6931, Training Accuracy: 0.4587, Validation Accuracy: 0.5056\n",
      "Epoch [97/500], Training Loss: 0.7039, Validation Loss: 0.6932, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [98/500], Training Loss: 0.7108, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [99/500], Training Loss: 0.6969, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [100/500], Training Loss: 0.6923, Validation Loss: 0.6932, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [101/500], Training Loss: 0.6952, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [102/500], Training Loss: 0.8668, Validation Loss: 0.6932, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [103/500], Training Loss: 0.7030, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [104/500], Training Loss: 0.6940, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.4944\n",
      "Epoch [105/500], Training Loss: 0.6928, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [106/500], Training Loss: 0.8190, Validation Loss: 0.6933, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [107/500], Training Loss: 0.6930, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [108/500], Training Loss: 0.9403, Validation Loss: 0.6931, Training Accuracy: 0.4763, Validation Accuracy: 0.5056\n",
      "Epoch [109/500], Training Loss: 0.8484, Validation Loss: 0.6931, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [110/500], Training Loss: 0.9415, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [111/500], Training Loss: 1.1917, Validation Loss: 0.6932, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [112/500], Training Loss: 0.8540, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [113/500], Training Loss: 0.6919, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.4944\n",
      "Epoch [114/500], Training Loss: 0.8177, Validation Loss: 0.6931, Training Accuracy: 0.4813, Validation Accuracy: 0.5056\n",
      "Epoch [115/500], Training Loss: 0.9409, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [116/500], Training Loss: 0.9417, Validation Loss: 0.6932, Training Accuracy: 0.4913, Validation Accuracy: 0.5056\n",
      "Epoch [117/500], Training Loss: 0.8270, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [118/500], Training Loss: 0.7127, Validation Loss: 0.6932, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [119/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [120/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.4675, Validation Accuracy: 0.5056\n",
      "Epoch [121/500], Training Loss: 0.6954, Validation Loss: 0.6933, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [122/500], Training Loss: 0.6917, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [123/500], Training Loss: 0.6921, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [124/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [125/500], Training Loss: 0.8229, Validation Loss: 0.6932, Training Accuracy: 0.4600, Validation Accuracy: 0.4944\n",
      "Epoch [126/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [127/500], Training Loss: 0.6932, Validation Loss: 0.6932, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [128/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [129/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [130/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [131/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [132/500], Training Loss: 0.6959, Validation Loss: 0.6932, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [133/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [134/500], Training Loss: 0.6923, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [135/500], Training Loss: 0.8167, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [136/500], Training Loss: 0.6940, Validation Loss: 0.6932, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [137/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [138/500], Training Loss: 0.6937, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [139/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [140/500], Training Loss: 0.6948, Validation Loss: 0.6931, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [141/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [142/500], Training Loss: 0.6933, Validation Loss: 0.6933, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [143/500], Training Loss: 0.8317, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [144/500], Training Loss: 0.8168, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [145/500], Training Loss: 0.6965, Validation Loss: 0.6932, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [146/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.4725, Validation Accuracy: 0.4944\n",
      "Epoch [147/500], Training Loss: 0.8175, Validation Loss: 0.6931, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [148/500], Training Loss: 0.8172, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [149/500], Training Loss: 0.6966, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [150/500], Training Loss: 0.6938, Validation Loss: 0.6931, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [151/500], Training Loss: 0.6993, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [152/500], Training Loss: 0.7024, Validation Loss: 0.6931, Training Accuracy: 0.4713, Validation Accuracy: 0.5056\n",
      "Epoch [153/500], Training Loss: 0.6932, Validation Loss: 0.6931, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [154/500], Training Loss: 0.6933, Validation Loss: 0.6932, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [155/500], Training Loss: 0.6926, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [156/500], Training Loss: 0.6943, Validation Loss: 0.6932, Training Accuracy: 0.4938, Validation Accuracy: 0.4944\n",
      "Epoch [157/500], Training Loss: 0.6939, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [158/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.4944\n",
      "Epoch [159/500], Training Loss: 0.7035, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [160/500], Training Loss: 0.8179, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [161/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [162/500], Training Loss: 0.6996, Validation Loss: 0.6931, Training Accuracy: 0.4888, Validation Accuracy: 0.5056\n",
      "Epoch [163/500], Training Loss: 0.6926, Validation Loss: 0.6932, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [164/500], Training Loss: 0.6972, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [165/500], Training Loss: 0.7066, Validation Loss: 0.6931, Training Accuracy: 0.4675, Validation Accuracy: 0.5056\n",
      "Epoch [166/500], Training Loss: 0.7059, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [167/500], Training Loss: 0.6929, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [168/500], Training Loss: 0.8175, Validation Loss: 0.6931, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [169/500], Training Loss: 0.7119, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [170/500], Training Loss: 0.7286, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [171/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [172/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.4725, Validation Accuracy: 0.4944\n",
      "Epoch [173/500], Training Loss: 0.6941, Validation Loss: 0.6931, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [174/500], Training Loss: 0.6937, Validation Loss: 0.6932, Training Accuracy: 0.4625, Validation Accuracy: 0.5056\n",
      "Epoch [175/500], Training Loss: 0.8178, Validation Loss: 0.6932, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [176/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [177/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [178/500], Training Loss: 0.7090, Validation Loss: 0.6932, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [179/500], Training Loss: 0.6939, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [180/500], Training Loss: 0.6929, Validation Loss: 0.6931, Training Accuracy: 0.4888, Validation Accuracy: 0.4944\n",
      "Epoch [181/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [182/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [183/500], Training Loss: 0.6938, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [184/500], Training Loss: 0.6966, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [185/500], Training Loss: 0.6924, Validation Loss: 0.6931, Training Accuracy: 0.4988, Validation Accuracy: 0.5056\n",
      "Epoch [186/500], Training Loss: 0.6925, Validation Loss: 0.6931, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [187/500], Training Loss: 0.6939, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [188/500], Training Loss: 0.6932, Validation Loss: 0.6933, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [189/500], Training Loss: 0.6927, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [190/500], Training Loss: 0.7014, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [191/500], Training Loss: 0.6928, Validation Loss: 0.6932, Training Accuracy: 0.4650, Validation Accuracy: 0.4944\n",
      "Epoch [192/500], Training Loss: 0.6939, Validation Loss: 0.6932, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [193/500], Training Loss: 0.6927, Validation Loss: 0.6932, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [194/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [195/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [196/500], Training Loss: 0.7096, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [197/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [198/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [199/500], Training Loss: 0.6939, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [200/500], Training Loss: 0.6925, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [201/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [202/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [203/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [204/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4525, Validation Accuracy: 0.5056\n",
      "Epoch [205/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [206/500], Training Loss: 0.6942, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [207/500], Training Loss: 0.6924, Validation Loss: 0.6932, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [208/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [209/500], Training Loss: 0.6939, Validation Loss: 0.6933, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [210/500], Training Loss: 0.8179, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [211/500], Training Loss: 0.6924, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [212/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [213/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.4650, Validation Accuracy: 0.5056\n",
      "Epoch [214/500], Training Loss: 0.7005, Validation Loss: 0.6931, Training Accuracy: 0.4963, Validation Accuracy: 0.4944\n",
      "Epoch [215/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [216/500], Training Loss: 0.7184, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [217/500], Training Loss: 0.6926, Validation Loss: 0.6932, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [218/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [219/500], Training Loss: 0.7056, Validation Loss: 0.6931, Training Accuracy: 0.4713, Validation Accuracy: 0.5056\n",
      "Epoch [220/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [221/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [222/500], Training Loss: 0.6950, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [223/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [224/500], Training Loss: 0.7626, Validation Loss: 0.6931, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [225/500], Training Loss: 0.7464, Validation Loss: 0.6931, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [226/500], Training Loss: 0.6946, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [227/500], Training Loss: 0.6943, Validation Loss: 0.6931, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [228/500], Training Loss: 0.6930, Validation Loss: 0.6932, Training Accuracy: 0.4763, Validation Accuracy: 0.5056\n",
      "Epoch [229/500], Training Loss: 0.6935, Validation Loss: 0.6933, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [230/500], Training Loss: 0.6926, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [231/500], Training Loss: 0.8167, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [232/500], Training Loss: 0.6920, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [233/500], Training Loss: 0.8168, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [234/500], Training Loss: 0.8166, Validation Loss: 0.6931, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [235/500], Training Loss: 0.9417, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [236/500], Training Loss: 0.7061, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [237/500], Training Loss: 0.6901, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [238/500], Training Loss: 0.7114, Validation Loss: 0.6932, Training Accuracy: 0.4775, Validation Accuracy: 0.4944\n",
      "Epoch [239/500], Training Loss: 0.9411, Validation Loss: 0.6932, Training Accuracy: 0.4738, Validation Accuracy: 0.5056\n",
      "Epoch [240/500], Training Loss: 0.6942, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [241/500], Training Loss: 0.8176, Validation Loss: 0.6932, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [242/500], Training Loss: 0.6924, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.4944\n",
      "Epoch [243/500], Training Loss: 0.7242, Validation Loss: 0.6931, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [244/500], Training Loss: 0.6977, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [245/500], Training Loss: 0.8177, Validation Loss: 0.6932, Training Accuracy: 0.4988, Validation Accuracy: 0.5056\n",
      "Epoch [246/500], Training Loss: 0.6954, Validation Loss: 0.6932, Training Accuracy: 0.4863, Validation Accuracy: 0.4944\n",
      "Epoch [247/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [248/500], Training Loss: 0.6926, Validation Loss: 0.6932, Training Accuracy: 0.4888, Validation Accuracy: 0.4944\n",
      "Epoch [249/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [250/500], Training Loss: 0.6927, Validation Loss: 0.6932, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [251/500], Training Loss: 0.6928, Validation Loss: 0.6932, Training Accuracy: 0.4600, Validation Accuracy: 0.5056\n",
      "Epoch [252/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [253/500], Training Loss: 0.6938, Validation Loss: 0.6931, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [254/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [255/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [256/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [257/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.4675, Validation Accuracy: 0.4944\n",
      "Epoch [258/500], Training Loss: 0.6940, Validation Loss: 0.6932, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [259/500], Training Loss: 0.6957, Validation Loss: 0.6932, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [260/500], Training Loss: 0.6943, Validation Loss: 0.6933, Training Accuracy: 0.4575, Validation Accuracy: 0.5056\n",
      "Epoch [261/500], Training Loss: 0.6937, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [262/500], Training Loss: 0.6927, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [263/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [264/500], Training Loss: 0.7656, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [265/500], Training Loss: 0.6925, Validation Loss: 0.6931, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [266/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [267/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [268/500], Training Loss: 0.6926, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [269/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [270/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [271/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [272/500], Training Loss: 0.6937, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [273/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [274/500], Training Loss: 0.6927, Validation Loss: 0.6932, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [275/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [276/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [277/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [278/500], Training Loss: 0.6916, Validation Loss: 0.6932, Training Accuracy: 0.4888, Validation Accuracy: 0.5056\n",
      "Epoch [279/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.4750, Validation Accuracy: 0.4944\n",
      "Epoch [280/500], Training Loss: 0.6933, Validation Loss: 0.6932, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [281/500], Training Loss: 0.7466, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [282/500], Training Loss: 0.6937, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [283/500], Training Loss: 0.6937, Validation Loss: 0.6932, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [284/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [285/500], Training Loss: 0.6928, Validation Loss: 0.6931, Training Accuracy: 0.4913, Validation Accuracy: 0.5056\n",
      "Epoch [286/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4725, Validation Accuracy: 0.4944\n",
      "Epoch [287/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [288/500], Training Loss: 0.6926, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [289/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [290/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [291/500], Training Loss: 0.8168, Validation Loss: 0.6932, Training Accuracy: 0.4913, Validation Accuracy: 0.4944\n",
      "Epoch [292/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.4500, Validation Accuracy: 0.5056\n",
      "Epoch [293/500], Training Loss: 0.6927, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [294/500], Training Loss: 0.8178, Validation Loss: 0.6932, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [295/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.4788, Validation Accuracy: 0.4944\n",
      "Epoch [296/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [297/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [298/500], Training Loss: 0.6917, Validation Loss: 0.6932, Training Accuracy: 0.4963, Validation Accuracy: 0.4944\n",
      "Epoch [299/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.4688, Validation Accuracy: 0.5056\n",
      "Epoch [300/500], Training Loss: 0.6923, Validation Loss: 0.6932, Training Accuracy: 0.4963, Validation Accuracy: 0.5056\n",
      "Epoch [301/500], Training Loss: 0.6908, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [302/500], Training Loss: 0.8176, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [303/500], Training Loss: 0.6926, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [304/500], Training Loss: 0.6932, Validation Loss: 0.6932, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [305/500], Training Loss: 0.6927, Validation Loss: 0.6931, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [306/500], Training Loss: 0.6933, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [307/500], Training Loss: 0.7062, Validation Loss: 0.6931, Training Accuracy: 0.4587, Validation Accuracy: 0.5056\n",
      "Epoch [308/500], Training Loss: 0.6940, Validation Loss: 0.6932, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [309/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [310/500], Training Loss: 0.6914, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [311/500], Training Loss: 0.6937, Validation Loss: 0.6932, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [312/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [313/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [314/500], Training Loss: 0.6927, Validation Loss: 0.6932, Training Accuracy: 0.4963, Validation Accuracy: 0.4944\n",
      "Epoch [315/500], Training Loss: 0.8176, Validation Loss: 0.6931, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [316/500], Training Loss: 0.6939, Validation Loss: 0.6932, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [317/500], Training Loss: 0.6924, Validation Loss: 0.6931, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [318/500], Training Loss: 0.6941, Validation Loss: 0.6931, Training Accuracy: 0.4575, Validation Accuracy: 0.5056\n",
      "Epoch [319/500], Training Loss: 0.6928, Validation Loss: 0.6934, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [320/500], Training Loss: 0.7878, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [321/500], Training Loss: 0.6939, Validation Loss: 0.6933, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [322/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [323/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [324/500], Training Loss: 0.6970, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [325/500], Training Loss: 0.6917, Validation Loss: 0.6932, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [326/500], Training Loss: 0.7467, Validation Loss: 0.6933, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [327/500], Training Loss: 0.7071, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [328/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4775, Validation Accuracy: 0.4944\n",
      "Epoch [329/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [330/500], Training Loss: 0.6926, Validation Loss: 0.6932, Training Accuracy: 0.4738, Validation Accuracy: 0.5056\n",
      "Epoch [331/500], Training Loss: 0.6927, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [332/500], Training Loss: 0.7114, Validation Loss: 0.6931, Training Accuracy: 0.4763, Validation Accuracy: 0.5056\n",
      "Epoch [333/500], Training Loss: 0.6916, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [334/500], Training Loss: 0.6995, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [335/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.4700, Validation Accuracy: 0.4944\n",
      "Epoch [336/500], Training Loss: 0.6936, Validation Loss: 0.6933, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [337/500], Training Loss: 0.6941, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [338/500], Training Loss: 0.8181, Validation Loss: 0.6931, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [339/500], Training Loss: 0.6930, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [340/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [341/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [342/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [343/500], Training Loss: 0.6930, Validation Loss: 0.6931, Training Accuracy: 0.4913, Validation Accuracy: 0.5056\n",
      "Epoch [344/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [345/500], Training Loss: 0.6917, Validation Loss: 0.6932, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [346/500], Training Loss: 0.6925, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.4944\n",
      "Epoch [347/500], Training Loss: 0.6928, Validation Loss: 0.6933, Training Accuracy: 0.4963, Validation Accuracy: 0.5056\n",
      "Epoch [348/500], Training Loss: 0.6977, Validation Loss: 0.6932, Training Accuracy: 0.4738, Validation Accuracy: 0.5056\n",
      "Epoch [349/500], Training Loss: 0.6925, Validation Loss: 0.6932, Training Accuracy: 0.4675, Validation Accuracy: 0.5056\n",
      "Epoch [350/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [351/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.4700, Validation Accuracy: 0.4944\n",
      "Epoch [352/500], Training Loss: 0.7487, Validation Loss: 0.6932, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [353/500], Training Loss: 0.6925, Validation Loss: 0.6932, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [354/500], Training Loss: 0.6937, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [355/500], Training Loss: 0.6933, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [356/500], Training Loss: 0.8176, Validation Loss: 0.6932, Training Accuracy: 0.4988, Validation Accuracy: 0.5056\n",
      "Epoch [357/500], Training Loss: 0.6910, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.4944\n",
      "Epoch [358/500], Training Loss: 0.6911, Validation Loss: 0.6932, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [359/500], Training Loss: 0.8324, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [360/500], Training Loss: 0.9418, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [361/500], Training Loss: 0.8159, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [362/500], Training Loss: 0.6927, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [363/500], Training Loss: 0.6919, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.4944\n",
      "Epoch [364/500], Training Loss: 0.7510, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [365/500], Training Loss: 1.0275, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [366/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4813, Validation Accuracy: 0.5056\n",
      "Epoch [367/500], Training Loss: 0.8167, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [368/500], Training Loss: 0.7048, Validation Loss: 0.6932, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [369/500], Training Loss: 0.6937, Validation Loss: 0.6934, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [370/500], Training Loss: 0.6992, Validation Loss: 0.6932, Training Accuracy: 0.4662, Validation Accuracy: 0.5056\n",
      "Epoch [371/500], Training Loss: 0.6917, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [372/500], Training Loss: 0.8161, Validation Loss: 0.6931, Training Accuracy: 0.4813, Validation Accuracy: 0.4944\n",
      "Epoch [373/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [374/500], Training Loss: 0.8212, Validation Loss: 0.6931, Training Accuracy: 0.4963, Validation Accuracy: 0.4944\n",
      "Epoch [375/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [376/500], Training Loss: 0.8166, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [377/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [378/500], Training Loss: 0.9411, Validation Loss: 0.6932, Training Accuracy: 0.4637, Validation Accuracy: 0.4944\n",
      "Epoch [379/500], Training Loss: 0.9509, Validation Loss: 0.6932, Training Accuracy: 0.4813, Validation Accuracy: 0.4944\n",
      "Epoch [380/500], Training Loss: 0.9411, Validation Loss: 0.6931, Training Accuracy: 0.4738, Validation Accuracy: 0.5056\n",
      "Epoch [381/500], Training Loss: 0.8176, Validation Loss: 0.6931, Training Accuracy: 0.4813, Validation Accuracy: 0.5056\n",
      "Epoch [382/500], Training Loss: 0.9403, Validation Loss: 0.6931, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [383/500], Training Loss: 0.7425, Validation Loss: 0.6932, Training Accuracy: 0.4537, Validation Accuracy: 0.5056\n",
      "Epoch [384/500], Training Loss: 0.8335, Validation Loss: 0.6931, Training Accuracy: 0.4813, Validation Accuracy: 0.5056\n",
      "Epoch [385/500], Training Loss: 0.8188, Validation Loss: 0.6931, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [386/500], Training Loss: 0.7108, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [387/500], Training Loss: 0.8152, Validation Loss: 0.6933, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [388/500], Training Loss: 1.1170, Validation Loss: 0.6932, Training Accuracy: 0.4788, Validation Accuracy: 0.4944\n",
      "Epoch [389/500], Training Loss: 1.1828, Validation Loss: 0.6932, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [390/500], Training Loss: 0.8182, Validation Loss: 0.6932, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [391/500], Training Loss: 0.7155, Validation Loss: 0.6932, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [392/500], Training Loss: 0.9399, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [393/500], Training Loss: 0.8176, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [394/500], Training Loss: 0.8175, Validation Loss: 0.6933, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [395/500], Training Loss: 0.7025, Validation Loss: 0.6931, Training Accuracy: 0.4625, Validation Accuracy: 0.5056\n",
      "Epoch [396/500], Training Loss: 0.8418, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [397/500], Training Loss: 0.8174, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [398/500], Training Loss: 0.6981, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [399/500], Training Loss: 0.8164, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [400/500], Training Loss: 0.6928, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [401/500], Training Loss: 0.6932, Validation Loss: 0.6932, Training Accuracy: 0.4913, Validation Accuracy: 0.5056\n",
      "Epoch [402/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [403/500], Training Loss: 0.9419, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [404/500], Training Loss: 0.8241, Validation Loss: 0.6932, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [405/500], Training Loss: 0.8179, Validation Loss: 0.6931, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [406/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [407/500], Training Loss: 0.9411, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [408/500], Training Loss: 0.8308, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [409/500], Training Loss: 0.6972, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [410/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [411/500], Training Loss: 0.6928, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [412/500], Training Loss: 0.6926, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [413/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [414/500], Training Loss: 0.6929, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [415/500], Training Loss: 0.8140, Validation Loss: 0.6932, Training Accuracy: 0.5062, Validation Accuracy: 0.5056\n",
      "Epoch [416/500], Training Loss: 0.8166, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [417/500], Training Loss: 0.8203, Validation Loss: 0.6931, Training Accuracy: 0.4988, Validation Accuracy: 0.5056\n",
      "Epoch [418/500], Training Loss: 0.6925, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [419/500], Training Loss: 0.7050, Validation Loss: 0.6932, Training Accuracy: 0.5038, Validation Accuracy: 0.4944\n",
      "Epoch [420/500], Training Loss: 0.8172, Validation Loss: 0.6932, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [421/500], Training Loss: 0.6923, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [422/500], Training Loss: 0.6927, Validation Loss: 0.6931, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [423/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [424/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [425/500], Training Loss: 0.6940, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [426/500], Training Loss: 0.6909, Validation Loss: 0.6932, Training Accuracy: 0.4988, Validation Accuracy: 0.4944\n",
      "Epoch [427/500], Training Loss: 0.6972, Validation Loss: 0.6932, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [428/500], Training Loss: 0.7000, Validation Loss: 0.6932, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [429/500], Training Loss: 0.8157, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [430/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.4944\n",
      "Epoch [431/500], Training Loss: 0.6929, Validation Loss: 0.6931, Training Accuracy: 0.4838, Validation Accuracy: 0.4944\n",
      "Epoch [432/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [433/500], Training Loss: 0.6917, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [434/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [435/500], Training Loss: 0.6932, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [436/500], Training Loss: 0.6919, Validation Loss: 0.6933, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [437/500], Training Loss: 0.9494, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [438/500], Training Loss: 0.6941, Validation Loss: 0.6932, Training Accuracy: 0.4625, Validation Accuracy: 0.5056\n",
      "Epoch [439/500], Training Loss: 0.8175, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [440/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.4944\n",
      "Epoch [441/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [442/500], Training Loss: 0.6927, Validation Loss: 0.6932, Training Accuracy: 0.4688, Validation Accuracy: 0.5056\n",
      "Epoch [443/500], Training Loss: 0.6926, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [444/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [445/500], Training Loss: 0.6933, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [446/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [447/500], Training Loss: 0.6971, Validation Loss: 0.6931, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [448/500], Training Loss: 0.6933, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [449/500], Training Loss: 0.6919, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [450/500], Training Loss: 0.8167, Validation Loss: 0.6931, Training Accuracy: 0.4688, Validation Accuracy: 0.5056\n",
      "Epoch [451/500], Training Loss: 0.8140, Validation Loss: 0.6932, Training Accuracy: 0.4888, Validation Accuracy: 0.5056\n",
      "Epoch [452/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [453/500], Training Loss: 0.6935, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [454/500], Training Loss: 0.6925, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [455/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [456/500], Training Loss: 0.6931, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [457/500], Training Loss: 0.6929, Validation Loss: 0.6932, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [458/500], Training Loss: 0.8174, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [459/500], Training Loss: 0.6927, Validation Loss: 0.6931, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [460/500], Training Loss: 1.0646, Validation Loss: 0.6934, Training Accuracy: 0.4650, Validation Accuracy: 0.5056\n",
      "Epoch [461/500], Training Loss: 0.8169, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [462/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [463/500], Training Loss: 0.8169, Validation Loss: 0.6932, Training Accuracy: 0.4763, Validation Accuracy: 0.4944\n",
      "Epoch [464/500], Training Loss: 0.8315, Validation Loss: 0.6931, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [465/500], Training Loss: 0.6934, Validation Loss: 0.6931, Training Accuracy: 0.4625, Validation Accuracy: 0.5056\n",
      "Epoch [466/500], Training Loss: 0.6918, Validation Loss: 0.6932, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [467/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [468/500], Training Loss: 0.8166, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [469/500], Training Loss: 0.6926, Validation Loss: 0.6931, Training Accuracy: 0.4713, Validation Accuracy: 0.5056\n",
      "Epoch [470/500], Training Loss: 0.8183, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [471/500], Training Loss: 0.7156, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.4944\n",
      "Epoch [472/500], Training Loss: 0.8168, Validation Loss: 0.6932, Training Accuracy: 0.4562, Validation Accuracy: 0.5056\n",
      "Epoch [473/500], Training Loss: 0.8175, Validation Loss: 0.6932, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [474/500], Training Loss: 0.6928, Validation Loss: 0.6932, Training Accuracy: 0.4988, Validation Accuracy: 0.4944\n",
      "Epoch [475/500], Training Loss: 0.9409, Validation Loss: 0.6932, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [476/500], Training Loss: 0.6921, Validation Loss: 0.6932, Training Accuracy: 0.4587, Validation Accuracy: 0.5056\n",
      "Epoch [477/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [478/500], Training Loss: 0.8185, Validation Loss: 0.6932, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [479/500], Training Loss: 0.6930, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [480/500], Training Loss: 0.6925, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [481/500], Training Loss: 0.6975, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [482/500], Training Loss: 0.6928, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [483/500], Training Loss: 0.6938, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [484/500], Training Loss: 0.6917, Validation Loss: 0.6932, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [485/500], Training Loss: 0.9540, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [486/500], Training Loss: 0.6934, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [487/500], Training Loss: 0.6915, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [488/500], Training Loss: 0.6924, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [489/500], Training Loss: 0.6933, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [490/500], Training Loss: 0.6940, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [491/500], Training Loss: 0.6935, Validation Loss: 0.6932, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [492/500], Training Loss: 0.6926, Validation Loss: 0.6932, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [493/500], Training Loss: 0.6918, Validation Loss: 0.6931, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [494/500], Training Loss: 0.8168, Validation Loss: 0.6933, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [495/500], Training Loss: 0.6918, Validation Loss: 0.6932, Training Accuracy: 0.4688, Validation Accuracy: 0.5056\n",
      "Epoch [496/500], Training Loss: 0.6937, Validation Loss: 0.6932, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [497/500], Training Loss: 0.8177, Validation Loss: 0.6932, Training Accuracy: 0.4713, Validation Accuracy: 0.5056\n",
      "Epoch [498/500], Training Loss: 0.7017, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [499/500], Training Loss: 0.6944, Validation Loss: 0.6932, Training Accuracy: 0.4938, Validation Accuracy: 0.4944\n",
      "Epoch [500/500], Training Loss: 0.8168, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Training Time: 11.46 seconds\n",
      "Epoch [1/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [2/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [3/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [4/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [5/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [6/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [7/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [8/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [9/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [10/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [11/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [12/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [13/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [14/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [15/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [16/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [17/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [18/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [19/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [20/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [21/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [22/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [23/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [24/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [25/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [26/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [27/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [28/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [29/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [30/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [31/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [32/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [33/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [34/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [35/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [36/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [37/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [38/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [39/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [40/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [41/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [42/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [43/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [44/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [45/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [46/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [47/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [48/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [49/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [50/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [51/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [52/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [53/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [54/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [55/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [56/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [57/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [58/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [59/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [60/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [61/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [62/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [63/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [64/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [65/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [66/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [67/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [68/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [69/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [70/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [71/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [72/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [73/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [74/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [75/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [76/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [77/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [78/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [79/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [80/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [81/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [82/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [83/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [84/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [85/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [86/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [87/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [88/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [89/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [90/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [91/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [92/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [93/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [94/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [95/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [96/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [97/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [98/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [99/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [100/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [101/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [102/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [103/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [104/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [105/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [106/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [107/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [108/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [109/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [110/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [111/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [112/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [113/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [114/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [115/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [116/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [117/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [118/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [119/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [120/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [121/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [122/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [123/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [124/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [125/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [126/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [127/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [128/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [129/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [130/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [131/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [132/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [133/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [134/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [135/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [136/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [137/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [138/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [139/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [140/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [141/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [142/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [143/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [144/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [145/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [146/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [147/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [148/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [149/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [150/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [151/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [152/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [153/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [154/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [155/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [156/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [157/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [158/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [159/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [160/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [161/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [162/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [163/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [164/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [165/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [166/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [167/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [168/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [169/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [170/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [171/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [172/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [173/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [174/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [175/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [176/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [177/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [178/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [179/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [180/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [181/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [182/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [183/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [184/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [185/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [186/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [187/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [188/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [189/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [190/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [191/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [192/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [193/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [194/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [195/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [196/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [197/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [198/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [199/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [200/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [201/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [202/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [203/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [204/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [205/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [206/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [207/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [208/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [209/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [210/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [211/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [212/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [213/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [214/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [215/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [216/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [217/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [218/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [219/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [220/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [221/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [222/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [223/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [224/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [225/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [226/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [227/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [228/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [229/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [230/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [231/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [232/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [233/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [234/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [235/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [236/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [237/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [238/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [239/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [240/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [241/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [242/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [243/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [244/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [245/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [246/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [247/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [248/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [249/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [250/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [251/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [252/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [253/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [254/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [255/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [256/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [257/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [258/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [259/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [260/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [261/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [262/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [263/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [264/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [265/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [266/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [267/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [268/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [269/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [270/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [271/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [272/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [273/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [274/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [275/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [276/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [277/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [278/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [279/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [280/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [281/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [282/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [283/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [284/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [285/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [286/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [287/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [288/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [289/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [290/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [291/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [292/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [293/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [294/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [295/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [296/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [297/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [298/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [299/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [300/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [301/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [302/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [303/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [304/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [305/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [306/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [307/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [308/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [309/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [310/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [311/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [312/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [313/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [314/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [315/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [316/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [317/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [318/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [319/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [320/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [321/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [322/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [323/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [324/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [325/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [326/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [327/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [328/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [329/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [330/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [331/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [332/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [333/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [334/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [335/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [336/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [337/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [338/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [339/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [340/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [341/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [342/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [343/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [344/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [345/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [346/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [347/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [348/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [349/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [350/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [351/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [352/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [353/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [354/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [355/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [356/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [357/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [358/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [359/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [360/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [361/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [362/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [363/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [364/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [365/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [366/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [367/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [368/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [369/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [370/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [371/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [372/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [373/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [374/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [375/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [376/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [377/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [378/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [379/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [380/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [381/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [382/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [383/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [384/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [385/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [386/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [387/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [388/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [389/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [390/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [391/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [392/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [393/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [394/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [395/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [396/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [397/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [398/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [399/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [400/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [401/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [402/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [403/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [404/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [405/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [406/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [407/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [408/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [409/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [410/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [411/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [412/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [413/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [414/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [415/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [416/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [417/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [418/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [419/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [420/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [421/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [422/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [423/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [424/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [425/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [426/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [427/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [428/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [429/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [430/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [431/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [432/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [433/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [434/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [435/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [436/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [437/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [438/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [439/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [440/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [441/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [442/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [443/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [444/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [445/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [446/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [447/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [448/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [449/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [450/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [451/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [452/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [453/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [454/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [455/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [456/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [457/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [458/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [459/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [460/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [461/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [462/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [463/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [464/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [465/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [466/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [467/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [468/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [469/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [470/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [471/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [472/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [473/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [474/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [475/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [476/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [477/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [478/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [479/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [480/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [481/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [482/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [483/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [484/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [485/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [486/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [487/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [488/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [489/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [490/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [491/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [492/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [493/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [494/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [495/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [496/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [497/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [498/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [499/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Epoch [500/500], Test Loss: 0.6150, Testing Accuracy: 0.7071, \n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.1, Training Accuracy: 0.9463, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.3, Training Accuracy: 0.8600, Validation Accuracy: 0.8202, Testing Accuracy: 0.7879\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.5, Training Accuracy: 0.5900, Validation Accuracy: 0.5843, Testing Accuracy: 0.6768\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n",
      "Dropout Rate: 0.7, Training Accuracy: 0.4875, Validation Accuracy: 0.5056, Testing Accuracy: 0.7071\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, dropout1, dropout2, dropout3, dropout4):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "    \n",
    "        self.fc1 = nn.Linear(7, 256)  # Input layer\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)  # Hidden layers\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(dropout3)\n",
    "\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(dropout4)\n",
    "\n",
    "        self.fc5 = nn.Linear(32, 1)  # Output layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Using sigmoid because of Binary Target\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    " \n",
    "dropouts_rates = [0.1, 0.3, 0.5, 0.7]\n",
    "results = []\n",
    "\n",
    "for rate in dropouts_rates:\n",
    "    model = NeuralNetwork(dropout1 = rate, dropout2 = rate, dropout3 = rate, dropout4 = rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    summary(model, input_size=(1, 7))\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs = 500\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs): #defining the training loop\n",
    "        \n",
    "        model.train() #model in training mode\n",
    "        training_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0 \n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            outputs = model(inputs).squeeze()  # output -> predictions   :   labels -> actual values [ 1 or 0 ]\n",
    "            loss = loss_function(outputs, labels.float())  # loss is calsulated between predicted and the actual values\n",
    "            optimizer.zero_grad()  # Before backpropagation, initialize all weights to zero \n",
    "            loss.backward()  # performs backward propagation\n",
    "            optimizer.step()  # updates the parameters learnt from backpropagation (weights)\n",
    "\n",
    "            training_loss += loss.item()  # .item() - extracts the scalar value of the loss tensor. Loss is calculated per batch\n",
    "\n",
    "            predicted = torch.round(outputs)  # Convert probabilities to binary predictions \n",
    "            correct_predictions += (predicted == labels).sum().item()  #creates a tensor oa maps how many actually match that conditon\n",
    "            total_predictions += labels.size(0)  #first dimension of the tensor\n",
    "\n",
    "        train_losses.append(training_loss / len(train_loader))  #for loss calculation\n",
    "        train_accuracies.append(correct_predictions / total_predictions)\n",
    "\n",
    "\n",
    "        model.eval()  #model in evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_predictions = 0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_outputs = model(val_inputs).squeeze()\n",
    "                val_loss += loss_function(val_outputs, val_labels.float()).item()\n",
    "\n",
    "                predicted = torch.round(val_outputs)\n",
    "                val_correct_predictions += (predicted == val_labels).sum().item()\n",
    "                val_total_predictions += val_labels.size(0)\n",
    "\n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            val_accuracies.append(val_correct_predictions / val_total_predictions)\n",
    "\n",
    "        average_training_loss = training_loss / len(train_loader)  #loss per batch\n",
    "        average_validation_loss = val_loss / len(val_loader)\n",
    "        training_accuracy = correct_predictions / total_predictions  \n",
    "        validation_accuracy = val_correct_predictions / val_total_predictions\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                f'Training Loss: {average_training_loss:.4f}, '\n",
    "                f'Validation Loss: {average_validation_loss:.4f}, '\n",
    "                f'Training Accuracy: {training_accuracy:.4f}, '\n",
    "                f'Validation Accuracy: {validation_accuracy:.4f}')\n",
    "        \n",
    "        if average_validation_loss < best_val_loss:\n",
    "            best_val_loss = average_validation_loss\n",
    "            torch.save(model.state_dict(), 'best_model_weights.pth')\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'Training Time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load('best_model_weights.pth'))\n",
    "\n",
    "    # num_epochss = 600\n",
    "    for epoch in range(num_epochs):\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct_predictions = 0\n",
    "        test_total_predictions = 0\n",
    "\n",
    "        confusion_predictions = []\n",
    "        confusion_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_inputs, test_labels in test_loader:\n",
    "                test_outputs = model(test_inputs).squeeze()\n",
    "                test_loss += loss_function(test_outputs, test_labels.float()).item()\n",
    "                \n",
    "                predicted = torch.round(test_outputs)\n",
    "                test_correct_predictions += (predicted == test_labels.float()).sum().item()\n",
    "                test_total_predictions += test_labels.size(0)\n",
    "            \n",
    "                confusion_predictions.extend(predicted.numpy())  #for confusion matrix\n",
    "                confusion_labels.extend(test_labels.numpy())  #actual class labels\n",
    "\n",
    "            test_losses.append(test_loss / len(test_loader))  # Gives the average loss per batch\n",
    "            test_accuracies.append(test_correct_predictions / test_total_predictions)  # ratio of correct preds / total preds -> accuracy\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        test_accuracy = test_correct_predictions / test_total_predictions\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                f'Test Loss: {avg_test_loss:.4f}, '\n",
    "                f'Testing Accuracy: {test_accuracy:.4f}, ')\n",
    "        \n",
    "\n",
    "        results.append({\n",
    "        'dropout_rate': rate,\n",
    "        'train_accuracy': training_accuracy,\n",
    "        'val_accuracy': validation_accuracy,\n",
    "        'test_accuracy': test_accuracy\n",
    "    })\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Dropout Rate: {result['dropout_rate']}, \"\n",
    "          f\"Training Accuracy: {result['train_accuracy']:.4f}, \"\n",
    "          f\"Validation Accuracy: {result['val_accuracy']:.4f}, \"\n",
    "          f\"Testing Accuracy: {result['test_accuracy']:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch size as hyperparameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 0.6004, Validation Loss: 0.4874, Training Accuracy: 0.6987, Validation Accuracy: 0.7528\n",
      "Epoch [2/500], Training Loss: 0.6686, Validation Loss: 0.4662, Training Accuracy: 0.7163, Validation Accuracy: 0.7303\n",
      "Epoch [3/500], Training Loss: 0.6213, Validation Loss: 0.5770, Training Accuracy: 0.7087, Validation Accuracy: 0.6854\n",
      "Epoch [4/500], Training Loss: 0.5882, Validation Loss: 0.4763, Training Accuracy: 0.7037, Validation Accuracy: 0.7753\n",
      "Epoch [5/500], Training Loss: 0.5690, Validation Loss: 0.5905, Training Accuracy: 0.6937, Validation Accuracy: 0.7528\n",
      "Epoch [6/500], Training Loss: 0.5464, Validation Loss: 0.5188, Training Accuracy: 0.7225, Validation Accuracy: 0.6742\n",
      "Epoch [7/500], Training Loss: 0.5752, Validation Loss: 0.5046, Training Accuracy: 0.7063, Validation Accuracy: 0.7753\n",
      "Epoch [8/500], Training Loss: 0.5512, Validation Loss: 0.5073, Training Accuracy: 0.7163, Validation Accuracy: 0.7753\n",
      "Epoch [9/500], Training Loss: 0.5312, Validation Loss: 0.5357, Training Accuracy: 0.7288, Validation Accuracy: 0.6966\n",
      "Epoch [10/500], Training Loss: 0.5726, Validation Loss: 0.4703, Training Accuracy: 0.7188, Validation Accuracy: 0.7865\n",
      "Epoch [11/500], Training Loss: 0.5816, Validation Loss: 0.5317, Training Accuracy: 0.7238, Validation Accuracy: 0.6966\n",
      "Epoch [12/500], Training Loss: 0.5969, Validation Loss: 0.5484, Training Accuracy: 0.7087, Validation Accuracy: 0.7191\n",
      "Epoch [13/500], Training Loss: 0.5364, Validation Loss: 0.4607, Training Accuracy: 0.7375, Validation Accuracy: 0.7528\n",
      "Epoch [14/500], Training Loss: 0.5217, Validation Loss: 0.5477, Training Accuracy: 0.7450, Validation Accuracy: 0.7528\n",
      "Epoch [15/500], Training Loss: 0.5410, Validation Loss: 0.4508, Training Accuracy: 0.7375, Validation Accuracy: 0.7640\n",
      "Epoch [16/500], Training Loss: 0.5501, Validation Loss: 0.5647, Training Accuracy: 0.7163, Validation Accuracy: 0.7640\n",
      "Epoch [17/500], Training Loss: 0.5898, Validation Loss: 0.4881, Training Accuracy: 0.7362, Validation Accuracy: 0.7640\n",
      "Epoch [18/500], Training Loss: 0.6088, Validation Loss: 0.5858, Training Accuracy: 0.7275, Validation Accuracy: 0.5506\n",
      "Epoch [19/500], Training Loss: 0.7586, Validation Loss: 0.5076, Training Accuracy: 0.7275, Validation Accuracy: 0.6966\n",
      "Epoch [20/500], Training Loss: 0.5486, Validation Loss: 0.4945, Training Accuracy: 0.7325, Validation Accuracy: 0.7416\n",
      "Epoch [21/500], Training Loss: 0.6986, Validation Loss: 0.6147, Training Accuracy: 0.7200, Validation Accuracy: 0.7528\n",
      "Epoch [22/500], Training Loss: 0.6149, Validation Loss: 0.5029, Training Accuracy: 0.7150, Validation Accuracy: 0.7416\n",
      "Epoch [23/500], Training Loss: 0.5555, Validation Loss: 0.4696, Training Accuracy: 0.7087, Validation Accuracy: 0.7416\n",
      "Epoch [24/500], Training Loss: 0.5613, Validation Loss: 0.4849, Training Accuracy: 0.7250, Validation Accuracy: 0.7416\n",
      "Epoch [25/500], Training Loss: 0.5423, Validation Loss: 0.4958, Training Accuracy: 0.7238, Validation Accuracy: 0.6742\n",
      "Epoch [26/500], Training Loss: 0.5622, Validation Loss: 0.5065, Training Accuracy: 0.7150, Validation Accuracy: 0.7079\n",
      "Epoch [27/500], Training Loss: 0.5787, Validation Loss: 0.4967, Training Accuracy: 0.7212, Validation Accuracy: 0.7191\n",
      "Epoch [28/500], Training Loss: 0.5377, Validation Loss: 0.4836, Training Accuracy: 0.7350, Validation Accuracy: 0.7416\n",
      "Epoch [29/500], Training Loss: 0.5335, Validation Loss: 0.6190, Training Accuracy: 0.7350, Validation Accuracy: 0.6629\n",
      "Epoch [30/500], Training Loss: 0.5575, Validation Loss: 0.5305, Training Accuracy: 0.7312, Validation Accuracy: 0.6854\n",
      "Epoch [31/500], Training Loss: 0.5104, Validation Loss: 0.4650, Training Accuracy: 0.7325, Validation Accuracy: 0.7303\n",
      "Epoch [32/500], Training Loss: 0.5243, Validation Loss: 0.4463, Training Accuracy: 0.7350, Validation Accuracy: 0.7528\n",
      "Epoch [33/500], Training Loss: 0.5034, Validation Loss: 0.4767, Training Accuracy: 0.7450, Validation Accuracy: 0.7303\n",
      "Epoch [34/500], Training Loss: 0.5189, Validation Loss: 0.4817, Training Accuracy: 0.7362, Validation Accuracy: 0.7303\n",
      "Epoch [35/500], Training Loss: 0.5999, Validation Loss: 0.4877, Training Accuracy: 0.7488, Validation Accuracy: 0.7191\n",
      "Epoch [36/500], Training Loss: 0.5462, Validation Loss: 0.5699, Training Accuracy: 0.7438, Validation Accuracy: 0.7416\n",
      "Epoch [37/500], Training Loss: 0.4959, Validation Loss: 0.4709, Training Accuracy: 0.7638, Validation Accuracy: 0.7191\n",
      "Epoch [38/500], Training Loss: 0.5658, Validation Loss: 0.5216, Training Accuracy: 0.7150, Validation Accuracy: 0.6966\n",
      "Epoch [39/500], Training Loss: 0.5450, Validation Loss: 0.4501, Training Accuracy: 0.7400, Validation Accuracy: 0.7978\n",
      "Epoch [40/500], Training Loss: 0.5747, Validation Loss: 0.4563, Training Accuracy: 0.7163, Validation Accuracy: 0.6966\n",
      "Epoch [41/500], Training Loss: 0.5422, Validation Loss: 0.5280, Training Accuracy: 0.7450, Validation Accuracy: 0.7753\n",
      "Epoch [42/500], Training Loss: 0.5627, Validation Loss: 0.4769, Training Accuracy: 0.7225, Validation Accuracy: 0.6966\n",
      "Epoch [43/500], Training Loss: 0.5043, Validation Loss: 0.5212, Training Accuracy: 0.7575, Validation Accuracy: 0.7528\n",
      "Epoch [44/500], Training Loss: 0.5764, Validation Loss: 0.4735, Training Accuracy: 0.7438, Validation Accuracy: 0.7416\n",
      "Epoch [45/500], Training Loss: 0.5762, Validation Loss: 0.4808, Training Accuracy: 0.7288, Validation Accuracy: 0.7865\n",
      "Epoch [46/500], Training Loss: 0.5881, Validation Loss: 0.4601, Training Accuracy: 0.7100, Validation Accuracy: 0.7865\n",
      "Epoch [47/500], Training Loss: 0.6073, Validation Loss: 0.4498, Training Accuracy: 0.7212, Validation Accuracy: 0.7753\n",
      "Epoch [48/500], Training Loss: 0.5292, Validation Loss: 0.4650, Training Accuracy: 0.7288, Validation Accuracy: 0.7416\n",
      "Epoch [49/500], Training Loss: 0.5230, Validation Loss: 0.4638, Training Accuracy: 0.7388, Validation Accuracy: 0.7416\n",
      "Epoch [50/500], Training Loss: 0.5684, Validation Loss: 0.4719, Training Accuracy: 0.7388, Validation Accuracy: 0.7528\n",
      "Epoch [51/500], Training Loss: 0.5157, Validation Loss: 0.4877, Training Accuracy: 0.7425, Validation Accuracy: 0.7191\n",
      "Epoch [52/500], Training Loss: 0.5530, Validation Loss: 0.4724, Training Accuracy: 0.7262, Validation Accuracy: 0.7303\n",
      "Epoch [53/500], Training Loss: 0.5278, Validation Loss: 0.4466, Training Accuracy: 0.7250, Validation Accuracy: 0.7303\n",
      "Epoch [54/500], Training Loss: 0.5081, Validation Loss: 0.4500, Training Accuracy: 0.7462, Validation Accuracy: 0.7416\n",
      "Epoch [55/500], Training Loss: 0.5243, Validation Loss: 0.4612, Training Accuracy: 0.7412, Validation Accuracy: 0.7416\n",
      "Epoch [56/500], Training Loss: 0.5298, Validation Loss: 0.5305, Training Accuracy: 0.7462, Validation Accuracy: 0.7528\n",
      "Epoch [57/500], Training Loss: 0.5031, Validation Loss: 0.5394, Training Accuracy: 0.7525, Validation Accuracy: 0.7303\n",
      "Epoch [58/500], Training Loss: 0.5314, Validation Loss: 0.4602, Training Accuracy: 0.7462, Validation Accuracy: 0.7191\n",
      "Epoch [59/500], Training Loss: 0.5011, Validation Loss: 0.5170, Training Accuracy: 0.7575, Validation Accuracy: 0.7528\n",
      "Epoch [60/500], Training Loss: 0.5255, Validation Loss: 0.5828, Training Accuracy: 0.7500, Validation Accuracy: 0.6742\n",
      "Epoch [61/500], Training Loss: 0.5371, Validation Loss: 0.5178, Training Accuracy: 0.7350, Validation Accuracy: 0.6854\n",
      "Epoch [62/500], Training Loss: 0.5199, Validation Loss: 0.5003, Training Accuracy: 0.7325, Validation Accuracy: 0.7303\n",
      "Epoch [63/500], Training Loss: 0.5243, Validation Loss: 0.4546, Training Accuracy: 0.7475, Validation Accuracy: 0.7753\n",
      "Epoch [64/500], Training Loss: 0.6911, Validation Loss: 0.5254, Training Accuracy: 0.7100, Validation Accuracy: 0.6742\n",
      "Epoch [65/500], Training Loss: 0.6044, Validation Loss: 0.4367, Training Accuracy: 0.7462, Validation Accuracy: 0.7640\n",
      "Epoch [66/500], Training Loss: 0.6389, Validation Loss: 0.6303, Training Accuracy: 0.7037, Validation Accuracy: 0.6292\n",
      "Epoch [67/500], Training Loss: 0.7242, Validation Loss: 0.4685, Training Accuracy: 0.7125, Validation Accuracy: 0.7528\n",
      "Epoch [68/500], Training Loss: 0.5919, Validation Loss: 0.4977, Training Accuracy: 0.6663, Validation Accuracy: 0.7303\n",
      "Epoch [69/500], Training Loss: 0.5346, Validation Loss: 0.4618, Training Accuracy: 0.7200, Validation Accuracy: 0.7528\n",
      "Epoch [70/500], Training Loss: 0.5320, Validation Loss: 0.4535, Training Accuracy: 0.7212, Validation Accuracy: 0.7528\n",
      "Epoch [71/500], Training Loss: 0.5425, Validation Loss: 0.4637, Training Accuracy: 0.7388, Validation Accuracy: 0.7528\n",
      "Epoch [72/500], Training Loss: 0.5210, Validation Loss: 0.4690, Training Accuracy: 0.7450, Validation Accuracy: 0.7303\n",
      "Epoch [73/500], Training Loss: 0.5261, Validation Loss: 0.4475, Training Accuracy: 0.7250, Validation Accuracy: 0.7753\n",
      "Epoch [74/500], Training Loss: 0.5033, Validation Loss: 0.5157, Training Accuracy: 0.7388, Validation Accuracy: 0.6966\n",
      "Epoch [75/500], Training Loss: 0.5275, Validation Loss: 0.4924, Training Accuracy: 0.7312, Validation Accuracy: 0.7416\n",
      "Epoch [76/500], Training Loss: 0.5183, Validation Loss: 0.4852, Training Accuracy: 0.7450, Validation Accuracy: 0.7079\n",
      "Epoch [77/500], Training Loss: 0.4997, Validation Loss: 0.4611, Training Accuracy: 0.7500, Validation Accuracy: 0.7303\n",
      "Epoch [78/500], Training Loss: 0.4970, Validation Loss: 0.4745, Training Accuracy: 0.7612, Validation Accuracy: 0.7191\n",
      "Epoch [79/500], Training Loss: 0.5138, Validation Loss: 0.4577, Training Accuracy: 0.7462, Validation Accuracy: 0.7416\n",
      "Epoch [80/500], Training Loss: 0.5154, Validation Loss: 0.5076, Training Accuracy: 0.7488, Validation Accuracy: 0.7416\n",
      "Epoch [81/500], Training Loss: 0.5413, Validation Loss: 0.5040, Training Accuracy: 0.7450, Validation Accuracy: 0.7753\n",
      "Epoch [82/500], Training Loss: 0.5549, Validation Loss: 0.4705, Training Accuracy: 0.7113, Validation Accuracy: 0.7528\n",
      "Epoch [83/500], Training Loss: 0.5295, Validation Loss: 0.5763, Training Accuracy: 0.7288, Validation Accuracy: 0.7303\n",
      "Epoch [84/500], Training Loss: 0.5507, Validation Loss: 0.5120, Training Accuracy: 0.7300, Validation Accuracy: 0.7079\n",
      "Epoch [85/500], Training Loss: 0.5911, Validation Loss: 0.4894, Training Accuracy: 0.6763, Validation Accuracy: 0.7191\n",
      "Epoch [86/500], Training Loss: 0.5717, Validation Loss: 0.4892, Training Accuracy: 0.7238, Validation Accuracy: 0.6966\n",
      "Epoch [87/500], Training Loss: 0.7010, Validation Loss: 0.4894, Training Accuracy: 0.7125, Validation Accuracy: 0.7079\n",
      "Epoch [88/500], Training Loss: 0.5386, Validation Loss: 0.4926, Training Accuracy: 0.7200, Validation Accuracy: 0.7416\n",
      "Epoch [89/500], Training Loss: 0.5339, Validation Loss: 0.5855, Training Accuracy: 0.7288, Validation Accuracy: 0.7303\n",
      "Epoch [90/500], Training Loss: 0.5518, Validation Loss: 0.4864, Training Accuracy: 0.7175, Validation Accuracy: 0.7079\n",
      "Epoch [91/500], Training Loss: 0.6753, Validation Loss: 0.5188, Training Accuracy: 0.7050, Validation Accuracy: 0.6966\n",
      "Epoch [92/500], Training Loss: 0.5436, Validation Loss: 0.4540, Training Accuracy: 0.7125, Validation Accuracy: 0.7416\n",
      "Epoch [93/500], Training Loss: 0.5647, Validation Loss: 0.4366, Training Accuracy: 0.7150, Validation Accuracy: 0.7753\n",
      "Epoch [94/500], Training Loss: 0.5540, Validation Loss: 0.4931, Training Accuracy: 0.7075, Validation Accuracy: 0.6966\n",
      "Epoch [95/500], Training Loss: 0.5502, Validation Loss: 0.4724, Training Accuracy: 0.7288, Validation Accuracy: 0.7191\n",
      "Epoch [96/500], Training Loss: 0.5429, Validation Loss: 0.4701, Training Accuracy: 0.7525, Validation Accuracy: 0.7303\n",
      "Epoch [97/500], Training Loss: 0.5066, Validation Loss: 0.4428, Training Accuracy: 0.7538, Validation Accuracy: 0.7865\n",
      "Epoch [98/500], Training Loss: 0.6379, Validation Loss: 0.4588, Training Accuracy: 0.7500, Validation Accuracy: 0.7640\n",
      "Epoch [99/500], Training Loss: 0.5747, Validation Loss: 0.5455, Training Accuracy: 0.7388, Validation Accuracy: 0.6966\n",
      "Epoch [100/500], Training Loss: 0.5903, Validation Loss: 0.4481, Training Accuracy: 0.6937, Validation Accuracy: 0.7640\n",
      "Epoch [101/500], Training Loss: 0.5870, Validation Loss: 0.5196, Training Accuracy: 0.7475, Validation Accuracy: 0.7303\n",
      "Epoch [102/500], Training Loss: 0.5984, Validation Loss: 0.4694, Training Accuracy: 0.7562, Validation Accuracy: 0.7416\n",
      "Epoch [103/500], Training Loss: 0.5802, Validation Loss: 0.4326, Training Accuracy: 0.7238, Validation Accuracy: 0.7753\n",
      "Epoch [104/500], Training Loss: 0.6515, Validation Loss: 0.4852, Training Accuracy: 0.7412, Validation Accuracy: 0.7079\n",
      "Epoch [105/500], Training Loss: 0.6085, Validation Loss: 0.4802, Training Accuracy: 0.7275, Validation Accuracy: 0.7640\n",
      "Epoch [106/500], Training Loss: 0.5497, Validation Loss: 0.4497, Training Accuracy: 0.7288, Validation Accuracy: 0.7303\n",
      "Epoch [107/500], Training Loss: 0.5694, Validation Loss: 0.5040, Training Accuracy: 0.7212, Validation Accuracy: 0.6854\n",
      "Epoch [108/500], Training Loss: 0.5236, Validation Loss: 0.4755, Training Accuracy: 0.7225, Validation Accuracy: 0.7303\n",
      "Epoch [109/500], Training Loss: 0.5345, Validation Loss: 0.4951, Training Accuracy: 0.7362, Validation Accuracy: 0.7079\n",
      "Epoch [110/500], Training Loss: 0.5359, Validation Loss: 0.4750, Training Accuracy: 0.7500, Validation Accuracy: 0.7191\n",
      "Epoch [111/500], Training Loss: 0.5432, Validation Loss: 0.4988, Training Accuracy: 0.7212, Validation Accuracy: 0.7079\n",
      "Epoch [112/500], Training Loss: 0.7694, Validation Loss: 0.7338, Training Accuracy: 0.7500, Validation Accuracy: 0.7303\n",
      "Epoch [113/500], Training Loss: 0.6083, Validation Loss: 0.4796, Training Accuracy: 0.6963, Validation Accuracy: 0.7191\n",
      "Epoch [114/500], Training Loss: 0.5961, Validation Loss: 0.4821, Training Accuracy: 0.7000, Validation Accuracy: 0.7191\n",
      "Epoch [115/500], Training Loss: 0.5386, Validation Loss: 0.4571, Training Accuracy: 0.7262, Validation Accuracy: 0.7303\n",
      "Epoch [116/500], Training Loss: 0.5560, Validation Loss: 0.5512, Training Accuracy: 0.7050, Validation Accuracy: 0.6854\n",
      "Epoch [117/500], Training Loss: 0.5490, Validation Loss: 0.5674, Training Accuracy: 0.7000, Validation Accuracy: 0.6854\n",
      "Epoch [118/500], Training Loss: 0.7087, Validation Loss: 0.4682, Training Accuracy: 0.7200, Validation Accuracy: 0.7303\n",
      "Epoch [119/500], Training Loss: 0.8147, Validation Loss: 0.4640, Training Accuracy: 0.7425, Validation Accuracy: 0.7416\n",
      "Epoch [120/500], Training Loss: 0.5752, Validation Loss: 0.4503, Training Accuracy: 0.7150, Validation Accuracy: 0.7416\n",
      "Epoch [121/500], Training Loss: 0.5837, Validation Loss: 0.4632, Training Accuracy: 0.7212, Validation Accuracy: 0.7416\n",
      "Epoch [122/500], Training Loss: 0.5685, Validation Loss: 0.4621, Training Accuracy: 0.7362, Validation Accuracy: 0.7416\n",
      "Epoch [123/500], Training Loss: 0.6802, Validation Loss: 0.5097, Training Accuracy: 0.7163, Validation Accuracy: 0.7303\n",
      "Epoch [124/500], Training Loss: 0.5582, Validation Loss: 0.4705, Training Accuracy: 0.7137, Validation Accuracy: 0.7303\n",
      "Epoch [125/500], Training Loss: 0.5343, Validation Loss: 0.5835, Training Accuracy: 0.7288, Validation Accuracy: 0.6854\n",
      "Epoch [126/500], Training Loss: 0.5862, Validation Loss: 0.5644, Training Accuracy: 0.7125, Validation Accuracy: 0.7079\n",
      "Epoch [127/500], Training Loss: 0.5741, Validation Loss: 0.5514, Training Accuracy: 0.7325, Validation Accuracy: 0.6966\n",
      "Epoch [128/500], Training Loss: 0.5349, Validation Loss: 0.6548, Training Accuracy: 0.7275, Validation Accuracy: 0.6742\n",
      "Epoch [129/500], Training Loss: 0.5427, Validation Loss: 0.5068, Training Accuracy: 0.7338, Validation Accuracy: 0.7079\n",
      "Epoch [130/500], Training Loss: 0.5309, Validation Loss: 0.4944, Training Accuracy: 0.7225, Validation Accuracy: 0.6966\n",
      "Epoch [131/500], Training Loss: 0.5200, Validation Loss: 0.5032, Training Accuracy: 0.7238, Validation Accuracy: 0.6966\n",
      "Epoch [132/500], Training Loss: 0.6658, Validation Loss: 0.5100, Training Accuracy: 0.7325, Validation Accuracy: 0.7303\n",
      "Epoch [133/500], Training Loss: 0.5672, Validation Loss: 0.5410, Training Accuracy: 0.7238, Validation Accuracy: 0.7079\n",
      "Epoch [134/500], Training Loss: 0.7002, Validation Loss: 0.4976, Training Accuracy: 0.7175, Validation Accuracy: 0.6966\n",
      "Epoch [135/500], Training Loss: 0.6524, Validation Loss: 0.5057, Training Accuracy: 0.7113, Validation Accuracy: 0.6854\n",
      "Epoch [136/500], Training Loss: 0.6525, Validation Loss: 0.5165, Training Accuracy: 0.7375, Validation Accuracy: 0.6742\n",
      "Epoch [137/500], Training Loss: 0.7426, Validation Loss: 0.4756, Training Accuracy: 0.7288, Validation Accuracy: 0.7303\n",
      "Epoch [138/500], Training Loss: 0.6104, Validation Loss: 0.4710, Training Accuracy: 0.7312, Validation Accuracy: 0.7303\n",
      "Epoch [139/500], Training Loss: 0.6725, Validation Loss: 0.5034, Training Accuracy: 0.7100, Validation Accuracy: 0.7079\n",
      "Epoch [140/500], Training Loss: 0.6455, Validation Loss: 0.4735, Training Accuracy: 0.7150, Validation Accuracy: 0.7416\n",
      "Epoch [141/500], Training Loss: 0.5867, Validation Loss: 0.4784, Training Accuracy: 0.7188, Validation Accuracy: 0.7191\n",
      "Epoch [142/500], Training Loss: 0.6890, Validation Loss: 0.5312, Training Accuracy: 0.7275, Validation Accuracy: 0.6517\n",
      "Epoch [143/500], Training Loss: 0.5647, Validation Loss: 0.4757, Training Accuracy: 0.7087, Validation Accuracy: 0.7303\n",
      "Epoch [144/500], Training Loss: 0.5533, Validation Loss: 0.4509, Training Accuracy: 0.7312, Validation Accuracy: 0.7416\n",
      "Epoch [145/500], Training Loss: 0.5217, Validation Loss: 0.4327, Training Accuracy: 0.7375, Validation Accuracy: 0.7640\n",
      "Epoch [146/500], Training Loss: 0.5709, Validation Loss: 0.4606, Training Accuracy: 0.7538, Validation Accuracy: 0.7528\n",
      "Epoch [147/500], Training Loss: 0.5723, Validation Loss: 0.4576, Training Accuracy: 0.7225, Validation Accuracy: 0.7528\n",
      "Epoch [148/500], Training Loss: 0.6183, Validation Loss: 0.4514, Training Accuracy: 0.7238, Validation Accuracy: 0.7640\n",
      "Epoch [149/500], Training Loss: 0.5997, Validation Loss: 0.4280, Training Accuracy: 0.7512, Validation Accuracy: 0.7865\n",
      "Epoch [150/500], Training Loss: 0.5750, Validation Loss: 0.4375, Training Accuracy: 0.7475, Validation Accuracy: 0.7640\n",
      "Epoch [151/500], Training Loss: 0.5801, Validation Loss: 0.4832, Training Accuracy: 0.7625, Validation Accuracy: 0.7528\n",
      "Epoch [152/500], Training Loss: 0.6513, Validation Loss: 0.4848, Training Accuracy: 0.7362, Validation Accuracy: 0.7528\n",
      "Epoch [153/500], Training Loss: 0.6811, Validation Loss: 0.4856, Training Accuracy: 0.7175, Validation Accuracy: 0.6966\n",
      "Epoch [154/500], Training Loss: 0.6819, Validation Loss: 0.5317, Training Accuracy: 0.7325, Validation Accuracy: 0.6629\n",
      "Epoch [155/500], Training Loss: 0.6278, Validation Loss: 0.4770, Training Accuracy: 0.7412, Validation Accuracy: 0.7303\n",
      "Epoch [156/500], Training Loss: 0.6431, Validation Loss: 0.4379, Training Accuracy: 0.7312, Validation Accuracy: 0.7416\n",
      "Epoch [157/500], Training Loss: 0.5809, Validation Loss: 0.4419, Training Accuracy: 0.7525, Validation Accuracy: 0.7528\n",
      "Epoch [158/500], Training Loss: 0.6088, Validation Loss: 0.4915, Training Accuracy: 0.7350, Validation Accuracy: 0.7079\n",
      "Epoch [159/500], Training Loss: 0.5234, Validation Loss: 0.4639, Training Accuracy: 0.7362, Validation Accuracy: 0.7303\n",
      "Epoch [160/500], Training Loss: 0.7762, Validation Loss: 0.4958, Training Accuracy: 0.7163, Validation Accuracy: 0.6966\n",
      "Epoch [161/500], Training Loss: 0.5362, Validation Loss: 0.4822, Training Accuracy: 0.7212, Validation Accuracy: 0.6966\n",
      "Epoch [162/500], Training Loss: 0.5366, Validation Loss: 0.5135, Training Accuracy: 0.7350, Validation Accuracy: 0.7416\n",
      "Epoch [163/500], Training Loss: 0.9619, Validation Loss: 0.5870, Training Accuracy: 0.7362, Validation Accuracy: 0.7416\n",
      "Epoch [164/500], Training Loss: 0.9077, Validation Loss: 0.4955, Training Accuracy: 0.7238, Validation Accuracy: 0.7079\n",
      "Epoch [165/500], Training Loss: 0.5675, Validation Loss: 0.4948, Training Accuracy: 0.7188, Validation Accuracy: 0.6854\n",
      "Epoch [166/500], Training Loss: 0.5661, Validation Loss: 0.4837, Training Accuracy: 0.7050, Validation Accuracy: 0.7079\n",
      "Epoch [167/500], Training Loss: 0.6486, Validation Loss: 0.4960, Training Accuracy: 0.7212, Validation Accuracy: 0.7191\n",
      "Epoch [168/500], Training Loss: 0.6194, Validation Loss: 0.4797, Training Accuracy: 0.7262, Validation Accuracy: 0.7191\n",
      "Epoch [169/500], Training Loss: 0.4920, Validation Loss: 0.4981, Training Accuracy: 0.7450, Validation Accuracy: 0.6966\n",
      "Epoch [170/500], Training Loss: 0.6552, Validation Loss: 0.4596, Training Accuracy: 0.7350, Validation Accuracy: 0.7416\n",
      "Epoch [171/500], Training Loss: 0.5163, Validation Loss: 0.4500, Training Accuracy: 0.7375, Validation Accuracy: 0.7416\n",
      "Epoch [172/500], Training Loss: 0.6745, Validation Loss: 0.4676, Training Accuracy: 0.7113, Validation Accuracy: 0.7303\n",
      "Epoch [173/500], Training Loss: 0.5467, Validation Loss: 0.4798, Training Accuracy: 0.7250, Validation Accuracy: 0.7191\n",
      "Epoch [174/500], Training Loss: 0.6734, Validation Loss: 0.4500, Training Accuracy: 0.7175, Validation Accuracy: 0.7528\n",
      "Epoch [175/500], Training Loss: 0.6316, Validation Loss: 0.4426, Training Accuracy: 0.7325, Validation Accuracy: 0.7528\n",
      "Epoch [176/500], Training Loss: 0.7023, Validation Loss: 0.4582, Training Accuracy: 0.7288, Validation Accuracy: 0.7416\n",
      "Epoch [177/500], Training Loss: 0.7652, Validation Loss: 0.4865, Training Accuracy: 0.7375, Validation Accuracy: 0.7191\n",
      "Epoch [178/500], Training Loss: 0.6919, Validation Loss: 0.4879, Training Accuracy: 0.7087, Validation Accuracy: 0.7191\n",
      "Epoch [179/500], Training Loss: 0.6191, Validation Loss: 0.4580, Training Accuracy: 0.7175, Validation Accuracy: 0.7303\n",
      "Epoch [180/500], Training Loss: 0.6627, Validation Loss: 0.4707, Training Accuracy: 0.7013, Validation Accuracy: 0.7303\n",
      "Epoch [181/500], Training Loss: 0.5615, Validation Loss: 0.4943, Training Accuracy: 0.7275, Validation Accuracy: 0.7079\n",
      "Epoch [182/500], Training Loss: 0.5753, Validation Loss: 0.4743, Training Accuracy: 0.7350, Validation Accuracy: 0.7416\n",
      "Epoch [183/500], Training Loss: 0.5133, Validation Loss: 0.4731, Training Accuracy: 0.7312, Validation Accuracy: 0.7303\n",
      "Epoch [184/500], Training Loss: 0.6467, Validation Loss: 0.4465, Training Accuracy: 0.7262, Validation Accuracy: 0.7640\n",
      "Epoch [185/500], Training Loss: 0.5632, Validation Loss: 0.4377, Training Accuracy: 0.7163, Validation Accuracy: 0.7753\n",
      "Epoch [186/500], Training Loss: 0.5285, Validation Loss: 0.4296, Training Accuracy: 0.7462, Validation Accuracy: 0.7753\n",
      "Epoch [187/500], Training Loss: 0.5318, Validation Loss: 0.4653, Training Accuracy: 0.7500, Validation Accuracy: 0.7416\n",
      "Epoch [188/500], Training Loss: 0.5614, Validation Loss: 0.4569, Training Accuracy: 0.7238, Validation Accuracy: 0.7416\n",
      "Epoch [189/500], Training Loss: 0.5955, Validation Loss: 0.4825, Training Accuracy: 0.7262, Validation Accuracy: 0.7303\n",
      "Epoch [190/500], Training Loss: 0.5283, Validation Loss: 0.5347, Training Accuracy: 0.7500, Validation Accuracy: 0.7303\n",
      "Epoch [191/500], Training Loss: 0.6968, Validation Loss: 0.5042, Training Accuracy: 0.7200, Validation Accuracy: 0.6966\n",
      "Epoch [192/500], Training Loss: 0.5662, Validation Loss: 0.5910, Training Accuracy: 0.7350, Validation Accuracy: 0.6966\n",
      "Epoch [193/500], Training Loss: 0.5098, Validation Loss: 0.7268, Training Accuracy: 0.7400, Validation Accuracy: 0.6966\n",
      "Epoch [194/500], Training Loss: 0.7103, Validation Loss: 1.2241, Training Accuracy: 0.7238, Validation Accuracy: 0.7303\n",
      "Epoch [195/500], Training Loss: 0.5786, Validation Loss: 0.8601, Training Accuracy: 0.7325, Validation Accuracy: 0.6854\n",
      "Epoch [196/500], Training Loss: 0.5531, Validation Loss: 0.7396, Training Accuracy: 0.7450, Validation Accuracy: 0.6742\n",
      "Epoch [197/500], Training Loss: 0.5498, Validation Loss: 0.6032, Training Accuracy: 0.7262, Validation Accuracy: 0.6629\n",
      "Epoch [198/500], Training Loss: 0.5822, Validation Loss: 0.5304, Training Accuracy: 0.7163, Validation Accuracy: 0.6629\n",
      "Epoch [199/500], Training Loss: 0.5602, Validation Loss: 0.5355, Training Accuracy: 0.7212, Validation Accuracy: 0.6629\n",
      "Epoch [200/500], Training Loss: 0.6650, Validation Loss: 0.5292, Training Accuracy: 0.7200, Validation Accuracy: 0.6629\n",
      "Epoch [201/500], Training Loss: 0.5280, Validation Loss: 0.5208, Training Accuracy: 0.7200, Validation Accuracy: 0.6742\n",
      "Epoch [202/500], Training Loss: 0.5439, Validation Loss: 0.5255, Training Accuracy: 0.7175, Validation Accuracy: 0.7079\n",
      "Epoch [203/500], Training Loss: 0.5530, Validation Loss: 0.4900, Training Accuracy: 0.7488, Validation Accuracy: 0.7079\n",
      "Epoch [204/500], Training Loss: 0.6046, Validation Loss: 0.4849, Training Accuracy: 0.7475, Validation Accuracy: 0.7303\n",
      "Epoch [205/500], Training Loss: 0.6758, Validation Loss: 0.4859, Training Accuracy: 0.7562, Validation Accuracy: 0.7416\n",
      "Epoch [206/500], Training Loss: 0.6396, Validation Loss: 0.5257, Training Accuracy: 0.7438, Validation Accuracy: 0.6966\n",
      "Epoch [207/500], Training Loss: 0.5112, Validation Loss: 0.5833, Training Accuracy: 0.7388, Validation Accuracy: 0.6966\n",
      "Epoch [208/500], Training Loss: 0.5133, Validation Loss: 0.4848, Training Accuracy: 0.7388, Validation Accuracy: 0.7191\n",
      "Epoch [209/500], Training Loss: 0.6014, Validation Loss: 0.4584, Training Accuracy: 0.7350, Validation Accuracy: 0.7416\n",
      "Epoch [210/500], Training Loss: 0.6915, Validation Loss: 0.4606, Training Accuracy: 0.7588, Validation Accuracy: 0.7416\n",
      "Epoch [211/500], Training Loss: 0.6048, Validation Loss: 0.4852, Training Accuracy: 0.7438, Validation Accuracy: 0.7191\n",
      "Epoch [212/500], Training Loss: 0.6216, Validation Loss: 0.4615, Training Accuracy: 0.7525, Validation Accuracy: 0.7416\n",
      "Epoch [213/500], Training Loss: 0.6738, Validation Loss: 0.4868, Training Accuracy: 0.7425, Validation Accuracy: 0.7191\n",
      "Epoch [214/500], Training Loss: 0.5491, Validation Loss: 0.4752, Training Accuracy: 0.7425, Validation Accuracy: 0.7303\n",
      "Epoch [215/500], Training Loss: 0.5400, Validation Loss: 0.4686, Training Accuracy: 0.7525, Validation Accuracy: 0.7303\n",
      "Epoch [216/500], Training Loss: 0.5894, Validation Loss: 0.4774, Training Accuracy: 0.7500, Validation Accuracy: 0.7416\n",
      "Epoch [217/500], Training Loss: 0.5169, Validation Loss: 0.4720, Training Accuracy: 0.7425, Validation Accuracy: 0.7303\n",
      "Epoch [218/500], Training Loss: 0.4870, Validation Loss: 0.4666, Training Accuracy: 0.7562, Validation Accuracy: 0.7303\n",
      "Epoch [219/500], Training Loss: 0.5121, Validation Loss: 0.4582, Training Accuracy: 0.7325, Validation Accuracy: 0.7416\n",
      "Epoch [220/500], Training Loss: 0.5541, Validation Loss: 0.4500, Training Accuracy: 0.7362, Validation Accuracy: 0.7416\n",
      "Epoch [221/500], Training Loss: 0.5840, Validation Loss: 0.4426, Training Accuracy: 0.7475, Validation Accuracy: 0.7528\n",
      "Epoch [222/500], Training Loss: 0.6336, Validation Loss: 0.4319, Training Accuracy: 0.7538, Validation Accuracy: 0.7528\n",
      "Epoch [223/500], Training Loss: 0.6203, Validation Loss: 0.4724, Training Accuracy: 0.7438, Validation Accuracy: 0.7416\n",
      "Epoch [224/500], Training Loss: 0.5113, Validation Loss: 0.4842, Training Accuracy: 0.7425, Validation Accuracy: 0.7191\n",
      "Epoch [225/500], Training Loss: 0.5040, Validation Loss: 0.4695, Training Accuracy: 0.7538, Validation Accuracy: 0.7303\n",
      "Epoch [226/500], Training Loss: 0.5550, Validation Loss: 0.4605, Training Accuracy: 0.7475, Validation Accuracy: 0.7528\n",
      "Epoch [227/500], Training Loss: 0.7270, Validation Loss: 0.4991, Training Accuracy: 0.7525, Validation Accuracy: 0.7303\n",
      "Epoch [228/500], Training Loss: 0.7918, Validation Loss: 0.5661, Training Accuracy: 0.7500, Validation Accuracy: 0.7303\n",
      "Epoch [229/500], Training Loss: 0.9986, Validation Loss: 0.4718, Training Accuracy: 0.7450, Validation Accuracy: 0.7303\n",
      "Epoch [230/500], Training Loss: 0.5412, Validation Loss: 0.4831, Training Accuracy: 0.7488, Validation Accuracy: 0.7303\n",
      "Epoch [231/500], Training Loss: 0.5357, Validation Loss: 0.4807, Training Accuracy: 0.7450, Validation Accuracy: 0.7303\n",
      "Epoch [232/500], Training Loss: 0.6307, Validation Loss: 0.4831, Training Accuracy: 0.7338, Validation Accuracy: 0.7416\n",
      "Epoch [233/500], Training Loss: 0.5966, Validation Loss: 0.4623, Training Accuracy: 0.7325, Validation Accuracy: 0.7303\n",
      "Epoch [234/500], Training Loss: 0.5260, Validation Loss: 0.5426, Training Accuracy: 0.7338, Validation Accuracy: 0.7303\n",
      "Epoch [235/500], Training Loss: 0.8618, Validation Loss: 0.4716, Training Accuracy: 0.7250, Validation Accuracy: 0.7416\n",
      "Epoch [236/500], Training Loss: 0.5723, Validation Loss: 0.4710, Training Accuracy: 0.7238, Validation Accuracy: 0.7416\n",
      "Epoch [237/500], Training Loss: 0.5521, Validation Loss: 0.4866, Training Accuracy: 0.7450, Validation Accuracy: 0.7416\n",
      "Epoch [238/500], Training Loss: 0.6206, Validation Loss: 0.4683, Training Accuracy: 0.7338, Validation Accuracy: 0.7416\n",
      "Epoch [239/500], Training Loss: 0.7319, Validation Loss: 0.4513, Training Accuracy: 0.7275, Validation Accuracy: 0.7640\n",
      "Epoch [240/500], Training Loss: 0.6419, Validation Loss: 0.4431, Training Accuracy: 0.7412, Validation Accuracy: 0.7528\n",
      "Epoch [241/500], Training Loss: 0.7596, Validation Loss: 0.4794, Training Accuracy: 0.7425, Validation Accuracy: 0.7303\n",
      "Epoch [242/500], Training Loss: 0.6855, Validation Loss: 0.4766, Training Accuracy: 0.7462, Validation Accuracy: 0.7303\n",
      "Epoch [243/500], Training Loss: 0.5438, Validation Loss: 0.4754, Training Accuracy: 0.7250, Validation Accuracy: 0.7303\n",
      "Epoch [244/500], Training Loss: 0.9459, Validation Loss: 0.5158, Training Accuracy: 0.7275, Validation Accuracy: 0.7079\n",
      "Epoch [245/500], Training Loss: 0.5680, Validation Loss: 0.5188, Training Accuracy: 0.7400, Validation Accuracy: 0.7191\n",
      "Epoch [246/500], Training Loss: 0.6942, Validation Loss: 0.5170, Training Accuracy: 0.7450, Validation Accuracy: 0.7191\n",
      "Epoch [247/500], Training Loss: 0.5246, Validation Loss: 0.4685, Training Accuracy: 0.7425, Validation Accuracy: 0.7416\n",
      "Epoch [248/500], Training Loss: 0.5272, Validation Loss: 0.4842, Training Accuracy: 0.7388, Validation Accuracy: 0.7303\n",
      "Epoch [249/500], Training Loss: 0.5461, Validation Loss: 0.4985, Training Accuracy: 0.7225, Validation Accuracy: 0.7303\n",
      "Epoch [250/500], Training Loss: 0.7766, Validation Loss: 0.4911, Training Accuracy: 0.7425, Validation Accuracy: 0.7303\n",
      "Epoch [251/500], Training Loss: 0.9208, Validation Loss: 0.4969, Training Accuracy: 0.7375, Validation Accuracy: 0.7191\n",
      "Epoch [252/500], Training Loss: 0.5568, Validation Loss: 0.4815, Training Accuracy: 0.7338, Validation Accuracy: 0.7416\n",
      "Epoch [253/500], Training Loss: 0.5442, Validation Loss: 0.5020, Training Accuracy: 0.7462, Validation Accuracy: 0.7079\n",
      "Epoch [254/500], Training Loss: 0.5673, Validation Loss: 0.4920, Training Accuracy: 0.7550, Validation Accuracy: 0.7303\n",
      "Epoch [255/500], Training Loss: 0.6802, Validation Loss: 0.4774, Training Accuracy: 0.7525, Validation Accuracy: 0.7303\n",
      "Epoch [256/500], Training Loss: 0.6091, Validation Loss: 0.4921, Training Accuracy: 0.7475, Validation Accuracy: 0.7303\n",
      "Epoch [257/500], Training Loss: 0.5270, Validation Loss: 0.5002, Training Accuracy: 0.7450, Validation Accuracy: 0.7079\n",
      "Epoch [258/500], Training Loss: 0.6705, Validation Loss: 0.5279, Training Accuracy: 0.7425, Validation Accuracy: 0.6966\n",
      "Epoch [259/500], Training Loss: 0.5388, Validation Loss: 0.5243, Training Accuracy: 0.7450, Validation Accuracy: 0.7191\n",
      "Epoch [260/500], Training Loss: 0.5459, Validation Loss: 0.4801, Training Accuracy: 0.7338, Validation Accuracy: 0.7416\n",
      "Epoch [261/500], Training Loss: 0.5697, Validation Loss: 0.4782, Training Accuracy: 0.7625, Validation Accuracy: 0.7416\n",
      "Epoch [262/500], Training Loss: 0.5083, Validation Loss: 0.4656, Training Accuracy: 0.7612, Validation Accuracy: 0.7528\n",
      "Epoch [263/500], Training Loss: 0.5343, Validation Loss: 0.4972, Training Accuracy: 0.7588, Validation Accuracy: 0.7303\n",
      "Epoch [264/500], Training Loss: 0.5228, Validation Loss: 0.4966, Training Accuracy: 0.7425, Validation Accuracy: 0.7191\n",
      "Epoch [265/500], Training Loss: 0.5826, Validation Loss: 0.5222, Training Accuracy: 0.7288, Validation Accuracy: 0.6854\n",
      "Epoch [266/500], Training Loss: 0.6831, Validation Loss: 0.4983, Training Accuracy: 0.7063, Validation Accuracy: 0.7079\n",
      "Epoch [267/500], Training Loss: 0.6853, Validation Loss: 0.4836, Training Accuracy: 0.7150, Validation Accuracy: 0.7191\n",
      "Epoch [268/500], Training Loss: 0.7668, Validation Loss: 0.5020, Training Accuracy: 0.7288, Validation Accuracy: 0.7079\n",
      "Epoch [269/500], Training Loss: 0.5525, Validation Loss: 0.4994, Training Accuracy: 0.7300, Validation Accuracy: 0.7079\n",
      "Epoch [270/500], Training Loss: 0.5446, Validation Loss: 0.4981, Training Accuracy: 0.7150, Validation Accuracy: 0.6966\n",
      "Epoch [271/500], Training Loss: 0.5276, Validation Loss: 0.4738, Training Accuracy: 0.7300, Validation Accuracy: 0.7303\n",
      "Epoch [272/500], Training Loss: 0.6026, Validation Loss: 0.4441, Training Accuracy: 0.7412, Validation Accuracy: 0.7528\n",
      "Epoch [273/500], Training Loss: 0.6043, Validation Loss: 0.4682, Training Accuracy: 0.7250, Validation Accuracy: 0.7416\n",
      "Epoch [274/500], Training Loss: 0.5275, Validation Loss: 0.4656, Training Accuracy: 0.7350, Validation Accuracy: 0.7416\n",
      "Epoch [275/500], Training Loss: 0.5446, Validation Loss: 0.4665, Training Accuracy: 0.7512, Validation Accuracy: 0.7416\n",
      "Epoch [276/500], Training Loss: 0.6434, Validation Loss: 0.4868, Training Accuracy: 0.7462, Validation Accuracy: 0.7191\n",
      "Epoch [277/500], Training Loss: 0.5694, Validation Loss: 0.4914, Training Accuracy: 0.7400, Validation Accuracy: 0.7079\n",
      "Epoch [278/500], Training Loss: 0.5493, Validation Loss: 0.4822, Training Accuracy: 0.7400, Validation Accuracy: 0.7191\n",
      "Epoch [279/500], Training Loss: 0.6608, Validation Loss: 0.4892, Training Accuracy: 0.7375, Validation Accuracy: 0.7191\n",
      "Epoch [280/500], Training Loss: 0.5424, Validation Loss: 0.4991, Training Accuracy: 0.7250, Validation Accuracy: 0.7191\n",
      "Epoch [281/500], Training Loss: 0.5394, Validation Loss: 0.5120, Training Accuracy: 0.7288, Validation Accuracy: 0.6966\n",
      "Epoch [282/500], Training Loss: 0.5225, Validation Loss: 0.4951, Training Accuracy: 0.7250, Validation Accuracy: 0.7191\n",
      "Epoch [283/500], Training Loss: 0.5279, Validation Loss: 0.4911, Training Accuracy: 0.7412, Validation Accuracy: 0.7191\n",
      "Epoch [284/500], Training Loss: 0.5149, Validation Loss: 0.4895, Training Accuracy: 0.7412, Validation Accuracy: 0.7191\n",
      "Epoch [285/500], Training Loss: 0.5531, Validation Loss: 0.4912, Training Accuracy: 0.7300, Validation Accuracy: 0.7191\n",
      "Epoch [286/500], Training Loss: 0.5081, Validation Loss: 0.4666, Training Accuracy: 0.7488, Validation Accuracy: 0.7416\n",
      "Epoch [287/500], Training Loss: 0.6813, Validation Loss: 0.4576, Training Accuracy: 0.7312, Validation Accuracy: 0.7528\n",
      "Epoch [288/500], Training Loss: 0.6883, Validation Loss: 0.4448, Training Accuracy: 0.7450, Validation Accuracy: 0.7528\n",
      "Epoch [289/500], Training Loss: 0.5048, Validation Loss: 0.4421, Training Accuracy: 0.7500, Validation Accuracy: 0.7528\n",
      "Epoch [290/500], Training Loss: 0.6283, Validation Loss: 0.4399, Training Accuracy: 0.7638, Validation Accuracy: 0.7528\n",
      "Epoch [291/500], Training Loss: 0.6090, Validation Loss: 0.4356, Training Accuracy: 0.7412, Validation Accuracy: 0.7640\n",
      "Epoch [292/500], Training Loss: 0.5179, Validation Loss: 0.4489, Training Accuracy: 0.7425, Validation Accuracy: 0.7640\n",
      "Epoch [293/500], Training Loss: 0.5439, Validation Loss: 0.4455, Training Accuracy: 0.7638, Validation Accuracy: 0.7528\n",
      "Epoch [294/500], Training Loss: 0.6827, Validation Loss: 0.6824, Training Accuracy: 0.7625, Validation Accuracy: 0.7528\n",
      "Epoch [295/500], Training Loss: 0.5083, Validation Loss: 0.4627, Training Accuracy: 0.7638, Validation Accuracy: 0.7528\n",
      "Epoch [296/500], Training Loss: 0.5345, Validation Loss: 0.4654, Training Accuracy: 0.7462, Validation Accuracy: 0.7528\n",
      "Epoch [297/500], Training Loss: 0.5091, Validation Loss: 0.4566, Training Accuracy: 0.7562, Validation Accuracy: 0.7528\n",
      "Epoch [298/500], Training Loss: 0.5021, Validation Loss: 0.4658, Training Accuracy: 0.7712, Validation Accuracy: 0.7416\n",
      "Epoch [299/500], Training Loss: 0.5099, Validation Loss: 0.4546, Training Accuracy: 0.7600, Validation Accuracy: 0.7528\n",
      "Epoch [300/500], Training Loss: 0.5521, Validation Loss: 0.4457, Training Accuracy: 0.7362, Validation Accuracy: 0.7640\n",
      "Epoch [301/500], Training Loss: 0.9201, Validation Loss: 0.4523, Training Accuracy: 0.7400, Validation Accuracy: 0.7640\n",
      "Epoch [302/500], Training Loss: 0.6810, Validation Loss: 0.4435, Training Accuracy: 0.7388, Validation Accuracy: 0.7640\n",
      "Epoch [303/500], Training Loss: 0.5374, Validation Loss: 0.4785, Training Accuracy: 0.7450, Validation Accuracy: 0.7528\n",
      "Epoch [304/500], Training Loss: 0.6942, Validation Loss: 0.4420, Training Accuracy: 0.7175, Validation Accuracy: 0.7978\n",
      "Epoch [305/500], Training Loss: 0.5320, Validation Loss: 0.4482, Training Accuracy: 0.7388, Validation Accuracy: 0.7865\n",
      "Epoch [306/500], Training Loss: 0.5395, Validation Loss: 0.4344, Training Accuracy: 0.7312, Validation Accuracy: 0.8090\n",
      "Epoch [307/500], Training Loss: 0.6742, Validation Loss: 0.4440, Training Accuracy: 0.7425, Validation Accuracy: 0.7865\n",
      "Epoch [308/500], Training Loss: 0.5619, Validation Loss: 0.4447, Training Accuracy: 0.7350, Validation Accuracy: 0.7753\n",
      "Epoch [309/500], Training Loss: 0.5472, Validation Loss: 0.4483, Training Accuracy: 0.7375, Validation Accuracy: 0.7753\n",
      "Epoch [310/500], Training Loss: 0.5739, Validation Loss: 0.4903, Training Accuracy: 0.7412, Validation Accuracy: 0.7416\n",
      "Epoch [311/500], Training Loss: 0.5940, Validation Loss: 0.4709, Training Accuracy: 0.7087, Validation Accuracy: 0.7640\n",
      "Epoch [312/500], Training Loss: 0.5484, Validation Loss: 0.4625, Training Accuracy: 0.7113, Validation Accuracy: 0.7528\n",
      "Epoch [313/500], Training Loss: 0.5503, Validation Loss: 0.4710, Training Accuracy: 0.7163, Validation Accuracy: 0.7416\n",
      "Epoch [314/500], Training Loss: 0.5324, Validation Loss: 0.4589, Training Accuracy: 0.7300, Validation Accuracy: 0.7640\n",
      "Epoch [315/500], Training Loss: 0.5282, Validation Loss: 0.4465, Training Accuracy: 0.7350, Validation Accuracy: 0.7640\n",
      "Epoch [316/500], Training Loss: 0.5038, Validation Loss: 0.4484, Training Accuracy: 0.7562, Validation Accuracy: 0.7528\n",
      "Epoch [317/500], Training Loss: 0.5220, Validation Loss: 0.4762, Training Accuracy: 0.7412, Validation Accuracy: 0.7303\n",
      "Epoch [318/500], Training Loss: 0.5252, Validation Loss: 0.4621, Training Accuracy: 0.7312, Validation Accuracy: 0.7416\n",
      "Epoch [319/500], Training Loss: 0.5129, Validation Loss: 0.4700, Training Accuracy: 0.7362, Validation Accuracy: 0.7303\n",
      "Epoch [320/500], Training Loss: 0.5200, Validation Loss: 0.4684, Training Accuracy: 0.7312, Validation Accuracy: 0.7303\n",
      "Epoch [321/500], Training Loss: 0.6272, Validation Loss: 0.4639, Training Accuracy: 0.7175, Validation Accuracy: 0.7416\n",
      "Epoch [322/500], Training Loss: 0.5317, Validation Loss: 0.4581, Training Accuracy: 0.7262, Validation Accuracy: 0.7416\n",
      "Epoch [323/500], Training Loss: 0.5625, Validation Loss: 0.4421, Training Accuracy: 0.7163, Validation Accuracy: 0.7640\n",
      "Epoch [324/500], Training Loss: 0.9341, Validation Loss: 0.4457, Training Accuracy: 0.7462, Validation Accuracy: 0.7640\n",
      "Epoch [325/500], Training Loss: 1.6217, Validation Loss: 0.4405, Training Accuracy: 0.7275, Validation Accuracy: 0.7640\n",
      "Epoch [326/500], Training Loss: 1.5682, Validation Loss: 2.4690, Training Accuracy: 0.7275, Validation Accuracy: 0.7865\n",
      "Epoch [327/500], Training Loss: 2.1341, Validation Loss: 0.4596, Training Accuracy: 0.7350, Validation Accuracy: 0.7528\n",
      "Epoch [328/500], Training Loss: 0.6272, Validation Loss: 0.4546, Training Accuracy: 0.7212, Validation Accuracy: 0.7528\n",
      "Epoch [329/500], Training Loss: 0.5595, Validation Loss: 0.4589, Training Accuracy: 0.7512, Validation Accuracy: 0.7528\n",
      "Epoch [330/500], Training Loss: 0.5001, Validation Loss: 0.4642, Training Accuracy: 0.7675, Validation Accuracy: 0.7528\n",
      "Epoch [331/500], Training Loss: 0.5152, Validation Loss: 0.4795, Training Accuracy: 0.7475, Validation Accuracy: 0.7416\n",
      "Epoch [332/500], Training Loss: 0.6444, Validation Loss: 0.4810, Training Accuracy: 0.7438, Validation Accuracy: 0.7416\n",
      "Epoch [333/500], Training Loss: 0.5526, Validation Loss: 0.5303, Training Accuracy: 0.7150, Validation Accuracy: 0.6966\n",
      "Epoch [334/500], Training Loss: 0.6828, Validation Loss: 0.5080, Training Accuracy: 0.7300, Validation Accuracy: 0.7079\n",
      "Epoch [335/500], Training Loss: 0.6486, Validation Loss: 0.5013, Training Accuracy: 0.7438, Validation Accuracy: 0.7191\n",
      "Epoch [336/500], Training Loss: 0.5296, Validation Loss: 0.4686, Training Accuracy: 0.7450, Validation Accuracy: 0.7528\n",
      "Epoch [337/500], Training Loss: 0.5145, Validation Loss: 0.4577, Training Accuracy: 0.7562, Validation Accuracy: 0.7640\n",
      "Epoch [338/500], Training Loss: 0.5568, Validation Loss: 0.4518, Training Accuracy: 0.7400, Validation Accuracy: 0.7753\n",
      "Epoch [339/500], Training Loss: 0.5302, Validation Loss: 0.4289, Training Accuracy: 0.7338, Validation Accuracy: 0.7753\n",
      "Epoch [340/500], Training Loss: 0.5335, Validation Loss: 0.4141, Training Accuracy: 0.7525, Validation Accuracy: 0.7978\n",
      "Epoch [341/500], Training Loss: 0.6084, Validation Loss: 0.4341, Training Accuracy: 0.7325, Validation Accuracy: 0.7865\n",
      "Epoch [342/500], Training Loss: 0.5570, Validation Loss: 0.4318, Training Accuracy: 0.7400, Validation Accuracy: 0.7978\n",
      "Epoch [343/500], Training Loss: 0.6172, Validation Loss: 0.4510, Training Accuracy: 0.6937, Validation Accuracy: 0.8315\n",
      "Epoch [344/500], Training Loss: 0.7305, Validation Loss: 0.4787, Training Accuracy: 0.6825, Validation Accuracy: 0.8090\n",
      "Epoch [345/500], Training Loss: 0.6984, Validation Loss: 0.4464, Training Accuracy: 0.7225, Validation Accuracy: 0.8090\n",
      "Epoch [346/500], Training Loss: 0.5899, Validation Loss: 0.4698, Training Accuracy: 0.7400, Validation Accuracy: 0.7753\n",
      "Epoch [347/500], Training Loss: 0.5584, Validation Loss: 0.4388, Training Accuracy: 0.7338, Validation Accuracy: 0.8090\n",
      "Epoch [348/500], Training Loss: 0.5506, Validation Loss: 0.4257, Training Accuracy: 0.7475, Validation Accuracy: 0.8090\n",
      "Epoch [349/500], Training Loss: 0.7257, Validation Loss: 0.4419, Training Accuracy: 0.7188, Validation Accuracy: 0.8090\n",
      "Epoch [350/500], Training Loss: 0.5812, Validation Loss: 0.4394, Training Accuracy: 0.7312, Validation Accuracy: 0.8090\n",
      "Epoch [351/500], Training Loss: 1.0826, Validation Loss: 0.4469, Training Accuracy: 0.7262, Validation Accuracy: 0.8202\n",
      "Epoch [352/500], Training Loss: 0.6868, Validation Loss: 0.4480, Training Accuracy: 0.7350, Validation Accuracy: 0.7978\n",
      "Epoch [353/500], Training Loss: 0.5717, Validation Loss: 0.4380, Training Accuracy: 0.7188, Validation Accuracy: 0.7978\n",
      "Epoch [354/500], Training Loss: 0.6446, Validation Loss: 0.4610, Training Accuracy: 0.7300, Validation Accuracy: 0.7978\n",
      "Epoch [355/500], Training Loss: 0.6759, Validation Loss: 0.4934, Training Accuracy: 0.7350, Validation Accuracy: 0.7865\n",
      "Epoch [356/500], Training Loss: 0.5871, Validation Loss: 0.4503, Training Accuracy: 0.7175, Validation Accuracy: 0.7978\n",
      "Epoch [357/500], Training Loss: 0.5507, Validation Loss: 0.4568, Training Accuracy: 0.7312, Validation Accuracy: 0.8090\n",
      "Epoch [358/500], Training Loss: 0.5464, Validation Loss: 0.4490, Training Accuracy: 0.7325, Validation Accuracy: 0.7978\n",
      "Epoch [359/500], Training Loss: 1.1995, Validation Loss: 0.4713, Training Accuracy: 0.7412, Validation Accuracy: 0.8090\n",
      "Epoch [360/500], Training Loss: 0.6870, Validation Loss: 0.4416, Training Accuracy: 0.7163, Validation Accuracy: 0.8202\n",
      "Epoch [361/500], Training Loss: 0.5725, Validation Loss: 0.4609, Training Accuracy: 0.7338, Validation Accuracy: 0.8202\n",
      "Epoch [362/500], Training Loss: 0.5488, Validation Loss: 0.4572, Training Accuracy: 0.7300, Validation Accuracy: 0.7865\n",
      "Epoch [363/500], Training Loss: 0.5795, Validation Loss: 0.4519, Training Accuracy: 0.7475, Validation Accuracy: 0.7865\n",
      "Epoch [364/500], Training Loss: 0.5342, Validation Loss: 0.4571, Training Accuracy: 0.7400, Validation Accuracy: 0.7865\n",
      "Epoch [365/500], Training Loss: 0.5299, Validation Loss: 0.4483, Training Accuracy: 0.7550, Validation Accuracy: 0.7865\n",
      "Epoch [366/500], Training Loss: 0.5286, Validation Loss: 0.4568, Training Accuracy: 0.7400, Validation Accuracy: 0.7753\n",
      "Epoch [367/500], Training Loss: 0.5254, Validation Loss: 0.4529, Training Accuracy: 0.7375, Validation Accuracy: 0.8090\n",
      "Epoch [368/500], Training Loss: 0.5556, Validation Loss: 0.4506, Training Accuracy: 0.7275, Validation Accuracy: 0.7978\n",
      "Epoch [369/500], Training Loss: 0.5351, Validation Loss: 0.4322, Training Accuracy: 0.7262, Validation Accuracy: 0.8090\n",
      "Epoch [370/500], Training Loss: 0.5167, Validation Loss: 0.4293, Training Accuracy: 0.7512, Validation Accuracy: 0.8090\n",
      "Epoch [371/500], Training Loss: 0.6180, Validation Loss: 0.4432, Training Accuracy: 0.7188, Validation Accuracy: 0.7978\n",
      "Epoch [372/500], Training Loss: 0.5429, Validation Loss: 0.4584, Training Accuracy: 0.7250, Validation Accuracy: 0.7978\n",
      "Epoch [373/500], Training Loss: 0.6245, Validation Loss: 0.4839, Training Accuracy: 0.7275, Validation Accuracy: 0.7865\n",
      "Epoch [374/500], Training Loss: 0.5520, Validation Loss: 0.4972, Training Accuracy: 0.7350, Validation Accuracy: 0.7753\n",
      "Epoch [375/500], Training Loss: 0.5947, Validation Loss: 0.4747, Training Accuracy: 0.7175, Validation Accuracy: 0.7528\n",
      "Epoch [376/500], Training Loss: 0.5572, Validation Loss: 0.4194, Training Accuracy: 0.7438, Validation Accuracy: 0.8090\n",
      "Epoch [377/500], Training Loss: 0.5876, Validation Loss: 0.4631, Training Accuracy: 0.7275, Validation Accuracy: 0.7640\n",
      "Epoch [378/500], Training Loss: 0.5324, Validation Loss: 0.5926, Training Accuracy: 0.7312, Validation Accuracy: 0.7528\n",
      "Epoch [379/500], Training Loss: 1.5614, Validation Loss: 0.4578, Training Accuracy: 0.7225, Validation Accuracy: 0.7753\n",
      "Epoch [380/500], Training Loss: 0.5486, Validation Loss: 0.4501, Training Accuracy: 0.7275, Validation Accuracy: 0.7978\n",
      "Epoch [381/500], Training Loss: 0.5321, Validation Loss: 0.4494, Training Accuracy: 0.7438, Validation Accuracy: 0.7865\n",
      "Epoch [382/500], Training Loss: 0.5317, Validation Loss: 0.4474, Training Accuracy: 0.7412, Validation Accuracy: 0.7865\n",
      "Epoch [383/500], Training Loss: 0.7060, Validation Loss: 0.4587, Training Accuracy: 0.7275, Validation Accuracy: 0.7753\n",
      "Epoch [384/500], Training Loss: 0.5300, Validation Loss: 0.4588, Training Accuracy: 0.7438, Validation Accuracy: 0.7753\n",
      "Epoch [385/500], Training Loss: 0.5395, Validation Loss: 0.4658, Training Accuracy: 0.7375, Validation Accuracy: 0.7640\n",
      "Epoch [386/500], Training Loss: 0.5309, Validation Loss: 0.4533, Training Accuracy: 0.7450, Validation Accuracy: 0.7865\n",
      "Epoch [387/500], Training Loss: 0.5238, Validation Loss: 0.4488, Training Accuracy: 0.7462, Validation Accuracy: 0.7865\n",
      "Epoch [388/500], Training Loss: 0.5317, Validation Loss: 0.4595, Training Accuracy: 0.7325, Validation Accuracy: 0.7753\n",
      "Epoch [389/500], Training Loss: 0.6076, Validation Loss: 0.4466, Training Accuracy: 0.7212, Validation Accuracy: 0.7978\n",
      "Epoch [390/500], Training Loss: 0.5256, Validation Loss: 0.4687, Training Accuracy: 0.7488, Validation Accuracy: 0.7640\n",
      "Epoch [391/500], Training Loss: 0.5206, Validation Loss: 0.4715, Training Accuracy: 0.7512, Validation Accuracy: 0.7640\n",
      "Epoch [392/500], Training Loss: 0.5238, Validation Loss: 0.4621, Training Accuracy: 0.7500, Validation Accuracy: 0.7528\n",
      "Epoch [393/500], Training Loss: 0.6120, Validation Loss: 0.4854, Training Accuracy: 0.7312, Validation Accuracy: 0.7528\n",
      "Epoch [394/500], Training Loss: 0.5383, Validation Loss: 0.4501, Training Accuracy: 0.7362, Validation Accuracy: 0.7753\n",
      "Epoch [395/500], Training Loss: 0.5536, Validation Loss: 0.4548, Training Accuracy: 0.7275, Validation Accuracy: 0.7865\n",
      "Epoch [396/500], Training Loss: 0.7191, Validation Loss: 0.7321, Training Accuracy: 0.7312, Validation Accuracy: 0.7978\n",
      "Epoch [397/500], Training Loss: 0.5734, Validation Loss: 0.4808, Training Accuracy: 0.7163, Validation Accuracy: 0.7416\n",
      "Epoch [398/500], Training Loss: 0.5422, Validation Loss: 0.4543, Training Accuracy: 0.7275, Validation Accuracy: 0.7978\n",
      "Epoch [399/500], Training Loss: 0.6831, Validation Loss: 0.4544, Training Accuracy: 0.7400, Validation Accuracy: 0.7865\n",
      "Epoch [400/500], Training Loss: 0.6406, Validation Loss: 0.4670, Training Accuracy: 0.7425, Validation Accuracy: 0.7753\n",
      "Epoch [401/500], Training Loss: 0.6507, Validation Loss: 0.4859, Training Accuracy: 0.7300, Validation Accuracy: 0.7416\n",
      "Epoch [402/500], Training Loss: 0.9707, Validation Loss: 0.4772, Training Accuracy: 0.7338, Validation Accuracy: 0.7416\n",
      "Epoch [403/500], Training Loss: 0.9314, Validation Loss: 0.4773, Training Accuracy: 0.7137, Validation Accuracy: 0.7416\n",
      "Epoch [404/500], Training Loss: 1.3152, Validation Loss: 0.4607, Training Accuracy: 0.7312, Validation Accuracy: 0.7303\n",
      "Epoch [405/500], Training Loss: 8.3145, Validation Loss: 0.4853, Training Accuracy: 0.6312, Validation Accuracy: 0.7416\n",
      "Epoch [406/500], Training Loss: 1.9054, Validation Loss: 0.4884, Training Accuracy: 0.7037, Validation Accuracy: 0.7416\n",
      "Epoch [407/500], Training Loss: 0.5818, Validation Loss: 0.4867, Training Accuracy: 0.7025, Validation Accuracy: 0.7416\n",
      "Epoch [408/500], Training Loss: 0.5805, Validation Loss: 0.5114, Training Accuracy: 0.6987, Validation Accuracy: 0.7079\n",
      "Epoch [409/500], Training Loss: 0.5694, Validation Loss: 0.5035, Training Accuracy: 0.6987, Validation Accuracy: 0.7191\n",
      "Epoch [410/500], Training Loss: 0.5633, Validation Loss: 0.4935, Training Accuracy: 0.7100, Validation Accuracy: 0.7416\n",
      "Epoch [411/500], Training Loss: 0.7289, Validation Loss: 0.5129, Training Accuracy: 0.7262, Validation Accuracy: 0.7528\n",
      "Epoch [412/500], Training Loss: 0.5601, Validation Loss: 0.5168, Training Accuracy: 0.7362, Validation Accuracy: 0.7416\n",
      "Epoch [413/500], Training Loss: 0.5771, Validation Loss: 0.5554, Training Accuracy: 0.7000, Validation Accuracy: 0.6854\n",
      "Epoch [414/500], Training Loss: 0.5693, Validation Loss: 0.5532, Training Accuracy: 0.7200, Validation Accuracy: 0.6854\n",
      "Epoch [415/500], Training Loss: 0.6315, Validation Loss: 0.5502, Training Accuracy: 0.7175, Validation Accuracy: 0.6854\n",
      "Epoch [416/500], Training Loss: 0.5618, Validation Loss: 0.5509, Training Accuracy: 0.7188, Validation Accuracy: 0.6854\n",
      "Epoch [417/500], Training Loss: 0.5477, Validation Loss: 0.5499, Training Accuracy: 0.7362, Validation Accuracy: 0.6854\n",
      "Epoch [418/500], Training Loss: 0.5559, Validation Loss: 0.5494, Training Accuracy: 0.7275, Validation Accuracy: 0.6854\n",
      "Epoch [419/500], Training Loss: 0.5513, Validation Loss: 0.5289, Training Accuracy: 0.7412, Validation Accuracy: 0.6966\n",
      "Epoch [420/500], Training Loss: 0.5609, Validation Loss: 0.5522, Training Accuracy: 0.7225, Validation Accuracy: 0.6742\n",
      "Epoch [421/500], Training Loss: 0.5772, Validation Loss: 0.5453, Training Accuracy: 0.6987, Validation Accuracy: 0.6742\n",
      "Epoch [422/500], Training Loss: 0.5704, Validation Loss: 0.5434, Training Accuracy: 0.7113, Validation Accuracy: 0.6742\n",
      "Epoch [423/500], Training Loss: 0.7114, Validation Loss: 0.5572, Training Accuracy: 0.6950, Validation Accuracy: 0.6629\n",
      "Epoch [424/500], Training Loss: 0.5906, Validation Loss: 0.5463, Training Accuracy: 0.6775, Validation Accuracy: 0.6629\n",
      "Epoch [425/500], Training Loss: 0.5665, Validation Loss: 0.5397, Training Accuracy: 0.6875, Validation Accuracy: 0.6629\n",
      "Epoch [426/500], Training Loss: 0.5633, Validation Loss: 0.5374, Training Accuracy: 0.6925, Validation Accuracy: 0.6629\n",
      "Epoch [427/500], Training Loss: 0.5710, Validation Loss: 0.5332, Training Accuracy: 0.6825, Validation Accuracy: 0.6629\n",
      "Epoch [428/500], Training Loss: 0.5894, Validation Loss: 0.5370, Training Accuracy: 0.6600, Validation Accuracy: 0.6629\n",
      "Epoch [429/500], Training Loss: 0.5671, Validation Loss: 0.5339, Training Accuracy: 0.6825, Validation Accuracy: 0.6629\n",
      "Epoch [430/500], Training Loss: 0.6063, Validation Loss: 0.5355, Training Accuracy: 0.6700, Validation Accuracy: 0.6629\n",
      "Epoch [431/500], Training Loss: 0.5898, Validation Loss: 0.5160, Training Accuracy: 0.6700, Validation Accuracy: 0.6742\n",
      "Epoch [432/500], Training Loss: 0.6762, Validation Loss: 0.5145, Training Accuracy: 0.7137, Validation Accuracy: 0.6742\n",
      "Epoch [433/500], Training Loss: 0.6696, Validation Loss: 0.5148, Training Accuracy: 0.7100, Validation Accuracy: 0.6742\n",
      "Epoch [434/500], Training Loss: 0.5629, Validation Loss: 0.5091, Training Accuracy: 0.7050, Validation Accuracy: 0.6854\n",
      "Epoch [435/500], Training Loss: 0.5614, Validation Loss: 0.5128, Training Accuracy: 0.7050, Validation Accuracy: 0.6854\n",
      "Epoch [436/500], Training Loss: 0.8290, Validation Loss: 0.5136, Training Accuracy: 0.7275, Validation Accuracy: 0.6854\n",
      "Epoch [437/500], Training Loss: 0.6661, Validation Loss: 1.1810, Training Accuracy: 0.7188, Validation Accuracy: 0.6854\n",
      "Epoch [438/500], Training Loss: 0.5719, Validation Loss: 0.5275, Training Accuracy: 0.6950, Validation Accuracy: 0.6629\n",
      "Epoch [439/500], Training Loss: 0.9207, Validation Loss: 0.5274, Training Accuracy: 0.7113, Validation Accuracy: 0.6742\n",
      "Epoch [440/500], Training Loss: 0.7985, Validation Loss: 0.5162, Training Accuracy: 0.7225, Validation Accuracy: 0.6854\n",
      "Epoch [441/500], Training Loss: 0.9674, Validation Loss: 0.5262, Training Accuracy: 0.7275, Validation Accuracy: 0.6742\n",
      "Epoch [442/500], Training Loss: 0.8927, Validation Loss: 0.5252, Training Accuracy: 0.7163, Validation Accuracy: 0.6742\n",
      "Epoch [443/500], Training Loss: 0.7700, Validation Loss: 0.5498, Training Accuracy: 0.7050, Validation Accuracy: 0.6517\n",
      "Epoch [444/500], Training Loss: 0.6697, Validation Loss: 0.5524, Training Accuracy: 0.7075, Validation Accuracy: 0.6629\n",
      "Epoch [445/500], Training Loss: 0.5652, Validation Loss: 0.5422, Training Accuracy: 0.7063, Validation Accuracy: 0.6629\n",
      "Epoch [446/500], Training Loss: 0.7269, Validation Loss: 0.5428, Training Accuracy: 0.7150, Validation Accuracy: 0.6629\n",
      "Epoch [447/500], Training Loss: 0.5642, Validation Loss: 0.5416, Training Accuracy: 0.7125, Validation Accuracy: 0.6629\n",
      "Epoch [448/500], Training Loss: 0.5658, Validation Loss: 0.5378, Training Accuracy: 0.7087, Validation Accuracy: 0.6629\n",
      "Epoch [449/500], Training Loss: 0.5604, Validation Loss: 0.5043, Training Accuracy: 0.7163, Validation Accuracy: 0.6966\n",
      "Epoch [450/500], Training Loss: 0.5779, Validation Loss: 0.5453, Training Accuracy: 0.7063, Validation Accuracy: 0.6629\n",
      "Epoch [451/500], Training Loss: 0.5537, Validation Loss: 0.5168, Training Accuracy: 0.7150, Validation Accuracy: 0.6742\n",
      "Epoch [452/500], Training Loss: 0.9209, Validation Loss: 0.5160, Training Accuracy: 0.6975, Validation Accuracy: 0.6742\n",
      "Epoch [453/500], Training Loss: 0.8883, Validation Loss: 0.5162, Training Accuracy: 0.7063, Validation Accuracy: 0.6742\n",
      "Epoch [454/500], Training Loss: 1.1503, Validation Loss: 0.4855, Training Accuracy: 0.7150, Validation Accuracy: 0.7191\n",
      "Epoch [455/500], Training Loss: 1.3248, Validation Loss: 0.4993, Training Accuracy: 0.7137, Validation Accuracy: 0.6966\n",
      "Epoch [456/500], Training Loss: 0.6209, Validation Loss: 0.4992, Training Accuracy: 0.7025, Validation Accuracy: 0.6966\n",
      "Epoch [457/500], Training Loss: 0.8759, Validation Loss: 0.5082, Training Accuracy: 0.7250, Validation Accuracy: 0.6854\n",
      "Epoch [458/500], Training Loss: 0.5769, Validation Loss: 0.5085, Training Accuracy: 0.7013, Validation Accuracy: 0.6854\n",
      "Epoch [459/500], Training Loss: 0.6740, Validation Loss: 0.5065, Training Accuracy: 0.7050, Validation Accuracy: 0.6854\n",
      "Epoch [460/500], Training Loss: 0.5685, Validation Loss: 0.5066, Training Accuracy: 0.6825, Validation Accuracy: 0.6854\n",
      "Epoch [461/500], Training Loss: 0.8622, Validation Loss: 0.5044, Training Accuracy: 0.6900, Validation Accuracy: 0.6854\n",
      "Epoch [462/500], Training Loss: 0.6336, Validation Loss: 0.5057, Training Accuracy: 0.6925, Validation Accuracy: 0.6854\n",
      "Epoch [463/500], Training Loss: 0.5468, Validation Loss: 0.5057, Training Accuracy: 0.7000, Validation Accuracy: 0.6854\n",
      "Epoch [464/500], Training Loss: 0.5581, Validation Loss: 0.5056, Training Accuracy: 0.6987, Validation Accuracy: 0.6854\n",
      "Epoch [465/500], Training Loss: 0.5633, Validation Loss: 0.4996, Training Accuracy: 0.6900, Validation Accuracy: 0.6966\n",
      "Epoch [466/500], Training Loss: 1.2851, Validation Loss: 0.4971, Training Accuracy: 0.6975, Validation Accuracy: 0.6966\n",
      "Epoch [467/500], Training Loss: 1.6505, Validation Loss: 0.4981, Training Accuracy: 0.7037, Validation Accuracy: 0.6966\n",
      "Epoch [468/500], Training Loss: 1.7481, Validation Loss: 0.5242, Training Accuracy: 0.7050, Validation Accuracy: 0.6742\n",
      "Epoch [469/500], Training Loss: 1.5885, Validation Loss: 0.5203, Training Accuracy: 0.6950, Validation Accuracy: 0.6742\n",
      "Epoch [470/500], Training Loss: 1.4718, Validation Loss: 0.5194, Training Accuracy: 0.6975, Validation Accuracy: 0.6742\n",
      "Epoch [471/500], Training Loss: 1.0045, Validation Loss: 0.4901, Training Accuracy: 0.7100, Validation Accuracy: 0.7079\n",
      "Epoch [472/500], Training Loss: 0.8545, Validation Loss: 0.5116, Training Accuracy: 0.7300, Validation Accuracy: 0.6966\n",
      "Epoch [473/500], Training Loss: 0.7854, Validation Loss: 0.5084, Training Accuracy: 0.7262, Validation Accuracy: 0.6966\n",
      "Epoch [474/500], Training Loss: 0.6886, Validation Loss: 0.4873, Training Accuracy: 0.7137, Validation Accuracy: 0.7191\n",
      "Epoch [475/500], Training Loss: 0.8695, Validation Loss: 0.4839, Training Accuracy: 0.7262, Validation Accuracy: 0.7191\n",
      "Epoch [476/500], Training Loss: 1.2777, Validation Loss: 0.4843, Training Accuracy: 0.7225, Validation Accuracy: 0.7191\n",
      "Epoch [477/500], Training Loss: 1.3238, Validation Loss: 0.4908, Training Accuracy: 0.7300, Validation Accuracy: 0.7079\n",
      "Epoch [478/500], Training Loss: 0.9809, Validation Loss: 0.5099, Training Accuracy: 0.7000, Validation Accuracy: 0.6966\n",
      "Epoch [479/500], Training Loss: 0.5719, Validation Loss: 0.5089, Training Accuracy: 0.7000, Validation Accuracy: 0.6966\n",
      "Epoch [480/500], Training Loss: 0.5564, Validation Loss: 0.5078, Training Accuracy: 0.7050, Validation Accuracy: 0.6966\n",
      "Epoch [481/500], Training Loss: 0.6715, Validation Loss: 0.5082, Training Accuracy: 0.7137, Validation Accuracy: 0.6966\n",
      "Epoch [482/500], Training Loss: 0.6567, Validation Loss: 0.5080, Training Accuracy: 0.7288, Validation Accuracy: 0.6966\n",
      "Epoch [483/500], Training Loss: 0.5870, Validation Loss: 0.5112, Training Accuracy: 0.7113, Validation Accuracy: 0.6966\n",
      "Epoch [484/500], Training Loss: 0.5689, Validation Loss: 0.5104, Training Accuracy: 0.7050, Validation Accuracy: 0.6966\n",
      "Epoch [485/500], Training Loss: 0.6942, Validation Loss: 0.5059, Training Accuracy: 0.6950, Validation Accuracy: 0.6966\n",
      "Epoch [486/500], Training Loss: 0.5632, Validation Loss: 0.5035, Training Accuracy: 0.7137, Validation Accuracy: 0.6966\n",
      "Epoch [487/500], Training Loss: 0.5612, Validation Loss: 0.5042, Training Accuracy: 0.7050, Validation Accuracy: 0.6966\n",
      "Epoch [488/500], Training Loss: 0.5553, Validation Loss: 0.5175, Training Accuracy: 0.7113, Validation Accuracy: 0.6854\n",
      "Epoch [489/500], Training Loss: 0.7459, Validation Loss: 0.5022, Training Accuracy: 0.7338, Validation Accuracy: 0.7191\n",
      "Epoch [490/500], Training Loss: 0.5727, Validation Loss: 0.5134, Training Accuracy: 0.7225, Validation Accuracy: 0.7191\n",
      "Epoch [491/500], Training Loss: 0.5525, Validation Loss: 0.5143, Training Accuracy: 0.7312, Validation Accuracy: 0.7191\n",
      "Epoch [492/500], Training Loss: 0.5717, Validation Loss: 0.5157, Training Accuracy: 0.7225, Validation Accuracy: 0.7191\n",
      "Epoch [493/500], Training Loss: 0.5618, Validation Loss: 0.5142, Training Accuracy: 0.7175, Validation Accuracy: 0.7191\n",
      "Epoch [494/500], Training Loss: 0.5695, Validation Loss: 0.5228, Training Accuracy: 0.7188, Validation Accuracy: 0.7191\n",
      "Epoch [495/500], Training Loss: 0.5764, Validation Loss: 0.5147, Training Accuracy: 0.7150, Validation Accuracy: 0.7303\n",
      "Epoch [496/500], Training Loss: 0.6863, Validation Loss: 0.5169, Training Accuracy: 0.7400, Validation Accuracy: 0.7303\n",
      "Epoch [497/500], Training Loss: 1.6742, Validation Loss: 0.7622, Training Accuracy: 0.7200, Validation Accuracy: 0.7303\n",
      "Epoch [498/500], Training Loss: 1.1793, Validation Loss: 0.5073, Training Accuracy: 0.7412, Validation Accuracy: 0.7416\n",
      "Epoch [499/500], Training Loss: 0.5557, Validation Loss: 0.5177, Training Accuracy: 0.7312, Validation Accuracy: 0.7416\n",
      "Epoch [500/500], Training Loss: 0.6676, Validation Loss: 0.4995, Training Accuracy: 0.7550, Validation Accuracy: 0.7528\n",
      "Training Time: 21.85 seconds\n",
      "Epoch [1/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [2/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [3/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [4/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [5/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [6/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [7/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [8/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [9/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [10/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [11/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [12/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [13/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [14/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [15/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [16/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [17/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [18/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [19/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [20/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [21/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [22/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [23/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [24/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [25/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [26/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [27/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [28/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [29/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [30/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [31/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [32/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [33/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [34/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [35/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [36/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [37/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [38/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [39/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [40/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [41/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [42/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [43/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [44/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [45/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [46/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [47/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [48/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [49/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [50/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [51/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [52/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [53/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [54/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [55/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [56/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [57/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [58/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [59/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [60/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [61/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [62/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [63/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [64/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [65/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [66/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [67/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [68/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [69/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [70/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [71/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [72/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [73/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [74/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [75/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [76/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [77/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [78/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [79/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [80/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [81/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [82/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [83/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [84/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [85/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [86/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [87/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [88/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [89/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [90/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [91/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [92/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [93/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [94/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [95/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [96/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [97/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [98/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [99/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [100/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [101/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [102/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [103/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [104/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [105/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [106/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [107/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [108/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [109/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [110/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [111/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [112/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [113/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [114/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [115/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [116/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [117/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [118/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [119/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [120/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [121/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [122/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [123/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [124/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [125/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [126/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [127/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [128/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [129/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [130/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [131/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [132/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [133/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [134/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [135/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [136/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [137/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [138/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [139/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [140/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [141/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [142/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [143/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [144/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [145/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [146/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [147/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [148/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [149/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [150/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [151/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [152/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [153/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [154/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [155/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [156/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/v5ysl19s0hbdkdprhb3xqd4r0000gn/T/ipykernel_34536/3099791766.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_weights.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [157/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [158/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [159/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [160/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [161/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [162/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [163/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [164/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [165/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [166/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [167/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [168/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [169/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [170/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [171/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [172/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [173/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [174/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [175/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [176/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [177/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [178/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [179/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [180/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [181/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [182/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [183/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [184/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [185/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [186/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [187/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [188/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [189/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [190/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [191/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [192/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [193/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [194/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [195/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [196/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [197/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [198/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [199/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [200/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [201/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [202/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [203/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [204/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [205/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [206/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [207/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [208/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [209/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [210/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [211/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [212/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [213/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [214/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [215/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [216/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [217/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [218/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [219/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [220/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [221/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [222/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [223/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [224/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [225/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [226/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [227/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [228/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [229/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [230/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [231/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [232/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [233/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [234/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [235/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [236/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [237/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [238/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [239/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [240/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [241/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [242/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [243/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [244/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [245/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [246/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [247/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [248/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [249/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [250/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [251/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [252/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [253/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [254/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [255/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [256/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [257/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [258/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [259/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [260/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [261/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [262/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [263/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [264/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [265/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [266/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [267/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [268/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [269/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [270/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [271/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [272/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [273/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [274/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [275/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [276/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [277/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [278/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [279/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [280/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [281/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [282/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [283/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [284/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [285/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [286/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [287/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [288/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [289/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [290/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [291/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [292/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [293/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [294/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [295/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [296/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [297/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [298/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [299/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [300/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [301/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [302/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [303/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [304/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [305/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [306/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [307/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [308/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [309/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [310/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [311/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [312/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [313/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [314/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [315/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [316/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [317/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [318/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [319/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [320/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [321/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [322/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [323/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [324/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [325/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [326/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [327/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [328/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [329/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [330/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [331/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [332/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [333/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [334/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [335/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [336/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [337/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [338/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [339/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [340/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [341/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [342/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [343/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [344/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [345/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [346/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [347/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [348/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [349/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [350/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [351/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [352/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [353/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [354/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [355/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [356/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [357/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [358/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [359/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [360/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [361/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [362/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [363/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [364/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [365/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [366/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [367/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [368/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [369/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [370/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [371/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [372/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [373/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [374/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [375/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [376/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [377/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [378/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [379/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [380/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [381/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [382/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [383/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [384/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [385/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [386/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [387/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [388/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [389/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [390/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [391/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [392/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [393/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [394/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [395/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [396/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [397/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [398/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [399/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [400/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [401/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [402/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [403/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [404/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [405/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [406/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [407/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [408/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [409/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [410/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [411/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [412/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [413/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [414/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [415/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [416/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [417/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [418/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [419/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [420/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [421/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [422/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [423/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [424/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [425/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [426/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [427/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [428/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [429/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [430/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [431/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [432/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [433/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [434/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [435/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [436/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [437/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [438/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [439/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [440/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [441/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [442/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [443/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [444/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [445/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [446/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [447/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [448/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [449/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [450/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [451/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [452/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [453/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [454/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [455/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [456/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [457/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [458/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [459/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [460/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [461/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [462/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [463/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [464/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [465/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [466/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [467/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [468/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [469/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [470/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [471/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [472/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [473/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [474/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [475/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [476/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [477/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [478/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [479/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [480/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [481/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [482/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [483/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [484/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [485/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [486/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [487/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [488/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [489/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [490/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [491/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [492/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [493/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [494/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [495/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [496/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [497/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [498/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [499/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [500/500], Test Loss: 1.4873, Testing Accuracy: 0.7273\n",
      "Epoch [1/500], Training Loss: 0.6211, Validation Loss: 0.5091, Training Accuracy: 0.6488, Validation Accuracy: 0.7753\n",
      "Epoch [2/500], Training Loss: 0.5321, Validation Loss: 0.5341, Training Accuracy: 0.7375, Validation Accuracy: 0.7416\n",
      "Epoch [3/500], Training Loss: 0.5473, Validation Loss: 0.5537, Training Accuracy: 0.7438, Validation Accuracy: 0.7303\n",
      "Epoch [4/500], Training Loss: 0.5395, Validation Loss: 0.4876, Training Accuracy: 0.7250, Validation Accuracy: 0.7416\n",
      "Epoch [5/500], Training Loss: 0.5169, Validation Loss: 0.5513, Training Accuracy: 0.7412, Validation Accuracy: 0.7640\n",
      "Epoch [6/500], Training Loss: 0.5204, Validation Loss: 0.4967, Training Accuracy: 0.7500, Validation Accuracy: 0.7640\n",
      "Epoch [7/500], Training Loss: 0.5207, Validation Loss: 0.5031, Training Accuracy: 0.7600, Validation Accuracy: 0.7191\n",
      "Epoch [8/500], Training Loss: 0.5201, Validation Loss: 0.4805, Training Accuracy: 0.7488, Validation Accuracy: 0.7640\n",
      "Epoch [9/500], Training Loss: 0.4827, Validation Loss: 0.5235, Training Accuracy: 0.7588, Validation Accuracy: 0.7303\n",
      "Epoch [10/500], Training Loss: 0.5290, Validation Loss: 0.5265, Training Accuracy: 0.7400, Validation Accuracy: 0.6629\n",
      "Epoch [11/500], Training Loss: 0.5419, Validation Loss: 0.4983, Training Accuracy: 0.7200, Validation Accuracy: 0.7640\n",
      "Epoch [12/500], Training Loss: 0.5010, Validation Loss: 0.4996, Training Accuracy: 0.7612, Validation Accuracy: 0.7753\n",
      "Epoch [13/500], Training Loss: 0.5270, Validation Loss: 0.5253, Training Accuracy: 0.7450, Validation Accuracy: 0.6966\n",
      "Epoch [14/500], Training Loss: 0.5157, Validation Loss: 0.5010, Training Accuracy: 0.7488, Validation Accuracy: 0.7753\n",
      "Epoch [15/500], Training Loss: 0.5026, Validation Loss: 0.4682, Training Accuracy: 0.7475, Validation Accuracy: 0.7865\n",
      "Epoch [16/500], Training Loss: 0.4989, Validation Loss: 0.5251, Training Accuracy: 0.7500, Validation Accuracy: 0.7865\n",
      "Epoch [17/500], Training Loss: 0.4835, Validation Loss: 0.4986, Training Accuracy: 0.7750, Validation Accuracy: 0.7978\n",
      "Epoch [18/500], Training Loss: 0.4940, Validation Loss: 0.5119, Training Accuracy: 0.7525, Validation Accuracy: 0.7865\n",
      "Epoch [19/500], Training Loss: 0.5152, Validation Loss: 0.4890, Training Accuracy: 0.7388, Validation Accuracy: 0.7865\n",
      "Epoch [20/500], Training Loss: 0.4576, Validation Loss: 0.6140, Training Accuracy: 0.7675, Validation Accuracy: 0.7191\n",
      "Epoch [21/500], Training Loss: 0.4815, Validation Loss: 0.5272, Training Accuracy: 0.7650, Validation Accuracy: 0.7191\n",
      "Epoch [22/500], Training Loss: 0.4940, Validation Loss: 0.5236, Training Accuracy: 0.7650, Validation Accuracy: 0.7191\n",
      "Epoch [23/500], Training Loss: 0.4776, Validation Loss: 0.5306, Training Accuracy: 0.7625, Validation Accuracy: 0.7640\n",
      "Epoch [24/500], Training Loss: 0.5196, Validation Loss: 0.4731, Training Accuracy: 0.7575, Validation Accuracy: 0.7978\n",
      "Epoch [25/500], Training Loss: 0.4741, Validation Loss: 0.4837, Training Accuracy: 0.7712, Validation Accuracy: 0.7978\n",
      "Epoch [26/500], Training Loss: 0.4894, Validation Loss: 0.4606, Training Accuracy: 0.7688, Validation Accuracy: 0.7753\n",
      "Epoch [27/500], Training Loss: 0.4807, Validation Loss: 0.5105, Training Accuracy: 0.7588, Validation Accuracy: 0.7865\n",
      "Epoch [28/500], Training Loss: 0.5035, Validation Loss: 0.4678, Training Accuracy: 0.7612, Validation Accuracy: 0.7640\n",
      "Epoch [29/500], Training Loss: 0.4872, Validation Loss: 0.4769, Training Accuracy: 0.7600, Validation Accuracy: 0.7528\n",
      "Epoch [30/500], Training Loss: 0.4466, Validation Loss: 0.5092, Training Accuracy: 0.7937, Validation Accuracy: 0.7753\n",
      "Epoch [31/500], Training Loss: 0.5247, Validation Loss: 0.4694, Training Accuracy: 0.7550, Validation Accuracy: 0.7528\n",
      "Epoch [32/500], Training Loss: 0.4514, Validation Loss: 0.4906, Training Accuracy: 0.7612, Validation Accuracy: 0.7865\n",
      "Epoch [33/500], Training Loss: 0.4530, Validation Loss: 0.5451, Training Accuracy: 0.7875, Validation Accuracy: 0.6629\n",
      "Epoch [34/500], Training Loss: 0.5088, Validation Loss: 0.5429, Training Accuracy: 0.7400, Validation Accuracy: 0.7416\n",
      "Epoch [35/500], Training Loss: 0.5613, Validation Loss: 0.6343, Training Accuracy: 0.7738, Validation Accuracy: 0.7528\n",
      "Epoch [36/500], Training Loss: 0.4822, Validation Loss: 0.4692, Training Accuracy: 0.8025, Validation Accuracy: 0.7978\n",
      "Epoch [37/500], Training Loss: 0.4725, Validation Loss: 0.5022, Training Accuracy: 0.7950, Validation Accuracy: 0.7191\n",
      "Epoch [38/500], Training Loss: 0.4380, Validation Loss: 0.4954, Training Accuracy: 0.8013, Validation Accuracy: 0.7528\n",
      "Epoch [39/500], Training Loss: 0.4388, Validation Loss: 0.4649, Training Accuracy: 0.7913, Validation Accuracy: 0.7753\n",
      "Epoch [40/500], Training Loss: 0.4470, Validation Loss: 0.4615, Training Accuracy: 0.7812, Validation Accuracy: 0.7416\n",
      "Epoch [41/500], Training Loss: 0.4964, Validation Loss: 0.5310, Training Accuracy: 0.7550, Validation Accuracy: 0.7640\n",
      "Epoch [42/500], Training Loss: 0.4594, Validation Loss: 0.4786, Training Accuracy: 0.7937, Validation Accuracy: 0.7303\n",
      "Epoch [43/500], Training Loss: 0.4517, Validation Loss: 0.4990, Training Accuracy: 0.7850, Validation Accuracy: 0.7303\n",
      "Epoch [44/500], Training Loss: 0.4587, Validation Loss: 0.4620, Training Accuracy: 0.7800, Validation Accuracy: 0.7978\n",
      "Epoch [45/500], Training Loss: 0.4403, Validation Loss: 0.4959, Training Accuracy: 0.7975, Validation Accuracy: 0.7528\n",
      "Epoch [46/500], Training Loss: 0.4360, Validation Loss: 0.5254, Training Accuracy: 0.7987, Validation Accuracy: 0.7416\n",
      "Epoch [47/500], Training Loss: 0.4151, Validation Loss: 0.4878, Training Accuracy: 0.7925, Validation Accuracy: 0.7303\n",
      "Epoch [48/500], Training Loss: 0.4274, Validation Loss: 0.5522, Training Accuracy: 0.7850, Validation Accuracy: 0.7753\n",
      "Epoch [49/500], Training Loss: 0.4235, Validation Loss: 0.5425, Training Accuracy: 0.8025, Validation Accuracy: 0.7753\n",
      "Epoch [50/500], Training Loss: 0.4401, Validation Loss: 0.4781, Training Accuracy: 0.7963, Validation Accuracy: 0.7865\n",
      "Epoch [51/500], Training Loss: 0.4402, Validation Loss: 0.4431, Training Accuracy: 0.7963, Validation Accuracy: 0.7753\n",
      "Epoch [52/500], Training Loss: 0.4594, Validation Loss: 0.4561, Training Accuracy: 0.7937, Validation Accuracy: 0.7640\n",
      "Epoch [53/500], Training Loss: 0.4473, Validation Loss: 0.4500, Training Accuracy: 0.7975, Validation Accuracy: 0.8090\n",
      "Epoch [54/500], Training Loss: 0.4391, Validation Loss: 0.4865, Training Accuracy: 0.7913, Validation Accuracy: 0.7753\n",
      "Epoch [55/500], Training Loss: 0.4384, Validation Loss: 0.4844, Training Accuracy: 0.7837, Validation Accuracy: 0.7753\n",
      "Epoch [56/500], Training Loss: 0.4995, Validation Loss: 0.4697, Training Accuracy: 0.7950, Validation Accuracy: 0.7865\n",
      "Epoch [57/500], Training Loss: 0.4540, Validation Loss: 0.4451, Training Accuracy: 0.7738, Validation Accuracy: 0.7753\n",
      "Epoch [58/500], Training Loss: 0.5080, Validation Loss: 0.4690, Training Accuracy: 0.7887, Validation Accuracy: 0.7416\n",
      "Epoch [59/500], Training Loss: 0.4556, Validation Loss: 0.4486, Training Accuracy: 0.7875, Validation Accuracy: 0.7865\n",
      "Epoch [60/500], Training Loss: 0.4917, Validation Loss: 0.5182, Training Accuracy: 0.7712, Validation Accuracy: 0.6966\n",
      "Epoch [61/500], Training Loss: 0.4940, Validation Loss: 0.4998, Training Accuracy: 0.7488, Validation Accuracy: 0.7528\n",
      "Epoch [62/500], Training Loss: 0.4535, Validation Loss: 0.4590, Training Accuracy: 0.7700, Validation Accuracy: 0.7528\n",
      "Epoch [63/500], Training Loss: 0.4176, Validation Loss: 0.4461, Training Accuracy: 0.7837, Validation Accuracy: 0.7865\n",
      "Epoch [64/500], Training Loss: 0.4907, Validation Loss: 0.5614, Training Accuracy: 0.7863, Validation Accuracy: 0.7640\n",
      "Epoch [65/500], Training Loss: 0.4325, Validation Loss: 0.5016, Training Accuracy: 0.8200, Validation Accuracy: 0.7865\n",
      "Epoch [66/500], Training Loss: 0.4131, Validation Loss: 0.4994, Training Accuracy: 0.7863, Validation Accuracy: 0.7640\n",
      "Epoch [67/500], Training Loss: 0.4494, Validation Loss: 0.5408, Training Accuracy: 0.7887, Validation Accuracy: 0.7528\n",
      "Epoch [68/500], Training Loss: 0.4220, Validation Loss: 0.4739, Training Accuracy: 0.8075, Validation Accuracy: 0.7865\n",
      "Epoch [69/500], Training Loss: 0.4521, Validation Loss: 0.4837, Training Accuracy: 0.7925, Validation Accuracy: 0.7640\n",
      "Epoch [70/500], Training Loss: 0.4654, Validation Loss: 0.5092, Training Accuracy: 0.7887, Validation Accuracy: 0.6966\n",
      "Epoch [71/500], Training Loss: 0.4369, Validation Loss: 0.4680, Training Accuracy: 0.7688, Validation Accuracy: 0.7528\n",
      "Epoch [72/500], Training Loss: 0.4577, Validation Loss: 0.5189, Training Accuracy: 0.7788, Validation Accuracy: 0.7303\n",
      "Epoch [73/500], Training Loss: 0.4531, Validation Loss: 0.4729, Training Accuracy: 0.7800, Validation Accuracy: 0.7528\n",
      "Epoch [74/500], Training Loss: 0.4418, Validation Loss: 0.4729, Training Accuracy: 0.8000, Validation Accuracy: 0.7528\n",
      "Epoch [75/500], Training Loss: 0.4327, Validation Loss: 0.4336, Training Accuracy: 0.7925, Validation Accuracy: 0.7865\n",
      "Epoch [76/500], Training Loss: 0.4106, Validation Loss: 0.4335, Training Accuracy: 0.7987, Validation Accuracy: 0.8202\n",
      "Epoch [77/500], Training Loss: 0.4533, Validation Loss: 0.4702, Training Accuracy: 0.7975, Validation Accuracy: 0.7528\n",
      "Epoch [78/500], Training Loss: 0.4650, Validation Loss: 0.5248, Training Accuracy: 0.7812, Validation Accuracy: 0.7640\n",
      "Epoch [79/500], Training Loss: 0.4367, Validation Loss: 0.5635, Training Accuracy: 0.7887, Validation Accuracy: 0.7753\n",
      "Epoch [80/500], Training Loss: 0.4118, Validation Loss: 0.4572, Training Accuracy: 0.8113, Validation Accuracy: 0.7753\n",
      "Epoch [81/500], Training Loss: 0.4145, Validation Loss: 0.4705, Training Accuracy: 0.8125, Validation Accuracy: 0.7978\n",
      "Epoch [82/500], Training Loss: 0.4117, Validation Loss: 0.4611, Training Accuracy: 0.8025, Validation Accuracy: 0.7528\n",
      "Epoch [83/500], Training Loss: 0.4248, Validation Loss: 0.4558, Training Accuracy: 0.7950, Validation Accuracy: 0.7753\n",
      "Epoch [84/500], Training Loss: 0.4503, Validation Loss: 0.6123, Training Accuracy: 0.8125, Validation Accuracy: 0.7865\n",
      "Epoch [85/500], Training Loss: 0.4916, Validation Loss: 0.5885, Training Accuracy: 0.7812, Validation Accuracy: 0.7528\n",
      "Epoch [86/500], Training Loss: 0.4528, Validation Loss: 0.5809, Training Accuracy: 0.7788, Validation Accuracy: 0.7416\n",
      "Epoch [87/500], Training Loss: 0.4453, Validation Loss: 0.5707, Training Accuracy: 0.7700, Validation Accuracy: 0.8090\n",
      "Epoch [88/500], Training Loss: 0.4248, Validation Loss: 0.4243, Training Accuracy: 0.7950, Validation Accuracy: 0.7978\n",
      "Epoch [89/500], Training Loss: 0.4077, Validation Loss: 0.5527, Training Accuracy: 0.7913, Validation Accuracy: 0.8090\n",
      "Epoch [90/500], Training Loss: 0.4094, Validation Loss: 0.4114, Training Accuracy: 0.8163, Validation Accuracy: 0.8090\n",
      "Epoch [91/500], Training Loss: 0.4303, Validation Loss: 0.4323, Training Accuracy: 0.8137, Validation Accuracy: 0.7865\n",
      "Epoch [92/500], Training Loss: 0.3898, Validation Loss: 0.4306, Training Accuracy: 0.8013, Validation Accuracy: 0.7865\n",
      "Epoch [93/500], Training Loss: 0.4053, Validation Loss: 0.4401, Training Accuracy: 0.8150, Validation Accuracy: 0.7753\n",
      "Epoch [94/500], Training Loss: 0.3982, Validation Loss: 0.4408, Training Accuracy: 0.8200, Validation Accuracy: 0.7640\n",
      "Epoch [95/500], Training Loss: 0.4101, Validation Loss: 0.4664, Training Accuracy: 0.8250, Validation Accuracy: 0.7753\n",
      "Epoch [96/500], Training Loss: 0.4049, Validation Loss: 0.4950, Training Accuracy: 0.8187, Validation Accuracy: 0.7865\n",
      "Epoch [97/500], Training Loss: 0.4165, Validation Loss: 0.4954, Training Accuracy: 0.8037, Validation Accuracy: 0.7753\n",
      "Epoch [98/500], Training Loss: 0.4043, Validation Loss: 0.4370, Training Accuracy: 0.8237, Validation Accuracy: 0.8202\n",
      "Epoch [99/500], Training Loss: 0.3990, Validation Loss: 0.4606, Training Accuracy: 0.8163, Validation Accuracy: 0.8202\n",
      "Epoch [100/500], Training Loss: 0.4374, Validation Loss: 0.4258, Training Accuracy: 0.8287, Validation Accuracy: 0.8202\n",
      "Epoch [101/500], Training Loss: 0.3992, Validation Loss: 0.4165, Training Accuracy: 0.8125, Validation Accuracy: 0.8202\n",
      "Epoch [102/500], Training Loss: 0.4005, Validation Loss: 0.4391, Training Accuracy: 0.8187, Validation Accuracy: 0.7978\n",
      "Epoch [103/500], Training Loss: 0.4266, Validation Loss: 0.4568, Training Accuracy: 0.8075, Validation Accuracy: 0.8090\n",
      "Epoch [104/500], Training Loss: 0.3842, Validation Loss: 0.4953, Training Accuracy: 0.8313, Validation Accuracy: 0.7416\n",
      "Epoch [105/500], Training Loss: 0.4256, Validation Loss: 0.4322, Training Accuracy: 0.8113, Validation Accuracy: 0.8090\n",
      "Epoch [106/500], Training Loss: 0.3908, Validation Loss: 0.5470, Training Accuracy: 0.8100, Validation Accuracy: 0.7978\n",
      "Epoch [107/500], Training Loss: 0.4446, Validation Loss: 0.4634, Training Accuracy: 0.8063, Validation Accuracy: 0.7978\n",
      "Epoch [108/500], Training Loss: 0.4364, Validation Loss: 0.5144, Training Accuracy: 0.8025, Validation Accuracy: 0.7528\n",
      "Epoch [109/500], Training Loss: 0.4318, Validation Loss: 0.5319, Training Accuracy: 0.7875, Validation Accuracy: 0.7865\n",
      "Epoch [110/500], Training Loss: 0.4455, Validation Loss: 0.5015, Training Accuracy: 0.7975, Validation Accuracy: 0.7753\n",
      "Epoch [111/500], Training Loss: 0.4124, Validation Loss: 0.6335, Training Accuracy: 0.8113, Validation Accuracy: 0.7753\n",
      "Epoch [112/500], Training Loss: 0.4173, Validation Loss: 0.4339, Training Accuracy: 0.8025, Validation Accuracy: 0.7753\n",
      "Epoch [113/500], Training Loss: 0.4005, Validation Loss: 0.4817, Training Accuracy: 0.8200, Validation Accuracy: 0.7528\n",
      "Epoch [114/500], Training Loss: 0.4370, Validation Loss: 0.4349, Training Accuracy: 0.7950, Validation Accuracy: 0.7753\n",
      "Epoch [115/500], Training Loss: 0.4455, Validation Loss: 0.4449, Training Accuracy: 0.7887, Validation Accuracy: 0.7978\n",
      "Epoch [116/500], Training Loss: 0.4279, Validation Loss: 0.4923, Training Accuracy: 0.8113, Validation Accuracy: 0.8090\n",
      "Epoch [117/500], Training Loss: 0.4143, Validation Loss: 0.4172, Training Accuracy: 0.8000, Validation Accuracy: 0.7640\n",
      "Epoch [118/500], Training Loss: 0.3809, Validation Loss: 0.4322, Training Accuracy: 0.8225, Validation Accuracy: 0.7753\n",
      "Epoch [119/500], Training Loss: 0.5852, Validation Loss: 0.4557, Training Accuracy: 0.7825, Validation Accuracy: 0.7978\n",
      "Epoch [120/500], Training Loss: 0.4001, Validation Loss: 0.5008, Training Accuracy: 0.8113, Validation Accuracy: 0.7303\n",
      "Epoch [121/500], Training Loss: 0.3649, Validation Loss: 0.6093, Training Accuracy: 0.8237, Validation Accuracy: 0.7640\n",
      "Epoch [122/500], Training Loss: 0.4854, Validation Loss: 0.5531, Training Accuracy: 0.8025, Validation Accuracy: 0.7865\n",
      "Epoch [123/500], Training Loss: 0.3880, Validation Loss: 0.5532, Training Accuracy: 0.8100, Validation Accuracy: 0.7978\n",
      "Epoch [124/500], Training Loss: 0.4370, Validation Loss: 0.4666, Training Accuracy: 0.8150, Validation Accuracy: 0.7753\n",
      "Epoch [125/500], Training Loss: 0.4071, Validation Loss: 0.5323, Training Accuracy: 0.8187, Validation Accuracy: 0.7753\n",
      "Epoch [126/500], Training Loss: 0.4199, Validation Loss: 0.4583, Training Accuracy: 0.8075, Validation Accuracy: 0.7978\n",
      "Epoch [127/500], Training Loss: 0.4304, Validation Loss: 0.5224, Training Accuracy: 0.8013, Validation Accuracy: 0.7528\n",
      "Epoch [128/500], Training Loss: 0.4217, Validation Loss: 0.5146, Training Accuracy: 0.8025, Validation Accuracy: 0.7640\n",
      "Epoch [129/500], Training Loss: 0.4331, Validation Loss: 0.4765, Training Accuracy: 0.7963, Validation Accuracy: 0.7528\n",
      "Epoch [130/500], Training Loss: 0.3682, Validation Loss: 0.5932, Training Accuracy: 0.8313, Validation Accuracy: 0.7978\n",
      "Epoch [131/500], Training Loss: 0.4572, Validation Loss: 0.5369, Training Accuracy: 0.8100, Validation Accuracy: 0.7865\n",
      "Epoch [132/500], Training Loss: 0.3871, Validation Loss: 0.5417, Training Accuracy: 0.8100, Validation Accuracy: 0.7303\n",
      "Epoch [133/500], Training Loss: 0.3797, Validation Loss: 0.4548, Training Accuracy: 0.8313, Validation Accuracy: 0.7978\n",
      "Epoch [134/500], Training Loss: 0.3831, Validation Loss: 0.4695, Training Accuracy: 0.8337, Validation Accuracy: 0.7865\n",
      "Epoch [135/500], Training Loss: 0.3889, Validation Loss: 0.5055, Training Accuracy: 0.8225, Validation Accuracy: 0.7978\n",
      "Epoch [136/500], Training Loss: 0.3482, Validation Loss: 0.4718, Training Accuracy: 0.8400, Validation Accuracy: 0.7978\n",
      "Epoch [137/500], Training Loss: 0.3738, Validation Loss: 0.4804, Training Accuracy: 0.8425, Validation Accuracy: 0.7640\n",
      "Epoch [138/500], Training Loss: 0.4286, Validation Loss: 0.5546, Training Accuracy: 0.8113, Validation Accuracy: 0.7303\n",
      "Epoch [139/500], Training Loss: 0.5559, Validation Loss: 0.5908, Training Accuracy: 0.8037, Validation Accuracy: 0.7079\n",
      "Epoch [140/500], Training Loss: 0.4375, Validation Loss: 0.5271, Training Accuracy: 0.8063, Validation Accuracy: 0.7640\n",
      "Epoch [141/500], Training Loss: 0.3748, Validation Loss: 0.4544, Training Accuracy: 0.8237, Validation Accuracy: 0.7753\n",
      "Epoch [142/500], Training Loss: 0.4040, Validation Loss: 0.5036, Training Accuracy: 0.8125, Validation Accuracy: 0.7753\n",
      "Epoch [143/500], Training Loss: 0.4008, Validation Loss: 0.5420, Training Accuracy: 0.8163, Validation Accuracy: 0.7640\n",
      "Epoch [144/500], Training Loss: 0.3928, Validation Loss: 0.4998, Training Accuracy: 0.8175, Validation Accuracy: 0.7753\n",
      "Epoch [145/500], Training Loss: 0.4630, Validation Loss: 0.5354, Training Accuracy: 0.7825, Validation Accuracy: 0.7640\n",
      "Epoch [146/500], Training Loss: 0.5417, Validation Loss: 0.4958, Training Accuracy: 0.7987, Validation Accuracy: 0.7753\n",
      "Epoch [147/500], Training Loss: 0.4147, Validation Loss: 0.5197, Training Accuracy: 0.8075, Validation Accuracy: 0.7753\n",
      "Epoch [148/500], Training Loss: 0.4450, Validation Loss: 0.4811, Training Accuracy: 0.8125, Validation Accuracy: 0.7528\n",
      "Epoch [149/500], Training Loss: 0.4310, Validation Loss: 0.4423, Training Accuracy: 0.8125, Validation Accuracy: 0.8090\n",
      "Epoch [150/500], Training Loss: 0.4167, Validation Loss: 0.4516, Training Accuracy: 0.8063, Validation Accuracy: 0.7865\n",
      "Epoch [151/500], Training Loss: 0.4116, Validation Loss: 0.4500, Training Accuracy: 0.8125, Validation Accuracy: 0.7865\n",
      "Epoch [152/500], Training Loss: 0.4280, Validation Loss: 0.4285, Training Accuracy: 0.7937, Validation Accuracy: 0.7978\n",
      "Epoch [153/500], Training Loss: 0.3933, Validation Loss: 0.4903, Training Accuracy: 0.8200, Validation Accuracy: 0.7978\n",
      "Epoch [154/500], Training Loss: 0.4390, Validation Loss: 0.5709, Training Accuracy: 0.8025, Validation Accuracy: 0.8090\n",
      "Epoch [155/500], Training Loss: 0.4372, Validation Loss: 0.4839, Training Accuracy: 0.8037, Validation Accuracy: 0.8090\n",
      "Epoch [156/500], Training Loss: 0.4401, Validation Loss: 0.4317, Training Accuracy: 0.8050, Validation Accuracy: 0.7753\n",
      "Epoch [157/500], Training Loss: 0.5823, Validation Loss: 0.3870, Training Accuracy: 0.7950, Validation Accuracy: 0.8315\n",
      "Epoch [158/500], Training Loss: 0.4110, Validation Loss: 0.4199, Training Accuracy: 0.8063, Validation Accuracy: 0.7978\n",
      "Epoch [159/500], Training Loss: 0.3813, Validation Loss: 0.4133, Training Accuracy: 0.8125, Validation Accuracy: 0.7865\n",
      "Epoch [160/500], Training Loss: 0.4529, Validation Loss: 0.4319, Training Accuracy: 0.8163, Validation Accuracy: 0.7865\n",
      "Epoch [161/500], Training Loss: 0.4034, Validation Loss: 0.3849, Training Accuracy: 0.8263, Validation Accuracy: 0.8202\n",
      "Epoch [162/500], Training Loss: 0.4028, Validation Loss: 0.4110, Training Accuracy: 0.8237, Validation Accuracy: 0.8090\n",
      "Epoch [163/500], Training Loss: 0.4244, Validation Loss: 0.4538, Training Accuracy: 0.8163, Validation Accuracy: 0.7865\n",
      "Epoch [164/500], Training Loss: 0.3622, Validation Loss: 0.4339, Training Accuracy: 0.8287, Validation Accuracy: 0.8090\n",
      "Epoch [165/500], Training Loss: 0.3781, Validation Loss: 0.4424, Training Accuracy: 0.8163, Validation Accuracy: 0.8202\n",
      "Epoch [166/500], Training Loss: 0.3382, Validation Loss: 0.4081, Training Accuracy: 0.8462, Validation Accuracy: 0.8090\n",
      "Epoch [167/500], Training Loss: 0.3858, Validation Loss: 0.4243, Training Accuracy: 0.8125, Validation Accuracy: 0.7978\n",
      "Epoch [168/500], Training Loss: 0.3436, Validation Loss: 0.4275, Training Accuracy: 0.8363, Validation Accuracy: 0.8090\n",
      "Epoch [169/500], Training Loss: 0.3749, Validation Loss: 0.4773, Training Accuracy: 0.8250, Validation Accuracy: 0.7978\n",
      "Epoch [170/500], Training Loss: 0.4061, Validation Loss: 0.5325, Training Accuracy: 0.8150, Validation Accuracy: 0.7865\n",
      "Epoch [171/500], Training Loss: 0.4075, Validation Loss: 1.4596, Training Accuracy: 0.8075, Validation Accuracy: 0.7978\n",
      "Epoch [172/500], Training Loss: 0.3978, Validation Loss: 0.5137, Training Accuracy: 0.8263, Validation Accuracy: 0.8315\n",
      "Epoch [173/500], Training Loss: 0.3710, Validation Loss: 0.4505, Training Accuracy: 0.8225, Validation Accuracy: 0.8315\n",
      "Epoch [174/500], Training Loss: 0.4029, Validation Loss: 0.4832, Training Accuracy: 0.8275, Validation Accuracy: 0.7753\n",
      "Epoch [175/500], Training Loss: 0.4293, Validation Loss: 0.4873, Training Accuracy: 0.8125, Validation Accuracy: 0.7303\n",
      "Epoch [176/500], Training Loss: 0.3837, Validation Loss: 0.4813, Training Accuracy: 0.8287, Validation Accuracy: 0.7528\n",
      "Epoch [177/500], Training Loss: 0.3776, Validation Loss: 0.4534, Training Accuracy: 0.8225, Validation Accuracy: 0.7978\n",
      "Epoch [178/500], Training Loss: 0.3858, Validation Loss: 0.5249, Training Accuracy: 0.8250, Validation Accuracy: 0.7753\n",
      "Epoch [179/500], Training Loss: 0.3706, Validation Loss: 0.5816, Training Accuracy: 0.8462, Validation Accuracy: 0.7753\n",
      "Epoch [180/500], Training Loss: 0.4295, Validation Loss: 0.5179, Training Accuracy: 0.8137, Validation Accuracy: 0.7753\n",
      "Epoch [181/500], Training Loss: 0.3668, Validation Loss: 1.5121, Training Accuracy: 0.8413, Validation Accuracy: 0.7865\n",
      "Epoch [182/500], Training Loss: 0.3730, Validation Loss: 0.5019, Training Accuracy: 0.8387, Validation Accuracy: 0.7978\n",
      "Epoch [183/500], Training Loss: 0.3749, Validation Loss: 0.4637, Training Accuracy: 0.8325, Validation Accuracy: 0.8090\n",
      "Epoch [184/500], Training Loss: 0.3736, Validation Loss: 0.4525, Training Accuracy: 0.8350, Validation Accuracy: 0.7865\n",
      "Epoch [185/500], Training Loss: 0.3832, Validation Loss: 0.5344, Training Accuracy: 0.8300, Validation Accuracy: 0.7978\n",
      "Epoch [186/500], Training Loss: 0.4461, Validation Loss: 0.4599, Training Accuracy: 0.8075, Validation Accuracy: 0.7865\n",
      "Epoch [187/500], Training Loss: 0.3917, Validation Loss: 0.4690, Training Accuracy: 0.8462, Validation Accuracy: 0.7865\n",
      "Epoch [188/500], Training Loss: 0.4582, Validation Loss: 0.4922, Training Accuracy: 0.8025, Validation Accuracy: 0.7640\n",
      "Epoch [189/500], Training Loss: 0.4156, Validation Loss: 0.5133, Training Accuracy: 0.8063, Validation Accuracy: 0.7753\n",
      "Epoch [190/500], Training Loss: 0.3947, Validation Loss: 0.4887, Training Accuracy: 0.8200, Validation Accuracy: 0.7978\n",
      "Epoch [191/500], Training Loss: 0.3534, Validation Loss: 0.4527, Training Accuracy: 0.8287, Validation Accuracy: 0.7753\n",
      "Epoch [192/500], Training Loss: 0.3616, Validation Loss: 0.5323, Training Accuracy: 0.8500, Validation Accuracy: 0.7528\n",
      "Epoch [193/500], Training Loss: 0.3503, Validation Loss: 0.5114, Training Accuracy: 0.8488, Validation Accuracy: 0.7640\n",
      "Epoch [194/500], Training Loss: 0.4946, Validation Loss: 0.4568, Training Accuracy: 0.8250, Validation Accuracy: 0.7753\n",
      "Epoch [195/500], Training Loss: 0.3415, Validation Loss: 0.4962, Training Accuracy: 0.8375, Validation Accuracy: 0.7865\n",
      "Epoch [196/500], Training Loss: 0.3726, Validation Loss: 0.4340, Training Accuracy: 0.8300, Validation Accuracy: 0.8202\n",
      "Epoch [197/500], Training Loss: 0.3404, Validation Loss: 0.4748, Training Accuracy: 0.8425, Validation Accuracy: 0.7978\n",
      "Epoch [198/500], Training Loss: 0.3724, Validation Loss: 1.4457, Training Accuracy: 0.8250, Validation Accuracy: 0.8090\n",
      "Epoch [199/500], Training Loss: 0.5301, Validation Loss: 0.4381, Training Accuracy: 0.8125, Validation Accuracy: 0.8090\n",
      "Epoch [200/500], Training Loss: 0.4047, Validation Loss: 0.5717, Training Accuracy: 0.8100, Validation Accuracy: 0.7753\n",
      "Epoch [201/500], Training Loss: 0.3969, Validation Loss: 0.5829, Training Accuracy: 0.8325, Validation Accuracy: 0.8090\n",
      "Epoch [202/500], Training Loss: 0.3742, Validation Loss: 0.5257, Training Accuracy: 0.8287, Validation Accuracy: 0.7978\n",
      "Epoch [203/500], Training Loss: 0.3536, Validation Loss: 0.4487, Training Accuracy: 0.8350, Validation Accuracy: 0.7978\n",
      "Epoch [204/500], Training Loss: 0.3779, Validation Loss: 0.4639, Training Accuracy: 0.8375, Validation Accuracy: 0.7640\n",
      "Epoch [205/500], Training Loss: 0.3900, Validation Loss: 0.4343, Training Accuracy: 0.8200, Validation Accuracy: 0.7978\n",
      "Epoch [206/500], Training Loss: 0.3775, Validation Loss: 0.5883, Training Accuracy: 0.8175, Validation Accuracy: 0.7865\n",
      "Epoch [207/500], Training Loss: 0.3785, Validation Loss: 0.4853, Training Accuracy: 0.8400, Validation Accuracy: 0.7865\n",
      "Epoch [208/500], Training Loss: 0.4806, Validation Loss: 0.4904, Training Accuracy: 0.8325, Validation Accuracy: 0.7865\n",
      "Epoch [209/500], Training Loss: 0.3983, Validation Loss: 0.6725, Training Accuracy: 0.8287, Validation Accuracy: 0.7865\n",
      "Epoch [210/500], Training Loss: 0.3838, Validation Loss: 0.4705, Training Accuracy: 0.8400, Validation Accuracy: 0.7753\n",
      "Epoch [211/500], Training Loss: 0.3797, Validation Loss: 1.4920, Training Accuracy: 0.8313, Validation Accuracy: 0.7416\n",
      "Epoch [212/500], Training Loss: 0.3809, Validation Loss: 0.4983, Training Accuracy: 0.8438, Validation Accuracy: 0.7753\n",
      "Epoch [213/500], Training Loss: 0.4137, Validation Loss: 0.5474, Training Accuracy: 0.8313, Validation Accuracy: 0.7640\n",
      "Epoch [214/500], Training Loss: 0.3919, Validation Loss: 0.6057, Training Accuracy: 0.8250, Validation Accuracy: 0.7640\n",
      "Epoch [215/500], Training Loss: 0.4671, Validation Loss: 0.4891, Training Accuracy: 0.8075, Validation Accuracy: 0.7528\n",
      "Epoch [216/500], Training Loss: 0.4850, Validation Loss: 0.5814, Training Accuracy: 0.7837, Validation Accuracy: 0.7753\n",
      "Epoch [217/500], Training Loss: 0.4615, Validation Loss: 0.6595, Training Accuracy: 0.7875, Validation Accuracy: 0.7640\n",
      "Epoch [218/500], Training Loss: 0.4803, Validation Loss: 0.4671, Training Accuracy: 0.7812, Validation Accuracy: 0.7753\n",
      "Epoch [219/500], Training Loss: 0.3732, Validation Loss: 1.5129, Training Accuracy: 0.8200, Validation Accuracy: 0.7753\n",
      "Epoch [220/500], Training Loss: 0.5813, Validation Loss: 0.5604, Training Accuracy: 0.8113, Validation Accuracy: 0.7528\n",
      "Epoch [221/500], Training Loss: 0.4968, Validation Loss: 0.5048, Training Accuracy: 0.8337, Validation Accuracy: 0.7753\n",
      "Epoch [222/500], Training Loss: 0.6934, Validation Loss: 0.4738, Training Accuracy: 0.8150, Validation Accuracy: 0.7753\n",
      "Epoch [223/500], Training Loss: 0.4677, Validation Loss: 0.5710, Training Accuracy: 0.7925, Validation Accuracy: 0.7753\n",
      "Epoch [224/500], Training Loss: 0.4126, Validation Loss: 0.4961, Training Accuracy: 0.8225, Validation Accuracy: 0.7865\n",
      "Epoch [225/500], Training Loss: 0.4152, Validation Loss: 0.5054, Training Accuracy: 0.8375, Validation Accuracy: 0.7865\n",
      "Epoch [226/500], Training Loss: 0.4105, Validation Loss: 0.4777, Training Accuracy: 0.8313, Validation Accuracy: 0.7865\n",
      "Epoch [227/500], Training Loss: 0.3849, Validation Loss: 0.5180, Training Accuracy: 0.8163, Validation Accuracy: 0.8090\n",
      "Epoch [228/500], Training Loss: 0.4118, Validation Loss: 0.4391, Training Accuracy: 0.8025, Validation Accuracy: 0.7978\n",
      "Epoch [229/500], Training Loss: 0.4054, Validation Loss: 0.4497, Training Accuracy: 0.8275, Validation Accuracy: 0.7640\n",
      "Epoch [230/500], Training Loss: 0.3665, Validation Loss: 0.4815, Training Accuracy: 0.8250, Validation Accuracy: 0.7865\n",
      "Epoch [231/500], Training Loss: 0.4024, Validation Loss: 0.4822, Training Accuracy: 0.8337, Validation Accuracy: 0.7528\n",
      "Epoch [232/500], Training Loss: 0.3465, Validation Loss: 0.4857, Training Accuracy: 0.8250, Validation Accuracy: 0.7978\n",
      "Epoch [233/500], Training Loss: 0.3925, Validation Loss: 0.4127, Training Accuracy: 0.8237, Validation Accuracy: 0.8202\n",
      "Epoch [234/500], Training Loss: 0.3651, Validation Loss: 0.4461, Training Accuracy: 0.8450, Validation Accuracy: 0.8202\n",
      "Epoch [235/500], Training Loss: 0.4110, Validation Loss: 0.4460, Training Accuracy: 0.8263, Validation Accuracy: 0.8090\n",
      "Epoch [236/500], Training Loss: 0.3996, Validation Loss: 0.4416, Training Accuracy: 0.8113, Validation Accuracy: 0.7978\n",
      "Epoch [237/500], Training Loss: 0.3857, Validation Loss: 0.4816, Training Accuracy: 0.8137, Validation Accuracy: 0.7978\n",
      "Epoch [238/500], Training Loss: 0.3745, Validation Loss: 0.4700, Training Accuracy: 0.8387, Validation Accuracy: 0.7978\n",
      "Epoch [239/500], Training Loss: 0.3875, Validation Loss: 0.4796, Training Accuracy: 0.8175, Validation Accuracy: 0.7865\n",
      "Epoch [240/500], Training Loss: 0.4085, Validation Loss: 0.4797, Training Accuracy: 0.8200, Validation Accuracy: 0.7865\n",
      "Epoch [241/500], Training Loss: 0.4248, Validation Loss: 0.5793, Training Accuracy: 0.8137, Validation Accuracy: 0.7978\n",
      "Epoch [242/500], Training Loss: 0.3820, Validation Loss: 0.5748, Training Accuracy: 0.8325, Validation Accuracy: 0.7978\n",
      "Epoch [243/500], Training Loss: 0.3467, Validation Loss: 0.7577, Training Accuracy: 0.8475, Validation Accuracy: 0.7978\n",
      "Epoch [244/500], Training Loss: 0.4123, Validation Loss: 0.5247, Training Accuracy: 0.8175, Validation Accuracy: 0.7978\n",
      "Epoch [245/500], Training Loss: 0.3587, Validation Loss: 0.5094, Training Accuracy: 0.8287, Validation Accuracy: 0.8090\n",
      "Epoch [246/500], Training Loss: 0.3559, Validation Loss: 0.4117, Training Accuracy: 0.8413, Validation Accuracy: 0.8090\n",
      "Epoch [247/500], Training Loss: 0.4035, Validation Loss: 0.5115, Training Accuracy: 0.8187, Validation Accuracy: 0.8427\n",
      "Epoch [248/500], Training Loss: 0.3705, Validation Loss: 0.4423, Training Accuracy: 0.8500, Validation Accuracy: 0.8090\n",
      "Epoch [249/500], Training Loss: 0.3583, Validation Loss: 0.5049, Training Accuracy: 0.8425, Validation Accuracy: 0.8202\n",
      "Epoch [250/500], Training Loss: 0.4169, Validation Loss: 0.3823, Training Accuracy: 0.8337, Validation Accuracy: 0.8315\n",
      "Epoch [251/500], Training Loss: 0.3942, Validation Loss: 0.4223, Training Accuracy: 0.8363, Validation Accuracy: 0.8090\n",
      "Epoch [252/500], Training Loss: 0.4828, Validation Loss: 0.4325, Training Accuracy: 0.8025, Validation Accuracy: 0.7865\n",
      "Epoch [253/500], Training Loss: 0.4104, Validation Loss: 0.4346, Training Accuracy: 0.8187, Validation Accuracy: 0.7978\n",
      "Epoch [254/500], Training Loss: 0.3654, Validation Loss: 0.5236, Training Accuracy: 0.8163, Validation Accuracy: 0.7753\n",
      "Epoch [255/500], Training Loss: 0.3931, Validation Loss: 0.4832, Training Accuracy: 0.8163, Validation Accuracy: 0.7865\n",
      "Epoch [256/500], Training Loss: 0.5527, Validation Loss: 0.4445, Training Accuracy: 0.8150, Validation Accuracy: 0.7753\n",
      "Epoch [257/500], Training Loss: 0.4997, Validation Loss: 0.4411, Training Accuracy: 0.8225, Validation Accuracy: 0.7640\n",
      "Epoch [258/500], Training Loss: 0.4081, Validation Loss: 0.4395, Training Accuracy: 0.8113, Validation Accuracy: 0.7528\n",
      "Epoch [259/500], Training Loss: 0.3664, Validation Loss: 0.5128, Training Accuracy: 0.8250, Validation Accuracy: 0.7640\n",
      "Epoch [260/500], Training Loss: 0.3713, Validation Loss: 0.4765, Training Accuracy: 0.8100, Validation Accuracy: 0.7753\n",
      "Epoch [261/500], Training Loss: 0.3744, Validation Loss: 0.4645, Training Accuracy: 0.8313, Validation Accuracy: 0.7753\n",
      "Epoch [262/500], Training Loss: 0.3458, Validation Loss: 0.4577, Training Accuracy: 0.8325, Validation Accuracy: 0.7978\n",
      "Epoch [263/500], Training Loss: 0.3765, Validation Loss: 0.5072, Training Accuracy: 0.8375, Validation Accuracy: 0.7865\n",
      "Epoch [264/500], Training Loss: 0.4609, Validation Loss: 0.5457, Training Accuracy: 0.8063, Validation Accuracy: 0.7978\n",
      "Epoch [265/500], Training Loss: 0.3849, Validation Loss: 0.5793, Training Accuracy: 0.8375, Validation Accuracy: 0.7865\n",
      "Epoch [266/500], Training Loss: 0.4485, Validation Loss: 0.5585, Training Accuracy: 0.8025, Validation Accuracy: 0.7865\n",
      "Epoch [267/500], Training Loss: 0.4001, Validation Loss: 0.4799, Training Accuracy: 0.7963, Validation Accuracy: 0.7753\n",
      "Epoch [268/500], Training Loss: 0.4160, Validation Loss: 0.4842, Training Accuracy: 0.8163, Validation Accuracy: 0.7753\n",
      "Epoch [269/500], Training Loss: 0.4975, Validation Loss: 0.5347, Training Accuracy: 0.8050, Validation Accuracy: 0.7753\n",
      "Epoch [270/500], Training Loss: 0.4080, Validation Loss: 0.6082, Training Accuracy: 0.8050, Validation Accuracy: 0.7753\n",
      "Epoch [271/500], Training Loss: 0.4063, Validation Loss: 0.4762, Training Accuracy: 0.8225, Validation Accuracy: 0.7753\n",
      "Epoch [272/500], Training Loss: 0.3666, Validation Loss: 0.5096, Training Accuracy: 0.8113, Validation Accuracy: 0.8202\n",
      "Epoch [273/500], Training Loss: 0.3862, Validation Loss: 0.6052, Training Accuracy: 0.8187, Validation Accuracy: 0.7978\n",
      "Epoch [274/500], Training Loss: 0.4479, Validation Loss: 0.6672, Training Accuracy: 0.8037, Validation Accuracy: 0.7865\n",
      "Epoch [275/500], Training Loss: 0.4519, Validation Loss: 0.5832, Training Accuracy: 0.8137, Validation Accuracy: 0.7640\n",
      "Epoch [276/500], Training Loss: 0.4272, Validation Loss: 0.5209, Training Accuracy: 0.8163, Validation Accuracy: 0.8202\n",
      "Epoch [277/500], Training Loss: 0.4173, Validation Loss: 0.5554, Training Accuracy: 0.8400, Validation Accuracy: 0.7978\n",
      "Epoch [278/500], Training Loss: 0.3578, Validation Loss: 0.4808, Training Accuracy: 0.8225, Validation Accuracy: 0.7978\n",
      "Epoch [279/500], Training Loss: 0.4194, Validation Loss: 0.4934, Training Accuracy: 0.8237, Validation Accuracy: 0.8090\n",
      "Epoch [280/500], Training Loss: 0.4271, Validation Loss: 0.4716, Training Accuracy: 0.8037, Validation Accuracy: 0.7753\n",
      "Epoch [281/500], Training Loss: 0.3782, Validation Loss: 0.4715, Training Accuracy: 0.8225, Validation Accuracy: 0.7753\n",
      "Epoch [282/500], Training Loss: 0.3697, Validation Loss: 0.5436, Training Accuracy: 0.8313, Validation Accuracy: 0.7753\n",
      "Epoch [283/500], Training Loss: 0.5548, Validation Loss: 0.5316, Training Accuracy: 0.8137, Validation Accuracy: 0.7753\n",
      "Epoch [284/500], Training Loss: 0.4021, Validation Loss: 0.5081, Training Accuracy: 0.8237, Validation Accuracy: 0.7865\n",
      "Epoch [285/500], Training Loss: 0.4370, Validation Loss: 0.4633, Training Accuracy: 0.8263, Validation Accuracy: 0.7978\n",
      "Epoch [286/500], Training Loss: 0.4269, Validation Loss: 0.4086, Training Accuracy: 0.8213, Validation Accuracy: 0.8202\n",
      "Epoch [287/500], Training Loss: 0.4283, Validation Loss: 0.4490, Training Accuracy: 0.8175, Validation Accuracy: 0.8090\n",
      "Epoch [288/500], Training Loss: 0.3939, Validation Loss: 0.4202, Training Accuracy: 0.8113, Validation Accuracy: 0.7978\n",
      "Epoch [289/500], Training Loss: 0.5818, Validation Loss: 0.5720, Training Accuracy: 0.8187, Validation Accuracy: 0.7640\n",
      "Epoch [290/500], Training Loss: 0.4437, Validation Loss: 0.8861, Training Accuracy: 0.8175, Validation Accuracy: 0.7528\n",
      "Epoch [291/500], Training Loss: 0.3924, Validation Loss: 0.5158, Training Accuracy: 0.8375, Validation Accuracy: 0.7978\n",
      "Epoch [292/500], Training Loss: 0.4257, Validation Loss: 0.4269, Training Accuracy: 0.8387, Validation Accuracy: 0.7978\n",
      "Epoch [293/500], Training Loss: 0.4120, Validation Loss: 0.4827, Training Accuracy: 0.8275, Validation Accuracy: 0.7640\n",
      "Epoch [294/500], Training Loss: 0.3709, Validation Loss: 0.5017, Training Accuracy: 0.8200, Validation Accuracy: 0.7978\n",
      "Epoch [295/500], Training Loss: 0.3990, Validation Loss: 0.4902, Training Accuracy: 0.8225, Validation Accuracy: 0.8090\n",
      "Epoch [296/500], Training Loss: 0.4793, Validation Loss: 0.5537, Training Accuracy: 0.8350, Validation Accuracy: 0.7978\n",
      "Epoch [297/500], Training Loss: 0.5050, Validation Loss: 0.4485, Training Accuracy: 0.8287, Validation Accuracy: 0.8090\n",
      "Epoch [298/500], Training Loss: 0.3584, Validation Loss: 0.5368, Training Accuracy: 0.8337, Validation Accuracy: 0.7865\n",
      "Epoch [299/500], Training Loss: 0.4945, Validation Loss: 0.4971, Training Accuracy: 0.8275, Validation Accuracy: 0.7865\n",
      "Epoch [300/500], Training Loss: 0.3945, Validation Loss: 0.5197, Training Accuracy: 0.8375, Validation Accuracy: 0.7528\n",
      "Epoch [301/500], Training Loss: 0.4190, Validation Loss: 0.4336, Training Accuracy: 0.8150, Validation Accuracy: 0.8090\n",
      "Epoch [302/500], Training Loss: 0.4166, Validation Loss: 0.4112, Training Accuracy: 0.8275, Validation Accuracy: 0.8202\n",
      "Epoch [303/500], Training Loss: 0.4084, Validation Loss: 0.5177, Training Accuracy: 0.8087, Validation Accuracy: 0.8202\n",
      "Epoch [304/500], Training Loss: 0.3886, Validation Loss: 0.4702, Training Accuracy: 0.8263, Validation Accuracy: 0.7640\n",
      "Epoch [305/500], Training Loss: 0.4274, Validation Loss: 0.5450, Training Accuracy: 0.8213, Validation Accuracy: 0.7978\n",
      "Epoch [306/500], Training Loss: 0.3606, Validation Loss: 0.5647, Training Accuracy: 0.8275, Validation Accuracy: 0.8090\n",
      "Epoch [307/500], Training Loss: 0.4046, Validation Loss: 0.5341, Training Accuracy: 0.8287, Validation Accuracy: 0.7978\n",
      "Epoch [308/500], Training Loss: 0.3655, Validation Loss: 0.4393, Training Accuracy: 0.8413, Validation Accuracy: 0.8090\n",
      "Epoch [309/500], Training Loss: 0.3867, Validation Loss: 1.4857, Training Accuracy: 0.8400, Validation Accuracy: 0.7978\n",
      "Epoch [310/500], Training Loss: 0.3406, Validation Loss: 0.4542, Training Accuracy: 0.8350, Validation Accuracy: 0.8202\n",
      "Epoch [311/500], Training Loss: 0.3979, Validation Loss: 0.4888, Training Accuracy: 0.8512, Validation Accuracy: 0.8202\n",
      "Epoch [312/500], Training Loss: 0.4018, Validation Loss: 0.5175, Training Accuracy: 0.8413, Validation Accuracy: 0.8090\n",
      "Epoch [313/500], Training Loss: 0.4714, Validation Loss: 0.5259, Training Accuracy: 0.8263, Validation Accuracy: 0.8315\n",
      "Epoch [314/500], Training Loss: 0.3654, Validation Loss: 0.4446, Training Accuracy: 0.8413, Validation Accuracy: 0.8315\n",
      "Epoch [315/500], Training Loss: 0.4214, Validation Loss: 0.4819, Training Accuracy: 0.8237, Validation Accuracy: 0.7865\n",
      "Epoch [316/500], Training Loss: 0.5382, Validation Loss: 0.5096, Training Accuracy: 0.8137, Validation Accuracy: 0.8090\n",
      "Epoch [317/500], Training Loss: 0.3498, Validation Loss: 0.6089, Training Accuracy: 0.8488, Validation Accuracy: 0.8315\n",
      "Epoch [318/500], Training Loss: 0.4432, Validation Loss: 0.4164, Training Accuracy: 0.8475, Validation Accuracy: 0.7978\n",
      "Epoch [319/500], Training Loss: 0.3710, Validation Loss: 1.5265, Training Accuracy: 0.8462, Validation Accuracy: 0.8202\n",
      "Epoch [320/500], Training Loss: 0.3736, Validation Loss: 0.4880, Training Accuracy: 0.8512, Validation Accuracy: 0.8202\n",
      "Epoch [321/500], Training Loss: 0.3809, Validation Loss: 0.4634, Training Accuracy: 0.8413, Validation Accuracy: 0.7978\n",
      "Epoch [322/500], Training Loss: 0.3482, Validation Loss: 0.3933, Training Accuracy: 0.8462, Validation Accuracy: 0.8202\n",
      "Epoch [323/500], Training Loss: 0.3536, Validation Loss: 0.5029, Training Accuracy: 0.8500, Validation Accuracy: 0.8202\n",
      "Epoch [324/500], Training Loss: 0.4267, Validation Loss: 0.4779, Training Accuracy: 0.8438, Validation Accuracy: 0.8090\n",
      "Epoch [325/500], Training Loss: 0.3197, Validation Loss: 0.4547, Training Accuracy: 0.8562, Validation Accuracy: 0.8427\n",
      "Epoch [326/500], Training Loss: 0.3589, Validation Loss: 0.5369, Training Accuracy: 0.8400, Validation Accuracy: 0.8202\n",
      "Epoch [327/500], Training Loss: 0.3498, Validation Loss: 0.4749, Training Accuracy: 0.8462, Validation Accuracy: 0.8202\n",
      "Epoch [328/500], Training Loss: 0.3965, Validation Loss: 0.5026, Training Accuracy: 0.8325, Validation Accuracy: 0.7978\n",
      "Epoch [329/500], Training Loss: 0.4779, Validation Loss: 0.5075, Training Accuracy: 0.8287, Validation Accuracy: 0.7865\n",
      "Epoch [330/500], Training Loss: 0.3355, Validation Loss: 0.4626, Training Accuracy: 0.8438, Validation Accuracy: 0.7865\n",
      "Epoch [331/500], Training Loss: 0.3460, Validation Loss: 0.4764, Training Accuracy: 0.8400, Validation Accuracy: 0.8090\n",
      "Epoch [332/500], Training Loss: 0.3705, Validation Loss: 0.5068, Training Accuracy: 0.8363, Validation Accuracy: 0.8090\n",
      "Epoch [333/500], Training Loss: 0.3407, Validation Loss: 0.4449, Training Accuracy: 0.8462, Validation Accuracy: 0.7978\n",
      "Epoch [334/500], Training Loss: 0.3671, Validation Loss: 0.3730, Training Accuracy: 0.8313, Validation Accuracy: 0.7978\n",
      "Epoch [335/500], Training Loss: 0.3316, Validation Loss: 0.5391, Training Accuracy: 0.8488, Validation Accuracy: 0.7978\n",
      "Epoch [336/500], Training Loss: 0.4178, Validation Loss: 0.4680, Training Accuracy: 0.8175, Validation Accuracy: 0.7865\n",
      "Epoch [337/500], Training Loss: 0.3846, Validation Loss: 1.5762, Training Accuracy: 0.8125, Validation Accuracy: 0.7865\n",
      "Epoch [338/500], Training Loss: 0.3789, Validation Loss: 0.4847, Training Accuracy: 0.8250, Validation Accuracy: 0.8090\n",
      "Epoch [339/500], Training Loss: 0.3652, Validation Loss: 0.4944, Training Accuracy: 0.8525, Validation Accuracy: 0.8090\n",
      "Epoch [340/500], Training Loss: 0.5319, Validation Loss: 0.7030, Training Accuracy: 0.8313, Validation Accuracy: 0.7640\n",
      "Epoch [341/500], Training Loss: 0.3528, Validation Loss: 3.4612, Training Accuracy: 0.8225, Validation Accuracy: 0.7753\n",
      "Epoch [342/500], Training Loss: 0.4901, Validation Loss: 0.5968, Training Accuracy: 0.8275, Validation Accuracy: 0.8090\n",
      "Epoch [343/500], Training Loss: 0.4044, Validation Loss: 0.6214, Training Accuracy: 0.8200, Validation Accuracy: 0.7978\n",
      "Epoch [344/500], Training Loss: 0.4079, Validation Loss: 0.5957, Training Accuracy: 0.8413, Validation Accuracy: 0.7865\n",
      "Epoch [345/500], Training Loss: 0.3863, Validation Loss: 0.4692, Training Accuracy: 0.8438, Validation Accuracy: 0.8090\n",
      "Epoch [346/500], Training Loss: 0.4883, Validation Loss: 0.5096, Training Accuracy: 0.8075, Validation Accuracy: 0.8090\n",
      "Epoch [347/500], Training Loss: 0.4048, Validation Loss: 0.4494, Training Accuracy: 0.8213, Validation Accuracy: 0.7978\n",
      "Epoch [348/500], Training Loss: 0.4059, Validation Loss: 0.5167, Training Accuracy: 0.8187, Validation Accuracy: 0.7978\n",
      "Epoch [349/500], Training Loss: 0.4175, Validation Loss: 0.6845, Training Accuracy: 0.8237, Validation Accuracy: 0.7303\n",
      "Epoch [350/500], Training Loss: 0.5394, Validation Loss: 0.5700, Training Accuracy: 0.8263, Validation Accuracy: 0.7640\n",
      "Epoch [351/500], Training Loss: 0.4042, Validation Loss: 1.5938, Training Accuracy: 0.8387, Validation Accuracy: 0.7416\n",
      "Epoch [352/500], Training Loss: 0.4941, Validation Loss: 0.4814, Training Accuracy: 0.8100, Validation Accuracy: 0.8090\n",
      "Epoch [353/500], Training Loss: 0.4436, Validation Loss: 0.6006, Training Accuracy: 0.8263, Validation Accuracy: 0.7303\n",
      "Epoch [354/500], Training Loss: 0.4288, Validation Loss: 0.4832, Training Accuracy: 0.8187, Validation Accuracy: 0.7978\n",
      "Epoch [355/500], Training Loss: 0.4105, Validation Loss: 0.5027, Training Accuracy: 0.8175, Validation Accuracy: 0.7640\n",
      "Epoch [356/500], Training Loss: 0.4165, Validation Loss: 0.5576, Training Accuracy: 0.8113, Validation Accuracy: 0.8090\n",
      "Epoch [357/500], Training Loss: 0.4592, Validation Loss: 0.5170, Training Accuracy: 0.8063, Validation Accuracy: 0.7865\n",
      "Epoch [358/500], Training Loss: 0.3875, Validation Loss: 0.4302, Training Accuracy: 0.8175, Validation Accuracy: 0.7978\n",
      "Epoch [359/500], Training Loss: 0.3767, Validation Loss: 0.4771, Training Accuracy: 0.8363, Validation Accuracy: 0.7865\n",
      "Epoch [360/500], Training Loss: 0.3508, Validation Loss: 0.6519, Training Accuracy: 0.8413, Validation Accuracy: 0.7640\n",
      "Epoch [361/500], Training Loss: 0.4998, Validation Loss: 0.4952, Training Accuracy: 0.8200, Validation Accuracy: 0.7865\n",
      "Epoch [362/500], Training Loss: 0.5637, Validation Loss: 0.5940, Training Accuracy: 0.8237, Validation Accuracy: 0.7978\n",
      "Epoch [363/500], Training Loss: 0.6116, Validation Loss: 0.5939, Training Accuracy: 0.8200, Validation Accuracy: 0.8090\n",
      "Epoch [364/500], Training Loss: 0.4030, Validation Loss: 0.4930, Training Accuracy: 0.8375, Validation Accuracy: 0.7978\n",
      "Epoch [365/500], Training Loss: 0.5356, Validation Loss: 0.4101, Training Accuracy: 0.8263, Validation Accuracy: 0.8202\n",
      "Epoch [366/500], Training Loss: 0.5681, Validation Loss: 0.3941, Training Accuracy: 0.8200, Validation Accuracy: 0.8202\n",
      "Epoch [367/500], Training Loss: 0.3262, Validation Loss: 0.5220, Training Accuracy: 0.8525, Validation Accuracy: 0.8315\n",
      "Epoch [368/500], Training Loss: 0.4745, Validation Loss: 1.4223, Training Accuracy: 0.8450, Validation Accuracy: 0.8090\n",
      "Epoch [369/500], Training Loss: 0.4557, Validation Loss: 0.5992, Training Accuracy: 0.8625, Validation Accuracy: 0.8090\n",
      "Epoch [370/500], Training Loss: 0.3421, Validation Loss: 0.5855, Training Accuracy: 0.8450, Validation Accuracy: 0.8202\n",
      "Epoch [371/500], Training Loss: 0.3843, Validation Loss: 0.6838, Training Accuracy: 0.8438, Validation Accuracy: 0.8315\n",
      "Epoch [372/500], Training Loss: 0.6606, Validation Loss: 0.4925, Training Accuracy: 0.8225, Validation Accuracy: 0.8315\n",
      "Epoch [373/500], Training Loss: 0.3424, Validation Loss: 0.4474, Training Accuracy: 0.8512, Validation Accuracy: 0.8315\n",
      "Epoch [374/500], Training Loss: 0.4302, Validation Loss: 0.4481, Training Accuracy: 0.8237, Validation Accuracy: 0.8539\n",
      "Epoch [375/500], Training Loss: 0.4604, Validation Loss: 0.5530, Training Accuracy: 0.7875, Validation Accuracy: 0.8202\n",
      "Epoch [376/500], Training Loss: 0.3662, Validation Loss: 0.4969, Training Accuracy: 0.8175, Validation Accuracy: 0.8090\n",
      "Epoch [377/500], Training Loss: 0.3570, Validation Loss: 0.6299, Training Accuracy: 0.8337, Validation Accuracy: 0.8202\n",
      "Epoch [378/500], Training Loss: 0.3854, Validation Loss: 0.6305, Training Accuracy: 0.8175, Validation Accuracy: 0.8202\n",
      "Epoch [379/500], Training Loss: 0.3999, Validation Loss: 2.4864, Training Accuracy: 0.8325, Validation Accuracy: 0.7978\n",
      "Epoch [380/500], Training Loss: 0.3701, Validation Loss: 0.5287, Training Accuracy: 0.8538, Validation Accuracy: 0.8090\n",
      "Epoch [381/500], Training Loss: 0.3367, Validation Loss: 0.4466, Training Accuracy: 0.8775, Validation Accuracy: 0.8090\n",
      "Epoch [382/500], Training Loss: 0.3480, Validation Loss: 0.4993, Training Accuracy: 0.8375, Validation Accuracy: 0.7978\n",
      "Epoch [383/500], Training Loss: 0.3624, Validation Loss: 0.4788, Training Accuracy: 0.8425, Validation Accuracy: 0.8202\n",
      "Epoch [384/500], Training Loss: 0.3324, Validation Loss: 0.4070, Training Accuracy: 0.8475, Validation Accuracy: 0.8090\n",
      "Epoch [385/500], Training Loss: 0.3484, Validation Loss: 0.5616, Training Accuracy: 0.8612, Validation Accuracy: 0.7978\n",
      "Epoch [386/500], Training Loss: 0.3347, Validation Loss: 0.4073, Training Accuracy: 0.8438, Validation Accuracy: 0.8090\n",
      "Epoch [387/500], Training Loss: 0.3910, Validation Loss: 0.3970, Training Accuracy: 0.8538, Validation Accuracy: 0.8090\n",
      "Epoch [388/500], Training Loss: 0.3640, Validation Loss: 0.4639, Training Accuracy: 0.8387, Validation Accuracy: 0.7978\n",
      "Epoch [389/500], Training Loss: 0.5046, Validation Loss: 0.4269, Training Accuracy: 0.8300, Validation Accuracy: 0.7978\n",
      "Epoch [390/500], Training Loss: 0.5610, Validation Loss: 0.5162, Training Accuracy: 0.8150, Validation Accuracy: 0.7753\n",
      "Epoch [391/500], Training Loss: 0.3228, Validation Loss: 0.4945, Training Accuracy: 0.8525, Validation Accuracy: 0.7640\n",
      "Epoch [392/500], Training Loss: 0.3494, Validation Loss: 0.5278, Training Accuracy: 0.8387, Validation Accuracy: 0.7640\n",
      "Epoch [393/500], Training Loss: 0.3521, Validation Loss: 0.5171, Training Accuracy: 0.8538, Validation Accuracy: 0.7640\n",
      "Epoch [394/500], Training Loss: 0.5379, Validation Loss: 0.4474, Training Accuracy: 0.8125, Validation Accuracy: 0.8315\n",
      "Epoch [395/500], Training Loss: 0.3484, Validation Loss: 0.4727, Training Accuracy: 0.8413, Validation Accuracy: 0.7865\n",
      "Epoch [396/500], Training Loss: 0.3718, Validation Loss: 0.5276, Training Accuracy: 0.8250, Validation Accuracy: 0.7978\n",
      "Epoch [397/500], Training Loss: 0.3911, Validation Loss: 0.5155, Training Accuracy: 0.8413, Validation Accuracy: 0.8202\n",
      "Epoch [398/500], Training Loss: 0.3569, Validation Loss: 0.4180, Training Accuracy: 0.8375, Validation Accuracy: 0.7978\n",
      "Epoch [399/500], Training Loss: 0.4879, Validation Loss: 0.4602, Training Accuracy: 0.8488, Validation Accuracy: 0.8090\n",
      "Epoch [400/500], Training Loss: 0.4398, Validation Loss: 0.4542, Training Accuracy: 0.8500, Validation Accuracy: 0.7978\n",
      "Epoch [401/500], Training Loss: 0.3799, Validation Loss: 0.4127, Training Accuracy: 0.8562, Validation Accuracy: 0.8315\n",
      "Epoch [402/500], Training Loss: 0.3845, Validation Loss: 0.4194, Training Accuracy: 0.8450, Validation Accuracy: 0.8202\n",
      "Epoch [403/500], Training Loss: 0.4153, Validation Loss: 0.4545, Training Accuracy: 0.8400, Validation Accuracy: 0.8090\n",
      "Epoch [404/500], Training Loss: 0.3340, Validation Loss: 0.5080, Training Accuracy: 0.8588, Validation Accuracy: 0.8090\n",
      "Epoch [405/500], Training Loss: 0.3195, Validation Loss: 0.6031, Training Accuracy: 0.8575, Validation Accuracy: 0.8315\n",
      "Epoch [406/500], Training Loss: 0.3740, Validation Loss: 0.4763, Training Accuracy: 0.8375, Validation Accuracy: 0.7978\n",
      "Epoch [407/500], Training Loss: 0.3839, Validation Loss: 0.5109, Training Accuracy: 0.8438, Validation Accuracy: 0.8427\n",
      "Epoch [408/500], Training Loss: 0.3526, Validation Loss: 0.5216, Training Accuracy: 0.8425, Validation Accuracy: 0.8202\n",
      "Epoch [409/500], Training Loss: 0.4572, Validation Loss: 0.4052, Training Accuracy: 0.8512, Validation Accuracy: 0.8427\n",
      "Epoch [410/500], Training Loss: 0.3194, Validation Loss: 0.3913, Training Accuracy: 0.8638, Validation Accuracy: 0.8090\n",
      "Epoch [411/500], Training Loss: 0.3345, Validation Loss: 0.4644, Training Accuracy: 0.8500, Validation Accuracy: 0.8202\n",
      "Epoch [412/500], Training Loss: 0.3056, Validation Loss: 0.4213, Training Accuracy: 0.8575, Validation Accuracy: 0.8202\n",
      "Epoch [413/500], Training Loss: 0.3048, Validation Loss: 0.4303, Training Accuracy: 0.8612, Validation Accuracy: 0.8090\n",
      "Epoch [414/500], Training Loss: 0.3581, Validation Loss: 0.4871, Training Accuracy: 0.8413, Validation Accuracy: 0.8090\n",
      "Epoch [415/500], Training Loss: 0.4472, Validation Loss: 0.5014, Training Accuracy: 0.8413, Validation Accuracy: 0.7865\n",
      "Epoch [416/500], Training Loss: 0.3481, Validation Loss: 0.4337, Training Accuracy: 0.8562, Validation Accuracy: 0.8090\n",
      "Epoch [417/500], Training Loss: 0.4434, Validation Loss: 0.4011, Training Accuracy: 0.8187, Validation Accuracy: 0.8202\n",
      "Epoch [418/500], Training Loss: 0.4902, Validation Loss: 2.5920, Training Accuracy: 0.8425, Validation Accuracy: 0.8202\n",
      "Epoch [419/500], Training Loss: 0.4015, Validation Loss: 1.5811, Training Accuracy: 0.8200, Validation Accuracy: 0.7978\n",
      "Epoch [420/500], Training Loss: 0.8492, Validation Loss: 0.5082, Training Accuracy: 0.8400, Validation Accuracy: 0.7640\n",
      "Epoch [421/500], Training Loss: 0.4780, Validation Loss: 0.4498, Training Accuracy: 0.8562, Validation Accuracy: 0.7865\n",
      "Epoch [422/500], Training Loss: 0.3659, Validation Loss: 0.5078, Training Accuracy: 0.8363, Validation Accuracy: 0.8090\n",
      "Epoch [423/500], Training Loss: 0.5394, Validation Loss: 1.4679, Training Accuracy: 0.8400, Validation Accuracy: 0.8202\n",
      "Epoch [424/500], Training Loss: 0.5240, Validation Loss: 0.3908, Training Accuracy: 0.8438, Validation Accuracy: 0.7978\n",
      "Epoch [425/500], Training Loss: 0.3830, Validation Loss: 0.4442, Training Accuracy: 0.8350, Validation Accuracy: 0.7978\n",
      "Epoch [426/500], Training Loss: 0.3505, Validation Loss: 0.5259, Training Accuracy: 0.8588, Validation Accuracy: 0.8090\n",
      "Epoch [427/500], Training Loss: 0.4864, Validation Loss: 0.3916, Training Accuracy: 0.8462, Validation Accuracy: 0.8202\n",
      "Epoch [428/500], Training Loss: 0.4670, Validation Loss: 0.3737, Training Accuracy: 0.8287, Validation Accuracy: 0.8315\n",
      "Epoch [429/500], Training Loss: 0.3951, Validation Loss: 0.4263, Training Accuracy: 0.8350, Validation Accuracy: 0.8090\n",
      "Epoch [430/500], Training Loss: 0.5505, Validation Loss: 0.4432, Training Accuracy: 0.8187, Validation Accuracy: 0.7978\n",
      "Epoch [431/500], Training Loss: 0.3935, Validation Loss: 0.3500, Training Accuracy: 0.8225, Validation Accuracy: 0.8202\n",
      "Epoch [432/500], Training Loss: 0.6817, Validation Loss: 1.6235, Training Accuracy: 0.8125, Validation Accuracy: 0.7865\n",
      "Epoch [433/500], Training Loss: 0.5617, Validation Loss: 0.6500, Training Accuracy: 0.7987, Validation Accuracy: 0.7416\n",
      "Epoch [434/500], Training Loss: 0.3794, Validation Loss: 0.4153, Training Accuracy: 0.8275, Validation Accuracy: 0.7753\n",
      "Epoch [435/500], Training Loss: 0.3908, Validation Loss: 0.4624, Training Accuracy: 0.8263, Validation Accuracy: 0.7753\n",
      "Epoch [436/500], Training Loss: 0.3742, Validation Loss: 0.4224, Training Accuracy: 0.8375, Validation Accuracy: 0.8090\n",
      "Epoch [437/500], Training Loss: 0.3892, Validation Loss: 0.4067, Training Accuracy: 0.8350, Validation Accuracy: 0.8315\n",
      "Epoch [438/500], Training Loss: 0.3603, Validation Loss: 0.4789, Training Accuracy: 0.8562, Validation Accuracy: 0.7978\n",
      "Epoch [439/500], Training Loss: 0.4361, Validation Loss: 0.4298, Training Accuracy: 0.8200, Validation Accuracy: 0.7865\n",
      "Epoch [440/500], Training Loss: 0.3553, Validation Loss: 0.5907, Training Accuracy: 0.8475, Validation Accuracy: 0.7528\n",
      "Epoch [441/500], Training Loss: 0.4179, Validation Loss: 0.4177, Training Accuracy: 0.8225, Validation Accuracy: 0.7865\n",
      "Epoch [442/500], Training Loss: 0.3977, Validation Loss: 0.3993, Training Accuracy: 0.8087, Validation Accuracy: 0.7978\n",
      "Epoch [443/500], Training Loss: 0.3821, Validation Loss: 0.4127, Training Accuracy: 0.8187, Validation Accuracy: 0.7753\n",
      "Epoch [444/500], Training Loss: 0.3700, Validation Loss: 0.3937, Training Accuracy: 0.8300, Validation Accuracy: 0.7978\n",
      "Epoch [445/500], Training Loss: 0.3825, Validation Loss: 0.4377, Training Accuracy: 0.8225, Validation Accuracy: 0.7753\n",
      "Epoch [446/500], Training Loss: 0.6058, Validation Loss: 0.3892, Training Accuracy: 0.7925, Validation Accuracy: 0.7865\n",
      "Epoch [447/500], Training Loss: 0.3721, Validation Loss: 0.4125, Training Accuracy: 0.8387, Validation Accuracy: 0.7865\n",
      "Epoch [448/500], Training Loss: 0.6399, Validation Loss: 1.6395, Training Accuracy: 0.8300, Validation Accuracy: 0.7978\n",
      "Epoch [449/500], Training Loss: 0.6528, Validation Loss: 1.5790, Training Accuracy: 0.8337, Validation Accuracy: 0.7753\n",
      "Epoch [450/500], Training Loss: 0.3587, Validation Loss: 0.4857, Training Accuracy: 0.8413, Validation Accuracy: 0.8202\n",
      "Epoch [451/500], Training Loss: 0.4121, Validation Loss: 2.6487, Training Accuracy: 0.8413, Validation Accuracy: 0.7640\n",
      "Epoch [452/500], Training Loss: 0.5398, Validation Loss: 0.5286, Training Accuracy: 0.8287, Validation Accuracy: 0.7865\n",
      "Epoch [453/500], Training Loss: 0.4719, Validation Loss: 0.4956, Training Accuracy: 0.8050, Validation Accuracy: 0.7753\n",
      "Epoch [454/500], Training Loss: 0.5348, Validation Loss: 0.4755, Training Accuracy: 0.8063, Validation Accuracy: 0.7753\n",
      "Epoch [455/500], Training Loss: 0.4025, Validation Loss: 0.4227, Training Accuracy: 0.8263, Validation Accuracy: 0.8090\n",
      "Epoch [456/500], Training Loss: 0.3928, Validation Loss: 0.3842, Training Accuracy: 0.8313, Validation Accuracy: 0.8202\n",
      "Epoch [457/500], Training Loss: 0.3978, Validation Loss: 0.3994, Training Accuracy: 0.8187, Validation Accuracy: 0.8202\n",
      "Epoch [458/500], Training Loss: 0.5519, Validation Loss: 0.4135, Training Accuracy: 0.8250, Validation Accuracy: 0.7978\n",
      "Epoch [459/500], Training Loss: 0.4164, Validation Loss: 0.4505, Training Accuracy: 0.8100, Validation Accuracy: 0.7753\n",
      "Epoch [460/500], Training Loss: 0.3725, Validation Loss: 0.4667, Training Accuracy: 0.8350, Validation Accuracy: 0.7865\n",
      "Epoch [461/500], Training Loss: 0.3556, Validation Loss: 0.3925, Training Accuracy: 0.8525, Validation Accuracy: 0.8315\n",
      "Epoch [462/500], Training Loss: 0.3987, Validation Loss: 0.4651, Training Accuracy: 0.8237, Validation Accuracy: 0.8202\n",
      "Epoch [463/500], Training Loss: 0.4062, Validation Loss: 0.4742, Training Accuracy: 0.8313, Validation Accuracy: 0.7978\n",
      "Epoch [464/500], Training Loss: 0.3622, Validation Loss: 0.4975, Training Accuracy: 0.8562, Validation Accuracy: 0.8090\n",
      "Epoch [465/500], Training Loss: 0.3578, Validation Loss: 0.5309, Training Accuracy: 0.8337, Validation Accuracy: 0.8202\n",
      "Epoch [466/500], Training Loss: 0.5450, Validation Loss: 0.4281, Training Accuracy: 0.8337, Validation Accuracy: 0.7978\n",
      "Epoch [467/500], Training Loss: 0.6240, Validation Loss: 0.4798, Training Accuracy: 0.8337, Validation Accuracy: 0.7978\n",
      "Epoch [468/500], Training Loss: 0.3514, Validation Loss: 0.5334, Training Accuracy: 0.8462, Validation Accuracy: 0.8090\n",
      "Epoch [469/500], Training Loss: 0.3401, Validation Loss: 0.4863, Training Accuracy: 0.8462, Validation Accuracy: 0.8202\n",
      "Epoch [470/500], Training Loss: 0.3585, Validation Loss: 1.6355, Training Accuracy: 0.8375, Validation Accuracy: 0.8090\n",
      "Epoch [471/500], Training Loss: 0.3193, Validation Loss: 0.4498, Training Accuracy: 0.8600, Validation Accuracy: 0.7753\n",
      "Epoch [472/500], Training Loss: 0.4848, Validation Loss: 0.3626, Training Accuracy: 0.8438, Validation Accuracy: 0.8315\n",
      "Epoch [473/500], Training Loss: 0.5296, Validation Loss: 0.4196, Training Accuracy: 0.8450, Validation Accuracy: 0.8427\n",
      "Epoch [474/500], Training Loss: 0.4244, Validation Loss: 0.7680, Training Accuracy: 0.8200, Validation Accuracy: 0.7528\n",
      "Epoch [475/500], Training Loss: 0.3924, Validation Loss: 0.8319, Training Accuracy: 0.8225, Validation Accuracy: 0.8202\n",
      "Epoch [476/500], Training Loss: 0.5924, Validation Loss: 0.4752, Training Accuracy: 0.8100, Validation Accuracy: 0.7978\n",
      "Epoch [477/500], Training Loss: 0.4744, Validation Loss: 0.6525, Training Accuracy: 0.8287, Validation Accuracy: 0.8090\n",
      "Epoch [478/500], Training Loss: 0.4176, Validation Loss: 2.5164, Training Accuracy: 0.8350, Validation Accuracy: 0.8090\n",
      "Epoch [479/500], Training Loss: 0.5206, Validation Loss: 1.4985, Training Accuracy: 0.8313, Validation Accuracy: 0.7978\n",
      "Epoch [480/500], Training Loss: 0.4562, Validation Loss: 0.4116, Training Accuracy: 0.8087, Validation Accuracy: 0.8202\n",
      "Epoch [481/500], Training Loss: 0.4733, Validation Loss: 1.4921, Training Accuracy: 0.8400, Validation Accuracy: 0.7978\n",
      "Epoch [482/500], Training Loss: 0.3932, Validation Loss: 1.6441, Training Accuracy: 0.8287, Validation Accuracy: 0.8090\n",
      "Epoch [483/500], Training Loss: 0.4834, Validation Loss: 1.5286, Training Accuracy: 0.8375, Validation Accuracy: 0.8090\n",
      "Epoch [484/500], Training Loss: 0.3827, Validation Loss: 1.4156, Training Accuracy: 0.8300, Validation Accuracy: 0.8090\n",
      "Epoch [485/500], Training Loss: 0.3495, Validation Loss: 0.4386, Training Accuracy: 0.8413, Validation Accuracy: 0.8202\n",
      "Epoch [486/500], Training Loss: 0.6306, Validation Loss: 1.4138, Training Accuracy: 0.8588, Validation Accuracy: 0.7978\n",
      "Epoch [487/500], Training Loss: 0.4195, Validation Loss: 1.4072, Training Accuracy: 0.8200, Validation Accuracy: 0.8090\n",
      "Epoch [488/500], Training Loss: 0.4575, Validation Loss: 1.4187, Training Accuracy: 0.8588, Validation Accuracy: 0.7865\n",
      "Epoch [489/500], Training Loss: 0.4945, Validation Loss: 1.4606, Training Accuracy: 0.8300, Validation Accuracy: 0.7865\n",
      "Epoch [490/500], Training Loss: 0.3636, Validation Loss: 1.4386, Training Accuracy: 0.8438, Validation Accuracy: 0.7978\n",
      "Epoch [491/500], Training Loss: 0.3690, Validation Loss: 1.4587, Training Accuracy: 0.8488, Validation Accuracy: 0.7978\n",
      "Epoch [492/500], Training Loss: 0.3548, Validation Loss: 1.4625, Training Accuracy: 0.8538, Validation Accuracy: 0.7865\n",
      "Epoch [493/500], Training Loss: 0.3477, Validation Loss: 0.5531, Training Accuracy: 0.8562, Validation Accuracy: 0.7978\n",
      "Epoch [494/500], Training Loss: 0.3391, Validation Loss: 1.4691, Training Accuracy: 0.8562, Validation Accuracy: 0.8202\n",
      "Epoch [495/500], Training Loss: 0.3347, Validation Loss: 1.4898, Training Accuracy: 0.8562, Validation Accuracy: 0.8202\n",
      "Epoch [496/500], Training Loss: 0.5623, Validation Loss: 0.5114, Training Accuracy: 0.8213, Validation Accuracy: 0.8090\n",
      "Epoch [497/500], Training Loss: 0.3748, Validation Loss: 0.4386, Training Accuracy: 0.8512, Validation Accuracy: 0.8090\n",
      "Epoch [498/500], Training Loss: 0.3039, Validation Loss: 0.4562, Training Accuracy: 0.8662, Validation Accuracy: 0.8202\n",
      "Epoch [499/500], Training Loss: 0.3257, Validation Loss: 0.4982, Training Accuracy: 0.8575, Validation Accuracy: 0.8202\n",
      "Epoch [500/500], Training Loss: 0.3679, Validation Loss: 0.4248, Training Accuracy: 0.8562, Validation Accuracy: 0.8315\n",
      "Training Time: 12.01 seconds\n",
      "Epoch [1/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [2/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [3/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [4/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [5/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [6/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [7/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [8/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [9/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [10/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [11/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [12/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [13/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [14/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [15/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [16/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [17/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [18/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [19/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [20/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [21/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [22/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [23/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [24/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [25/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [26/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [27/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [28/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [29/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [30/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [31/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [32/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [33/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [34/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [35/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [36/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [37/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [38/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [39/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [40/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [41/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [42/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [43/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [44/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [45/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [46/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [47/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [48/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [49/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [50/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [51/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [52/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [53/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [54/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [55/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [56/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [57/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [58/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [59/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [60/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [61/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [62/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [63/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [64/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [65/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [66/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [67/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [68/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [69/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [70/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [71/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [72/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [73/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [74/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [75/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [76/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [77/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [78/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [79/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [80/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [81/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [82/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [83/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [84/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [85/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [86/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [87/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [88/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [89/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [90/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [91/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [92/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [93/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [94/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [95/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [96/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [97/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [98/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [99/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [100/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [101/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [102/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [103/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [104/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [105/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [106/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [107/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [108/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [109/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [110/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [111/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [112/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [113/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [114/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [115/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [116/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [117/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [118/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [119/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [120/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [121/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [122/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [123/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [124/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [125/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [126/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [127/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [128/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [129/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [130/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [131/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [132/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [133/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [134/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [135/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [136/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [137/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [138/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [139/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [140/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [141/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [142/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [143/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [144/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [145/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [146/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [147/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [148/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [149/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [150/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [151/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [152/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [153/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [154/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [155/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [156/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [157/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [158/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [159/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [160/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [161/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [162/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [163/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [164/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [165/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [166/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [167/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [168/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [169/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [170/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [171/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [172/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [173/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [174/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [175/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [176/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [177/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [178/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [179/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [180/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [181/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [182/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [183/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [184/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [185/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [186/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [187/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [188/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [189/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [190/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [191/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [192/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [193/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [194/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [195/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [196/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [197/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [198/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [199/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [200/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [201/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [202/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [203/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [204/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [205/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [206/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [207/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [208/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [209/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [210/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [211/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [212/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [213/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [214/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [215/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [216/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [217/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [218/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [219/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [220/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [221/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [222/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [223/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [224/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [225/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [226/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [227/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [228/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [229/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [230/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [231/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [232/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [233/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [234/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [235/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [236/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [237/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [238/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [239/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [240/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [241/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [242/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [243/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [244/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [245/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [246/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [247/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [248/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [249/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [250/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [251/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [252/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [253/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [254/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [255/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [256/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [257/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [258/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [259/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [260/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [261/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [262/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [263/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [264/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [265/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [266/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [267/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [268/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [269/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [270/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [271/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [272/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [273/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [274/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [275/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [276/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [277/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [278/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [279/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [280/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [281/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [282/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [283/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [284/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [285/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [286/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [287/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [288/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [289/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [290/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [291/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [292/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [293/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [294/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [295/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [296/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [297/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [298/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [299/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [300/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [301/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [302/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [303/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [304/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [305/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [306/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [307/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [308/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [309/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [310/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [311/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [312/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [313/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [314/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [315/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [316/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [317/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [318/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [319/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [320/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [321/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [322/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [323/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [324/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [325/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [326/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [327/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [328/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [329/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [330/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [331/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [332/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [333/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [334/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [335/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [336/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [337/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [338/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [339/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [340/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [341/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [342/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [343/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [344/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [345/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [346/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [347/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [348/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [349/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [350/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [351/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [352/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [353/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [354/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [355/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [356/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [357/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [358/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [359/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [360/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [361/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [362/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [363/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [364/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [365/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [366/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [367/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [368/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [369/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [370/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [371/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [372/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [373/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [374/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [375/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [376/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [377/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [378/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [379/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [380/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [381/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [382/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [383/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [384/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [385/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [386/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [387/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [388/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [389/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [390/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [391/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [392/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [393/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [394/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [395/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [396/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [397/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [398/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [399/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [400/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [401/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [402/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [403/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [404/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [405/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [406/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [407/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [408/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [409/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [410/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [411/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [412/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [413/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [414/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [415/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [416/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [417/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [418/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [419/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [420/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [421/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [422/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [423/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [424/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [425/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [426/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [427/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [428/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [429/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [430/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [431/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [432/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [433/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [434/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [435/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [436/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [437/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [438/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [439/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [440/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [441/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [442/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [443/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [444/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [445/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [446/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [447/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [448/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [449/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [450/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [451/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [452/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [453/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [454/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [455/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [456/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [457/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [458/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [459/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [460/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [461/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [462/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [463/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [464/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [465/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [466/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [467/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [468/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [469/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [470/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [471/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [472/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [473/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [474/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [475/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [476/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [477/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [478/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [479/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [480/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [481/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [482/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [483/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [484/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [485/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [486/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [487/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [488/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [489/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [490/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [491/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [492/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [493/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [494/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [495/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [496/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [497/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [498/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [499/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [500/500], Test Loss: 2.6322, Testing Accuracy: 0.7677\n",
      "Epoch [1/500], Training Loss: 0.5990, Validation Loss: 0.5147, Training Accuracy: 0.7037, Validation Accuracy: 0.7416\n",
      "Epoch [2/500], Training Loss: 0.5281, Validation Loss: 0.4896, Training Accuracy: 0.7412, Validation Accuracy: 0.7865\n",
      "Epoch [3/500], Training Loss: 0.5278, Validation Loss: 0.4967, Training Accuracy: 0.7375, Validation Accuracy: 0.7978\n",
      "Epoch [4/500], Training Loss: 0.5252, Validation Loss: 0.5128, Training Accuracy: 0.7538, Validation Accuracy: 0.7416\n",
      "Epoch [5/500], Training Loss: 0.5439, Validation Loss: 0.5108, Training Accuracy: 0.7462, Validation Accuracy: 0.7753\n",
      "Epoch [6/500], Training Loss: 0.5274, Validation Loss: 0.5516, Training Accuracy: 0.7488, Validation Accuracy: 0.7528\n",
      "Epoch [7/500], Training Loss: 0.5237, Validation Loss: 0.5510, Training Accuracy: 0.7400, Validation Accuracy: 0.7191\n",
      "Epoch [8/500], Training Loss: 0.4966, Validation Loss: 0.5311, Training Accuracy: 0.7575, Validation Accuracy: 0.7640\n",
      "Epoch [9/500], Training Loss: 0.4991, Validation Loss: 0.5318, Training Accuracy: 0.7512, Validation Accuracy: 0.7640\n",
      "Epoch [10/500], Training Loss: 0.5088, Validation Loss: 0.5289, Training Accuracy: 0.7375, Validation Accuracy: 0.7416\n",
      "Epoch [11/500], Training Loss: 0.4760, Validation Loss: 0.5268, Training Accuracy: 0.7750, Validation Accuracy: 0.7753\n",
      "Epoch [12/500], Training Loss: 0.4887, Validation Loss: 0.4845, Training Accuracy: 0.7700, Validation Accuracy: 0.7528\n",
      "Epoch [13/500], Training Loss: 0.4828, Validation Loss: 0.5145, Training Accuracy: 0.7738, Validation Accuracy: 0.7865\n",
      "Epoch [14/500], Training Loss: 0.4835, Validation Loss: 0.4899, Training Accuracy: 0.7688, Validation Accuracy: 0.7865\n",
      "Epoch [15/500], Training Loss: 0.4713, Validation Loss: 0.5026, Training Accuracy: 0.7675, Validation Accuracy: 0.7865\n",
      "Epoch [16/500], Training Loss: 0.4577, Validation Loss: 0.5748, Training Accuracy: 0.7788, Validation Accuracy: 0.7303\n",
      "Epoch [17/500], Training Loss: 0.5028, Validation Loss: 0.5237, Training Accuracy: 0.7725, Validation Accuracy: 0.8090\n",
      "Epoch [18/500], Training Loss: 0.4404, Validation Loss: 0.5270, Training Accuracy: 0.7812, Validation Accuracy: 0.7640\n",
      "Epoch [19/500], Training Loss: 0.4593, Validation Loss: 0.5127, Training Accuracy: 0.7788, Validation Accuracy: 0.7640\n",
      "Epoch [20/500], Training Loss: 0.4689, Validation Loss: 0.5188, Training Accuracy: 0.7762, Validation Accuracy: 0.7753\n",
      "Epoch [21/500], Training Loss: 0.4586, Validation Loss: 0.5386, Training Accuracy: 0.7688, Validation Accuracy: 0.7640\n",
      "Epoch [22/500], Training Loss: 0.4529, Validation Loss: 0.4659, Training Accuracy: 0.7788, Validation Accuracy: 0.7978\n",
      "Epoch [23/500], Training Loss: 0.4347, Validation Loss: 0.5336, Training Accuracy: 0.7812, Validation Accuracy: 0.7528\n",
      "Epoch [24/500], Training Loss: 0.4689, Validation Loss: 0.5052, Training Accuracy: 0.7700, Validation Accuracy: 0.7753\n",
      "Epoch [25/500], Training Loss: 0.4545, Validation Loss: 0.5064, Training Accuracy: 0.7863, Validation Accuracy: 0.7303\n",
      "Epoch [26/500], Training Loss: 0.4361, Validation Loss: 0.4691, Training Accuracy: 0.7850, Validation Accuracy: 0.8315\n",
      "Epoch [27/500], Training Loss: 0.4364, Validation Loss: 0.4797, Training Accuracy: 0.7837, Validation Accuracy: 0.8202\n",
      "Epoch [28/500], Training Loss: 0.4575, Validation Loss: 0.5140, Training Accuracy: 0.7825, Validation Accuracy: 0.7416\n",
      "Epoch [29/500], Training Loss: 0.4280, Validation Loss: 0.4838, Training Accuracy: 0.7788, Validation Accuracy: 0.7528\n",
      "Epoch [30/500], Training Loss: 0.4429, Validation Loss: 0.4753, Training Accuracy: 0.7975, Validation Accuracy: 0.7865\n",
      "Epoch [31/500], Training Loss: 0.4197, Validation Loss: 0.4731, Training Accuracy: 0.7913, Validation Accuracy: 0.7753\n",
      "Epoch [32/500], Training Loss: 0.4269, Validation Loss: 0.5045, Training Accuracy: 0.7738, Validation Accuracy: 0.7528\n",
      "Epoch [33/500], Training Loss: 0.4120, Validation Loss: 0.5094, Training Accuracy: 0.7863, Validation Accuracy: 0.7753\n",
      "Epoch [34/500], Training Loss: 0.4291, Validation Loss: 0.4891, Training Accuracy: 0.8013, Validation Accuracy: 0.7753\n",
      "Epoch [35/500], Training Loss: 0.4070, Validation Loss: 0.5448, Training Accuracy: 0.8050, Validation Accuracy: 0.7865\n",
      "Epoch [36/500], Training Loss: 0.4123, Validation Loss: 0.5822, Training Accuracy: 0.7987, Validation Accuracy: 0.7865\n",
      "Epoch [37/500], Training Loss: 0.4374, Validation Loss: 0.6221, Training Accuracy: 0.7950, Validation Accuracy: 0.7416\n",
      "Epoch [38/500], Training Loss: 0.4202, Validation Loss: 0.6007, Training Accuracy: 0.8013, Validation Accuracy: 0.7303\n",
      "Epoch [39/500], Training Loss: 0.4429, Validation Loss: 0.4910, Training Accuracy: 0.7963, Validation Accuracy: 0.7303\n",
      "Epoch [40/500], Training Loss: 0.4394, Validation Loss: 0.4859, Training Accuracy: 0.7913, Validation Accuracy: 0.7640\n",
      "Epoch [41/500], Training Loss: 0.4165, Validation Loss: 0.5036, Training Accuracy: 0.7950, Validation Accuracy: 0.7303\n",
      "Epoch [42/500], Training Loss: 0.4419, Validation Loss: 0.4867, Training Accuracy: 0.7850, Validation Accuracy: 0.7640\n",
      "Epoch [43/500], Training Loss: 0.4253, Validation Loss: 0.5063, Training Accuracy: 0.7937, Validation Accuracy: 0.8202\n",
      "Epoch [44/500], Training Loss: 0.4211, Validation Loss: 0.5177, Training Accuracy: 0.8250, Validation Accuracy: 0.7303\n",
      "Epoch [45/500], Training Loss: 0.3892, Validation Loss: 0.5171, Training Accuracy: 0.8037, Validation Accuracy: 0.7753\n",
      "Epoch [46/500], Training Loss: 0.4008, Validation Loss: 0.4650, Training Accuracy: 0.8125, Validation Accuracy: 0.7753\n",
      "Epoch [47/500], Training Loss: 0.4535, Validation Loss: 0.4606, Training Accuracy: 0.7762, Validation Accuracy: 0.7416\n",
      "Epoch [48/500], Training Loss: 0.3978, Validation Loss: 0.4924, Training Accuracy: 0.8013, Validation Accuracy: 0.7640\n",
      "Epoch [49/500], Training Loss: 0.3696, Validation Loss: 0.6828, Training Accuracy: 0.8163, Validation Accuracy: 0.7528\n",
      "Epoch [50/500], Training Loss: 0.4123, Validation Loss: 0.4889, Training Accuracy: 0.8113, Validation Accuracy: 0.7416\n",
      "Epoch [51/500], Training Loss: 0.4131, Validation Loss: 0.4590, Training Accuracy: 0.8187, Validation Accuracy: 0.7753\n",
      "Epoch [52/500], Training Loss: 0.4057, Validation Loss: 0.4655, Training Accuracy: 0.8037, Validation Accuracy: 0.7753\n",
      "Epoch [53/500], Training Loss: 0.3900, Validation Loss: 0.4809, Training Accuracy: 0.8187, Validation Accuracy: 0.7753\n",
      "Epoch [54/500], Training Loss: 0.4021, Validation Loss: 0.5091, Training Accuracy: 0.8075, Validation Accuracy: 0.7528\n",
      "Epoch [55/500], Training Loss: 0.3809, Validation Loss: 0.4343, Training Accuracy: 0.8025, Validation Accuracy: 0.7865\n",
      "Epoch [56/500], Training Loss: 0.3995, Validation Loss: 0.4482, Training Accuracy: 0.7987, Validation Accuracy: 0.7865\n",
      "Epoch [57/500], Training Loss: 0.3873, Validation Loss: 0.4249, Training Accuracy: 0.8200, Validation Accuracy: 0.8090\n",
      "Epoch [58/500], Training Loss: 0.3805, Validation Loss: 0.4681, Training Accuracy: 0.8125, Validation Accuracy: 0.7865\n",
      "Epoch [59/500], Training Loss: 0.3623, Validation Loss: 0.6447, Training Accuracy: 0.8350, Validation Accuracy: 0.7978\n",
      "Epoch [60/500], Training Loss: 0.3802, Validation Loss: 0.5132, Training Accuracy: 0.8400, Validation Accuracy: 0.7865\n",
      "Epoch [61/500], Training Loss: 0.3914, Validation Loss: 0.4655, Training Accuracy: 0.8250, Validation Accuracy: 0.7753\n",
      "Epoch [62/500], Training Loss: 0.3751, Validation Loss: 0.4982, Training Accuracy: 0.8337, Validation Accuracy: 0.7416\n",
      "Epoch [63/500], Training Loss: 0.4083, Validation Loss: 0.4731, Training Accuracy: 0.7925, Validation Accuracy: 0.7528\n",
      "Epoch [64/500], Training Loss: 0.3827, Validation Loss: 0.4932, Training Accuracy: 0.8050, Validation Accuracy: 0.7416\n",
      "Epoch [65/500], Training Loss: 0.4061, Validation Loss: 0.4794, Training Accuracy: 0.8250, Validation Accuracy: 0.7416\n",
      "Epoch [66/500], Training Loss: 0.3854, Validation Loss: 0.4552, Training Accuracy: 0.8300, Validation Accuracy: 0.7865\n",
      "Epoch [67/500], Training Loss: 0.3727, Validation Loss: 0.4263, Training Accuracy: 0.8150, Validation Accuracy: 0.8090\n",
      "Epoch [68/500], Training Loss: 0.3669, Validation Loss: 0.4078, Training Accuracy: 0.8187, Validation Accuracy: 0.7753\n",
      "Epoch [69/500], Training Loss: 0.3845, Validation Loss: 0.4500, Training Accuracy: 0.8175, Validation Accuracy: 0.8315\n",
      "Epoch [70/500], Training Loss: 0.3774, Validation Loss: 0.4781, Training Accuracy: 0.8113, Validation Accuracy: 0.8090\n",
      "Epoch [71/500], Training Loss: 0.3490, Validation Loss: 0.4383, Training Accuracy: 0.8512, Validation Accuracy: 0.7528\n",
      "Epoch [72/500], Training Loss: 0.3473, Validation Loss: 0.4992, Training Accuracy: 0.8425, Validation Accuracy: 0.7753\n",
      "Epoch [73/500], Training Loss: 0.3347, Validation Loss: 0.4575, Training Accuracy: 0.8387, Validation Accuracy: 0.7640\n",
      "Epoch [74/500], Training Loss: 0.3863, Validation Loss: 0.4422, Training Accuracy: 0.8175, Validation Accuracy: 0.7865\n",
      "Epoch [75/500], Training Loss: 0.3752, Validation Loss: 0.4387, Training Accuracy: 0.8225, Validation Accuracy: 0.7865\n",
      "Epoch [76/500], Training Loss: 0.3680, Validation Loss: 0.5002, Training Accuracy: 0.8425, Validation Accuracy: 0.7753\n",
      "Epoch [77/500], Training Loss: 0.3377, Validation Loss: 0.5442, Training Accuracy: 0.8387, Validation Accuracy: 0.8090\n",
      "Epoch [78/500], Training Loss: 0.3820, Validation Loss: 0.4695, Training Accuracy: 0.8213, Validation Accuracy: 0.7416\n",
      "Epoch [79/500], Training Loss: 0.3629, Validation Loss: 0.4833, Training Accuracy: 0.8450, Validation Accuracy: 0.8202\n",
      "Epoch [80/500], Training Loss: 0.3496, Validation Loss: 0.4528, Training Accuracy: 0.8200, Validation Accuracy: 0.8315\n",
      "Epoch [81/500], Training Loss: 0.3634, Validation Loss: 0.4689, Training Accuracy: 0.8350, Validation Accuracy: 0.7753\n",
      "Epoch [82/500], Training Loss: 0.3519, Validation Loss: 0.4446, Training Accuracy: 0.8375, Validation Accuracy: 0.7303\n",
      "Epoch [83/500], Training Loss: 0.4740, Validation Loss: 0.4796, Training Accuracy: 0.8337, Validation Accuracy: 0.7753\n",
      "Epoch [84/500], Training Loss: 0.3651, Validation Loss: 0.4640, Training Accuracy: 0.8413, Validation Accuracy: 0.7640\n",
      "Epoch [85/500], Training Loss: 0.3639, Validation Loss: 0.4134, Training Accuracy: 0.8300, Validation Accuracy: 0.7753\n",
      "Epoch [86/500], Training Loss: 0.3836, Validation Loss: 0.4588, Training Accuracy: 0.8225, Validation Accuracy: 0.7865\n",
      "Epoch [87/500], Training Loss: 0.3600, Validation Loss: 0.4887, Training Accuracy: 0.8150, Validation Accuracy: 0.7978\n",
      "Epoch [88/500], Training Loss: 0.3512, Validation Loss: 0.4354, Training Accuracy: 0.8363, Validation Accuracy: 0.8202\n",
      "Epoch [89/500], Training Loss: 0.3547, Validation Loss: 0.4948, Training Accuracy: 0.8250, Validation Accuracy: 0.7978\n",
      "Epoch [90/500], Training Loss: 0.3184, Validation Loss: 0.5287, Training Accuracy: 0.8413, Validation Accuracy: 0.7753\n",
      "Epoch [91/500], Training Loss: 0.3652, Validation Loss: 0.5104, Training Accuracy: 0.8250, Validation Accuracy: 0.7978\n",
      "Epoch [92/500], Training Loss: 0.3899, Validation Loss: 0.4249, Training Accuracy: 0.8337, Validation Accuracy: 0.8315\n",
      "Epoch [93/500], Training Loss: 0.3398, Validation Loss: 0.4990, Training Accuracy: 0.8438, Validation Accuracy: 0.7865\n",
      "Epoch [94/500], Training Loss: 0.3520, Validation Loss: 0.4059, Training Accuracy: 0.8438, Validation Accuracy: 0.8090\n",
      "Epoch [95/500], Training Loss: 0.3293, Validation Loss: 0.4354, Training Accuracy: 0.8488, Validation Accuracy: 0.7978\n",
      "Epoch [96/500], Training Loss: 0.3267, Validation Loss: 0.5178, Training Accuracy: 0.8400, Validation Accuracy: 0.7978\n",
      "Epoch [97/500], Training Loss: 0.3480, Validation Loss: 0.5038, Training Accuracy: 0.8575, Validation Accuracy: 0.7978\n",
      "Epoch [98/500], Training Loss: 0.3080, Validation Loss: 0.4926, Training Accuracy: 0.8500, Validation Accuracy: 0.7865\n",
      "Epoch [99/500], Training Loss: 0.3021, Validation Loss: 0.4452, Training Accuracy: 0.8488, Validation Accuracy: 0.8090\n",
      "Epoch [100/500], Training Loss: 0.3382, Validation Loss: 0.4456, Training Accuracy: 0.8475, Validation Accuracy: 0.7865\n",
      "Epoch [101/500], Training Loss: 0.3298, Validation Loss: 0.4147, Training Accuracy: 0.8275, Validation Accuracy: 0.8202\n",
      "Epoch [102/500], Training Loss: 0.3529, Validation Loss: 0.4764, Training Accuracy: 0.8263, Validation Accuracy: 0.7640\n",
      "Epoch [103/500], Training Loss: 0.3546, Validation Loss: 0.3991, Training Accuracy: 0.8425, Validation Accuracy: 0.7978\n",
      "Epoch [104/500], Training Loss: 0.3322, Validation Loss: 0.4199, Training Accuracy: 0.8562, Validation Accuracy: 0.8090\n",
      "Epoch [105/500], Training Loss: 0.3228, Validation Loss: 0.4300, Training Accuracy: 0.8387, Validation Accuracy: 0.8539\n",
      "Epoch [106/500], Training Loss: 0.3692, Validation Loss: 0.4646, Training Accuracy: 0.8375, Validation Accuracy: 0.8090\n",
      "Epoch [107/500], Training Loss: 0.3288, Validation Loss: 0.4490, Training Accuracy: 0.8612, Validation Accuracy: 0.7753\n",
      "Epoch [108/500], Training Loss: 0.3363, Validation Loss: 0.5115, Training Accuracy: 0.8525, Validation Accuracy: 0.8090\n",
      "Epoch [109/500], Training Loss: 0.3090, Validation Loss: 0.5139, Training Accuracy: 0.8450, Validation Accuracy: 0.7865\n",
      "Epoch [110/500], Training Loss: 0.3274, Validation Loss: 0.5842, Training Accuracy: 0.8462, Validation Accuracy: 0.7303\n",
      "Epoch [111/500], Training Loss: 0.3599, Validation Loss: 0.6327, Training Accuracy: 0.8375, Validation Accuracy: 0.7753\n",
      "Epoch [112/500], Training Loss: 0.3626, Validation Loss: 0.5068, Training Accuracy: 0.8387, Validation Accuracy: 0.7978\n",
      "Epoch [113/500], Training Loss: 0.3230, Validation Loss: 0.4688, Training Accuracy: 0.8512, Validation Accuracy: 0.7978\n",
      "Epoch [114/500], Training Loss: 0.2945, Validation Loss: 0.4913, Training Accuracy: 0.8488, Validation Accuracy: 0.8202\n",
      "Epoch [115/500], Training Loss: 0.3218, Validation Loss: 0.4914, Training Accuracy: 0.8500, Validation Accuracy: 0.7978\n",
      "Epoch [116/500], Training Loss: 0.3045, Validation Loss: 0.5113, Training Accuracy: 0.8500, Validation Accuracy: 0.8090\n",
      "Epoch [117/500], Training Loss: 0.3354, Validation Loss: 0.4807, Training Accuracy: 0.8562, Validation Accuracy: 0.7640\n",
      "Epoch [118/500], Training Loss: 0.3361, Validation Loss: 0.5886, Training Accuracy: 0.8300, Validation Accuracy: 0.7978\n",
      "Epoch [119/500], Training Loss: 0.2795, Validation Loss: 0.5862, Training Accuracy: 0.8738, Validation Accuracy: 0.7753\n",
      "Epoch [120/500], Training Loss: 0.2935, Validation Loss: 0.6882, Training Accuracy: 0.8675, Validation Accuracy: 0.7865\n",
      "Epoch [121/500], Training Loss: 0.3178, Validation Loss: 0.5175, Training Accuracy: 0.8512, Validation Accuracy: 0.8090\n",
      "Epoch [122/500], Training Loss: 0.3653, Validation Loss: 0.4686, Training Accuracy: 0.8375, Validation Accuracy: 0.8202\n",
      "Epoch [123/500], Training Loss: 0.3431, Validation Loss: 0.5246, Training Accuracy: 0.8450, Validation Accuracy: 0.7865\n",
      "Epoch [124/500], Training Loss: 0.2996, Validation Loss: 0.5457, Training Accuracy: 0.8638, Validation Accuracy: 0.7978\n",
      "Epoch [125/500], Training Loss: 0.3376, Validation Loss: 0.4757, Training Accuracy: 0.8500, Validation Accuracy: 0.7978\n",
      "Epoch [126/500], Training Loss: 0.5621, Validation Loss: 0.5127, Training Accuracy: 0.8612, Validation Accuracy: 0.8202\n",
      "Epoch [127/500], Training Loss: 0.2941, Validation Loss: 0.5705, Training Accuracy: 0.8562, Validation Accuracy: 0.7978\n",
      "Epoch [128/500], Training Loss: 0.3656, Validation Loss: 0.4471, Training Accuracy: 0.8475, Validation Accuracy: 0.8090\n",
      "Epoch [129/500], Training Loss: 0.3319, Validation Loss: 0.5367, Training Accuracy: 0.8488, Validation Accuracy: 0.7753\n",
      "Epoch [130/500], Training Loss: 0.3217, Validation Loss: 0.4442, Training Accuracy: 0.8562, Validation Accuracy: 0.7640\n",
      "Epoch [131/500], Training Loss: 0.2871, Validation Loss: 0.5454, Training Accuracy: 0.8488, Validation Accuracy: 0.8090\n",
      "Epoch [132/500], Training Loss: 0.3063, Validation Loss: 0.6402, Training Accuracy: 0.8450, Validation Accuracy: 0.8202\n",
      "Epoch [133/500], Training Loss: 0.4117, Validation Loss: 0.6859, Training Accuracy: 0.8688, Validation Accuracy: 0.8090\n",
      "Epoch [134/500], Training Loss: 0.2991, Validation Loss: 0.4920, Training Accuracy: 0.8475, Validation Accuracy: 0.7753\n",
      "Epoch [135/500], Training Loss: 0.3474, Validation Loss: 0.5316, Training Accuracy: 0.8538, Validation Accuracy: 0.7865\n",
      "Epoch [136/500], Training Loss: 0.3168, Validation Loss: 0.4693, Training Accuracy: 0.8500, Validation Accuracy: 0.8202\n",
      "Epoch [137/500], Training Loss: 0.3182, Validation Loss: 0.4177, Training Accuracy: 0.8538, Validation Accuracy: 0.7978\n",
      "Epoch [138/500], Training Loss: 0.3082, Validation Loss: 0.4768, Training Accuracy: 0.8525, Validation Accuracy: 0.8090\n",
      "Epoch [139/500], Training Loss: 0.3263, Validation Loss: 0.4862, Training Accuracy: 0.8525, Validation Accuracy: 0.7865\n",
      "Epoch [140/500], Training Loss: 0.2913, Validation Loss: 0.4678, Training Accuracy: 0.8675, Validation Accuracy: 0.8202\n",
      "Epoch [141/500], Training Loss: 0.3143, Validation Loss: 0.6021, Training Accuracy: 0.8438, Validation Accuracy: 0.8315\n",
      "Epoch [142/500], Training Loss: 0.4627, Validation Loss: 0.4328, Training Accuracy: 0.8575, Validation Accuracy: 0.8202\n",
      "Epoch [143/500], Training Loss: 0.3182, Validation Loss: 0.6098, Training Accuracy: 0.8612, Validation Accuracy: 0.8090\n",
      "Epoch [144/500], Training Loss: 0.3558, Validation Loss: 0.5335, Training Accuracy: 0.8550, Validation Accuracy: 0.8427\n",
      "Epoch [145/500], Training Loss: 0.3178, Validation Loss: 0.4642, Training Accuracy: 0.8475, Validation Accuracy: 0.8315\n",
      "Epoch [146/500], Training Loss: 0.3118, Validation Loss: 0.5444, Training Accuracy: 0.8500, Validation Accuracy: 0.7753\n",
      "Epoch [147/500], Training Loss: 0.3320, Validation Loss: 0.5301, Training Accuracy: 0.8450, Validation Accuracy: 0.7865\n",
      "Epoch [148/500], Training Loss: 0.3097, Validation Loss: 0.4489, Training Accuracy: 0.8550, Validation Accuracy: 0.8090\n",
      "Epoch [149/500], Training Loss: 0.3765, Validation Loss: 0.5575, Training Accuracy: 0.8500, Validation Accuracy: 0.7303\n",
      "Epoch [150/500], Training Loss: 0.3479, Validation Loss: 0.5251, Training Accuracy: 0.8550, Validation Accuracy: 0.7865\n",
      "Epoch [151/500], Training Loss: 0.2955, Validation Loss: 0.5119, Training Accuracy: 0.8650, Validation Accuracy: 0.7753\n",
      "Epoch [152/500], Training Loss: 0.2816, Validation Loss: 0.5982, Training Accuracy: 0.8662, Validation Accuracy: 0.7640\n",
      "Epoch [153/500], Training Loss: 0.2965, Validation Loss: 0.4443, Training Accuracy: 0.8675, Validation Accuracy: 0.7528\n",
      "Epoch [154/500], Training Loss: 0.3024, Validation Loss: 0.5187, Training Accuracy: 0.8638, Validation Accuracy: 0.7753\n",
      "Epoch [155/500], Training Loss: 0.2951, Validation Loss: 0.4483, Training Accuracy: 0.8675, Validation Accuracy: 0.7753\n",
      "Epoch [156/500], Training Loss: 0.2692, Validation Loss: 0.5248, Training Accuracy: 0.8650, Validation Accuracy: 0.7753\n",
      "Epoch [157/500], Training Loss: 0.2691, Validation Loss: 0.5181, Training Accuracy: 0.8712, Validation Accuracy: 0.7753\n",
      "Epoch [158/500], Training Loss: 0.2751, Validation Loss: 0.6611, Training Accuracy: 0.8625, Validation Accuracy: 0.7753\n",
      "Epoch [159/500], Training Loss: 0.2863, Validation Loss: 0.4960, Training Accuracy: 0.8875, Validation Accuracy: 0.7978\n",
      "Epoch [160/500], Training Loss: 0.3028, Validation Loss: 0.5712, Training Accuracy: 0.8625, Validation Accuracy: 0.7978\n",
      "Epoch [161/500], Training Loss: 0.3266, Validation Loss: 0.4136, Training Accuracy: 0.8575, Validation Accuracy: 0.7978\n",
      "Epoch [162/500], Training Loss: 0.3133, Validation Loss: 0.5703, Training Accuracy: 0.8662, Validation Accuracy: 0.8202\n",
      "Epoch [163/500], Training Loss: 0.2585, Validation Loss: 0.5063, Training Accuracy: 0.8700, Validation Accuracy: 0.7978\n",
      "Epoch [164/500], Training Loss: 0.2653, Validation Loss: 0.5959, Training Accuracy: 0.8788, Validation Accuracy: 0.8090\n",
      "Epoch [165/500], Training Loss: 0.4115, Validation Loss: 0.5160, Training Accuracy: 0.8700, Validation Accuracy: 0.8202\n",
      "Epoch [166/500], Training Loss: 0.2719, Validation Loss: 2.4369, Training Accuracy: 0.8662, Validation Accuracy: 0.8202\n",
      "Epoch [167/500], Training Loss: 0.3146, Validation Loss: 0.6812, Training Accuracy: 0.8662, Validation Accuracy: 0.7865\n",
      "Epoch [168/500], Training Loss: 0.3061, Validation Loss: 0.6011, Training Accuracy: 0.8738, Validation Accuracy: 0.8090\n",
      "Epoch [169/500], Training Loss: 0.2688, Validation Loss: 0.7448, Training Accuracy: 0.8750, Validation Accuracy: 0.8090\n",
      "Epoch [170/500], Training Loss: 0.2856, Validation Loss: 0.4976, Training Accuracy: 0.8788, Validation Accuracy: 0.7865\n",
      "Epoch [171/500], Training Loss: 0.2617, Validation Loss: 0.5858, Training Accuracy: 0.8775, Validation Accuracy: 0.7865\n",
      "Epoch [172/500], Training Loss: 0.2707, Validation Loss: 0.5987, Training Accuracy: 0.8800, Validation Accuracy: 0.8202\n",
      "Epoch [173/500], Training Loss: 0.3103, Validation Loss: 0.4170, Training Accuracy: 0.8788, Validation Accuracy: 0.8090\n",
      "Epoch [174/500], Training Loss: 0.2734, Validation Loss: 0.5324, Training Accuracy: 0.8800, Validation Accuracy: 0.7978\n",
      "Epoch [175/500], Training Loss: 0.3159, Validation Loss: 0.6290, Training Accuracy: 0.8762, Validation Accuracy: 0.8202\n",
      "Epoch [176/500], Training Loss: 0.2529, Validation Loss: 0.5519, Training Accuracy: 0.8850, Validation Accuracy: 0.7978\n",
      "Epoch [177/500], Training Loss: 0.2722, Validation Loss: 0.5246, Training Accuracy: 0.8888, Validation Accuracy: 0.7978\n",
      "Epoch [178/500], Training Loss: 0.2681, Validation Loss: 0.5892, Training Accuracy: 0.8862, Validation Accuracy: 0.8202\n",
      "Epoch [179/500], Training Loss: 0.2728, Validation Loss: 1.5697, Training Accuracy: 0.8725, Validation Accuracy: 0.7753\n",
      "Epoch [180/500], Training Loss: 0.2516, Validation Loss: 1.5288, Training Accuracy: 0.8812, Validation Accuracy: 0.8090\n",
      "Epoch [181/500], Training Loss: 0.2560, Validation Loss: 0.5984, Training Accuracy: 0.8838, Validation Accuracy: 0.8202\n",
      "Epoch [182/500], Training Loss: 0.2705, Validation Loss: 0.4867, Training Accuracy: 0.8675, Validation Accuracy: 0.8090\n",
      "Epoch [183/500], Training Loss: 0.2435, Validation Loss: 0.5116, Training Accuracy: 0.9038, Validation Accuracy: 0.7753\n",
      "Epoch [184/500], Training Loss: 0.3060, Validation Loss: 0.5182, Training Accuracy: 0.8638, Validation Accuracy: 0.7865\n",
      "Epoch [185/500], Training Loss: 0.2775, Validation Loss: 0.3953, Training Accuracy: 0.8750, Validation Accuracy: 0.8202\n",
      "Epoch [186/500], Training Loss: 0.2844, Validation Loss: 0.4654, Training Accuracy: 0.8675, Validation Accuracy: 0.8315\n",
      "Epoch [187/500], Training Loss: 0.2634, Validation Loss: 0.4698, Training Accuracy: 0.8938, Validation Accuracy: 0.7978\n",
      "Epoch [188/500], Training Loss: 0.2521, Validation Loss: 0.5924, Training Accuracy: 0.8875, Validation Accuracy: 0.7865\n",
      "Epoch [189/500], Training Loss: 0.2645, Validation Loss: 0.6656, Training Accuracy: 0.8875, Validation Accuracy: 0.7303\n",
      "Epoch [190/500], Training Loss: 0.3666, Validation Loss: 1.6181, Training Accuracy: 0.8788, Validation Accuracy: 0.7528\n",
      "Epoch [191/500], Training Loss: 0.2699, Validation Loss: 0.6941, Training Accuracy: 0.8725, Validation Accuracy: 0.7528\n",
      "Epoch [192/500], Training Loss: 0.3781, Validation Loss: 0.6666, Training Accuracy: 0.8688, Validation Accuracy: 0.7528\n",
      "Epoch [193/500], Training Loss: 0.2892, Validation Loss: 0.5036, Training Accuracy: 0.8762, Validation Accuracy: 0.7640\n",
      "Epoch [194/500], Training Loss: 0.2815, Validation Loss: 1.5485, Training Accuracy: 0.8750, Validation Accuracy: 0.7753\n",
      "Epoch [195/500], Training Loss: 0.2792, Validation Loss: 0.5656, Training Accuracy: 0.8612, Validation Accuracy: 0.7303\n",
      "Epoch [196/500], Training Loss: 0.2693, Validation Loss: 0.7130, Training Accuracy: 0.8762, Validation Accuracy: 0.7865\n",
      "Epoch [197/500], Training Loss: 0.2152, Validation Loss: 2.4895, Training Accuracy: 0.9000, Validation Accuracy: 0.7753\n",
      "Epoch [198/500], Training Loss: 0.2859, Validation Loss: 0.4860, Training Accuracy: 0.8738, Validation Accuracy: 0.8090\n",
      "Epoch [199/500], Training Loss: 0.3059, Validation Loss: 0.4931, Training Accuracy: 0.8600, Validation Accuracy: 0.8090\n",
      "Epoch [200/500], Training Loss: 0.2499, Validation Loss: 0.5954, Training Accuracy: 0.8812, Validation Accuracy: 0.7978\n",
      "Epoch [201/500], Training Loss: 0.2593, Validation Loss: 0.5586, Training Accuracy: 0.8850, Validation Accuracy: 0.7753\n",
      "Epoch [202/500], Training Loss: 0.2442, Validation Loss: 1.4713, Training Accuracy: 0.8925, Validation Accuracy: 0.7978\n",
      "Epoch [203/500], Training Loss: 0.2472, Validation Loss: 1.4700, Training Accuracy: 0.8950, Validation Accuracy: 0.7640\n",
      "Epoch [204/500], Training Loss: 0.2642, Validation Loss: 0.5336, Training Accuracy: 0.8925, Validation Accuracy: 0.7528\n",
      "Epoch [205/500], Training Loss: 0.2613, Validation Loss: 0.4729, Training Accuracy: 0.8850, Validation Accuracy: 0.7528\n",
      "Epoch [206/500], Training Loss: 0.2363, Validation Loss: 0.5632, Training Accuracy: 0.8838, Validation Accuracy: 0.7865\n",
      "Epoch [207/500], Training Loss: 0.2564, Validation Loss: 0.4156, Training Accuracy: 0.8888, Validation Accuracy: 0.7640\n",
      "Epoch [208/500], Training Loss: 0.2484, Validation Loss: 0.5847, Training Accuracy: 0.8925, Validation Accuracy: 0.7865\n",
      "Epoch [209/500], Training Loss: 0.3127, Validation Loss: 0.4447, Training Accuracy: 0.8662, Validation Accuracy: 0.8427\n",
      "Epoch [210/500], Training Loss: 0.2732, Validation Loss: 0.6081, Training Accuracy: 0.8688, Validation Accuracy: 0.7753\n",
      "Epoch [211/500], Training Loss: 0.2763, Validation Loss: 0.5364, Training Accuracy: 0.8762, Validation Accuracy: 0.7753\n",
      "Epoch [212/500], Training Loss: 0.2643, Validation Loss: 0.4193, Training Accuracy: 0.8838, Validation Accuracy: 0.7753\n",
      "Epoch [213/500], Training Loss: 0.2261, Validation Loss: 0.5281, Training Accuracy: 0.8775, Validation Accuracy: 0.8315\n",
      "Epoch [214/500], Training Loss: 0.2752, Validation Loss: 0.4890, Training Accuracy: 0.8838, Validation Accuracy: 0.7865\n",
      "Epoch [215/500], Training Loss: 0.2680, Validation Loss: 1.5036, Training Accuracy: 0.8812, Validation Accuracy: 0.8202\n",
      "Epoch [216/500], Training Loss: 0.3968, Validation Loss: 1.4004, Training Accuracy: 0.8600, Validation Accuracy: 0.8427\n",
      "Epoch [217/500], Training Loss: 0.2662, Validation Loss: 0.5159, Training Accuracy: 0.8638, Validation Accuracy: 0.8539\n",
      "Epoch [218/500], Training Loss: 0.2645, Validation Loss: 0.4947, Training Accuracy: 0.8888, Validation Accuracy: 0.8427\n",
      "Epoch [219/500], Training Loss: 0.2435, Validation Loss: 0.4425, Training Accuracy: 0.8800, Validation Accuracy: 0.7978\n",
      "Epoch [220/500], Training Loss: 0.2203, Validation Loss: 0.4953, Training Accuracy: 0.9100, Validation Accuracy: 0.7978\n",
      "Epoch [221/500], Training Loss: 0.2518, Validation Loss: 0.4725, Training Accuracy: 0.8925, Validation Accuracy: 0.7978\n",
      "Epoch [222/500], Training Loss: 0.2653, Validation Loss: 0.5613, Training Accuracy: 0.8838, Validation Accuracy: 0.8090\n",
      "Epoch [223/500], Training Loss: 0.1966, Validation Loss: 1.5810, Training Accuracy: 0.9075, Validation Accuracy: 0.8090\n",
      "Epoch [224/500], Training Loss: 0.2442, Validation Loss: 1.4996, Training Accuracy: 0.8850, Validation Accuracy: 0.7978\n",
      "Epoch [225/500], Training Loss: 0.2407, Validation Loss: 1.4774, Training Accuracy: 0.8812, Validation Accuracy: 0.7865\n",
      "Epoch [226/500], Training Loss: 0.2780, Validation Loss: 1.5053, Training Accuracy: 0.8450, Validation Accuracy: 0.7753\n",
      "Epoch [227/500], Training Loss: 0.3237, Validation Loss: 1.4834, Training Accuracy: 0.8625, Validation Accuracy: 0.7978\n",
      "Epoch [228/500], Training Loss: 0.3006, Validation Loss: 0.5515, Training Accuracy: 0.8725, Validation Accuracy: 0.7528\n",
      "Epoch [229/500], Training Loss: 0.2497, Validation Loss: 0.5379, Training Accuracy: 0.8850, Validation Accuracy: 0.7416\n",
      "Epoch [230/500], Training Loss: 0.4271, Validation Loss: 0.7042, Training Accuracy: 0.8638, Validation Accuracy: 0.7303\n",
      "Epoch [231/500], Training Loss: 0.2929, Validation Loss: 0.4495, Training Accuracy: 0.8688, Validation Accuracy: 0.7865\n",
      "Epoch [232/500], Training Loss: 0.2818, Validation Loss: 0.6684, Training Accuracy: 0.8850, Validation Accuracy: 0.7978\n",
      "Epoch [233/500], Training Loss: 0.2272, Validation Loss: 1.6297, Training Accuracy: 0.8925, Validation Accuracy: 0.7640\n",
      "Epoch [234/500], Training Loss: 0.2468, Validation Loss: 0.5918, Training Accuracy: 0.8962, Validation Accuracy: 0.7753\n",
      "Epoch [235/500], Training Loss: 0.2961, Validation Loss: 1.4942, Training Accuracy: 0.8912, Validation Accuracy: 0.7865\n",
      "Epoch [236/500], Training Loss: 0.2601, Validation Loss: 0.5994, Training Accuracy: 0.8900, Validation Accuracy: 0.8090\n",
      "Epoch [237/500], Training Loss: 0.2364, Validation Loss: 1.4503, Training Accuracy: 0.8962, Validation Accuracy: 0.8090\n",
      "Epoch [238/500], Training Loss: 0.2929, Validation Loss: 0.5528, Training Accuracy: 0.8788, Validation Accuracy: 0.7753\n",
      "Epoch [239/500], Training Loss: 0.2719, Validation Loss: 1.5484, Training Accuracy: 0.8788, Validation Accuracy: 0.7978\n",
      "Epoch [240/500], Training Loss: 0.2610, Validation Loss: 0.5801, Training Accuracy: 0.8762, Validation Accuracy: 0.7753\n",
      "Epoch [241/500], Training Loss: 0.2420, Validation Loss: 1.5716, Training Accuracy: 0.8962, Validation Accuracy: 0.7865\n",
      "Epoch [242/500], Training Loss: 0.2469, Validation Loss: 1.5493, Training Accuracy: 0.8975, Validation Accuracy: 0.7753\n",
      "Epoch [243/500], Training Loss: 0.3984, Validation Loss: 0.5321, Training Accuracy: 0.8725, Validation Accuracy: 0.8090\n",
      "Epoch [244/500], Training Loss: 0.2184, Validation Loss: 1.5946, Training Accuracy: 0.9000, Validation Accuracy: 0.8202\n",
      "Epoch [245/500], Training Loss: 0.3548, Validation Loss: 0.4913, Training Accuracy: 0.8962, Validation Accuracy: 0.7978\n",
      "Epoch [246/500], Training Loss: 0.2458, Validation Loss: 1.5352, Training Accuracy: 0.9000, Validation Accuracy: 0.8427\n",
      "Epoch [247/500], Training Loss: 0.2858, Validation Loss: 0.5344, Training Accuracy: 0.8725, Validation Accuracy: 0.7865\n",
      "Epoch [248/500], Training Loss: 0.2470, Validation Loss: 0.6589, Training Accuracy: 0.8938, Validation Accuracy: 0.7978\n",
      "Epoch [249/500], Training Loss: 0.2625, Validation Loss: 0.4939, Training Accuracy: 0.8762, Validation Accuracy: 0.8202\n",
      "Epoch [250/500], Training Loss: 0.2428, Validation Loss: 1.5921, Training Accuracy: 0.8775, Validation Accuracy: 0.8202\n",
      "Epoch [251/500], Training Loss: 0.2687, Validation Loss: 0.4868, Training Accuracy: 0.8850, Validation Accuracy: 0.7978\n",
      "Epoch [252/500], Training Loss: 0.2061, Validation Loss: 1.6452, Training Accuracy: 0.8925, Validation Accuracy: 0.7865\n",
      "Epoch [253/500], Training Loss: 0.2179, Validation Loss: 1.7060, Training Accuracy: 0.9062, Validation Accuracy: 0.7978\n",
      "Epoch [254/500], Training Loss: 0.2503, Validation Loss: 0.7378, Training Accuracy: 0.8925, Validation Accuracy: 0.7753\n",
      "Epoch [255/500], Training Loss: 0.2443, Validation Loss: 2.5225, Training Accuracy: 0.8875, Validation Accuracy: 0.8090\n",
      "Epoch [256/500], Training Loss: 0.3483, Validation Loss: 1.5702, Training Accuracy: 0.8838, Validation Accuracy: 0.7640\n",
      "Epoch [257/500], Training Loss: 0.2458, Validation Loss: 0.6951, Training Accuracy: 0.8962, Validation Accuracy: 0.7865\n",
      "Epoch [258/500], Training Loss: 0.3515, Validation Loss: 0.5783, Training Accuracy: 0.8950, Validation Accuracy: 0.7865\n",
      "Epoch [259/500], Training Loss: 0.2219, Validation Loss: 1.4918, Training Accuracy: 0.9000, Validation Accuracy: 0.7978\n",
      "Epoch [260/500], Training Loss: 0.2446, Validation Loss: 0.5294, Training Accuracy: 0.8912, Validation Accuracy: 0.8090\n",
      "Epoch [261/500], Training Loss: 0.2957, Validation Loss: 1.5513, Training Accuracy: 0.8825, Validation Accuracy: 0.7865\n",
      "Epoch [262/500], Training Loss: 0.2486, Validation Loss: 0.5327, Training Accuracy: 0.8838, Validation Accuracy: 0.7865\n",
      "Epoch [263/500], Training Loss: 0.2301, Validation Loss: 0.5997, Training Accuracy: 0.8962, Validation Accuracy: 0.7753\n",
      "Epoch [264/500], Training Loss: 0.3851, Validation Loss: 0.5357, Training Accuracy: 0.8925, Validation Accuracy: 0.7416\n",
      "Epoch [265/500], Training Loss: 0.2458, Validation Loss: 0.5334, Training Accuracy: 0.8962, Validation Accuracy: 0.7753\n",
      "Epoch [266/500], Training Loss: 0.2465, Validation Loss: 0.6537, Training Accuracy: 0.8988, Validation Accuracy: 0.7753\n",
      "Epoch [267/500], Training Loss: 0.2300, Validation Loss: 0.6317, Training Accuracy: 0.9025, Validation Accuracy: 0.7753\n",
      "Epoch [268/500], Training Loss: 0.2744, Validation Loss: 0.4324, Training Accuracy: 0.8738, Validation Accuracy: 0.7978\n",
      "Epoch [269/500], Training Loss: 0.2341, Validation Loss: 0.6797, Training Accuracy: 0.9000, Validation Accuracy: 0.7753\n",
      "Epoch [270/500], Training Loss: 0.2522, Validation Loss: 0.7595, Training Accuracy: 0.8825, Validation Accuracy: 0.7640\n",
      "Epoch [271/500], Training Loss: 0.2152, Validation Loss: 2.6003, Training Accuracy: 0.8912, Validation Accuracy: 0.7416\n",
      "Epoch [272/500], Training Loss: 0.6522, Validation Loss: 0.6357, Training Accuracy: 0.8738, Validation Accuracy: 0.7303\n",
      "Epoch [273/500], Training Loss: 0.2524, Validation Loss: 0.7028, Training Accuracy: 0.8825, Validation Accuracy: 0.7640\n",
      "Epoch [274/500], Training Loss: 0.3220, Validation Loss: 0.6483, Training Accuracy: 0.8838, Validation Accuracy: 0.7640\n",
      "Epoch [275/500], Training Loss: 0.2238, Validation Loss: 0.5695, Training Accuracy: 0.9062, Validation Accuracy: 0.8090\n",
      "Epoch [276/500], Training Loss: 0.2745, Validation Loss: 0.6520, Training Accuracy: 0.8962, Validation Accuracy: 0.7865\n",
      "Epoch [277/500], Training Loss: 0.2637, Validation Loss: 0.4909, Training Accuracy: 0.8800, Validation Accuracy: 0.8427\n",
      "Epoch [278/500], Training Loss: 0.2369, Validation Loss: 1.4858, Training Accuracy: 0.8888, Validation Accuracy: 0.8202\n",
      "Epoch [279/500], Training Loss: 0.3567, Validation Loss: 0.6285, Training Accuracy: 0.9025, Validation Accuracy: 0.7865\n",
      "Epoch [280/500], Training Loss: 0.2898, Validation Loss: 2.5003, Training Accuracy: 0.8700, Validation Accuracy: 0.7753\n",
      "Epoch [281/500], Training Loss: 0.2427, Validation Loss: 1.4782, Training Accuracy: 0.9000, Validation Accuracy: 0.7865\n",
      "Epoch [282/500], Training Loss: 0.3978, Validation Loss: 1.4823, Training Accuracy: 0.8838, Validation Accuracy: 0.8090\n",
      "Epoch [283/500], Training Loss: 0.3401, Validation Loss: 1.5079, Training Accuracy: 0.8962, Validation Accuracy: 0.7528\n",
      "Epoch [284/500], Training Loss: 0.3726, Validation Loss: 1.4505, Training Accuracy: 0.8900, Validation Accuracy: 0.7640\n",
      "Epoch [285/500], Training Loss: 0.2808, Validation Loss: 1.5049, Training Accuracy: 0.8675, Validation Accuracy: 0.7303\n",
      "Epoch [286/500], Training Loss: 0.2440, Validation Loss: 2.5236, Training Accuracy: 0.8850, Validation Accuracy: 0.7640\n",
      "Epoch [287/500], Training Loss: 0.2608, Validation Loss: 1.5282, Training Accuracy: 0.9038, Validation Accuracy: 0.7640\n",
      "Epoch [288/500], Training Loss: 0.2657, Validation Loss: 1.4935, Training Accuracy: 0.8762, Validation Accuracy: 0.7753\n",
      "Epoch [289/500], Training Loss: 0.2367, Validation Loss: 1.5177, Training Accuracy: 0.9000, Validation Accuracy: 0.7753\n",
      "Epoch [290/500], Training Loss: 0.2205, Validation Loss: 1.5688, Training Accuracy: 0.9025, Validation Accuracy: 0.7753\n",
      "Epoch [291/500], Training Loss: 0.2302, Validation Loss: 1.5316, Training Accuracy: 0.8962, Validation Accuracy: 0.7640\n",
      "Epoch [292/500], Training Loss: 0.2471, Validation Loss: 1.5492, Training Accuracy: 0.8788, Validation Accuracy: 0.7640\n",
      "Epoch [293/500], Training Loss: 0.2275, Validation Loss: 0.5948, Training Accuracy: 0.8975, Validation Accuracy: 0.7753\n",
      "Epoch [294/500], Training Loss: 0.2230, Validation Loss: 0.6356, Training Accuracy: 0.9000, Validation Accuracy: 0.7640\n",
      "Epoch [295/500], Training Loss: 0.2399, Validation Loss: 1.5436, Training Accuracy: 0.8862, Validation Accuracy: 0.7865\n",
      "Epoch [296/500], Training Loss: 0.2165, Validation Loss: 1.5068, Training Accuracy: 0.8988, Validation Accuracy: 0.7416\n",
      "Epoch [297/500], Training Loss: 0.3506, Validation Loss: 0.5446, Training Accuracy: 0.8962, Validation Accuracy: 0.7640\n",
      "Epoch [298/500], Training Loss: 0.3829, Validation Loss: 1.5994, Training Accuracy: 0.9000, Validation Accuracy: 0.7865\n",
      "Epoch [299/500], Training Loss: 0.2095, Validation Loss: 2.5760, Training Accuracy: 0.9050, Validation Accuracy: 0.7978\n",
      "Epoch [300/500], Training Loss: 0.2416, Validation Loss: 2.4429, Training Accuracy: 0.8988, Validation Accuracy: 0.8090\n",
      "Epoch [301/500], Training Loss: 0.2454, Validation Loss: 1.5925, Training Accuracy: 0.8862, Validation Accuracy: 0.8090\n",
      "Epoch [302/500], Training Loss: 0.2378, Validation Loss: 1.6436, Training Accuracy: 0.8762, Validation Accuracy: 0.8202\n",
      "Epoch [303/500], Training Loss: 0.3550, Validation Loss: 1.6060, Training Accuracy: 0.8988, Validation Accuracy: 0.7753\n",
      "Epoch [304/500], Training Loss: 0.2227, Validation Loss: 1.5724, Training Accuracy: 0.8925, Validation Accuracy: 0.8090\n",
      "Epoch [305/500], Training Loss: 0.2206, Validation Loss: 1.4591, Training Accuracy: 0.8875, Validation Accuracy: 0.8090\n",
      "Epoch [306/500], Training Loss: 0.2211, Validation Loss: 1.4096, Training Accuracy: 0.9038, Validation Accuracy: 0.8090\n",
      "Epoch [307/500], Training Loss: 0.2090, Validation Loss: 2.4071, Training Accuracy: 0.9012, Validation Accuracy: 0.8202\n",
      "Epoch [308/500], Training Loss: 0.2741, Validation Loss: 2.4550, Training Accuracy: 0.9038, Validation Accuracy: 0.8427\n",
      "Epoch [309/500], Training Loss: 0.2351, Validation Loss: 1.4576, Training Accuracy: 0.8962, Validation Accuracy: 0.8090\n",
      "Epoch [310/500], Training Loss: 0.2455, Validation Loss: 1.5862, Training Accuracy: 0.8962, Validation Accuracy: 0.7865\n",
      "Epoch [311/500], Training Loss: 0.2596, Validation Loss: 1.4485, Training Accuracy: 0.8912, Validation Accuracy: 0.8090\n",
      "Epoch [312/500], Training Loss: 0.2709, Validation Loss: 1.5502, Training Accuracy: 0.9012, Validation Accuracy: 0.8090\n",
      "Epoch [313/500], Training Loss: 0.3368, Validation Loss: 1.6512, Training Accuracy: 0.9038, Validation Accuracy: 0.7865\n",
      "Epoch [314/500], Training Loss: 0.2496, Validation Loss: 0.4556, Training Accuracy: 0.9012, Validation Accuracy: 0.7753\n",
      "Epoch [315/500], Training Loss: 0.2648, Validation Loss: 0.5031, Training Accuracy: 0.8850, Validation Accuracy: 0.7865\n",
      "Epoch [316/500], Training Loss: 0.2182, Validation Loss: 0.6109, Training Accuracy: 0.9062, Validation Accuracy: 0.7865\n",
      "Epoch [317/500], Training Loss: 0.3355, Validation Loss: 1.5653, Training Accuracy: 0.9075, Validation Accuracy: 0.8090\n",
      "Epoch [318/500], Training Loss: 0.2043, Validation Loss: 0.5878, Training Accuracy: 0.9175, Validation Accuracy: 0.7865\n",
      "Epoch [319/500], Training Loss: 0.3388, Validation Loss: 0.5516, Training Accuracy: 0.9062, Validation Accuracy: 0.7978\n",
      "Epoch [320/500], Training Loss: 0.4333, Validation Loss: 0.5967, Training Accuracy: 0.8775, Validation Accuracy: 0.7978\n",
      "Epoch [321/500], Training Loss: 0.2325, Validation Loss: 0.6838, Training Accuracy: 0.8925, Validation Accuracy: 0.7753\n",
      "Epoch [322/500], Training Loss: 0.2539, Validation Loss: 0.5917, Training Accuracy: 0.8975, Validation Accuracy: 0.8090\n",
      "Epoch [323/500], Training Loss: 0.2773, Validation Loss: 0.4227, Training Accuracy: 0.8938, Validation Accuracy: 0.7978\n",
      "Epoch [324/500], Training Loss: 0.2285, Validation Loss: 0.6043, Training Accuracy: 0.8875, Validation Accuracy: 0.7978\n",
      "Epoch [325/500], Training Loss: 0.3622, Validation Loss: 0.5293, Training Accuracy: 0.9062, Validation Accuracy: 0.7865\n",
      "Epoch [326/500], Training Loss: 0.2359, Validation Loss: 1.5184, Training Accuracy: 0.9000, Validation Accuracy: 0.7978\n",
      "Epoch [327/500], Training Loss: 0.2186, Validation Loss: 1.4781, Training Accuracy: 0.9075, Validation Accuracy: 0.8090\n",
      "Epoch [328/500], Training Loss: 0.4918, Validation Loss: 2.4654, Training Accuracy: 0.8788, Validation Accuracy: 0.7640\n",
      "Epoch [329/500], Training Loss: 0.2432, Validation Loss: 1.5374, Training Accuracy: 0.9062, Validation Accuracy: 0.7753\n",
      "Epoch [330/500], Training Loss: 0.2999, Validation Loss: 1.5562, Training Accuracy: 0.8700, Validation Accuracy: 0.7640\n",
      "Epoch [331/500], Training Loss: 0.2318, Validation Loss: 1.5372, Training Accuracy: 0.8825, Validation Accuracy: 0.7978\n",
      "Epoch [332/500], Training Loss: 0.2451, Validation Loss: 0.5623, Training Accuracy: 0.8938, Validation Accuracy: 0.8427\n",
      "Epoch [333/500], Training Loss: 0.2163, Validation Loss: 1.5729, Training Accuracy: 0.8988, Validation Accuracy: 0.8090\n",
      "Epoch [334/500], Training Loss: 0.2068, Validation Loss: 2.4586, Training Accuracy: 0.9025, Validation Accuracy: 0.7978\n",
      "Epoch [335/500], Training Loss: 0.3386, Validation Loss: 0.5554, Training Accuracy: 0.9038, Validation Accuracy: 0.7978\n",
      "Epoch [336/500], Training Loss: 0.1792, Validation Loss: 2.4350, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [337/500], Training Loss: 0.1766, Validation Loss: 2.4678, Training Accuracy: 0.9187, Validation Accuracy: 0.7753\n",
      "Epoch [338/500], Training Loss: 0.3319, Validation Loss: 1.4520, Training Accuracy: 0.9062, Validation Accuracy: 0.7753\n",
      "Epoch [339/500], Training Loss: 0.5959, Validation Loss: 1.6096, Training Accuracy: 0.8988, Validation Accuracy: 0.7416\n",
      "Epoch [340/500], Training Loss: 0.2540, Validation Loss: 2.5542, Training Accuracy: 0.9087, Validation Accuracy: 0.7303\n",
      "Epoch [341/500], Training Loss: 0.3670, Validation Loss: 2.5615, Training Accuracy: 0.8975, Validation Accuracy: 0.7528\n",
      "Epoch [342/500], Training Loss: 0.2239, Validation Loss: 2.5297, Training Accuracy: 0.8988, Validation Accuracy: 0.7528\n",
      "Epoch [343/500], Training Loss: 0.4843, Validation Loss: 2.5302, Training Accuracy: 0.8938, Validation Accuracy: 0.7640\n",
      "Epoch [344/500], Training Loss: 0.1788, Validation Loss: 2.4757, Training Accuracy: 0.9062, Validation Accuracy: 0.7416\n",
      "Epoch [345/500], Training Loss: 0.2093, Validation Loss: 2.4869, Training Accuracy: 0.9025, Validation Accuracy: 0.7191\n",
      "Epoch [346/500], Training Loss: 0.2357, Validation Loss: 0.6719, Training Accuracy: 0.9025, Validation Accuracy: 0.7303\n",
      "Epoch [347/500], Training Loss: 0.2800, Validation Loss: 0.6449, Training Accuracy: 0.8925, Validation Accuracy: 0.7753\n",
      "Epoch [348/500], Training Loss: 0.3851, Validation Loss: 0.6323, Training Accuracy: 0.8825, Validation Accuracy: 0.7753\n",
      "Epoch [349/500], Training Loss: 0.2149, Validation Loss: 2.5468, Training Accuracy: 0.8975, Validation Accuracy: 0.7640\n",
      "Epoch [350/500], Training Loss: 0.1953, Validation Loss: 2.6072, Training Accuracy: 0.9038, Validation Accuracy: 0.7753\n",
      "Epoch [351/500], Training Loss: 0.2262, Validation Loss: 2.5332, Training Accuracy: 0.9025, Validation Accuracy: 0.7528\n",
      "Epoch [352/500], Training Loss: 0.3577, Validation Loss: 1.6307, Training Accuracy: 0.8950, Validation Accuracy: 0.7753\n",
      "Epoch [353/500], Training Loss: 0.3671, Validation Loss: 0.6967, Training Accuracy: 0.8838, Validation Accuracy: 0.7865\n",
      "Epoch [354/500], Training Loss: 0.3690, Validation Loss: 0.6955, Training Accuracy: 0.8888, Validation Accuracy: 0.7416\n",
      "Epoch [355/500], Training Loss: 0.3526, Validation Loss: 0.7005, Training Accuracy: 0.9000, Validation Accuracy: 0.7528\n",
      "Epoch [356/500], Training Loss: 0.3684, Validation Loss: 0.6456, Training Accuracy: 0.9125, Validation Accuracy: 0.7753\n",
      "Epoch [357/500], Training Loss: 0.2799, Validation Loss: 0.7004, Training Accuracy: 0.8988, Validation Accuracy: 0.7640\n",
      "Epoch [358/500], Training Loss: 0.2382, Validation Loss: 2.4962, Training Accuracy: 0.8875, Validation Accuracy: 0.7753\n",
      "Epoch [359/500], Training Loss: 0.2187, Validation Loss: 0.7452, Training Accuracy: 0.9012, Validation Accuracy: 0.7753\n",
      "Epoch [360/500], Training Loss: 0.2882, Validation Loss: 0.6006, Training Accuracy: 0.8850, Validation Accuracy: 0.7978\n",
      "Epoch [361/500], Training Loss: 0.2577, Validation Loss: 0.5709, Training Accuracy: 0.8788, Validation Accuracy: 0.7640\n",
      "Epoch [362/500], Training Loss: 0.2544, Validation Loss: 0.6258, Training Accuracy: 0.8988, Validation Accuracy: 0.7865\n",
      "Epoch [363/500], Training Loss: 0.2103, Validation Loss: 1.6584, Training Accuracy: 0.9062, Validation Accuracy: 0.7865\n",
      "Epoch [364/500], Training Loss: 0.2213, Validation Loss: 1.5947, Training Accuracy: 0.9025, Validation Accuracy: 0.7528\n",
      "Epoch [365/500], Training Loss: 0.2235, Validation Loss: 1.5904, Training Accuracy: 0.9012, Validation Accuracy: 0.7753\n",
      "Epoch [366/500], Training Loss: 0.3075, Validation Loss: 3.5655, Training Accuracy: 0.9087, Validation Accuracy: 0.7753\n",
      "Epoch [367/500], Training Loss: 0.1948, Validation Loss: 1.6582, Training Accuracy: 0.9113, Validation Accuracy: 0.7753\n",
      "Epoch [368/500], Training Loss: 0.2098, Validation Loss: 2.6066, Training Accuracy: 0.9025, Validation Accuracy: 0.8202\n",
      "Epoch [369/500], Training Loss: 0.1878, Validation Loss: 2.5683, Training Accuracy: 0.9137, Validation Accuracy: 0.7978\n",
      "Epoch [370/500], Training Loss: 0.1729, Validation Loss: 1.6617, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [371/500], Training Loss: 0.2221, Validation Loss: 2.5470, Training Accuracy: 0.9100, Validation Accuracy: 0.8090\n",
      "Epoch [372/500], Training Loss: 0.1827, Validation Loss: 2.5462, Training Accuracy: 0.9113, Validation Accuracy: 0.7978\n",
      "Epoch [373/500], Training Loss: 0.2150, Validation Loss: 2.5551, Training Accuracy: 0.9175, Validation Accuracy: 0.7978\n",
      "Epoch [374/500], Training Loss: 0.2893, Validation Loss: 3.6091, Training Accuracy: 0.8938, Validation Accuracy: 0.7865\n",
      "Epoch [375/500], Training Loss: 0.2275, Validation Loss: 2.5031, Training Accuracy: 0.9062, Validation Accuracy: 0.7753\n",
      "Epoch [376/500], Training Loss: 0.3727, Validation Loss: 2.4678, Training Accuracy: 0.9025, Validation Accuracy: 0.7978\n",
      "Epoch [377/500], Training Loss: 0.2076, Validation Loss: 2.4381, Training Accuracy: 0.9062, Validation Accuracy: 0.7978\n",
      "Epoch [378/500], Training Loss: 0.2661, Validation Loss: 2.4693, Training Accuracy: 0.8900, Validation Accuracy: 0.7865\n",
      "Epoch [379/500], Training Loss: 0.2475, Validation Loss: 2.4745, Training Accuracy: 0.8900, Validation Accuracy: 0.7865\n",
      "Epoch [380/500], Training Loss: 0.3463, Validation Loss: 2.4929, Training Accuracy: 0.9075, Validation Accuracy: 0.7978\n",
      "Epoch [381/500], Training Loss: 0.2806, Validation Loss: 2.4314, Training Accuracy: 0.8850, Validation Accuracy: 0.7753\n",
      "Epoch [382/500], Training Loss: 0.2659, Validation Loss: 1.5619, Training Accuracy: 0.8988, Validation Accuracy: 0.7640\n",
      "Epoch [383/500], Training Loss: 0.2520, Validation Loss: 0.6648, Training Accuracy: 0.8900, Validation Accuracy: 0.8090\n",
      "Epoch [384/500], Training Loss: 0.2494, Validation Loss: 2.4840, Training Accuracy: 0.8875, Validation Accuracy: 0.8090\n",
      "Epoch [385/500], Training Loss: 0.3829, Validation Loss: 2.5368, Training Accuracy: 0.8838, Validation Accuracy: 0.7978\n",
      "Epoch [386/500], Training Loss: 0.3018, Validation Loss: 0.6472, Training Accuracy: 0.9012, Validation Accuracy: 0.7640\n",
      "Epoch [387/500], Training Loss: 0.2374, Validation Loss: 2.5453, Training Accuracy: 0.9137, Validation Accuracy: 0.7865\n",
      "Epoch [388/500], Training Loss: 0.2365, Validation Loss: 1.5497, Training Accuracy: 0.8938, Validation Accuracy: 0.7528\n",
      "Epoch [389/500], Training Loss: 0.2787, Validation Loss: 0.5584, Training Accuracy: 0.9050, Validation Accuracy: 0.7865\n",
      "Epoch [390/500], Training Loss: 0.7729, Validation Loss: 0.5192, Training Accuracy: 0.8862, Validation Accuracy: 0.7978\n",
      "Epoch [391/500], Training Loss: 0.2965, Validation Loss: 1.5177, Training Accuracy: 0.8788, Validation Accuracy: 0.8539\n",
      "Epoch [392/500], Training Loss: 0.2401, Validation Loss: 1.4997, Training Accuracy: 0.8712, Validation Accuracy: 0.7865\n",
      "Epoch [393/500], Training Loss: 0.3388, Validation Loss: 1.5242, Training Accuracy: 0.8962, Validation Accuracy: 0.7416\n",
      "Epoch [394/500], Training Loss: 0.5059, Validation Loss: 1.5164, Training Accuracy: 0.8750, Validation Accuracy: 0.7753\n",
      "Epoch [395/500], Training Loss: 0.5264, Validation Loss: 1.4878, Training Accuracy: 0.8662, Validation Accuracy: 0.7978\n",
      "Epoch [396/500], Training Loss: 0.2756, Validation Loss: 1.4812, Training Accuracy: 0.8862, Validation Accuracy: 0.7978\n",
      "Epoch [397/500], Training Loss: 0.3599, Validation Loss: 1.4846, Training Accuracy: 0.9025, Validation Accuracy: 0.7753\n",
      "Epoch [398/500], Training Loss: 0.2258, Validation Loss: 1.5062, Training Accuracy: 0.8975, Validation Accuracy: 0.7528\n",
      "Epoch [399/500], Training Loss: 0.3652, Validation Loss: 1.4737, Training Accuracy: 0.8850, Validation Accuracy: 0.7865\n",
      "Epoch [400/500], Training Loss: 0.4205, Validation Loss: 2.3980, Training Accuracy: 0.8638, Validation Accuracy: 0.7753\n",
      "Epoch [401/500], Training Loss: 0.3351, Validation Loss: 2.3677, Training Accuracy: 0.9062, Validation Accuracy: 0.7978\n",
      "Epoch [402/500], Training Loss: 0.3329, Validation Loss: 2.3854, Training Accuracy: 0.9012, Validation Accuracy: 0.7753\n",
      "Epoch [403/500], Training Loss: 0.3235, Validation Loss: 2.3788, Training Accuracy: 0.9087, Validation Accuracy: 0.7753\n",
      "Epoch [404/500], Training Loss: 0.3605, Validation Loss: 0.5938, Training Accuracy: 0.8912, Validation Accuracy: 0.7528\n",
      "Epoch [405/500], Training Loss: 0.3844, Validation Loss: 2.4173, Training Accuracy: 0.8725, Validation Accuracy: 0.7416\n",
      "Epoch [406/500], Training Loss: 0.2545, Validation Loss: 0.5608, Training Accuracy: 0.8850, Validation Accuracy: 0.7528\n",
      "Epoch [407/500], Training Loss: 0.2260, Validation Loss: 0.7582, Training Accuracy: 0.8988, Validation Accuracy: 0.7753\n",
      "Epoch [408/500], Training Loss: 0.2424, Validation Loss: 0.6621, Training Accuracy: 0.8800, Validation Accuracy: 0.7753\n",
      "Epoch [409/500], Training Loss: 0.2185, Validation Loss: 1.5866, Training Accuracy: 0.8800, Validation Accuracy: 0.7416\n",
      "Epoch [410/500], Training Loss: 0.2135, Validation Loss: 1.6050, Training Accuracy: 0.8850, Validation Accuracy: 0.7303\n",
      "Epoch [411/500], Training Loss: 0.2081, Validation Loss: 1.5239, Training Accuracy: 0.8988, Validation Accuracy: 0.7416\n",
      "Epoch [412/500], Training Loss: 0.2276, Validation Loss: 1.5155, Training Accuracy: 0.8925, Validation Accuracy: 0.8090\n",
      "Epoch [413/500], Training Loss: 0.3567, Validation Loss: 1.5020, Training Accuracy: 0.9062, Validation Accuracy: 0.8202\n",
      "Epoch [414/500], Training Loss: 0.2223, Validation Loss: 0.4674, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [415/500], Training Loss: 0.1787, Validation Loss: 1.6024, Training Accuracy: 0.9213, Validation Accuracy: 0.7865\n",
      "Epoch [416/500], Training Loss: 0.2051, Validation Loss: 2.4711, Training Accuracy: 0.9150, Validation Accuracy: 0.7978\n",
      "Epoch [417/500], Training Loss: 0.1783, Validation Loss: 2.4827, Training Accuracy: 0.9137, Validation Accuracy: 0.7978\n",
      "Epoch [418/500], Training Loss: 0.2061, Validation Loss: 2.4733, Training Accuracy: 0.8975, Validation Accuracy: 0.7865\n",
      "Epoch [419/500], Training Loss: 0.2033, Validation Loss: 1.5577, Training Accuracy: 0.9113, Validation Accuracy: 0.7978\n",
      "Epoch [420/500], Training Loss: 0.2149, Validation Loss: 1.5557, Training Accuracy: 0.9062, Validation Accuracy: 0.7978\n",
      "Epoch [421/500], Training Loss: 0.1779, Validation Loss: 2.5157, Training Accuracy: 0.9225, Validation Accuracy: 0.7640\n",
      "Epoch [422/500], Training Loss: 0.3495, Validation Loss: 2.5525, Training Accuracy: 0.9163, Validation Accuracy: 0.7865\n",
      "Epoch [423/500], Training Loss: 0.2106, Validation Loss: 1.4491, Training Accuracy: 0.8950, Validation Accuracy: 0.7865\n",
      "Epoch [424/500], Training Loss: 0.1795, Validation Loss: 2.4608, Training Accuracy: 0.9313, Validation Accuracy: 0.7640\n",
      "Epoch [425/500], Training Loss: 0.1895, Validation Loss: 2.4563, Training Accuracy: 0.9087, Validation Accuracy: 0.7640\n",
      "Epoch [426/500], Training Loss: 0.1778, Validation Loss: 1.5582, Training Accuracy: 0.9163, Validation Accuracy: 0.7865\n",
      "Epoch [427/500], Training Loss: 0.2033, Validation Loss: 2.5130, Training Accuracy: 0.9075, Validation Accuracy: 0.7753\n",
      "Epoch [428/500], Training Loss: 0.2271, Validation Loss: 0.5333, Training Accuracy: 0.9100, Validation Accuracy: 0.7865\n",
      "Epoch [429/500], Training Loss: 0.2094, Validation Loss: 2.4305, Training Accuracy: 0.8975, Validation Accuracy: 0.8090\n",
      "Epoch [430/500], Training Loss: 0.1988, Validation Loss: 0.5973, Training Accuracy: 0.9150, Validation Accuracy: 0.8202\n",
      "Epoch [431/500], Training Loss: 0.1861, Validation Loss: 2.5245, Training Accuracy: 0.9175, Validation Accuracy: 0.7865\n",
      "Epoch [432/500], Training Loss: 0.2027, Validation Loss: 2.5477, Training Accuracy: 0.9025, Validation Accuracy: 0.7753\n",
      "Epoch [433/500], Training Loss: 0.3398, Validation Loss: 2.4078, Training Accuracy: 0.9237, Validation Accuracy: 0.7865\n",
      "Epoch [434/500], Training Loss: 0.1701, Validation Loss: 1.4664, Training Accuracy: 0.9275, Validation Accuracy: 0.7865\n",
      "Epoch [435/500], Training Loss: 0.1930, Validation Loss: 2.3854, Training Accuracy: 0.9137, Validation Accuracy: 0.7865\n",
      "Epoch [436/500], Training Loss: 0.2084, Validation Loss: 2.3844, Training Accuracy: 0.9200, Validation Accuracy: 0.7640\n",
      "Epoch [437/500], Training Loss: 0.3014, Validation Loss: 0.6192, Training Accuracy: 0.9300, Validation Accuracy: 0.7640\n",
      "Epoch [438/500], Training Loss: 0.1881, Validation Loss: 2.3785, Training Accuracy: 0.9163, Validation Accuracy: 0.8090\n",
      "Epoch [439/500], Training Loss: 0.1705, Validation Loss: 2.4321, Training Accuracy: 0.9225, Validation Accuracy: 0.8202\n",
      "Epoch [440/500], Training Loss: 0.1770, Validation Loss: 2.3961, Training Accuracy: 0.9263, Validation Accuracy: 0.8202\n",
      "Epoch [441/500], Training Loss: 0.1579, Validation Loss: 1.5215, Training Accuracy: 0.9350, Validation Accuracy: 0.8202\n",
      "Epoch [442/500], Training Loss: 0.2053, Validation Loss: 2.4570, Training Accuracy: 0.9137, Validation Accuracy: 0.8090\n",
      "Epoch [443/500], Training Loss: 0.2032, Validation Loss: 0.4696, Training Accuracy: 0.9062, Validation Accuracy: 0.8090\n",
      "Epoch [444/500], Training Loss: 0.2047, Validation Loss: 2.5139, Training Accuracy: 0.9075, Validation Accuracy: 0.7865\n",
      "Epoch [445/500], Training Loss: 0.1805, Validation Loss: 3.4380, Training Accuracy: 0.9150, Validation Accuracy: 0.7528\n",
      "Epoch [446/500], Training Loss: 0.2016, Validation Loss: 1.4759, Training Accuracy: 0.9038, Validation Accuracy: 0.7753\n",
      "Epoch [447/500], Training Loss: 0.2185, Validation Loss: 0.5825, Training Accuracy: 0.9275, Validation Accuracy: 0.7865\n",
      "Epoch [448/500], Training Loss: 0.2018, Validation Loss: 2.4721, Training Accuracy: 0.9163, Validation Accuracy: 0.7978\n",
      "Epoch [449/500], Training Loss: 0.3043, Validation Loss: 2.4660, Training Accuracy: 0.8975, Validation Accuracy: 0.7865\n",
      "Epoch [450/500], Training Loss: 0.3154, Validation Loss: 2.4619, Training Accuracy: 0.9213, Validation Accuracy: 0.7753\n",
      "Epoch [451/500], Training Loss: 0.3125, Validation Loss: 2.3969, Training Accuracy: 0.9163, Validation Accuracy: 0.7978\n",
      "Epoch [452/500], Training Loss: 0.4281, Validation Loss: 2.3960, Training Accuracy: 0.9175, Validation Accuracy: 0.7978\n",
      "Epoch [453/500], Training Loss: 0.1701, Validation Loss: 2.5324, Training Accuracy: 0.9237, Validation Accuracy: 0.7753\n",
      "Epoch [454/500], Training Loss: 0.2074, Validation Loss: 2.5112, Training Accuracy: 0.9200, Validation Accuracy: 0.7753\n",
      "Epoch [455/500], Training Loss: 0.1798, Validation Loss: 2.4837, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [456/500], Training Loss: 0.3193, Validation Loss: 0.5531, Training Accuracy: 0.9062, Validation Accuracy: 0.7978\n",
      "Epoch [457/500], Training Loss: 0.2355, Validation Loss: 2.4008, Training Accuracy: 0.8988, Validation Accuracy: 0.7753\n",
      "Epoch [458/500], Training Loss: 0.1952, Validation Loss: 2.4354, Training Accuracy: 0.9163, Validation Accuracy: 0.7753\n",
      "Epoch [459/500], Training Loss: 0.3504, Validation Loss: 1.4763, Training Accuracy: 0.9213, Validation Accuracy: 0.7865\n",
      "Epoch [460/500], Training Loss: 0.3287, Validation Loss: 2.5432, Training Accuracy: 0.9150, Validation Accuracy: 0.7865\n",
      "Epoch [461/500], Training Loss: 0.1979, Validation Loss: 2.4685, Training Accuracy: 0.9150, Validation Accuracy: 0.7640\n",
      "Epoch [462/500], Training Loss: 0.2406, Validation Loss: 2.5219, Training Accuracy: 0.9225, Validation Accuracy: 0.7640\n",
      "Epoch [463/500], Training Loss: 0.2311, Validation Loss: 0.6751, Training Accuracy: 0.8950, Validation Accuracy: 0.7753\n",
      "Epoch [464/500], Training Loss: 0.1961, Validation Loss: 0.7023, Training Accuracy: 0.9125, Validation Accuracy: 0.7640\n",
      "Epoch [465/500], Training Loss: 0.3642, Validation Loss: 0.6170, Training Accuracy: 0.9025, Validation Accuracy: 0.7865\n",
      "Epoch [466/500], Training Loss: 0.3096, Validation Loss: 2.6064, Training Accuracy: 0.9163, Validation Accuracy: 0.7865\n",
      "Epoch [467/500], Training Loss: 0.2315, Validation Loss: 2.5347, Training Accuracy: 0.9125, Validation Accuracy: 0.7865\n",
      "Epoch [468/500], Training Loss: 0.1777, Validation Loss: 2.7433, Training Accuracy: 0.9113, Validation Accuracy: 0.7865\n",
      "Epoch [469/500], Training Loss: 0.4413, Validation Loss: 2.5518, Training Accuracy: 0.9175, Validation Accuracy: 0.7865\n",
      "Epoch [470/500], Training Loss: 0.3130, Validation Loss: 2.4061, Training Accuracy: 0.9200, Validation Accuracy: 0.8090\n",
      "Epoch [471/500], Training Loss: 0.2155, Validation Loss: 1.5848, Training Accuracy: 0.8988, Validation Accuracy: 0.7865\n",
      "Epoch [472/500], Training Loss: 0.1658, Validation Loss: 2.4599, Training Accuracy: 0.9287, Validation Accuracy: 0.7865\n",
      "Epoch [473/500], Training Loss: 0.2238, Validation Loss: 2.5368, Training Accuracy: 0.9213, Validation Accuracy: 0.7640\n",
      "Epoch [474/500], Training Loss: 0.2001, Validation Loss: 2.4077, Training Accuracy: 0.9213, Validation Accuracy: 0.8090\n",
      "Epoch [475/500], Training Loss: 0.1898, Validation Loss: 2.5605, Training Accuracy: 0.9263, Validation Accuracy: 0.7978\n",
      "Epoch [476/500], Training Loss: 0.2062, Validation Loss: 2.4810, Training Accuracy: 0.9137, Validation Accuracy: 0.7978\n",
      "Epoch [477/500], Training Loss: 0.5586, Validation Loss: 3.6232, Training Accuracy: 0.9113, Validation Accuracy: 0.7416\n",
      "Epoch [478/500], Training Loss: 0.4998, Validation Loss: 1.5320, Training Accuracy: 0.8862, Validation Accuracy: 0.7753\n",
      "Epoch [479/500], Training Loss: 0.2118, Validation Loss: 2.5737, Training Accuracy: 0.9012, Validation Accuracy: 0.7978\n",
      "Epoch [480/500], Training Loss: 0.2253, Validation Loss: 1.5392, Training Accuracy: 0.8988, Validation Accuracy: 0.7753\n",
      "Epoch [481/500], Training Loss: 0.3526, Validation Loss: 1.5787, Training Accuracy: 0.8975, Validation Accuracy: 0.7978\n",
      "Epoch [482/500], Training Loss: 0.2480, Validation Loss: 1.4904, Training Accuracy: 0.8975, Validation Accuracy: 0.7865\n",
      "Epoch [483/500], Training Loss: 0.2023, Validation Loss: 1.7800, Training Accuracy: 0.9050, Validation Accuracy: 0.7865\n",
      "Epoch [484/500], Training Loss: 0.2285, Validation Loss: 1.4971, Training Accuracy: 0.8988, Validation Accuracy: 0.7753\n",
      "Epoch [485/500], Training Loss: 0.2610, Validation Loss: 2.6083, Training Accuracy: 0.8888, Validation Accuracy: 0.7978\n",
      "Epoch [486/500], Training Loss: 0.2460, Validation Loss: 3.4461, Training Accuracy: 0.9000, Validation Accuracy: 0.7865\n",
      "Epoch [487/500], Training Loss: 0.2553, Validation Loss: 1.5946, Training Accuracy: 0.9025, Validation Accuracy: 0.7978\n",
      "Epoch [488/500], Training Loss: 0.2472, Validation Loss: 0.4979, Training Accuracy: 0.8875, Validation Accuracy: 0.7978\n",
      "Epoch [489/500], Training Loss: 0.2017, Validation Loss: 2.4607, Training Accuracy: 0.9087, Validation Accuracy: 0.8090\n",
      "Epoch [490/500], Training Loss: 0.2501, Validation Loss: 2.5079, Training Accuracy: 0.8962, Validation Accuracy: 0.7865\n",
      "Epoch [491/500], Training Loss: 0.2546, Validation Loss: 0.5329, Training Accuracy: 0.8825, Validation Accuracy: 0.7865\n",
      "Epoch [492/500], Training Loss: 0.2157, Validation Loss: 0.5882, Training Accuracy: 0.9000, Validation Accuracy: 0.7865\n",
      "Epoch [493/500], Training Loss: 0.2138, Validation Loss: 2.5979, Training Accuracy: 0.9125, Validation Accuracy: 0.7753\n",
      "Epoch [494/500], Training Loss: 0.1989, Validation Loss: 2.4340, Training Accuracy: 0.9150, Validation Accuracy: 0.7640\n",
      "Epoch [495/500], Training Loss: 0.2124, Validation Loss: 1.5293, Training Accuracy: 0.9025, Validation Accuracy: 0.7865\n",
      "Epoch [496/500], Training Loss: 0.2111, Validation Loss: 1.5263, Training Accuracy: 0.9038, Validation Accuracy: 0.7753\n",
      "Epoch [497/500], Training Loss: 0.1773, Validation Loss: 2.4776, Training Accuracy: 0.9062, Validation Accuracy: 0.7640\n",
      "Epoch [498/500], Training Loss: 0.2427, Validation Loss: 1.5067, Training Accuracy: 0.9125, Validation Accuracy: 0.7640\n",
      "Epoch [499/500], Training Loss: 0.1902, Validation Loss: 2.4384, Training Accuracy: 0.9237, Validation Accuracy: 0.7865\n",
      "Epoch [500/500], Training Loss: 0.2499, Validation Loss: 2.5130, Training Accuracy: 0.9337, Validation Accuracy: 0.7865\n",
      "Training Time: 6.77 seconds\n",
      "Epoch [1/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [2/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [3/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [4/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [5/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [6/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [7/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [8/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [9/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [10/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [11/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [12/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [13/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [14/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [15/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [16/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [17/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [18/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [19/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [20/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [21/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [22/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [23/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [24/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [25/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [26/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [27/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [28/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [29/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [30/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [31/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [32/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [33/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [34/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [35/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [36/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [37/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [38/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [39/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [40/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [41/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [42/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [43/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [44/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [45/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [46/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [47/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [48/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [49/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [50/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [51/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [52/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [53/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [54/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [55/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [56/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [57/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [58/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [59/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [60/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [61/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [62/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [63/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [64/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [65/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [66/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [67/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [68/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [69/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [70/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [71/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [72/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [73/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [74/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [75/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [76/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [77/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [78/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [79/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [80/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [81/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [82/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [83/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [84/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [85/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [86/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [87/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [88/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [89/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [90/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [91/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [92/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [93/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [94/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [95/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [96/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [97/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [98/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [99/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [100/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [101/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [102/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [103/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [104/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [105/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [106/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [107/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [108/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [109/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [110/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [111/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [112/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [113/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [114/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [115/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [116/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [117/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [118/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [119/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [120/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [121/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [122/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [123/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [124/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [125/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [126/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [127/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [128/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [129/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [130/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [131/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [132/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [133/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [134/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [135/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [136/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [137/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [138/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [139/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [140/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [141/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [142/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [143/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [144/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [145/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [146/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [147/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [148/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [149/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [150/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [151/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [152/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [153/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [154/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [155/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [156/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [157/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [158/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [159/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [160/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [161/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [162/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [163/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [164/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [165/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [166/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [167/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [168/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [169/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [170/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [171/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [172/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [173/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [174/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [175/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [176/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [177/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [178/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [179/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [180/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [181/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [182/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [183/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [184/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [185/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [186/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [187/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [188/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [189/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [190/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [191/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [192/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [193/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [194/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [195/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [196/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [197/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [198/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [199/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [200/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [201/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [202/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [203/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [204/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [205/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [206/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [207/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [208/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [209/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [210/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [211/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [212/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [213/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [214/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [215/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [216/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [217/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [218/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [219/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [220/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [221/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [222/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [223/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [224/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [225/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [226/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [227/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [228/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [229/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [230/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [231/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [232/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [233/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [234/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [235/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [236/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [237/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [238/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [239/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [240/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [241/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [242/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [243/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [244/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [245/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [246/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [247/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [248/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [249/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [250/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [251/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [252/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [253/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [254/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [255/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [256/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [257/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [258/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [259/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [260/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [261/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [262/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [263/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [264/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [265/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [266/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [267/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [268/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [269/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [270/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [271/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [272/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [273/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [274/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [275/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [276/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [277/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [278/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [279/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [280/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [281/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [282/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [283/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [284/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [285/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [286/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [287/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [288/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [289/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [290/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [291/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [292/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [293/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [294/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [295/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [296/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [297/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [298/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [299/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [300/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [301/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [302/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [303/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [304/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [305/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [306/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [307/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [308/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [309/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [310/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [311/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [312/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [313/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [314/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [315/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [316/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [317/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [318/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [319/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [320/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [321/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [322/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [323/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [324/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [325/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [326/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [327/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [328/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [329/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [330/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [331/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [332/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [333/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [334/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [335/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [336/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [337/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [338/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [339/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [340/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [341/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [342/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [343/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [344/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [345/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [346/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [347/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [348/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [349/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [350/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [351/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [352/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [353/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [354/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [355/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [356/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [357/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [358/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [359/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [360/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [361/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [362/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [363/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [364/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [365/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [366/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [367/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [368/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [369/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [370/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [371/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [372/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [373/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [374/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [375/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [376/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [377/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [378/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [379/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [380/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [381/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [382/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [383/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [384/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [385/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [386/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [387/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [388/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [389/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [390/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [391/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [392/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [393/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [394/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [395/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [396/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [397/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [398/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [399/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [400/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [401/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [402/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [403/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [404/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [405/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [406/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [407/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [408/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [409/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [410/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [411/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [412/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [413/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [414/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [415/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [416/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [417/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [418/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [419/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [420/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [421/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [422/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [423/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [424/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [425/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [426/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [427/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [428/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [429/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [430/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [431/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [432/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [433/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [434/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [435/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [436/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [437/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [438/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [439/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [440/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [441/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [442/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [443/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [444/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [445/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [446/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [447/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [448/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [449/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [450/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [451/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [452/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [453/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [454/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [455/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [456/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [457/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [458/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [459/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [460/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [461/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [462/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [463/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [464/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [465/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [466/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [467/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [468/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [469/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [470/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [471/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [472/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [473/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [474/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [475/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [476/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [477/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [478/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [479/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [480/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [481/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [482/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [483/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [484/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [485/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [486/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [487/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [488/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [489/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [490/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [491/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [492/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [493/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [494/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [495/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [496/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [497/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [498/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [499/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Epoch [500/500], Test Loss: 0.7520, Testing Accuracy: 0.7778\n",
      "Batch Size: 8, Training Accuracy: 0.7550, Validation Accuracy: 0.7528, Testing Accuracy: 0.7273\n",
      "Batch Size: 16, Training Accuracy: 0.8562, Validation Accuracy: 0.8315, Testing Accuracy: 0.7677\n",
      "Batch Size: 32, Training Accuracy: 0.9337, Validation Accuracy: 0.7865, Testing Accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(7, 256)  # Input layer\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)  # Hidden layers\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc5 = nn.Linear(32, 1)  # Output layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Using sigmoid because of Binary Target\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Different batch sizes\n",
    "batch_sizes = [8, 16, 32]\n",
    "results_batch_size = []\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "learning_rate = 0.01\n",
    "num_epochs = 500\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "for batch in batch_sizes:\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=False)\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    summary(model, input_size=(1, 7))\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        training_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = loss_function(outputs, labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss += loss.item()\n",
    "            predicted = torch.round(outputs)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "        train_losses.append(training_loss / len(train_loader))\n",
    "        train_accuracies.append(correct_predictions / total_predictions)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_predictions = 0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_outputs = model(val_inputs).squeeze()\n",
    "                val_outputs = val_outputs.view(-1)  \n",
    "                val_loss += loss_function(val_outputs, val_labels.float()).item()\n",
    "                predicted = torch.round(val_outputs)\n",
    "                val_correct_predictions += (predicted == val_labels).sum().item()\n",
    "                val_total_predictions += val_labels.size(0)\n",
    "\n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            val_accuracies.append(val_correct_predictions / val_total_predictions)\n",
    "\n",
    "        average_training_loss = training_loss / len(train_loader)\n",
    "        average_validation_loss = val_loss / len(val_loader)\n",
    "        training_accuracy = correct_predictions / total_predictions\n",
    "        validation_accuracy = val_correct_predictions / val_total_predictions\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "              f'Training Loss: {average_training_loss:.4f}, '\n",
    "              f'Validation Loss: {average_validation_loss:.4f}, '\n",
    "              f'Training Accuracy: {training_accuracy:.4f}, '\n",
    "              f'Validation Accuracy: {validation_accuracy:.4f}')\n",
    "\n",
    "        if average_validation_loss < best_val_loss:\n",
    "            best_val_loss = average_validation_loss\n",
    "            torch.save(model.state_dict(), 'best_model_weights.pth')\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'Training Time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "    # Testing the model\n",
    "    model.load_state_dict(torch.load('best_model_weights.pth'))\n",
    "\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct_predictions = 0\n",
    "        test_total_predictions = 0\n",
    "\n",
    "        confusion_predictions = []\n",
    "        confusion_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_inputs, test_labels in test_loader:\n",
    "                test_outputs = model(test_inputs).squeeze()\n",
    "                test_outputs = test_outputs.view(-1)  \n",
    "                test_loss += loss_function(test_outputs, test_labels.float()).item()\n",
    "                \n",
    "                predicted = torch.round(test_outputs)\n",
    "                test_correct_predictions += (predicted == test_labels.float()).sum().item()\n",
    "                test_total_predictions += test_labels.size(0)\n",
    "            \n",
    "                confusion_predictions.extend(predicted.numpy())\n",
    "                confusion_labels.extend(test_labels.numpy())\n",
    "\n",
    "            test_losses.append(test_loss / len(test_loader))\n",
    "            test_accuracies.append(test_correct_predictions / test_total_predictions)\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        test_accuracy = test_correct_predictions / test_total_predictions\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "              f'Test Loss: {avg_test_loss:.4f}, '\n",
    "              f'Testing Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    results_batch_size.append({\n",
    "        'batch_size': batch,\n",
    "        'train_accuracy': training_accuracy,\n",
    "        'val_accuracy': validation_accuracy,\n",
    "        'test_accuracy': test_accuracy\n",
    "    })\n",
    "\n",
    "for result in results_batch_size:\n",
    "    print(f\"Batch Size: {result['batch_size']}, \"\n",
    "          f\"Training Accuracy: {result['train_accuracy']:.4f}, \"\n",
    "          f\"Validation Accuracy: {result['val_accuracy']:.4f}, \"\n",
    "          f\"Testing Accuracy: {result['test_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_sizes = [result['batch_size'] for result in results_batch_size]\n",
    "test_accuracies = [result['test_accuracy'] for result in results_batch_size]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(batch_sizes, test_accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('Testing Accuracies vs Batch Sizes')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.xticks(batch_sizes) \n",
    "plt.grid()\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing learning rate as hyper parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 3.4222, Validation Loss: 0.6354, Training Accuracy: 0.5737, Validation Accuracy: 0.5730\n",
      "Epoch [2/500], Training Loss: 2.4506, Validation Loss: 0.6946, Training Accuracy: 0.5350, Validation Accuracy: 0.5056\n",
      "Epoch [3/500], Training Loss: 1.0806, Validation Loss: 0.7035, Training Accuracy: 0.4938, Validation Accuracy: 0.4944\n",
      "Epoch [4/500], Training Loss: 0.7734, Validation Loss: 0.6947, Training Accuracy: 0.5088, Validation Accuracy: 0.5056\n",
      "Epoch [5/500], Training Loss: 1.7634, Validation Loss: 0.6921, Training Accuracy: 0.5050, Validation Accuracy: 0.4944\n",
      "Epoch [6/500], Training Loss: 0.6977, Validation Loss: 0.6933, Training Accuracy: 0.4988, Validation Accuracy: 0.5056\n",
      "Epoch [7/500], Training Loss: 0.6934, Validation Loss: 0.6936, Training Accuracy: 0.4988, Validation Accuracy: 0.4944\n",
      "Epoch [8/500], Training Loss: 0.6953, Validation Loss: 0.6936, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [9/500], Training Loss: 0.6938, Validation Loss: 0.6937, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [10/500], Training Loss: 0.6990, Validation Loss: 0.7017, Training Accuracy: 0.4775, Validation Accuracy: 0.4944\n",
      "Epoch [11/500], Training Loss: 0.6984, Validation Loss: 0.6932, Training Accuracy: 0.4763, Validation Accuracy: 0.5056\n",
      "Epoch [12/500], Training Loss: 0.6947, Validation Loss: 0.6931, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [13/500], Training Loss: 0.6959, Validation Loss: 0.6934, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [14/500], Training Loss: 0.6959, Validation Loss: 0.6931, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [15/500], Training Loss: 0.6956, Validation Loss: 0.6941, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [16/500], Training Loss: 0.6970, Validation Loss: 0.6931, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [17/500], Training Loss: 0.6958, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [18/500], Training Loss: 0.6955, Validation Loss: 0.6933, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [19/500], Training Loss: 0.6948, Validation Loss: 0.6940, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [20/500], Training Loss: 0.6944, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [21/500], Training Loss: 0.7135, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [22/500], Training Loss: 0.6948, Validation Loss: 0.6938, Training Accuracy: 0.4650, Validation Accuracy: 0.4944\n",
      "Epoch [23/500], Training Loss: 0.6945, Validation Loss: 0.6931, Training Accuracy: 0.4675, Validation Accuracy: 0.5056\n",
      "Epoch [24/500], Training Loss: 0.6947, Validation Loss: 0.6955, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [25/500], Training Loss: 0.6949, Validation Loss: 0.6932, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [26/500], Training Loss: 0.7088, Validation Loss: 0.6986, Training Accuracy: 0.4963, Validation Accuracy: 0.4944\n",
      "Epoch [27/500], Training Loss: 0.7110, Validation Loss: 0.6944, Training Accuracy: 0.4725, Validation Accuracy: 0.4944\n",
      "Epoch [28/500], Training Loss: 0.7230, Validation Loss: 0.6936, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [29/500], Training Loss: 0.6940, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [30/500], Training Loss: 0.6970, Validation Loss: 0.6948, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [31/500], Training Loss: 0.9462, Validation Loss: 0.6932, Training Accuracy: 0.4863, Validation Accuracy: 0.4944\n",
      "Epoch [32/500], Training Loss: 0.9663, Validation Loss: 0.6931, Training Accuracy: 0.4575, Validation Accuracy: 0.5056\n",
      "Epoch [33/500], Training Loss: 0.8189, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [34/500], Training Loss: 0.6939, Validation Loss: 0.6933, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [35/500], Training Loss: 0.6946, Validation Loss: 0.6941, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [36/500], Training Loss: 0.6933, Validation Loss: 0.6932, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [37/500], Training Loss: 0.6944, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [38/500], Training Loss: 0.6947, Validation Loss: 0.6931, Training Accuracy: 0.4763, Validation Accuracy: 0.5056\n",
      "Epoch [39/500], Training Loss: 0.7501, Validation Loss: 0.6936, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [40/500], Training Loss: 0.8271, Validation Loss: 0.6950, Training Accuracy: 0.4913, Validation Accuracy: 0.4944\n",
      "Epoch [41/500], Training Loss: 1.3154, Validation Loss: 0.6931, Training Accuracy: 0.4425, Validation Accuracy: 0.5056\n",
      "Epoch [42/500], Training Loss: 1.8569, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [43/500], Training Loss: 2.6737, Validation Loss: 0.6931, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [44/500], Training Loss: 1.8251, Validation Loss: 0.6965, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [45/500], Training Loss: 0.6936, Validation Loss: 0.6938, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [46/500], Training Loss: 0.8179, Validation Loss: 0.6935, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [47/500], Training Loss: 0.6951, Validation Loss: 0.6950, Training Accuracy: 0.4775, Validation Accuracy: 0.4944\n",
      "Epoch [48/500], Training Loss: 0.8183, Validation Loss: 0.6935, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [49/500], Training Loss: 0.6958, Validation Loss: 0.6951, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [50/500], Training Loss: 0.6937, Validation Loss: 0.6939, Training Accuracy: 0.5100, Validation Accuracy: 0.5056\n",
      "Epoch [51/500], Training Loss: 0.6961, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [52/500], Training Loss: 0.6965, Validation Loss: 0.6936, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [53/500], Training Loss: 0.8207, Validation Loss: 0.6936, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [54/500], Training Loss: 0.8221, Validation Loss: 0.6934, Training Accuracy: 0.4888, Validation Accuracy: 0.5056\n",
      "Epoch [55/500], Training Loss: 0.6939, Validation Loss: 0.6942, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [56/500], Training Loss: 0.6950, Validation Loss: 0.6938, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [57/500], Training Loss: 0.6946, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [58/500], Training Loss: 0.6942, Validation Loss: 0.6937, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [59/500], Training Loss: 0.6967, Validation Loss: 0.6933, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [60/500], Training Loss: 0.6952, Validation Loss: 0.6935, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [61/500], Training Loss: 0.6943, Validation Loss: 0.6934, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [62/500], Training Loss: 0.6965, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [63/500], Training Loss: 0.8182, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [64/500], Training Loss: 0.8278, Validation Loss: 0.6931, Training Accuracy: 0.4713, Validation Accuracy: 0.5056\n",
      "Epoch [65/500], Training Loss: 0.6952, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [66/500], Training Loss: 0.6979, Validation Loss: 0.6969, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [67/500], Training Loss: 0.7238, Validation Loss: 0.6936, Training Accuracy: 0.4600, Validation Accuracy: 0.4944\n",
      "Epoch [68/500], Training Loss: 0.6934, Validation Loss: 0.6935, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [69/500], Training Loss: 0.8189, Validation Loss: 0.6942, Training Accuracy: 0.5100, Validation Accuracy: 0.4944\n",
      "Epoch [70/500], Training Loss: 0.6954, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [71/500], Training Loss: 0.6964, Validation Loss: 0.6946, Training Accuracy: 0.4600, Validation Accuracy: 0.4944\n",
      "Epoch [72/500], Training Loss: 0.8182, Validation Loss: 0.6931, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [73/500], Training Loss: 0.8200, Validation Loss: 0.6938, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [74/500], Training Loss: 0.6945, Validation Loss: 0.6931, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [75/500], Training Loss: 0.8221, Validation Loss: 0.6980, Training Accuracy: 0.4913, Validation Accuracy: 0.4944\n",
      "Epoch [76/500], Training Loss: 0.9427, Validation Loss: 0.6945, Training Accuracy: 0.4963, Validation Accuracy: 0.5056\n",
      "Epoch [77/500], Training Loss: 0.6934, Validation Loss: 0.6933, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [78/500], Training Loss: 0.8186, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [79/500], Training Loss: 0.6956, Validation Loss: 0.6935, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [80/500], Training Loss: 0.8288, Validation Loss: 0.6948, Training Accuracy: 0.4913, Validation Accuracy: 0.5056\n",
      "Epoch [81/500], Training Loss: 1.0828, Validation Loss: 0.6934, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [82/500], Training Loss: 0.8192, Validation Loss: 0.6935, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [83/500], Training Loss: 0.6939, Validation Loss: 0.6935, Training Accuracy: 0.5100, Validation Accuracy: 0.5056\n",
      "Epoch [84/500], Training Loss: 0.6964, Validation Loss: 0.6939, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [85/500], Training Loss: 0.7596, Validation Loss: 0.6931, Training Accuracy: 0.4738, Validation Accuracy: 0.5056\n",
      "Epoch [86/500], Training Loss: 0.6942, Validation Loss: 0.6961, Training Accuracy: 0.5200, Validation Accuracy: 0.4944\n",
      "Epoch [87/500], Training Loss: 0.6963, Validation Loss: 0.6936, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [88/500], Training Loss: 0.6951, Validation Loss: 0.6945, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [89/500], Training Loss: 0.6924, Validation Loss: 0.6933, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [90/500], Training Loss: 0.6970, Validation Loss: 0.6956, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [91/500], Training Loss: 0.8198, Validation Loss: 0.6940, Training Accuracy: 0.4863, Validation Accuracy: 0.4944\n",
      "Epoch [92/500], Training Loss: 0.6945, Validation Loss: 0.6947, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [93/500], Training Loss: 0.6960, Validation Loss: 0.6958, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [94/500], Training Loss: 0.6943, Validation Loss: 0.6938, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [95/500], Training Loss: 0.8193, Validation Loss: 0.6934, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [96/500], Training Loss: 0.6953, Validation Loss: 0.6937, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [97/500], Training Loss: 0.6948, Validation Loss: 0.6934, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [98/500], Training Loss: 0.6969, Validation Loss: 0.6936, Training Accuracy: 0.4675, Validation Accuracy: 0.4944\n",
      "Epoch [99/500], Training Loss: 0.6949, Validation Loss: 0.6939, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [100/500], Training Loss: 0.8181, Validation Loss: 0.6933, Training Accuracy: 0.4838, Validation Accuracy: 0.4944\n",
      "Epoch [101/500], Training Loss: 0.6931, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [102/500], Training Loss: 0.6930, Validation Loss: 0.6938, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [103/500], Training Loss: 0.6957, Validation Loss: 0.6944, Training Accuracy: 0.4600, Validation Accuracy: 0.4944\n",
      "Epoch [104/500], Training Loss: 0.8191, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [105/500], Training Loss: 0.6945, Validation Loss: 0.6936, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [106/500], Training Loss: 8.7097, Validation Loss: 0.6931, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [107/500], Training Loss: 7.7055, Validation Loss: 0.6936, Training Accuracy: 0.4963, Validation Accuracy: 0.4944\n",
      "Epoch [108/500], Training Loss: 0.8411, Validation Loss: 0.6931, Training Accuracy: 0.4713, Validation Accuracy: 0.5056\n",
      "Epoch [109/500], Training Loss: 0.6941, Validation Loss: 0.6931, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [110/500], Training Loss: 0.8183, Validation Loss: 0.6931, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [111/500], Training Loss: 0.6940, Validation Loss: 0.6933, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [112/500], Training Loss: 0.8183, Validation Loss: 0.6934, Training Accuracy: 0.4738, Validation Accuracy: 0.4944\n",
      "Epoch [113/500], Training Loss: 0.9422, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [114/500], Training Loss: 0.6955, Validation Loss: 0.6960, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [115/500], Training Loss: 0.9100, Validation Loss: 0.6935, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [116/500], Training Loss: 0.6943, Validation Loss: 0.6946, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [117/500], Training Loss: 0.8197, Validation Loss: 0.6934, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [118/500], Training Loss: 0.6967, Validation Loss: 0.6931, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [119/500], Training Loss: 0.6955, Validation Loss: 0.6935, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [120/500], Training Loss: 0.6970, Validation Loss: 0.6937, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [121/500], Training Loss: 0.6941, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [122/500], Training Loss: 0.6910, Validation Loss: 0.6931, Training Accuracy: 0.4813, Validation Accuracy: 0.5056\n",
      "Epoch [123/500], Training Loss: 0.6967, Validation Loss: 0.6940, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [124/500], Training Loss: 0.8190, Validation Loss: 0.6945, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [125/500], Training Loss: 0.8182, Validation Loss: 0.6937, Training Accuracy: 0.4738, Validation Accuracy: 0.4944\n",
      "Epoch [126/500], Training Loss: 0.6924, Validation Loss: 0.6937, Training Accuracy: 0.5200, Validation Accuracy: 0.5056\n",
      "Epoch [127/500], Training Loss: 0.6957, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [128/500], Training Loss: 0.6936, Validation Loss: 0.6935, Training Accuracy: 0.5038, Validation Accuracy: 0.4944\n",
      "Epoch [129/500], Training Loss: 0.8186, Validation Loss: 0.6939, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [130/500], Training Loss: 0.8191, Validation Loss: 0.6948, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [131/500], Training Loss: 0.9440, Validation Loss: 0.6933, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [132/500], Training Loss: 0.6954, Validation Loss: 0.6936, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [133/500], Training Loss: 0.6942, Validation Loss: 0.6932, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [134/500], Training Loss: 0.6941, Validation Loss: 0.6937, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [135/500], Training Loss: 0.6936, Validation Loss: 0.6934, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [136/500], Training Loss: 0.6956, Validation Loss: 0.6937, Training Accuracy: 0.5175, Validation Accuracy: 0.5056\n",
      "Epoch [137/500], Training Loss: 0.6958, Validation Loss: 0.6940, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [138/500], Training Loss: 0.6948, Validation Loss: 0.6943, Training Accuracy: 0.5050, Validation Accuracy: 0.4944\n",
      "Epoch [139/500], Training Loss: 0.8187, Validation Loss: 0.6948, Training Accuracy: 0.5125, Validation Accuracy: 0.5056\n",
      "Epoch [140/500], Training Loss: 0.6964, Validation Loss: 0.6971, Training Accuracy: 0.5050, Validation Accuracy: 0.4944\n",
      "Epoch [141/500], Training Loss: 0.9442, Validation Loss: 0.7003, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [142/500], Training Loss: 0.6931, Validation Loss: 0.6942, Training Accuracy: 0.5062, Validation Accuracy: 0.4944\n",
      "Epoch [143/500], Training Loss: 0.6955, Validation Loss: 0.6931, Training Accuracy: 0.4587, Validation Accuracy: 0.5056\n",
      "Epoch [144/500], Training Loss: 0.6949, Validation Loss: 0.6997, Training Accuracy: 0.5250, Validation Accuracy: 0.4944\n",
      "Epoch [145/500], Training Loss: 0.7062, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [146/500], Training Loss: 0.6972, Validation Loss: 0.6981, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [147/500], Training Loss: 0.6952, Validation Loss: 0.6997, Training Accuracy: 0.5200, Validation Accuracy: 0.4944\n",
      "Epoch [148/500], Training Loss: 0.6964, Validation Loss: 0.6935, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [149/500], Training Loss: 0.9409, Validation Loss: 0.6946, Training Accuracy: 0.5062, Validation Accuracy: 0.4944\n",
      "Epoch [150/500], Training Loss: 0.6940, Validation Loss: 0.6931, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [151/500], Training Loss: 0.6976, Validation Loss: 0.6935, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [152/500], Training Loss: 0.8199, Validation Loss: 0.6964, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [153/500], Training Loss: 0.8196, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [154/500], Training Loss: 0.9423, Validation Loss: 0.6941, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [155/500], Training Loss: 0.8201, Validation Loss: 0.6936, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [156/500], Training Loss: 0.6929, Validation Loss: 0.6932, Training Accuracy: 0.4988, Validation Accuracy: 0.5056\n",
      "Epoch [157/500], Training Loss: 0.6939, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [158/500], Training Loss: 0.6932, Validation Loss: 0.6961, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [159/500], Training Loss: 0.6976, Validation Loss: 0.6931, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [160/500], Training Loss: 0.6942, Validation Loss: 0.6935, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [161/500], Training Loss: 0.6938, Validation Loss: 0.6935, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [162/500], Training Loss: 0.6955, Validation Loss: 0.6948, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [163/500], Training Loss: 0.6960, Validation Loss: 0.6931, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [164/500], Training Loss: 0.6949, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [165/500], Training Loss: 0.6932, Validation Loss: 0.6954, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [166/500], Training Loss: 0.6951, Validation Loss: 0.6931, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [167/500], Training Loss: 1.0658, Validation Loss: 0.6942, Training Accuracy: 0.5038, Validation Accuracy: 0.4944\n",
      "Epoch [168/500], Training Loss: 0.6949, Validation Loss: 0.6931, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [169/500], Training Loss: 0.8182, Validation Loss: 0.6936, Training Accuracy: 0.4938, Validation Accuracy: 0.4944\n",
      "Epoch [170/500], Training Loss: 0.9435, Validation Loss: 0.6944, Training Accuracy: 0.4700, Validation Accuracy: 0.4944\n",
      "Epoch [171/500], Training Loss: 0.6957, Validation Loss: 0.6936, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [172/500], Training Loss: 0.8173, Validation Loss: 0.6941, Training Accuracy: 0.5088, Validation Accuracy: 0.4944\n",
      "Epoch [173/500], Training Loss: 0.6939, Validation Loss: 0.6931, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [174/500], Training Loss: 0.6969, Validation Loss: 0.7015, Training Accuracy: 0.5050, Validation Accuracy: 0.4944\n",
      "Epoch [175/500], Training Loss: 0.8193, Validation Loss: 0.6937, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [176/500], Training Loss: 0.6950, Validation Loss: 0.6933, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [177/500], Training Loss: 0.6929, Validation Loss: 0.6938, Training Accuracy: 0.4988, Validation Accuracy: 0.4944\n",
      "Epoch [178/500], Training Loss: 0.6931, Validation Loss: 0.6937, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [179/500], Training Loss: 0.6972, Validation Loss: 0.6938, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [180/500], Training Loss: 0.6948, Validation Loss: 0.6933, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [181/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [182/500], Training Loss: 0.6946, Validation Loss: 0.6935, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [183/500], Training Loss: 0.6937, Validation Loss: 0.6934, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [184/500], Training Loss: 0.6945, Validation Loss: 0.6946, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [185/500], Training Loss: 0.6976, Validation Loss: 0.6938, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [186/500], Training Loss: 0.6938, Validation Loss: 0.6990, Training Accuracy: 0.5212, Validation Accuracy: 0.4944\n",
      "Epoch [187/500], Training Loss: 0.6951, Validation Loss: 0.6935, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [188/500], Training Loss: 0.9437, Validation Loss: 0.6931, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [189/500], Training Loss: 0.6939, Validation Loss: 0.6936, Training Accuracy: 0.5100, Validation Accuracy: 0.5056\n",
      "Epoch [190/500], Training Loss: 0.6944, Validation Loss: 0.6934, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [191/500], Training Loss: 0.6966, Validation Loss: 0.6953, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [192/500], Training Loss: 0.8194, Validation Loss: 0.6934, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [193/500], Training Loss: 0.6955, Validation Loss: 0.6933, Training Accuracy: 0.4675, Validation Accuracy: 0.5056\n",
      "Epoch [194/500], Training Loss: 0.6970, Validation Loss: 0.6968, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [195/500], Training Loss: 0.6956, Validation Loss: 0.6932, Training Accuracy: 0.5050, Validation Accuracy: 0.4944\n",
      "Epoch [196/500], Training Loss: 0.6949, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [197/500], Training Loss: 0.8187, Validation Loss: 0.6937, Training Accuracy: 0.4938, Validation Accuracy: 0.4944\n",
      "Epoch [198/500], Training Loss: 0.8183, Validation Loss: 0.6931, Training Accuracy: 0.4437, Validation Accuracy: 0.5056\n",
      "Epoch [199/500], Training Loss: 0.8186, Validation Loss: 0.6934, Training Accuracy: 0.5162, Validation Accuracy: 0.5056\n",
      "Epoch [200/500], Training Loss: 0.8202, Validation Loss: 0.6961, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [201/500], Training Loss: 0.8226, Validation Loss: 0.6983, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [202/500], Training Loss: 0.6976, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [203/500], Training Loss: 0.8196, Validation Loss: 0.6943, Training Accuracy: 0.4963, Validation Accuracy: 0.4944\n",
      "Epoch [204/500], Training Loss: 0.6970, Validation Loss: 0.6974, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [205/500], Training Loss: 0.6944, Validation Loss: 0.6942, Training Accuracy: 0.5325, Validation Accuracy: 0.5056\n",
      "Epoch [206/500], Training Loss: 0.8229, Validation Loss: 0.6940, Training Accuracy: 0.4813, Validation Accuracy: 0.4944\n",
      "Epoch [207/500], Training Loss: 0.6945, Validation Loss: 0.6935, Training Accuracy: 0.4575, Validation Accuracy: 0.5056\n",
      "Epoch [208/500], Training Loss: 0.6953, Validation Loss: 0.6938, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [209/500], Training Loss: 0.6956, Validation Loss: 0.6940, Training Accuracy: 0.5100, Validation Accuracy: 0.4944\n",
      "Epoch [210/500], Training Loss: 0.9447, Validation Loss: 0.6934, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [211/500], Training Loss: 0.6942, Validation Loss: 0.6932, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [212/500], Training Loss: 0.6943, Validation Loss: 0.6940, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [213/500], Training Loss: 0.8182, Validation Loss: 0.6935, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [214/500], Training Loss: 0.6954, Validation Loss: 0.6950, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [215/500], Training Loss: 0.8193, Validation Loss: 0.6939, Training Accuracy: 0.4888, Validation Accuracy: 0.4944\n",
      "Epoch [216/500], Training Loss: 0.6957, Validation Loss: 0.6936, Training Accuracy: 0.4725, Validation Accuracy: 0.4944\n",
      "Epoch [217/500], Training Loss: 0.8177, Validation Loss: 0.6931, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [218/500], Training Loss: 0.6991, Validation Loss: 0.6969, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [219/500], Training Loss: 0.6961, Validation Loss: 0.6937, Training Accuracy: 0.5012, Validation Accuracy: 0.4944\n",
      "Epoch [220/500], Training Loss: 0.8189, Validation Loss: 0.6941, Training Accuracy: 0.4788, Validation Accuracy: 0.4944\n",
      "Epoch [221/500], Training Loss: 0.6952, Validation Loss: 0.6934, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [222/500], Training Loss: 0.6971, Validation Loss: 0.6933, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [223/500], Training Loss: 0.8164, Validation Loss: 0.6933, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [224/500], Training Loss: 0.8201, Validation Loss: 0.6971, Training Accuracy: 0.4888, Validation Accuracy: 0.4944\n",
      "Epoch [225/500], Training Loss: 0.9429, Validation Loss: 0.6931, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [226/500], Training Loss: 0.8214, Validation Loss: 0.6947, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [227/500], Training Loss: 0.7005, Validation Loss: 0.6996, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [228/500], Training Loss: 0.8215, Validation Loss: 0.6950, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [229/500], Training Loss: 0.8216, Validation Loss: 0.6938, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [230/500], Training Loss: 0.6957, Validation Loss: 0.6941, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [231/500], Training Loss: 0.8221, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [232/500], Training Loss: 2.0460, Validation Loss: 0.6958, Training Accuracy: 0.5125, Validation Accuracy: 0.4944\n",
      "Epoch [233/500], Training Loss: 2.9112, Validation Loss: 0.6941, Training Accuracy: 0.5138, Validation Accuracy: 0.5056\n",
      "Epoch [234/500], Training Loss: 2.2987, Validation Loss: 0.6937, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [235/500], Training Loss: 2.5397, Validation Loss: 0.6969, Training Accuracy: 0.5062, Validation Accuracy: 0.4944\n",
      "Epoch [236/500], Training Loss: 1.7031, Validation Loss: 0.6938, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [237/500], Training Loss: 0.8193, Validation Loss: 0.6950, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [238/500], Training Loss: 0.6985, Validation Loss: 0.6953, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [239/500], Training Loss: 0.6958, Validation Loss: 0.6932, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [240/500], Training Loss: 0.8172, Validation Loss: 0.6931, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [241/500], Training Loss: 0.6937, Validation Loss: 0.6934, Training Accuracy: 0.5138, Validation Accuracy: 0.5056\n",
      "Epoch [242/500], Training Loss: 0.6941, Validation Loss: 0.6931, Training Accuracy: 0.4788, Validation Accuracy: 0.5056\n",
      "Epoch [243/500], Training Loss: 0.8220, Validation Loss: 0.6948, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [244/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.4913, Validation Accuracy: 0.5056\n",
      "Epoch [245/500], Training Loss: 0.8171, Validation Loss: 0.6932, Training Accuracy: 0.4662, Validation Accuracy: 0.5056\n",
      "Epoch [246/500], Training Loss: 0.8199, Validation Loss: 0.6960, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [247/500], Training Loss: 0.8245, Validation Loss: 0.6997, Training Accuracy: 0.4988, Validation Accuracy: 0.4944\n",
      "Epoch [248/500], Training Loss: 0.9404, Validation Loss: 0.6939, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [249/500], Training Loss: 0.6942, Validation Loss: 0.6932, Training Accuracy: 0.4725, Validation Accuracy: 0.4944\n",
      "Epoch [250/500], Training Loss: 0.6948, Validation Loss: 0.6935, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [251/500], Training Loss: 0.6965, Validation Loss: 0.6937, Training Accuracy: 0.4600, Validation Accuracy: 0.5056\n",
      "Epoch [252/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.4813, Validation Accuracy: 0.5056\n",
      "Epoch [253/500], Training Loss: 0.6921, Validation Loss: 0.6933, Training Accuracy: 0.4863, Validation Accuracy: 0.4944\n",
      "Epoch [254/500], Training Loss: 0.6934, Validation Loss: 0.6933, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [255/500], Training Loss: 0.8171, Validation Loss: 0.6937, Training Accuracy: 0.5062, Validation Accuracy: 0.4944\n",
      "Epoch [256/500], Training Loss: 0.6975, Validation Loss: 0.6982, Training Accuracy: 0.4888, Validation Accuracy: 0.5056\n",
      "Epoch [257/500], Training Loss: 0.8222, Validation Loss: 0.6931, Training Accuracy: 0.4888, Validation Accuracy: 0.5056\n",
      "Epoch [258/500], Training Loss: 0.6948, Validation Loss: 0.6933, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [259/500], Training Loss: 0.6957, Validation Loss: 0.6995, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [260/500], Training Loss: 0.8189, Validation Loss: 0.6966, Training Accuracy: 0.5100, Validation Accuracy: 0.5056\n",
      "Epoch [261/500], Training Loss: 0.6938, Validation Loss: 0.6944, Training Accuracy: 0.5075, Validation Accuracy: 0.4944\n",
      "Epoch [262/500], Training Loss: 0.6927, Validation Loss: 0.6935, Training Accuracy: 0.4913, Validation Accuracy: 0.5056\n",
      "Epoch [263/500], Training Loss: 0.8184, Validation Loss: 0.6933, Training Accuracy: 0.5038, Validation Accuracy: 0.4944\n",
      "Epoch [264/500], Training Loss: 0.9404, Validation Loss: 0.6931, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [265/500], Training Loss: 0.8179, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [266/500], Training Loss: 0.9244, Validation Loss: 0.6951, Training Accuracy: 0.4988, Validation Accuracy: 0.4944\n",
      "Epoch [267/500], Training Loss: 0.8198, Validation Loss: 0.6938, Training Accuracy: 0.4775, Validation Accuracy: 0.4944\n",
      "Epoch [268/500], Training Loss: 0.8180, Validation Loss: 0.6938, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [269/500], Training Loss: 0.6938, Validation Loss: 0.6931, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [270/500], Training Loss: 0.6925, Validation Loss: 0.6935, Training Accuracy: 0.4688, Validation Accuracy: 0.4944\n",
      "Epoch [271/500], Training Loss: 0.6935, Validation Loss: 0.6937, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [272/500], Training Loss: 0.6931, Validation Loss: 0.6938, Training Accuracy: 0.5050, Validation Accuracy: 0.4944\n",
      "Epoch [273/500], Training Loss: 0.6920, Validation Loss: 0.6931, Training Accuracy: 0.4863, Validation Accuracy: 0.5056\n",
      "Epoch [274/500], Training Loss: 0.8188, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [275/500], Training Loss: 0.6938, Validation Loss: 0.6931, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [276/500], Training Loss: 0.9450, Validation Loss: 0.6931, Training Accuracy: 0.4838, Validation Accuracy: 0.5056\n",
      "Epoch [277/500], Training Loss: 0.7044, Validation Loss: 0.6932, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [278/500], Training Loss: 0.6948, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [279/500], Training Loss: 0.6943, Validation Loss: 0.6933, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [280/500], Training Loss: 0.6948, Validation Loss: 0.6940, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [281/500], Training Loss: 0.6973, Validation Loss: 0.6971, Training Accuracy: 0.4688, Validation Accuracy: 0.4944\n",
      "Epoch [282/500], Training Loss: 0.8195, Validation Loss: 0.6931, Training Accuracy: 0.4888, Validation Accuracy: 0.5056\n",
      "Epoch [283/500], Training Loss: 0.9456, Validation Loss: 0.6937, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [284/500], Training Loss: 0.6923, Validation Loss: 0.6931, Training Accuracy: 0.4738, Validation Accuracy: 0.5056\n",
      "Epoch [285/500], Training Loss: 0.6935, Validation Loss: 0.6933, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [286/500], Training Loss: 0.8326, Validation Loss: 0.7017, Training Accuracy: 0.5050, Validation Accuracy: 0.4944\n",
      "Epoch [287/500], Training Loss: 0.6995, Validation Loss: 0.6943, Training Accuracy: 0.4813, Validation Accuracy: 0.4944\n",
      "Epoch [288/500], Training Loss: 0.8168, Validation Loss: 0.6938, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [289/500], Training Loss: 0.7095, Validation Loss: 0.6941, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [290/500], Training Loss: 0.8217, Validation Loss: 0.7014, Training Accuracy: 0.5075, Validation Accuracy: 0.4944\n",
      "Epoch [291/500], Training Loss: 0.7020, Validation Loss: 0.6974, Training Accuracy: 0.4700, Validation Accuracy: 0.4944\n",
      "Epoch [292/500], Training Loss: 0.6976, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [293/500], Training Loss: 0.6936, Validation Loss: 0.6946, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [294/500], Training Loss: 0.6976, Validation Loss: 0.6953, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [295/500], Training Loss: 0.6955, Validation Loss: 0.6931, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [296/500], Training Loss: 0.6933, Validation Loss: 0.6934, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [297/500], Training Loss: 0.6947, Validation Loss: 0.6933, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [298/500], Training Loss: 0.6955, Validation Loss: 0.6945, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [299/500], Training Loss: 0.6935, Validation Loss: 0.6950, Training Accuracy: 0.5150, Validation Accuracy: 0.4944\n",
      "Epoch [300/500], Training Loss: 1.0674, Validation Loss: 0.6933, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [301/500], Training Loss: 0.8205, Validation Loss: 0.6962, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [302/500], Training Loss: 0.9476, Validation Loss: 0.6942, Training Accuracy: 0.5150, Validation Accuracy: 0.5056\n",
      "Epoch [303/500], Training Loss: 0.6946, Validation Loss: 0.6941, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [304/500], Training Loss: 0.6957, Validation Loss: 0.6941, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [305/500], Training Loss: 0.6966, Validation Loss: 0.6934, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [306/500], Training Loss: 0.8179, Validation Loss: 0.6938, Training Accuracy: 0.4938, Validation Accuracy: 0.4944\n",
      "Epoch [307/500], Training Loss: 0.6961, Validation Loss: 0.6972, Training Accuracy: 0.5075, Validation Accuracy: 0.4944\n",
      "Epoch [308/500], Training Loss: 0.6955, Validation Loss: 0.6931, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [309/500], Training Loss: 0.6939, Validation Loss: 0.6952, Training Accuracy: 0.5038, Validation Accuracy: 0.4944\n",
      "Epoch [310/500], Training Loss: 0.6991, Validation Loss: 0.6944, Training Accuracy: 0.4500, Validation Accuracy: 0.4944\n",
      "Epoch [311/500], Training Loss: 0.6940, Validation Loss: 0.6933, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [312/500], Training Loss: 0.6942, Validation Loss: 0.6931, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [313/500], Training Loss: 0.6937, Validation Loss: 0.6933, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [314/500], Training Loss: 0.6960, Validation Loss: 0.7001, Training Accuracy: 0.5100, Validation Accuracy: 0.4944\n",
      "Epoch [315/500], Training Loss: 0.8209, Validation Loss: 0.6937, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [316/500], Training Loss: 0.6946, Validation Loss: 0.6934, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [317/500], Training Loss: 0.8195, Validation Loss: 0.6933, Training Accuracy: 0.4475, Validation Accuracy: 0.4944\n",
      "Epoch [318/500], Training Loss: 0.6952, Validation Loss: 0.6931, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [319/500], Training Loss: 0.6944, Validation Loss: 0.6949, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [320/500], Training Loss: 0.8197, Validation Loss: 0.6954, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [321/500], Training Loss: 0.6961, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [322/500], Training Loss: 0.8177, Validation Loss: 0.6945, Training Accuracy: 0.5112, Validation Accuracy: 0.4944\n",
      "Epoch [323/500], Training Loss: 0.6958, Validation Loss: 0.7007, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [324/500], Training Loss: 0.7011, Validation Loss: 0.6946, Training Accuracy: 0.4550, Validation Accuracy: 0.5056\n",
      "Epoch [325/500], Training Loss: 0.6957, Validation Loss: 0.6932, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [326/500], Training Loss: 0.6943, Validation Loss: 0.6937, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [327/500], Training Loss: 0.6938, Validation Loss: 0.6931, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [328/500], Training Loss: 0.6936, Validation Loss: 0.6934, Training Accuracy: 0.4775, Validation Accuracy: 0.4944\n",
      "Epoch [329/500], Training Loss: 0.6946, Validation Loss: 0.6956, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [330/500], Training Loss: 0.8190, Validation Loss: 0.6957, Training Accuracy: 0.5088, Validation Accuracy: 0.5056\n",
      "Epoch [331/500], Training Loss: 0.6966, Validation Loss: 0.6969, Training Accuracy: 0.5150, Validation Accuracy: 0.4944\n",
      "Epoch [332/500], Training Loss: 0.6962, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [333/500], Training Loss: 0.6971, Validation Loss: 0.6986, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [334/500], Training Loss: 0.9449, Validation Loss: 0.6936, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [335/500], Training Loss: 0.6943, Validation Loss: 0.6939, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [336/500], Training Loss: 0.6966, Validation Loss: 0.6931, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [337/500], Training Loss: 0.6941, Validation Loss: 0.6931, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [338/500], Training Loss: 0.6950, Validation Loss: 0.6935, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [339/500], Training Loss: 0.6942, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [340/500], Training Loss: 0.6967, Validation Loss: 0.6964, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [341/500], Training Loss: 0.6970, Validation Loss: 0.6976, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [342/500], Training Loss: 0.6955, Validation Loss: 0.6931, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [343/500], Training Loss: 0.6949, Validation Loss: 0.6935, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [344/500], Training Loss: 0.6966, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [345/500], Training Loss: 0.6975, Validation Loss: 0.6942, Training Accuracy: 0.4625, Validation Accuracy: 0.4944\n",
      "Epoch [346/500], Training Loss: 0.6945, Validation Loss: 0.6934, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [347/500], Training Loss: 0.6935, Validation Loss: 0.6949, Training Accuracy: 0.5075, Validation Accuracy: 0.4944\n",
      "Epoch [348/500], Training Loss: 0.6970, Validation Loss: 0.6939, Training Accuracy: 0.4725, Validation Accuracy: 0.4944\n",
      "Epoch [349/500], Training Loss: 0.6963, Validation Loss: 0.6965, Training Accuracy: 0.4963, Validation Accuracy: 0.4944\n",
      "Epoch [350/500], Training Loss: 0.6997, Validation Loss: 0.6946, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [351/500], Training Loss: 0.6951, Validation Loss: 0.6931, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [352/500], Training Loss: 0.6958, Validation Loss: 0.6936, Training Accuracy: 0.5075, Validation Accuracy: 0.4944\n",
      "Epoch [353/500], Training Loss: 0.6931, Validation Loss: 0.6932, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [354/500], Training Loss: 0.6933, Validation Loss: 0.6937, Training Accuracy: 0.5100, Validation Accuracy: 0.4944\n",
      "Epoch [355/500], Training Loss: 0.9424, Validation Loss: 0.6931, Training Accuracy: 0.4913, Validation Accuracy: 0.5056\n",
      "Epoch [356/500], Training Loss: 0.6936, Validation Loss: 0.6942, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [357/500], Training Loss: 0.6981, Validation Loss: 0.6947, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [358/500], Training Loss: 0.6942, Validation Loss: 0.6948, Training Accuracy: 0.5150, Validation Accuracy: 0.5056\n",
      "Epoch [359/500], Training Loss: 0.6986, Validation Loss: 0.6937, Training Accuracy: 0.4650, Validation Accuracy: 0.5056\n",
      "Epoch [360/500], Training Loss: 0.6952, Validation Loss: 0.6962, Training Accuracy: 0.5225, Validation Accuracy: 0.4944\n",
      "Epoch [361/500], Training Loss: 0.6947, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [362/500], Training Loss: 0.6948, Validation Loss: 0.6963, Training Accuracy: 0.5238, Validation Accuracy: 0.4944\n",
      "Epoch [363/500], Training Loss: 0.8202, Validation Loss: 0.6950, Training Accuracy: 0.5062, Validation Accuracy: 0.5056\n",
      "Epoch [364/500], Training Loss: 0.6942, Validation Loss: 0.6934, Training Accuracy: 0.5075, Validation Accuracy: 0.4944\n",
      "Epoch [365/500], Training Loss: 0.6961, Validation Loss: 0.6949, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [366/500], Training Loss: 0.6965, Validation Loss: 0.6939, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [367/500], Training Loss: 0.6958, Validation Loss: 0.6936, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [368/500], Training Loss: 0.6929, Validation Loss: 0.6938, Training Accuracy: 0.5138, Validation Accuracy: 0.4944\n",
      "Epoch [369/500], Training Loss: 0.6933, Validation Loss: 0.6931, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [370/500], Training Loss: 0.6939, Validation Loss: 0.6934, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [371/500], Training Loss: 0.9429, Validation Loss: 0.6937, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [372/500], Training Loss: 0.8169, Validation Loss: 0.6943, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [373/500], Training Loss: 0.6971, Validation Loss: 0.6949, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [374/500], Training Loss: 0.6937, Validation Loss: 0.6931, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [375/500], Training Loss: 0.6940, Validation Loss: 0.6958, Training Accuracy: 0.5100, Validation Accuracy: 0.4944\n",
      "Epoch [376/500], Training Loss: 0.6954, Validation Loss: 0.6938, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [377/500], Training Loss: 0.6946, Validation Loss: 0.6947, Training Accuracy: 0.5225, Validation Accuracy: 0.4944\n",
      "Epoch [378/500], Training Loss: 0.6942, Validation Loss: 0.6931, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [379/500], Training Loss: 0.6945, Validation Loss: 0.6931, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [380/500], Training Loss: 0.6959, Validation Loss: 0.6946, Training Accuracy: 0.4838, Validation Accuracy: 0.4944\n",
      "Epoch [381/500], Training Loss: 0.6939, Validation Loss: 0.6943, Training Accuracy: 0.5100, Validation Accuracy: 0.5056\n",
      "Epoch [382/500], Training Loss: 0.8179, Validation Loss: 0.6931, Training Accuracy: 0.4963, Validation Accuracy: 0.5056\n",
      "Epoch [383/500], Training Loss: 0.6943, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [384/500], Training Loss: 0.6948, Validation Loss: 0.6935, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [385/500], Training Loss: 0.6956, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [386/500], Training Loss: 0.6994, Validation Loss: 0.7012, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [387/500], Training Loss: 0.7012, Validation Loss: 0.6942, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [388/500], Training Loss: 0.8192, Validation Loss: 0.6934, Training Accuracy: 0.4938, Validation Accuracy: 0.5056\n",
      "Epoch [389/500], Training Loss: 0.6953, Validation Loss: 0.6932, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [390/500], Training Loss: 0.6936, Validation Loss: 0.6932, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [391/500], Training Loss: 0.6938, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [392/500], Training Loss: 0.6932, Validation Loss: 0.6939, Training Accuracy: 0.5112, Validation Accuracy: 0.4944\n",
      "Epoch [393/500], Training Loss: 0.6961, Validation Loss: 0.6950, Training Accuracy: 0.4650, Validation Accuracy: 0.4944\n",
      "Epoch [394/500], Training Loss: 0.6932, Validation Loss: 0.6934, Training Accuracy: 0.5050, Validation Accuracy: 0.5056\n",
      "Epoch [395/500], Training Loss: 0.6947, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [396/500], Training Loss: 0.6970, Validation Loss: 0.6975, Training Accuracy: 0.5100, Validation Accuracy: 0.5056\n",
      "Epoch [397/500], Training Loss: 0.6964, Validation Loss: 0.6957, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [398/500], Training Loss: 0.6969, Validation Loss: 0.6941, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [399/500], Training Loss: 0.6945, Validation Loss: 0.6933, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [400/500], Training Loss: 0.6932, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [401/500], Training Loss: 0.6943, Validation Loss: 0.6931, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [402/500], Training Loss: 0.6954, Validation Loss: 0.6939, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [403/500], Training Loss: 0.6944, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [404/500], Training Loss: 0.6958, Validation Loss: 0.6932, Training Accuracy: 0.4575, Validation Accuracy: 0.5056\n",
      "Epoch [405/500], Training Loss: 0.6976, Validation Loss: 0.6995, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [406/500], Training Loss: 0.6956, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [407/500], Training Loss: 0.6954, Validation Loss: 0.6942, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [408/500], Training Loss: 0.8187, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [409/500], Training Loss: 0.6949, Validation Loss: 0.6932, Training Accuracy: 0.4725, Validation Accuracy: 0.4944\n",
      "Epoch [410/500], Training Loss: 0.6997, Validation Loss: 0.6947, Training Accuracy: 0.4800, Validation Accuracy: 0.5056\n",
      "Epoch [411/500], Training Loss: 0.6958, Validation Loss: 0.6933, Training Accuracy: 0.4725, Validation Accuracy: 0.5056\n",
      "Epoch [412/500], Training Loss: 0.6931, Validation Loss: 0.6935, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [413/500], Training Loss: 0.6929, Validation Loss: 0.6967, Training Accuracy: 0.5200, Validation Accuracy: 0.5056\n",
      "Epoch [414/500], Training Loss: 0.6949, Validation Loss: 0.6949, Training Accuracy: 0.5012, Validation Accuracy: 0.4944\n",
      "Epoch [415/500], Training Loss: 0.6964, Validation Loss: 0.6931, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [416/500], Training Loss: 0.6950, Validation Loss: 0.6937, Training Accuracy: 0.5150, Validation Accuracy: 0.5056\n",
      "Epoch [417/500], Training Loss: 0.6948, Validation Loss: 0.6952, Training Accuracy: 0.5050, Validation Accuracy: 0.4944\n",
      "Epoch [418/500], Training Loss: 0.6963, Validation Loss: 0.6954, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [419/500], Training Loss: 0.6929, Validation Loss: 0.6962, Training Accuracy: 0.5238, Validation Accuracy: 0.4944\n",
      "Epoch [420/500], Training Loss: 0.6969, Validation Loss: 0.6941, Training Accuracy: 0.4650, Validation Accuracy: 0.4944\n",
      "Epoch [421/500], Training Loss: 0.6941, Validation Loss: 0.6935, Training Accuracy: 0.4850, Validation Accuracy: 0.4944\n",
      "Epoch [422/500], Training Loss: 0.6952, Validation Loss: 0.6932, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [423/500], Training Loss: 0.6945, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [424/500], Training Loss: 0.6940, Validation Loss: 0.6937, Training Accuracy: 0.4888, Validation Accuracy: 0.4944\n",
      "Epoch [425/500], Training Loss: 0.8189, Validation Loss: 0.6939, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [426/500], Training Loss: 0.6957, Validation Loss: 0.6931, Training Accuracy: 0.4675, Validation Accuracy: 0.5056\n",
      "Epoch [427/500], Training Loss: 0.6948, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [428/500], Training Loss: 0.6955, Validation Loss: 0.6941, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [429/500], Training Loss: 0.6947, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [430/500], Training Loss: 0.6940, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [431/500], Training Loss: 0.6981, Validation Loss: 0.6943, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [432/500], Training Loss: 2.0566, Validation Loss: 0.6948, Training Accuracy: 0.5075, Validation Accuracy: 0.4944\n",
      "Epoch [433/500], Training Loss: 0.6937, Validation Loss: 0.6931, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [434/500], Training Loss: 0.6941, Validation Loss: 0.6941, Training Accuracy: 0.5075, Validation Accuracy: 0.4944\n",
      "Epoch [435/500], Training Loss: 0.6953, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [436/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [437/500], Training Loss: 0.6947, Validation Loss: 0.6945, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [438/500], Training Loss: 0.8165, Validation Loss: 0.6934, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [439/500], Training Loss: 0.6973, Validation Loss: 0.6932, Training Accuracy: 0.4625, Validation Accuracy: 0.5056\n",
      "Epoch [440/500], Training Loss: 0.6943, Validation Loss: 0.6938, Training Accuracy: 0.5025, Validation Accuracy: 0.4944\n",
      "Epoch [441/500], Training Loss: 0.6989, Validation Loss: 0.6933, Training Accuracy: 0.4600, Validation Accuracy: 0.4944\n",
      "Epoch [442/500], Training Loss: 0.6964, Validation Loss: 0.6939, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [443/500], Training Loss: 0.8190, Validation Loss: 0.6941, Training Accuracy: 0.5000, Validation Accuracy: 0.4944\n",
      "Epoch [444/500], Training Loss: 0.6936, Validation Loss: 0.6931, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [445/500], Training Loss: 0.6946, Validation Loss: 0.6943, Training Accuracy: 0.4975, Validation Accuracy: 0.5056\n",
      "Epoch [446/500], Training Loss: 0.6947, Validation Loss: 0.6946, Training Accuracy: 0.5125, Validation Accuracy: 0.4944\n",
      "Epoch [447/500], Training Loss: 0.8192, Validation Loss: 0.6931, Training Accuracy: 0.4500, Validation Accuracy: 0.5056\n",
      "Epoch [448/500], Training Loss: 0.6965, Validation Loss: 0.6939, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [449/500], Training Loss: 0.9461, Validation Loss: 0.6935, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [450/500], Training Loss: 0.6939, Validation Loss: 0.6932, Training Accuracy: 0.4838, Validation Accuracy: 0.4944\n",
      "Epoch [451/500], Training Loss: 0.6951, Validation Loss: 0.6931, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [452/500], Training Loss: 0.6944, Validation Loss: 0.6931, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [453/500], Training Loss: 0.8254, Validation Loss: 0.6931, Training Accuracy: 0.4888, Validation Accuracy: 0.5056\n",
      "Epoch [454/500], Training Loss: 0.8189, Validation Loss: 0.6931, Training Accuracy: 0.4763, Validation Accuracy: 0.5056\n",
      "Epoch [455/500], Training Loss: 0.6938, Validation Loss: 0.6960, Training Accuracy: 0.5075, Validation Accuracy: 0.4944\n",
      "Epoch [456/500], Training Loss: 0.6996, Validation Loss: 0.6967, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [457/500], Training Loss: 0.6946, Validation Loss: 0.6943, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [458/500], Training Loss: 0.6941, Validation Loss: 0.6931, Training Accuracy: 0.4950, Validation Accuracy: 0.5056\n",
      "Epoch [459/500], Training Loss: 0.6957, Validation Loss: 0.6952, Training Accuracy: 0.4988, Validation Accuracy: 0.4944\n",
      "Epoch [460/500], Training Loss: 0.8190, Validation Loss: 0.6933, Training Accuracy: 0.4775, Validation Accuracy: 0.4944\n",
      "Epoch [461/500], Training Loss: 0.6928, Validation Loss: 0.6932, Training Accuracy: 0.5075, Validation Accuracy: 0.5056\n",
      "Epoch [462/500], Training Loss: 0.6951, Validation Loss: 0.6936, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [463/500], Training Loss: 0.6985, Validation Loss: 0.6951, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [464/500], Training Loss: 0.6939, Validation Loss: 0.6931, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [465/500], Training Loss: 0.6951, Validation Loss: 0.6932, Training Accuracy: 0.4725, Validation Accuracy: 0.4944\n",
      "Epoch [466/500], Training Loss: 0.6959, Validation Loss: 0.6972, Training Accuracy: 0.5012, Validation Accuracy: 0.5056\n",
      "Epoch [467/500], Training Loss: 0.6963, Validation Loss: 0.6932, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [468/500], Training Loss: 0.6964, Validation Loss: 0.6938, Training Accuracy: 0.4600, Validation Accuracy: 0.4944\n",
      "Epoch [469/500], Training Loss: 0.6958, Validation Loss: 0.6987, Training Accuracy: 0.5225, Validation Accuracy: 0.5056\n",
      "Epoch [470/500], Training Loss: 0.6994, Validation Loss: 0.6931, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [471/500], Training Loss: 0.8194, Validation Loss: 0.6954, Training Accuracy: 0.4950, Validation Accuracy: 0.4944\n",
      "Epoch [472/500], Training Loss: 0.8198, Validation Loss: 0.6932, Training Accuracy: 0.4900, Validation Accuracy: 0.4944\n",
      "Epoch [473/500], Training Loss: 0.8179, Validation Loss: 0.6952, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [474/500], Training Loss: 0.6946, Validation Loss: 0.6933, Training Accuracy: 0.4800, Validation Accuracy: 0.4944\n",
      "Epoch [475/500], Training Loss: 0.6952, Validation Loss: 0.6931, Training Accuracy: 0.4600, Validation Accuracy: 0.5056\n",
      "Epoch [476/500], Training Loss: 0.6947, Validation Loss: 0.6933, Training Accuracy: 0.4875, Validation Accuracy: 0.4944\n",
      "Epoch [477/500], Training Loss: 0.6964, Validation Loss: 0.6954, Training Accuracy: 0.4775, Validation Accuracy: 0.4944\n",
      "Epoch [478/500], Training Loss: 0.6950, Validation Loss: 0.6933, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [479/500], Training Loss: 0.6949, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [480/500], Training Loss: 0.8172, Validation Loss: 0.6931, Training Accuracy: 0.5038, Validation Accuracy: 0.5056\n",
      "Epoch [481/500], Training Loss: 0.8189, Validation Loss: 0.6931, Training Accuracy: 0.4963, Validation Accuracy: 0.5056\n",
      "Epoch [482/500], Training Loss: 0.6950, Validation Loss: 0.6950, Training Accuracy: 0.4925, Validation Accuracy: 0.5056\n",
      "Epoch [483/500], Training Loss: 0.6942, Validation Loss: 0.6935, Training Accuracy: 0.4763, Validation Accuracy: 0.5056\n",
      "Epoch [484/500], Training Loss: 0.6941, Validation Loss: 0.6931, Training Accuracy: 0.4650, Validation Accuracy: 0.5056\n",
      "Epoch [485/500], Training Loss: 0.6941, Validation Loss: 0.6932, Training Accuracy: 0.4700, Validation Accuracy: 0.5056\n",
      "Epoch [486/500], Training Loss: 0.6944, Validation Loss: 0.6931, Training Accuracy: 0.4875, Validation Accuracy: 0.5056\n",
      "Epoch [487/500], Training Loss: 0.8179, Validation Loss: 0.6938, Training Accuracy: 0.5050, Validation Accuracy: 0.4944\n",
      "Epoch [488/500], Training Loss: 0.6947, Validation Loss: 0.6939, Training Accuracy: 0.4825, Validation Accuracy: 0.4944\n",
      "Epoch [489/500], Training Loss: 0.6936, Validation Loss: 0.6939, Training Accuracy: 0.4825, Validation Accuracy: 0.5056\n",
      "Epoch [490/500], Training Loss: 0.6939, Validation Loss: 0.6931, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [491/500], Training Loss: 0.8189, Validation Loss: 0.6931, Training Accuracy: 0.4850, Validation Accuracy: 0.5056\n",
      "Epoch [492/500], Training Loss: 0.6950, Validation Loss: 0.6961, Training Accuracy: 0.4925, Validation Accuracy: 0.4944\n",
      "Epoch [493/500], Training Loss: 0.6952, Validation Loss: 0.6940, Training Accuracy: 0.5025, Validation Accuracy: 0.5056\n",
      "Epoch [494/500], Training Loss: 0.6955, Validation Loss: 0.6936, Training Accuracy: 0.4775, Validation Accuracy: 0.5056\n",
      "Epoch [495/500], Training Loss: 0.6942, Validation Loss: 0.6933, Training Accuracy: 0.4975, Validation Accuracy: 0.4944\n",
      "Epoch [496/500], Training Loss: 0.6941, Validation Loss: 0.6931, Training Accuracy: 0.5000, Validation Accuracy: 0.5056\n",
      "Epoch [497/500], Training Loss: 0.8188, Validation Loss: 0.6935, Training Accuracy: 0.4900, Validation Accuracy: 0.5056\n",
      "Epoch [498/500], Training Loss: 0.6977, Validation Loss: 0.6965, Training Accuracy: 0.4750, Validation Accuracy: 0.5056\n",
      "Epoch [499/500], Training Loss: 0.6941, Validation Loss: 0.6965, Training Accuracy: 0.5062, Validation Accuracy: 0.4944\n",
      "Epoch [500/500], Training Loss: 0.8202, Validation Loss: 0.6939, Training Accuracy: 0.4963, Validation Accuracy: 0.4944\n",
      "Training Time: 6.90 seconds\n",
      "Epoch [1/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [2/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [3/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [4/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [5/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [6/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [7/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [8/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [9/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [10/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [11/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [12/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [13/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [14/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [15/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [16/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [17/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [18/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [19/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [20/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [21/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [22/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [23/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [24/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [25/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [26/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [27/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [28/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [29/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [30/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [31/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [32/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [33/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [34/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [35/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [36/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [37/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [38/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [39/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [40/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [41/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [42/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [43/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [44/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [45/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [46/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [47/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [48/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [49/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [50/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [51/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [52/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [53/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [54/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [55/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [56/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [57/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [58/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [59/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [60/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [61/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [62/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [63/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [64/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [65/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [66/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [67/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [68/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [69/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [70/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [71/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [72/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [73/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [74/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [75/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [76/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [77/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [78/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [79/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [80/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [81/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [82/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [83/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [84/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [85/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [86/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [87/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [88/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [89/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [90/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [91/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [92/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [93/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [94/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [95/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [96/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [97/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [98/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [99/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [100/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [101/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [102/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [103/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [104/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [105/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [106/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [107/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [108/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [109/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [110/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [111/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [112/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [113/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [114/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [115/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [116/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [117/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [118/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [119/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [120/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [121/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [122/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [123/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [124/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [125/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [126/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [127/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [128/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [129/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [130/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [131/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [132/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [133/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [134/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [135/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [136/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [137/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [138/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [139/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [140/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [141/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [142/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [143/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [144/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [145/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [146/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [147/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [148/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [149/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [150/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [151/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [152/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [153/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [154/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [155/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [156/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [157/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [158/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [159/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [160/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [161/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [162/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [163/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [164/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [165/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [166/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [167/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [168/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [169/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [170/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [171/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [172/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [173/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [174/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [175/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [176/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [177/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [178/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [179/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [180/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [181/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [182/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [183/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [184/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [185/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [186/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [187/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [188/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [189/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [190/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [191/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [192/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [193/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [194/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [195/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [196/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [197/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [198/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [199/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [200/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [201/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [202/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [203/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [204/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [205/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [206/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [207/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [208/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [209/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [210/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [211/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [212/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [213/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [214/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [215/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [216/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [217/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [218/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [219/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [220/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [221/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [222/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [223/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [224/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [225/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [226/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [227/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [228/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [229/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [230/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [231/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [232/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [233/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [234/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [235/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [236/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [237/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [238/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [239/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [240/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [241/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [242/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [243/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [244/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [245/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [246/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [247/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [248/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [249/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [250/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [251/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [252/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [253/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [254/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [255/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [256/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [257/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [258/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [259/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [260/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [261/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [262/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [263/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [264/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [265/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [266/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [267/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [268/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [269/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [270/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [271/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [272/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [273/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [274/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [275/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [276/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [277/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [278/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [279/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [280/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [281/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [282/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [283/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [284/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [285/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [286/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [287/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [288/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [289/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [290/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [291/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [292/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [293/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [294/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [295/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [296/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [297/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [298/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [299/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [300/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [301/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [302/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [303/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [304/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [305/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [306/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [307/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [308/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [309/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [310/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [311/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [312/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [313/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [314/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [315/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [316/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [317/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [318/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [319/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [320/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [321/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [322/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [323/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [324/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [325/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [326/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [327/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [328/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [329/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [330/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [331/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [332/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [333/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [334/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [335/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [336/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [337/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [338/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [339/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [340/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [341/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [342/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [343/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [344/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [345/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [346/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [347/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [348/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [349/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [350/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [351/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [352/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [353/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [354/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [355/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [356/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [357/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [358/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [359/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [360/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [361/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [362/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [363/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [364/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [365/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/v5ysl19s0hbdkdprhb3xqd4r0000gn/T/ipykernel_34536/745533526.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_weights.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [366/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [367/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [368/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [369/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [370/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [371/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [372/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [373/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [374/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [375/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [376/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [377/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [378/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [379/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [380/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [381/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [382/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [383/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [384/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [385/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [386/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [387/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [388/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [389/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [390/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [391/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [392/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [393/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [394/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [395/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [396/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [397/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [398/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [399/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [400/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [401/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [402/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [403/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [404/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [405/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [406/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [407/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [408/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [409/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [410/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [411/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [412/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [413/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [414/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [415/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [416/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [417/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [418/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [419/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [420/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [421/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [422/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [423/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [424/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [425/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [426/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [427/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [428/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [429/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [430/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [431/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [432/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [433/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [434/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [435/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [436/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [437/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [438/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [439/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [440/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [441/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [442/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [443/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [444/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [445/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [446/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [447/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [448/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [449/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [450/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [451/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [452/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [453/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [454/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [455/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [456/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [457/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [458/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [459/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [460/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [461/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [462/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [463/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [464/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [465/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [466/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [467/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [468/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [469/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [470/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [471/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [472/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [473/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [474/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [475/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [476/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [477/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [478/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [479/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [480/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [481/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [482/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [483/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [484/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [485/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [486/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [487/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [488/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [489/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [490/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [491/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [492/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [493/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [494/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [495/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [496/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [497/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [498/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [499/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [500/500], Test Loss: 0.6677, Testing Accuracy: 0.5455\n",
      "Epoch [1/500], Training Loss: 0.5954, Validation Loss: 0.5132, Training Accuracy: 0.6963, Validation Accuracy: 0.7640\n",
      "Epoch [2/500], Training Loss: 0.5534, Validation Loss: 0.5218, Training Accuracy: 0.7388, Validation Accuracy: 0.7528\n",
      "Epoch [3/500], Training Loss: 0.5230, Validation Loss: 0.4770, Training Accuracy: 0.7450, Validation Accuracy: 0.7640\n",
      "Epoch [4/500], Training Loss: 0.5165, Validation Loss: 0.5134, Training Accuracy: 0.7350, Validation Accuracy: 0.7753\n",
      "Epoch [5/500], Training Loss: 0.5207, Validation Loss: 0.4918, Training Accuracy: 0.7588, Validation Accuracy: 0.7865\n",
      "Epoch [6/500], Training Loss: 0.5290, Validation Loss: 0.5143, Training Accuracy: 0.7475, Validation Accuracy: 0.7978\n",
      "Epoch [7/500], Training Loss: 0.4961, Validation Loss: 0.5103, Training Accuracy: 0.7600, Validation Accuracy: 0.7191\n",
      "Epoch [8/500], Training Loss: 0.4711, Validation Loss: 0.5040, Training Accuracy: 0.7688, Validation Accuracy: 0.7640\n",
      "Epoch [9/500], Training Loss: 0.4925, Validation Loss: 0.5286, Training Accuracy: 0.7688, Validation Accuracy: 0.7416\n",
      "Epoch [10/500], Training Loss: 0.4965, Validation Loss: 0.4962, Training Accuracy: 0.7588, Validation Accuracy: 0.7528\n",
      "Epoch [11/500], Training Loss: 0.4679, Validation Loss: 0.5033, Training Accuracy: 0.7863, Validation Accuracy: 0.7978\n",
      "Epoch [12/500], Training Loss: 0.4774, Validation Loss: 0.4692, Training Accuracy: 0.7775, Validation Accuracy: 0.7978\n",
      "Epoch [13/500], Training Loss: 0.4944, Validation Loss: 0.5797, Training Accuracy: 0.7675, Validation Accuracy: 0.7640\n",
      "Epoch [14/500], Training Loss: 0.4861, Validation Loss: 0.5137, Training Accuracy: 0.7700, Validation Accuracy: 0.7528\n",
      "Epoch [15/500], Training Loss: 0.4552, Validation Loss: 0.5625, Training Accuracy: 0.7775, Validation Accuracy: 0.7528\n",
      "Epoch [16/500], Training Loss: 0.4884, Validation Loss: 0.5384, Training Accuracy: 0.7550, Validation Accuracy: 0.7191\n",
      "Epoch [17/500], Training Loss: 0.4754, Validation Loss: 0.5533, Training Accuracy: 0.7638, Validation Accuracy: 0.7303\n",
      "Epoch [18/500], Training Loss: 0.4880, Validation Loss: 0.5454, Training Accuracy: 0.7550, Validation Accuracy: 0.7640\n",
      "Epoch [19/500], Training Loss: 0.4546, Validation Loss: 0.5126, Training Accuracy: 0.7712, Validation Accuracy: 0.7640\n",
      "Epoch [20/500], Training Loss: 0.4587, Validation Loss: 0.5036, Training Accuracy: 0.7788, Validation Accuracy: 0.7753\n",
      "Epoch [21/500], Training Loss: 0.4693, Validation Loss: 0.4930, Training Accuracy: 0.7825, Validation Accuracy: 0.7978\n",
      "Epoch [22/500], Training Loss: 0.4497, Validation Loss: 0.5547, Training Accuracy: 0.8100, Validation Accuracy: 0.7528\n",
      "Epoch [23/500], Training Loss: 0.5092, Validation Loss: 0.5012, Training Accuracy: 0.7600, Validation Accuracy: 0.7640\n",
      "Epoch [24/500], Training Loss: 0.4530, Validation Loss: 0.4598, Training Accuracy: 0.7825, Validation Accuracy: 0.7640\n",
      "Epoch [25/500], Training Loss: 0.4212, Validation Loss: 0.5288, Training Accuracy: 0.8163, Validation Accuracy: 0.7416\n",
      "Epoch [26/500], Training Loss: 0.4325, Validation Loss: 0.5046, Training Accuracy: 0.8125, Validation Accuracy: 0.7640\n",
      "Epoch [27/500], Training Loss: 0.4365, Validation Loss: 0.5496, Training Accuracy: 0.7913, Validation Accuracy: 0.7640\n",
      "Epoch [28/500], Training Loss: 0.4328, Validation Loss: 0.5480, Training Accuracy: 0.8025, Validation Accuracy: 0.7416\n",
      "Epoch [29/500], Training Loss: 0.4097, Validation Loss: 0.5631, Training Accuracy: 0.7975, Validation Accuracy: 0.7528\n",
      "Epoch [30/500], Training Loss: 0.4288, Validation Loss: 0.5342, Training Accuracy: 0.8025, Validation Accuracy: 0.7978\n",
      "Epoch [31/500], Training Loss: 0.4738, Validation Loss: 0.4718, Training Accuracy: 0.7662, Validation Accuracy: 0.8090\n",
      "Epoch [32/500], Training Loss: 0.4254, Validation Loss: 0.4920, Training Accuracy: 0.7937, Validation Accuracy: 0.7978\n",
      "Epoch [33/500], Training Loss: 0.4045, Validation Loss: 0.4762, Training Accuracy: 0.8025, Validation Accuracy: 0.7978\n",
      "Epoch [34/500], Training Loss: 0.4193, Validation Loss: 0.4243, Training Accuracy: 0.8037, Validation Accuracy: 0.8202\n",
      "Epoch [35/500], Training Loss: 0.4013, Validation Loss: 0.4555, Training Accuracy: 0.8175, Validation Accuracy: 0.7640\n",
      "Epoch [36/500], Training Loss: 0.4182, Validation Loss: 0.4825, Training Accuracy: 0.8187, Validation Accuracy: 0.7640\n",
      "Epoch [37/500], Training Loss: 0.4136, Validation Loss: 0.4922, Training Accuracy: 0.8063, Validation Accuracy: 0.7753\n",
      "Epoch [38/500], Training Loss: 0.4321, Validation Loss: 0.4569, Training Accuracy: 0.8037, Validation Accuracy: 0.7978\n",
      "Epoch [39/500], Training Loss: 0.3788, Validation Loss: 0.5097, Training Accuracy: 0.8225, Validation Accuracy: 0.7753\n",
      "Epoch [40/500], Training Loss: 0.3636, Validation Loss: 0.5341, Training Accuracy: 0.8225, Validation Accuracy: 0.7865\n",
      "Epoch [41/500], Training Loss: 0.4010, Validation Loss: 0.5032, Training Accuracy: 0.8400, Validation Accuracy: 0.7865\n",
      "Epoch [42/500], Training Loss: 0.4151, Validation Loss: 0.5170, Training Accuracy: 0.8075, Validation Accuracy: 0.7528\n",
      "Epoch [43/500], Training Loss: 0.4163, Validation Loss: 0.4634, Training Accuracy: 0.8013, Validation Accuracy: 0.7640\n",
      "Epoch [44/500], Training Loss: 0.4004, Validation Loss: 0.5089, Training Accuracy: 0.8100, Validation Accuracy: 0.7865\n",
      "Epoch [45/500], Training Loss: 0.3699, Validation Loss: 0.5126, Training Accuracy: 0.8313, Validation Accuracy: 0.7753\n",
      "Epoch [46/500], Training Loss: 0.4983, Validation Loss: 0.4500, Training Accuracy: 0.8137, Validation Accuracy: 0.7528\n",
      "Epoch [47/500], Training Loss: 0.4257, Validation Loss: 0.4538, Training Accuracy: 0.8075, Validation Accuracy: 0.7528\n",
      "Epoch [48/500], Training Loss: 0.4087, Validation Loss: 0.4415, Training Accuracy: 0.8025, Validation Accuracy: 0.7978\n",
      "Epoch [49/500], Training Loss: 0.3895, Validation Loss: 0.4642, Training Accuracy: 0.8350, Validation Accuracy: 0.7865\n",
      "Epoch [50/500], Training Loss: 0.3965, Validation Loss: 0.4490, Training Accuracy: 0.8125, Validation Accuracy: 0.7865\n",
      "Epoch [51/500], Training Loss: 0.3860, Validation Loss: 0.5479, Training Accuracy: 0.8100, Validation Accuracy: 0.7865\n",
      "Epoch [52/500], Training Loss: 0.3903, Validation Loss: 0.5068, Training Accuracy: 0.8137, Validation Accuracy: 0.7528\n",
      "Epoch [53/500], Training Loss: 0.4359, Validation Loss: 0.5855, Training Accuracy: 0.7975, Validation Accuracy: 0.6854\n",
      "Epoch [54/500], Training Loss: 0.4002, Validation Loss: 0.4694, Training Accuracy: 0.8187, Validation Accuracy: 0.7978\n",
      "Epoch [55/500], Training Loss: 0.3607, Validation Loss: 0.6687, Training Accuracy: 0.8425, Validation Accuracy: 0.7978\n",
      "Epoch [56/500], Training Loss: 0.3566, Validation Loss: 0.4804, Training Accuracy: 0.8425, Validation Accuracy: 0.8090\n",
      "Epoch [57/500], Training Loss: 0.3494, Validation Loss: 0.4679, Training Accuracy: 0.8375, Validation Accuracy: 0.7865\n",
      "Epoch [58/500], Training Loss: 0.3851, Validation Loss: 0.5266, Training Accuracy: 0.8250, Validation Accuracy: 0.7640\n",
      "Epoch [59/500], Training Loss: 0.3592, Validation Loss: 0.4535, Training Accuracy: 0.8413, Validation Accuracy: 0.8202\n",
      "Epoch [60/500], Training Loss: 0.3516, Validation Loss: 0.4313, Training Accuracy: 0.8425, Validation Accuracy: 0.8202\n",
      "Epoch [61/500], Training Loss: 0.3790, Validation Loss: 0.4688, Training Accuracy: 0.8375, Validation Accuracy: 0.7865\n",
      "Epoch [62/500], Training Loss: 0.3788, Validation Loss: 0.4818, Training Accuracy: 0.8113, Validation Accuracy: 0.7865\n",
      "Epoch [63/500], Training Loss: 0.3860, Validation Loss: 0.4219, Training Accuracy: 0.8313, Validation Accuracy: 0.8090\n",
      "Epoch [64/500], Training Loss: 0.3887, Validation Loss: 0.5380, Training Accuracy: 0.8213, Validation Accuracy: 0.7753\n",
      "Epoch [65/500], Training Loss: 0.4037, Validation Loss: 0.4529, Training Accuracy: 0.8150, Validation Accuracy: 0.7978\n",
      "Epoch [66/500], Training Loss: 0.3798, Validation Loss: 0.4726, Training Accuracy: 0.8213, Validation Accuracy: 0.7753\n",
      "Epoch [67/500], Training Loss: 0.3914, Validation Loss: 0.5431, Training Accuracy: 0.8137, Validation Accuracy: 0.7528\n",
      "Epoch [68/500], Training Loss: 0.3822, Validation Loss: 0.4187, Training Accuracy: 0.8275, Validation Accuracy: 0.8202\n",
      "Epoch [69/500], Training Loss: 0.3607, Validation Loss: 0.4567, Training Accuracy: 0.8400, Validation Accuracy: 0.7640\n",
      "Epoch [70/500], Training Loss: 0.3554, Validation Loss: 0.4592, Training Accuracy: 0.8163, Validation Accuracy: 0.8202\n",
      "Epoch [71/500], Training Loss: 0.3697, Validation Loss: 0.4607, Training Accuracy: 0.8300, Validation Accuracy: 0.8090\n",
      "Epoch [72/500], Training Loss: 0.3380, Validation Loss: 0.6140, Training Accuracy: 0.8538, Validation Accuracy: 0.8202\n",
      "Epoch [73/500], Training Loss: 0.3610, Validation Loss: 0.4467, Training Accuracy: 0.8313, Validation Accuracy: 0.7978\n",
      "Epoch [74/500], Training Loss: 0.4620, Validation Loss: 0.4967, Training Accuracy: 0.8550, Validation Accuracy: 0.7640\n",
      "Epoch [75/500], Training Loss: 0.3234, Validation Loss: 0.7198, Training Accuracy: 0.8562, Validation Accuracy: 0.8202\n",
      "Epoch [76/500], Training Loss: 0.3491, Validation Loss: 0.4713, Training Accuracy: 0.8512, Validation Accuracy: 0.7753\n",
      "Epoch [77/500], Training Loss: 0.3289, Validation Loss: 0.5482, Training Accuracy: 0.8438, Validation Accuracy: 0.7978\n",
      "Epoch [78/500], Training Loss: 0.3543, Validation Loss: 0.4336, Training Accuracy: 0.8413, Validation Accuracy: 0.8202\n",
      "Epoch [79/500], Training Loss: 0.3563, Validation Loss: 0.4928, Training Accuracy: 0.8413, Validation Accuracy: 0.8202\n",
      "Epoch [80/500], Training Loss: 0.3456, Validation Loss: 0.5227, Training Accuracy: 0.8488, Validation Accuracy: 0.7865\n",
      "Epoch [81/500], Training Loss: 0.3312, Validation Loss: 0.5110, Training Accuracy: 0.8638, Validation Accuracy: 0.7753\n",
      "Epoch [82/500], Training Loss: 0.3506, Validation Loss: 0.5988, Training Accuracy: 0.8425, Validation Accuracy: 0.7528\n",
      "Epoch [83/500], Training Loss: 0.3587, Validation Loss: 0.5163, Training Accuracy: 0.8538, Validation Accuracy: 0.8427\n",
      "Epoch [84/500], Training Loss: 0.3693, Validation Loss: 0.4593, Training Accuracy: 0.8425, Validation Accuracy: 0.8090\n",
      "Epoch [85/500], Training Loss: 0.3312, Validation Loss: 0.5043, Training Accuracy: 0.8550, Validation Accuracy: 0.7865\n",
      "Epoch [86/500], Training Loss: 0.4212, Validation Loss: 0.4658, Training Accuracy: 0.8263, Validation Accuracy: 0.7865\n",
      "Epoch [87/500], Training Loss: 0.3945, Validation Loss: 0.4735, Training Accuracy: 0.8300, Validation Accuracy: 0.8427\n",
      "Epoch [88/500], Training Loss: 0.3548, Validation Loss: 0.4290, Training Accuracy: 0.8438, Validation Accuracy: 0.8427\n",
      "Epoch [89/500], Training Loss: 0.3552, Validation Loss: 0.4517, Training Accuracy: 0.8400, Validation Accuracy: 0.8315\n",
      "Epoch [90/500], Training Loss: 0.3650, Validation Loss: 0.4469, Training Accuracy: 0.8337, Validation Accuracy: 0.8202\n",
      "Epoch [91/500], Training Loss: 0.3508, Validation Loss: 0.3800, Training Accuracy: 0.8500, Validation Accuracy: 0.8202\n",
      "Epoch [92/500], Training Loss: 0.3213, Validation Loss: 0.4155, Training Accuracy: 0.8600, Validation Accuracy: 0.8315\n",
      "Epoch [93/500], Training Loss: 0.3046, Validation Loss: 0.4592, Training Accuracy: 0.8525, Validation Accuracy: 0.7978\n",
      "Epoch [94/500], Training Loss: 0.3289, Validation Loss: 0.3901, Training Accuracy: 0.8675, Validation Accuracy: 0.8090\n",
      "Epoch [95/500], Training Loss: 0.3311, Validation Loss: 0.4424, Training Accuracy: 0.8488, Validation Accuracy: 0.8090\n",
      "Epoch [96/500], Training Loss: 0.3506, Validation Loss: 0.3851, Training Accuracy: 0.8550, Validation Accuracy: 0.8202\n",
      "Epoch [97/500], Training Loss: 0.3167, Validation Loss: 0.4121, Training Accuracy: 0.8662, Validation Accuracy: 0.8315\n",
      "Epoch [98/500], Training Loss: 0.3193, Validation Loss: 0.4483, Training Accuracy: 0.8725, Validation Accuracy: 0.8315\n",
      "Epoch [99/500], Training Loss: 0.3252, Validation Loss: 0.4476, Training Accuracy: 0.8588, Validation Accuracy: 0.8202\n",
      "Epoch [100/500], Training Loss: 0.4548, Validation Loss: 0.4103, Training Accuracy: 0.8488, Validation Accuracy: 0.8090\n",
      "Epoch [101/500], Training Loss: 0.3521, Validation Loss: 0.4137, Training Accuracy: 0.8538, Validation Accuracy: 0.7978\n",
      "Epoch [102/500], Training Loss: 0.3301, Validation Loss: 0.4954, Training Accuracy: 0.8562, Validation Accuracy: 0.8202\n",
      "Epoch [103/500], Training Loss: 0.3082, Validation Loss: 0.4582, Training Accuracy: 0.8612, Validation Accuracy: 0.8202\n",
      "Epoch [104/500], Training Loss: 0.3607, Validation Loss: 0.4765, Training Accuracy: 0.8400, Validation Accuracy: 0.7978\n",
      "Epoch [105/500], Training Loss: 0.3099, Validation Loss: 0.5421, Training Accuracy: 0.8525, Validation Accuracy: 0.8202\n",
      "Epoch [106/500], Training Loss: 0.3559, Validation Loss: 0.5343, Training Accuracy: 0.8425, Validation Accuracy: 0.7528\n",
      "Epoch [107/500], Training Loss: 0.3620, Validation Loss: 0.5264, Training Accuracy: 0.8525, Validation Accuracy: 0.7865\n",
      "Epoch [108/500], Training Loss: 0.3573, Validation Loss: 0.5820, Training Accuracy: 0.8512, Validation Accuracy: 0.7753\n",
      "Epoch [109/500], Training Loss: 0.3752, Validation Loss: 0.4470, Training Accuracy: 0.8462, Validation Accuracy: 0.8202\n",
      "Epoch [110/500], Training Loss: 0.3367, Validation Loss: 0.4287, Training Accuracy: 0.8550, Validation Accuracy: 0.8202\n",
      "Epoch [111/500], Training Loss: 0.3128, Validation Loss: 0.5457, Training Accuracy: 0.8488, Validation Accuracy: 0.8090\n",
      "Epoch [112/500], Training Loss: 0.4102, Validation Loss: 0.5175, Training Accuracy: 0.8400, Validation Accuracy: 0.7640\n",
      "Epoch [113/500], Training Loss: 0.3556, Validation Loss: 0.5037, Training Accuracy: 0.8375, Validation Accuracy: 0.7865\n",
      "Epoch [114/500], Training Loss: 0.3606, Validation Loss: 0.4744, Training Accuracy: 0.8512, Validation Accuracy: 0.8090\n",
      "Epoch [115/500], Training Loss: 0.3316, Validation Loss: 0.5019, Training Accuracy: 0.8612, Validation Accuracy: 0.8090\n",
      "Epoch [116/500], Training Loss: 0.2813, Validation Loss: 0.5545, Training Accuracy: 0.8650, Validation Accuracy: 0.7753\n",
      "Epoch [117/500], Training Loss: 0.2862, Validation Loss: 0.4495, Training Accuracy: 0.8762, Validation Accuracy: 0.8202\n",
      "Epoch [118/500], Training Loss: 0.3268, Validation Loss: 0.4094, Training Accuracy: 0.8612, Validation Accuracy: 0.8315\n",
      "Epoch [119/500], Training Loss: 0.3211, Validation Loss: 0.4378, Training Accuracy: 0.8725, Validation Accuracy: 0.8090\n",
      "Epoch [120/500], Training Loss: 0.3217, Validation Loss: 0.3634, Training Accuracy: 0.8738, Validation Accuracy: 0.8427\n",
      "Epoch [121/500], Training Loss: 0.3109, Validation Loss: 0.4179, Training Accuracy: 0.8638, Validation Accuracy: 0.8315\n",
      "Epoch [122/500], Training Loss: 0.2941, Validation Loss: 0.5176, Training Accuracy: 0.8762, Validation Accuracy: 0.8090\n",
      "Epoch [123/500], Training Loss: 0.2814, Validation Loss: 0.5154, Training Accuracy: 0.8912, Validation Accuracy: 0.8427\n",
      "Epoch [124/500], Training Loss: 0.2893, Validation Loss: 0.4695, Training Accuracy: 0.8812, Validation Accuracy: 0.7978\n",
      "Epoch [125/500], Training Loss: 0.3185, Validation Loss: 0.4739, Training Accuracy: 0.8638, Validation Accuracy: 0.7753\n",
      "Epoch [126/500], Training Loss: 0.2902, Validation Loss: 0.5103, Training Accuracy: 0.8862, Validation Accuracy: 0.7978\n",
      "Epoch [127/500], Training Loss: 0.2884, Validation Loss: 0.4804, Training Accuracy: 0.8775, Validation Accuracy: 0.7978\n",
      "Epoch [128/500], Training Loss: 0.2846, Validation Loss: 0.4851, Training Accuracy: 0.8762, Validation Accuracy: 0.8202\n",
      "Epoch [129/500], Training Loss: 0.2719, Validation Loss: 0.5778, Training Accuracy: 0.8762, Validation Accuracy: 0.8202\n",
      "Epoch [130/500], Training Loss: 0.3068, Validation Loss: 0.4811, Training Accuracy: 0.8800, Validation Accuracy: 0.8090\n",
      "Epoch [131/500], Training Loss: 0.2789, Validation Loss: 0.5314, Training Accuracy: 0.8762, Validation Accuracy: 0.8315\n",
      "Epoch [132/500], Training Loss: 0.3261, Validation Loss: 0.4603, Training Accuracy: 0.8862, Validation Accuracy: 0.8427\n",
      "Epoch [133/500], Training Loss: 0.2927, Validation Loss: 0.4043, Training Accuracy: 0.8762, Validation Accuracy: 0.8202\n",
      "Epoch [134/500], Training Loss: 0.3076, Validation Loss: 0.3839, Training Accuracy: 0.8825, Validation Accuracy: 0.8202\n",
      "Epoch [135/500], Training Loss: 0.2889, Validation Loss: 0.4150, Training Accuracy: 0.8862, Validation Accuracy: 0.8315\n",
      "Epoch [136/500], Training Loss: 0.2959, Validation Loss: 0.4690, Training Accuracy: 0.8750, Validation Accuracy: 0.8090\n",
      "Epoch [137/500], Training Loss: 0.2760, Validation Loss: 0.4816, Training Accuracy: 0.8675, Validation Accuracy: 0.7865\n",
      "Epoch [138/500], Training Loss: 0.2477, Validation Loss: 0.5681, Training Accuracy: 0.8812, Validation Accuracy: 0.8315\n",
      "Epoch [139/500], Training Loss: 0.4002, Validation Loss: 0.3845, Training Accuracy: 0.8850, Validation Accuracy: 0.8427\n",
      "Epoch [140/500], Training Loss: 0.3272, Validation Loss: 0.4317, Training Accuracy: 0.8675, Validation Accuracy: 0.8090\n",
      "Epoch [141/500], Training Loss: 0.2766, Validation Loss: 0.4604, Training Accuracy: 0.8812, Validation Accuracy: 0.8315\n",
      "Epoch [142/500], Training Loss: 0.2959, Validation Loss: 0.4490, Training Accuracy: 0.8938, Validation Accuracy: 0.8427\n",
      "Epoch [143/500], Training Loss: 0.3053, Validation Loss: 0.4600, Training Accuracy: 0.8888, Validation Accuracy: 0.8315\n",
      "Epoch [144/500], Training Loss: 0.2794, Validation Loss: 0.4808, Training Accuracy: 0.8788, Validation Accuracy: 0.8202\n",
      "Epoch [145/500], Training Loss: 0.2991, Validation Loss: 0.4438, Training Accuracy: 0.8838, Validation Accuracy: 0.8315\n",
      "Epoch [146/500], Training Loss: 0.2649, Validation Loss: 0.4911, Training Accuracy: 0.8775, Validation Accuracy: 0.8202\n",
      "Epoch [147/500], Training Loss: 0.3920, Validation Loss: 0.4147, Training Accuracy: 0.8838, Validation Accuracy: 0.8202\n",
      "Epoch [148/500], Training Loss: 0.2828, Validation Loss: 0.4036, Training Accuracy: 0.8762, Validation Accuracy: 0.8427\n",
      "Epoch [149/500], Training Loss: 0.2659, Validation Loss: 0.4124, Training Accuracy: 0.8888, Validation Accuracy: 0.8427\n",
      "Epoch [150/500], Training Loss: 0.2464, Validation Loss: 0.3703, Training Accuracy: 0.8888, Validation Accuracy: 0.8315\n",
      "Epoch [151/500], Training Loss: 0.3109, Validation Loss: 0.4141, Training Accuracy: 0.8650, Validation Accuracy: 0.8315\n",
      "Epoch [152/500], Training Loss: 0.3306, Validation Loss: 0.4300, Training Accuracy: 0.8762, Validation Accuracy: 0.8315\n",
      "Epoch [153/500], Training Loss: 0.2708, Validation Loss: 0.4275, Training Accuracy: 0.8950, Validation Accuracy: 0.8427\n",
      "Epoch [154/500], Training Loss: 0.2688, Validation Loss: 0.4721, Training Accuracy: 0.8888, Validation Accuracy: 0.8427\n",
      "Epoch [155/500], Training Loss: 0.3356, Validation Loss: 0.3895, Training Accuracy: 0.8675, Validation Accuracy: 0.8202\n",
      "Epoch [156/500], Training Loss: 0.3245, Validation Loss: 0.3802, Training Accuracy: 0.8700, Validation Accuracy: 0.8090\n",
      "Epoch [157/500], Training Loss: 0.2847, Validation Loss: 0.5116, Training Accuracy: 0.8700, Validation Accuracy: 0.8090\n",
      "Epoch [158/500], Training Loss: 0.2947, Validation Loss: 0.3966, Training Accuracy: 0.8662, Validation Accuracy: 0.8315\n",
      "Epoch [159/500], Training Loss: 0.3038, Validation Loss: 0.4772, Training Accuracy: 0.8812, Validation Accuracy: 0.8315\n",
      "Epoch [160/500], Training Loss: 0.3001, Validation Loss: 0.4250, Training Accuracy: 0.8825, Validation Accuracy: 0.7865\n",
      "Epoch [161/500], Training Loss: 0.3045, Validation Loss: 0.3826, Training Accuracy: 0.8800, Validation Accuracy: 0.8202\n",
      "Epoch [162/500], Training Loss: 0.2707, Validation Loss: 0.4527, Training Accuracy: 0.8850, Validation Accuracy: 0.8427\n",
      "Epoch [163/500], Training Loss: 0.2475, Validation Loss: 0.4460, Training Accuracy: 0.8975, Validation Accuracy: 0.8539\n",
      "Epoch [164/500], Training Loss: 0.2425, Validation Loss: 0.4541, Training Accuracy: 0.8975, Validation Accuracy: 0.8315\n",
      "Epoch [165/500], Training Loss: 0.2270, Validation Loss: 0.4309, Training Accuracy: 0.8912, Validation Accuracy: 0.8315\n",
      "Epoch [166/500], Training Loss: 0.2457, Validation Loss: 0.4289, Training Accuracy: 0.8962, Validation Accuracy: 0.7978\n",
      "Epoch [167/500], Training Loss: 0.2258, Validation Loss: 0.4758, Training Accuracy: 0.9075, Validation Accuracy: 0.8202\n",
      "Epoch [168/500], Training Loss: 0.3850, Validation Loss: 0.4651, Training Accuracy: 0.8850, Validation Accuracy: 0.8315\n",
      "Epoch [169/500], Training Loss: 0.2487, Validation Loss: 0.4689, Training Accuracy: 0.9012, Validation Accuracy: 0.8315\n",
      "Epoch [170/500], Training Loss: 0.2854, Validation Loss: 0.4252, Training Accuracy: 0.8975, Validation Accuracy: 0.8539\n",
      "Epoch [171/500], Training Loss: 0.2574, Validation Loss: 0.4100, Training Accuracy: 0.8938, Validation Accuracy: 0.8876\n",
      "Epoch [172/500], Training Loss: 0.2589, Validation Loss: 0.3554, Training Accuracy: 0.9000, Validation Accuracy: 0.8539\n",
      "Epoch [173/500], Training Loss: 0.3957, Validation Loss: 0.5161, Training Accuracy: 0.8900, Validation Accuracy: 0.8427\n",
      "Epoch [174/500], Training Loss: 0.3965, Validation Loss: 0.4939, Training Accuracy: 0.8838, Validation Accuracy: 0.8427\n",
      "Epoch [175/500], Training Loss: 0.2589, Validation Loss: 0.4848, Training Accuracy: 0.9025, Validation Accuracy: 0.8202\n",
      "Epoch [176/500], Training Loss: 0.2738, Validation Loss: 0.4391, Training Accuracy: 0.8800, Validation Accuracy: 0.8315\n",
      "Epoch [177/500], Training Loss: 0.2857, Validation Loss: 0.4036, Training Accuracy: 0.8862, Validation Accuracy: 0.8652\n",
      "Epoch [178/500], Training Loss: 0.2936, Validation Loss: 0.3402, Training Accuracy: 0.8850, Validation Accuracy: 0.8539\n",
      "Epoch [179/500], Training Loss: 0.3874, Validation Loss: 0.4022, Training Accuracy: 0.9012, Validation Accuracy: 0.8427\n",
      "Epoch [180/500], Training Loss: 0.2979, Validation Loss: 0.4147, Training Accuracy: 0.8800, Validation Accuracy: 0.8539\n",
      "Epoch [181/500], Training Loss: 0.2418, Validation Loss: 0.4748, Training Accuracy: 0.9012, Validation Accuracy: 0.8539\n",
      "Epoch [182/500], Training Loss: 0.2686, Validation Loss: 0.4721, Training Accuracy: 0.8962, Validation Accuracy: 0.8539\n",
      "Epoch [183/500], Training Loss: 0.2815, Validation Loss: 0.3975, Training Accuracy: 0.8838, Validation Accuracy: 0.8427\n",
      "Epoch [184/500], Training Loss: 0.2440, Validation Loss: 0.4492, Training Accuracy: 0.9050, Validation Accuracy: 0.8652\n",
      "Epoch [185/500], Training Loss: 0.2683, Validation Loss: 0.3752, Training Accuracy: 0.8925, Validation Accuracy: 0.8652\n",
      "Epoch [186/500], Training Loss: 0.2963, Validation Loss: 0.4573, Training Accuracy: 0.8762, Validation Accuracy: 0.8764\n",
      "Epoch [187/500], Training Loss: 0.2510, Validation Loss: 0.4186, Training Accuracy: 0.8975, Validation Accuracy: 0.8315\n",
      "Epoch [188/500], Training Loss: 0.3822, Validation Loss: 0.4423, Training Accuracy: 0.8912, Validation Accuracy: 0.8876\n",
      "Epoch [189/500], Training Loss: 0.2383, Validation Loss: 0.4000, Training Accuracy: 0.8988, Validation Accuracy: 0.8652\n",
      "Epoch [190/500], Training Loss: 0.2700, Validation Loss: 0.4896, Training Accuracy: 0.8800, Validation Accuracy: 0.8202\n",
      "Epoch [191/500], Training Loss: 0.3082, Validation Loss: 0.3854, Training Accuracy: 0.8725, Validation Accuracy: 0.8315\n",
      "Epoch [192/500], Training Loss: 0.2663, Validation Loss: 0.5436, Training Accuracy: 0.9038, Validation Accuracy: 0.8539\n",
      "Epoch [193/500], Training Loss: 0.2519, Validation Loss: 0.5297, Training Accuracy: 0.8838, Validation Accuracy: 0.8202\n",
      "Epoch [194/500], Training Loss: 0.2283, Validation Loss: 0.5715, Training Accuracy: 0.8988, Validation Accuracy: 0.8090\n",
      "Epoch [195/500], Training Loss: 0.2967, Validation Loss: 0.3893, Training Accuracy: 0.8700, Validation Accuracy: 0.8315\n",
      "Epoch [196/500], Training Loss: 0.2384, Validation Loss: 0.4840, Training Accuracy: 0.8938, Validation Accuracy: 0.8315\n",
      "Epoch [197/500], Training Loss: 0.2324, Validation Loss: 0.4159, Training Accuracy: 0.9062, Validation Accuracy: 0.8315\n",
      "Epoch [198/500], Training Loss: 0.2210, Validation Loss: 0.4417, Training Accuracy: 0.9137, Validation Accuracy: 0.8539\n",
      "Epoch [199/500], Training Loss: 0.2252, Validation Loss: 0.4274, Training Accuracy: 0.9050, Validation Accuracy: 0.8202\n",
      "Epoch [200/500], Training Loss: 0.2742, Validation Loss: 0.3382, Training Accuracy: 0.8925, Validation Accuracy: 0.8202\n",
      "Epoch [201/500], Training Loss: 0.2301, Validation Loss: 0.5094, Training Accuracy: 0.8962, Validation Accuracy: 0.8539\n",
      "Epoch [202/500], Training Loss: 0.2151, Validation Loss: 0.5501, Training Accuracy: 0.9150, Validation Accuracy: 0.8427\n",
      "Epoch [203/500], Training Loss: 0.3094, Validation Loss: 0.5659, Training Accuracy: 0.9263, Validation Accuracy: 0.8764\n",
      "Epoch [204/500], Training Loss: 0.3588, Validation Loss: 0.4831, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [205/500], Training Loss: 0.2612, Validation Loss: 0.3909, Training Accuracy: 0.8900, Validation Accuracy: 0.8090\n",
      "Epoch [206/500], Training Loss: 0.2681, Validation Loss: 0.4107, Training Accuracy: 0.8975, Validation Accuracy: 0.8315\n",
      "Epoch [207/500], Training Loss: 0.2397, Validation Loss: 0.3819, Training Accuracy: 0.9000, Validation Accuracy: 0.8202\n",
      "Epoch [208/500], Training Loss: 0.2019, Validation Loss: 0.4966, Training Accuracy: 0.9125, Validation Accuracy: 0.8652\n",
      "Epoch [209/500], Training Loss: 0.2327, Validation Loss: 0.3513, Training Accuracy: 0.9050, Validation Accuracy: 0.8539\n",
      "Epoch [210/500], Training Loss: 0.3417, Validation Loss: 0.4583, Training Accuracy: 0.8725, Validation Accuracy: 0.8202\n",
      "Epoch [211/500], Training Loss: 0.3104, Validation Loss: 0.4260, Training Accuracy: 0.8712, Validation Accuracy: 0.8202\n",
      "Epoch [212/500], Training Loss: 0.2897, Validation Loss: 0.4562, Training Accuracy: 0.8638, Validation Accuracy: 0.7978\n",
      "Epoch [213/500], Training Loss: 0.2706, Validation Loss: 0.4491, Training Accuracy: 0.8675, Validation Accuracy: 0.8427\n",
      "Epoch [214/500], Training Loss: 0.2707, Validation Loss: 0.4162, Training Accuracy: 0.8825, Validation Accuracy: 0.8427\n",
      "Epoch [215/500], Training Loss: 0.2689, Validation Loss: 0.4291, Training Accuracy: 0.8800, Validation Accuracy: 0.8427\n",
      "Epoch [216/500], Training Loss: 0.2644, Validation Loss: 0.6098, Training Accuracy: 0.8938, Validation Accuracy: 0.8315\n",
      "Epoch [217/500], Training Loss: 0.2543, Validation Loss: 0.6424, Training Accuracy: 0.8838, Validation Accuracy: 0.7865\n",
      "Epoch [218/500], Training Loss: 0.2542, Validation Loss: 0.6542, Training Accuracy: 0.8925, Validation Accuracy: 0.8315\n",
      "Epoch [219/500], Training Loss: 0.2531, Validation Loss: 0.4780, Training Accuracy: 0.9087, Validation Accuracy: 0.8315\n",
      "Epoch [220/500], Training Loss: 0.2418, Validation Loss: 0.5373, Training Accuracy: 0.8938, Validation Accuracy: 0.8427\n",
      "Epoch [221/500], Training Loss: 0.2481, Validation Loss: 0.5639, Training Accuracy: 0.8962, Validation Accuracy: 0.8315\n",
      "Epoch [222/500], Training Loss: 0.2493, Validation Loss: 0.5171, Training Accuracy: 0.8962, Validation Accuracy: 0.8539\n",
      "Epoch [223/500], Training Loss: 0.2676, Validation Loss: 0.3394, Training Accuracy: 0.8962, Validation Accuracy: 0.8652\n",
      "Epoch [224/500], Training Loss: 0.2201, Validation Loss: 0.4754, Training Accuracy: 0.9087, Validation Accuracy: 0.8427\n",
      "Epoch [225/500], Training Loss: 0.2337, Validation Loss: 0.5445, Training Accuracy: 0.8850, Validation Accuracy: 0.8202\n",
      "Epoch [226/500], Training Loss: 0.2354, Validation Loss: 0.4711, Training Accuracy: 0.9025, Validation Accuracy: 0.8202\n",
      "Epoch [227/500], Training Loss: 0.2592, Validation Loss: 0.4720, Training Accuracy: 0.8975, Validation Accuracy: 0.8539\n",
      "Epoch [228/500], Training Loss: 0.1974, Validation Loss: 0.5041, Training Accuracy: 0.9225, Validation Accuracy: 0.8652\n",
      "Epoch [229/500], Training Loss: 0.2233, Validation Loss: 0.3825, Training Accuracy: 0.9062, Validation Accuracy: 0.8764\n",
      "Epoch [230/500], Training Loss: 0.2232, Validation Loss: 0.5013, Training Accuracy: 0.9150, Validation Accuracy: 0.8539\n",
      "Epoch [231/500], Training Loss: 0.2038, Validation Loss: 0.4478, Training Accuracy: 0.9113, Validation Accuracy: 0.8315\n",
      "Epoch [232/500], Training Loss: 0.2077, Validation Loss: 0.5411, Training Accuracy: 0.9038, Validation Accuracy: 0.8315\n",
      "Epoch [233/500], Training Loss: 0.2339, Validation Loss: 0.4398, Training Accuracy: 0.9062, Validation Accuracy: 0.8539\n",
      "Epoch [234/500], Training Loss: 0.2499, Validation Loss: 0.5002, Training Accuracy: 0.8975, Validation Accuracy: 0.8315\n",
      "Epoch [235/500], Training Loss: 0.2852, Validation Loss: 0.4200, Training Accuracy: 0.8938, Validation Accuracy: 0.8427\n",
      "Epoch [236/500], Training Loss: 0.2616, Validation Loss: 0.5068, Training Accuracy: 0.8962, Validation Accuracy: 0.8315\n",
      "Epoch [237/500], Training Loss: 0.2349, Validation Loss: 0.5131, Training Accuracy: 0.8925, Validation Accuracy: 0.8090\n",
      "Epoch [238/500], Training Loss: 0.2198, Validation Loss: 1.5279, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [239/500], Training Loss: 0.2466, Validation Loss: 0.4157, Training Accuracy: 0.8988, Validation Accuracy: 0.8652\n",
      "Epoch [240/500], Training Loss: 0.2082, Validation Loss: 0.4358, Training Accuracy: 0.9125, Validation Accuracy: 0.8539\n",
      "Epoch [241/500], Training Loss: 0.2496, Validation Loss: 0.4164, Training Accuracy: 0.9137, Validation Accuracy: 0.8427\n",
      "Epoch [242/500], Training Loss: 0.2492, Validation Loss: 0.4532, Training Accuracy: 0.9038, Validation Accuracy: 0.8652\n",
      "Epoch [243/500], Training Loss: 0.2253, Validation Loss: 0.4371, Training Accuracy: 0.9050, Validation Accuracy: 0.8427\n",
      "Epoch [244/500], Training Loss: 0.2416, Validation Loss: 0.3892, Training Accuracy: 0.8988, Validation Accuracy: 0.8202\n",
      "Epoch [245/500], Training Loss: 0.2296, Validation Loss: 0.3638, Training Accuracy: 0.9025, Validation Accuracy: 0.8315\n",
      "Epoch [246/500], Training Loss: 0.1849, Validation Loss: 0.4956, Training Accuracy: 0.9187, Validation Accuracy: 0.8539\n",
      "Epoch [247/500], Training Loss: 0.2125, Validation Loss: 0.4595, Training Accuracy: 0.9125, Validation Accuracy: 0.8539\n",
      "Epoch [248/500], Training Loss: 0.2281, Validation Loss: 0.5103, Training Accuracy: 0.9050, Validation Accuracy: 0.8652\n",
      "Epoch [249/500], Training Loss: 0.2059, Validation Loss: 0.3863, Training Accuracy: 0.9137, Validation Accuracy: 0.8764\n",
      "Epoch [250/500], Training Loss: 0.1977, Validation Loss: 0.4385, Training Accuracy: 0.9163, Validation Accuracy: 0.8764\n",
      "Epoch [251/500], Training Loss: 0.2225, Validation Loss: 0.3781, Training Accuracy: 0.9025, Validation Accuracy: 0.8652\n",
      "Epoch [252/500], Training Loss: 0.2967, Validation Loss: 0.4012, Training Accuracy: 0.8912, Validation Accuracy: 0.8539\n",
      "Epoch [253/500], Training Loss: 0.2693, Validation Loss: 0.4251, Training Accuracy: 0.8988, Validation Accuracy: 0.8539\n",
      "Epoch [254/500], Training Loss: 0.2184, Validation Loss: 0.4928, Training Accuracy: 0.9000, Validation Accuracy: 0.8539\n",
      "Epoch [255/500], Training Loss: 0.2269, Validation Loss: 0.4544, Training Accuracy: 0.9113, Validation Accuracy: 0.8427\n",
      "Epoch [256/500], Training Loss: 0.2079, Validation Loss: 1.4391, Training Accuracy: 0.9050, Validation Accuracy: 0.8539\n",
      "Epoch [257/500], Training Loss: 0.2238, Validation Loss: 0.6343, Training Accuracy: 0.9000, Validation Accuracy: 0.8315\n",
      "Epoch [258/500], Training Loss: 0.1990, Validation Loss: 0.5861, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [259/500], Training Loss: 0.2721, Validation Loss: 0.4529, Training Accuracy: 0.8988, Validation Accuracy: 0.8315\n",
      "Epoch [260/500], Training Loss: 0.2341, Validation Loss: 0.5725, Training Accuracy: 0.9237, Validation Accuracy: 0.8427\n",
      "Epoch [261/500], Training Loss: 0.2729, Validation Loss: 0.4990, Training Accuracy: 0.8912, Validation Accuracy: 0.8315\n",
      "Epoch [262/500], Training Loss: 0.2600, Validation Loss: 0.4640, Training Accuracy: 0.8962, Validation Accuracy: 0.8427\n",
      "Epoch [263/500], Training Loss: 0.2519, Validation Loss: 0.5641, Training Accuracy: 0.9050, Validation Accuracy: 0.8539\n",
      "Epoch [264/500], Training Loss: 0.2258, Validation Loss: 0.5520, Training Accuracy: 0.9062, Validation Accuracy: 0.8539\n",
      "Epoch [265/500], Training Loss: 0.2714, Validation Loss: 0.4925, Training Accuracy: 0.8962, Validation Accuracy: 0.8427\n",
      "Epoch [266/500], Training Loss: 0.2063, Validation Loss: 0.5484, Training Accuracy: 0.9113, Validation Accuracy: 0.8427\n",
      "Epoch [267/500], Training Loss: 0.1980, Validation Loss: 0.6055, Training Accuracy: 0.9100, Validation Accuracy: 0.7978\n",
      "Epoch [268/500], Training Loss: 0.2188, Validation Loss: 0.4589, Training Accuracy: 0.9087, Validation Accuracy: 0.8427\n",
      "Epoch [269/500], Training Loss: 0.1963, Validation Loss: 0.4595, Training Accuracy: 0.9137, Validation Accuracy: 0.8202\n",
      "Epoch [270/500], Training Loss: 0.2135, Validation Loss: 0.5000, Training Accuracy: 0.9087, Validation Accuracy: 0.8202\n",
      "Epoch [271/500], Training Loss: 0.2067, Validation Loss: 0.5049, Training Accuracy: 0.9137, Validation Accuracy: 0.8202\n",
      "Epoch [272/500], Training Loss: 0.1827, Validation Loss: 0.5240, Training Accuracy: 0.9163, Validation Accuracy: 0.8315\n",
      "Epoch [273/500], Training Loss: 0.2118, Validation Loss: 0.4231, Training Accuracy: 0.9175, Validation Accuracy: 0.8427\n",
      "Epoch [274/500], Training Loss: 0.2507, Validation Loss: 0.4537, Training Accuracy: 0.9050, Validation Accuracy: 0.8315\n",
      "Epoch [275/500], Training Loss: 0.2002, Validation Loss: 0.5268, Training Accuracy: 0.9125, Validation Accuracy: 0.8202\n",
      "Epoch [276/500], Training Loss: 0.2031, Validation Loss: 0.5349, Training Accuracy: 0.9150, Validation Accuracy: 0.8202\n",
      "Epoch [277/500], Training Loss: 0.2110, Validation Loss: 0.3791, Training Accuracy: 0.9113, Validation Accuracy: 0.8315\n",
      "Epoch [278/500], Training Loss: 0.1911, Validation Loss: 0.5337, Training Accuracy: 0.9100, Validation Accuracy: 0.8090\n",
      "Epoch [279/500], Training Loss: 0.2133, Validation Loss: 0.5449, Training Accuracy: 0.9175, Validation Accuracy: 0.8202\n",
      "Epoch [280/500], Training Loss: 0.2101, Validation Loss: 0.4590, Training Accuracy: 0.9113, Validation Accuracy: 0.8090\n",
      "Epoch [281/500], Training Loss: 0.2064, Validation Loss: 0.4491, Training Accuracy: 0.9137, Validation Accuracy: 0.8315\n",
      "Epoch [282/500], Training Loss: 0.2343, Validation Loss: 0.4534, Training Accuracy: 0.8988, Validation Accuracy: 0.8315\n",
      "Epoch [283/500], Training Loss: 0.2456, Validation Loss: 0.3199, Training Accuracy: 0.8912, Validation Accuracy: 0.8315\n",
      "Epoch [284/500], Training Loss: 0.2322, Validation Loss: 0.4169, Training Accuracy: 0.8962, Validation Accuracy: 0.8652\n",
      "Epoch [285/500], Training Loss: 0.1962, Validation Loss: 0.4896, Training Accuracy: 0.9113, Validation Accuracy: 0.8427\n",
      "Epoch [286/500], Training Loss: 0.2980, Validation Loss: 0.7114, Training Accuracy: 0.9225, Validation Accuracy: 0.8427\n",
      "Epoch [287/500], Training Loss: 0.1998, Validation Loss: 0.4059, Training Accuracy: 0.9137, Validation Accuracy: 0.8539\n",
      "Epoch [288/500], Training Loss: 0.3927, Validation Loss: 0.3573, Training Accuracy: 0.9075, Validation Accuracy: 0.8652\n",
      "Epoch [289/500], Training Loss: 0.2300, Validation Loss: 0.5706, Training Accuracy: 0.9100, Validation Accuracy: 0.8202\n",
      "Epoch [290/500], Training Loss: 0.2279, Validation Loss: 0.4770, Training Accuracy: 0.9050, Validation Accuracy: 0.8202\n",
      "Epoch [291/500], Training Loss: 0.2438, Validation Loss: 0.5344, Training Accuracy: 0.9012, Validation Accuracy: 0.8090\n",
      "Epoch [292/500], Training Loss: 0.2192, Validation Loss: 0.6498, Training Accuracy: 0.9062, Validation Accuracy: 0.8427\n",
      "Epoch [293/500], Training Loss: 0.3553, Validation Loss: 0.6410, Training Accuracy: 0.9062, Validation Accuracy: 0.8202\n",
      "Epoch [294/500], Training Loss: 0.2111, Validation Loss: 0.6399, Training Accuracy: 0.9100, Validation Accuracy: 0.8090\n",
      "Epoch [295/500], Training Loss: 0.2186, Validation Loss: 0.4346, Training Accuracy: 0.9075, Validation Accuracy: 0.8315\n",
      "Epoch [296/500], Training Loss: 0.1943, Validation Loss: 0.5089, Training Accuracy: 0.9050, Validation Accuracy: 0.8652\n",
      "Epoch [297/500], Training Loss: 0.4844, Validation Loss: 0.6268, Training Accuracy: 0.8950, Validation Accuracy: 0.8315\n",
      "Epoch [298/500], Training Loss: 0.1931, Validation Loss: 0.5693, Training Accuracy: 0.9213, Validation Accuracy: 0.8315\n",
      "Epoch [299/500], Training Loss: 0.2008, Validation Loss: 0.5048, Training Accuracy: 0.9263, Validation Accuracy: 0.8539\n",
      "Epoch [300/500], Training Loss: 0.2041, Validation Loss: 0.5576, Training Accuracy: 0.9150, Validation Accuracy: 0.8315\n",
      "Epoch [301/500], Training Loss: 0.2471, Validation Loss: 0.4384, Training Accuracy: 0.9125, Validation Accuracy: 0.8539\n",
      "Epoch [302/500], Training Loss: 0.1900, Validation Loss: 0.5886, Training Accuracy: 0.9250, Validation Accuracy: 0.8539\n",
      "Epoch [303/500], Training Loss: 0.3303, Validation Loss: 0.6714, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [304/500], Training Loss: 0.2127, Validation Loss: 0.6132, Training Accuracy: 0.9038, Validation Accuracy: 0.8315\n",
      "Epoch [305/500], Training Loss: 0.2572, Validation Loss: 0.5895, Training Accuracy: 0.9050, Validation Accuracy: 0.8202\n",
      "Epoch [306/500], Training Loss: 0.2124, Validation Loss: 0.5525, Training Accuracy: 0.9200, Validation Accuracy: 0.8539\n",
      "Epoch [307/500], Training Loss: 0.3703, Validation Loss: 0.6458, Training Accuracy: 0.9050, Validation Accuracy: 0.8090\n",
      "Epoch [308/500], Training Loss: 0.2114, Validation Loss: 0.5992, Training Accuracy: 0.9113, Validation Accuracy: 0.8315\n",
      "Epoch [309/500], Training Loss: 0.2415, Validation Loss: 0.4302, Training Accuracy: 0.9050, Validation Accuracy: 0.8090\n",
      "Epoch [310/500], Training Loss: 0.2425, Validation Loss: 0.4907, Training Accuracy: 0.8975, Validation Accuracy: 0.8202\n",
      "Epoch [311/500], Training Loss: 0.1836, Validation Loss: 0.6158, Training Accuracy: 0.9075, Validation Accuracy: 0.8539\n",
      "Epoch [312/500], Training Loss: 0.2082, Validation Loss: 0.6018, Training Accuracy: 0.9200, Validation Accuracy: 0.8652\n",
      "Epoch [313/500], Training Loss: 0.2559, Validation Loss: 0.6100, Training Accuracy: 0.9062, Validation Accuracy: 0.8764\n",
      "Epoch [314/500], Training Loss: 0.4556, Validation Loss: 0.5589, Training Accuracy: 0.9263, Validation Accuracy: 0.8652\n",
      "Epoch [315/500], Training Loss: 0.2172, Validation Loss: 1.5166, Training Accuracy: 0.9100, Validation Accuracy: 0.8427\n",
      "Epoch [316/500], Training Loss: 0.2141, Validation Loss: 0.4728, Training Accuracy: 0.9087, Validation Accuracy: 0.8539\n",
      "Epoch [317/500], Training Loss: 0.2005, Validation Loss: 0.5509, Training Accuracy: 0.9075, Validation Accuracy: 0.8427\n",
      "Epoch [318/500], Training Loss: 0.2491, Validation Loss: 1.4729, Training Accuracy: 0.9150, Validation Accuracy: 0.8539\n",
      "Epoch [319/500], Training Loss: 0.3318, Validation Loss: 1.5093, Training Accuracy: 0.9150, Validation Accuracy: 0.8202\n",
      "Epoch [320/500], Training Loss: 0.2031, Validation Loss: 0.4892, Training Accuracy: 0.9175, Validation Accuracy: 0.8202\n",
      "Epoch [321/500], Training Loss: 0.2107, Validation Loss: 0.4505, Training Accuracy: 0.9113, Validation Accuracy: 0.8315\n",
      "Epoch [322/500], Training Loss: 0.1696, Validation Loss: 0.4990, Training Accuracy: 0.9325, Validation Accuracy: 0.8202\n",
      "Epoch [323/500], Training Loss: 0.2272, Validation Loss: 0.4503, Training Accuracy: 0.9038, Validation Accuracy: 0.8202\n",
      "Epoch [324/500], Training Loss: 0.2244, Validation Loss: 0.6384, Training Accuracy: 0.9113, Validation Accuracy: 0.8315\n",
      "Epoch [325/500], Training Loss: 0.1932, Validation Loss: 0.4908, Training Accuracy: 0.9200, Validation Accuracy: 0.8202\n",
      "Epoch [326/500], Training Loss: 0.2279, Validation Loss: 0.5848, Training Accuracy: 0.9087, Validation Accuracy: 0.8202\n",
      "Epoch [327/500], Training Loss: 0.2302, Validation Loss: 0.4023, Training Accuracy: 0.8988, Validation Accuracy: 0.8315\n",
      "Epoch [328/500], Training Loss: 0.1992, Validation Loss: 0.4997, Training Accuracy: 0.9225, Validation Accuracy: 0.8202\n",
      "Epoch [329/500], Training Loss: 0.2078, Validation Loss: 0.5984, Training Accuracy: 0.9237, Validation Accuracy: 0.8202\n",
      "Epoch [330/500], Training Loss: 0.1968, Validation Loss: 0.5584, Training Accuracy: 0.9150, Validation Accuracy: 0.8652\n",
      "Epoch [331/500], Training Loss: 0.1860, Validation Loss: 0.6094, Training Accuracy: 0.9163, Validation Accuracy: 0.8652\n",
      "Epoch [332/500], Training Loss: 0.2982, Validation Loss: 0.5499, Training Accuracy: 0.9250, Validation Accuracy: 0.8539\n",
      "Epoch [333/500], Training Loss: 0.1880, Validation Loss: 0.5965, Training Accuracy: 0.9213, Validation Accuracy: 0.8315\n",
      "Epoch [334/500], Training Loss: 0.2117, Validation Loss: 0.5042, Training Accuracy: 0.9100, Validation Accuracy: 0.8427\n",
      "Epoch [335/500], Training Loss: 0.2123, Validation Loss: 0.5196, Training Accuracy: 0.9113, Validation Accuracy: 0.8202\n",
      "Epoch [336/500], Training Loss: 0.2366, Validation Loss: 0.5313, Training Accuracy: 0.9038, Validation Accuracy: 0.8427\n",
      "Epoch [337/500], Training Loss: 0.2154, Validation Loss: 0.4477, Training Accuracy: 0.9137, Validation Accuracy: 0.8539\n",
      "Epoch [338/500], Training Loss: 0.1858, Validation Loss: 0.5050, Training Accuracy: 0.9225, Validation Accuracy: 0.8539\n",
      "Epoch [339/500], Training Loss: 0.2028, Validation Loss: 0.4808, Training Accuracy: 0.9237, Validation Accuracy: 0.8539\n",
      "Epoch [340/500], Training Loss: 0.2576, Validation Loss: 0.3839, Training Accuracy: 0.9087, Validation Accuracy: 0.8539\n",
      "Epoch [341/500], Training Loss: 0.2290, Validation Loss: 0.4347, Training Accuracy: 0.9163, Validation Accuracy: 0.8539\n",
      "Epoch [342/500], Training Loss: 0.2125, Validation Loss: 0.4609, Training Accuracy: 0.9062, Validation Accuracy: 0.8652\n",
      "Epoch [343/500], Training Loss: 0.2033, Validation Loss: 0.5096, Training Accuracy: 0.9125, Validation Accuracy: 0.8202\n",
      "Epoch [344/500], Training Loss: 0.1936, Validation Loss: 0.4491, Training Accuracy: 0.9163, Validation Accuracy: 0.8315\n",
      "Epoch [345/500], Training Loss: 0.2899, Validation Loss: 0.4240, Training Accuracy: 0.9125, Validation Accuracy: 0.8202\n",
      "Epoch [346/500], Training Loss: 0.2654, Validation Loss: 0.4560, Training Accuracy: 0.8925, Validation Accuracy: 0.8427\n",
      "Epoch [347/500], Training Loss: 0.2798, Validation Loss: 0.4071, Training Accuracy: 0.9175, Validation Accuracy: 0.8427\n",
      "Epoch [348/500], Training Loss: 0.3373, Validation Loss: 0.4109, Training Accuracy: 0.9062, Validation Accuracy: 0.8539\n",
      "Epoch [349/500], Training Loss: 0.2037, Validation Loss: 0.4456, Training Accuracy: 0.9113, Validation Accuracy: 0.8427\n",
      "Epoch [350/500], Training Loss: 0.2143, Validation Loss: 0.4747, Training Accuracy: 0.9125, Validation Accuracy: 0.8427\n",
      "Epoch [351/500], Training Loss: 0.2227, Validation Loss: 0.5670, Training Accuracy: 0.9100, Validation Accuracy: 0.8427\n",
      "Epoch [352/500], Training Loss: 0.1941, Validation Loss: 0.5552, Training Accuracy: 0.9213, Validation Accuracy: 0.8315\n",
      "Epoch [353/500], Training Loss: 0.2546, Validation Loss: 0.4557, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [354/500], Training Loss: 0.2088, Validation Loss: 0.6240, Training Accuracy: 0.9125, Validation Accuracy: 0.8202\n",
      "Epoch [355/500], Training Loss: 0.2325, Validation Loss: 0.4522, Training Accuracy: 0.9113, Validation Accuracy: 0.8202\n",
      "Epoch [356/500], Training Loss: 0.3431, Validation Loss: 0.3692, Training Accuracy: 0.9100, Validation Accuracy: 0.8427\n",
      "Epoch [357/500], Training Loss: 0.3893, Validation Loss: 0.4154, Training Accuracy: 0.8950, Validation Accuracy: 0.8652\n",
      "Epoch [358/500], Training Loss: 0.2202, Validation Loss: 0.4818, Training Accuracy: 0.9087, Validation Accuracy: 0.8315\n",
      "Epoch [359/500], Training Loss: 0.2310, Validation Loss: 0.3906, Training Accuracy: 0.8888, Validation Accuracy: 0.8427\n",
      "Epoch [360/500], Training Loss: 0.1693, Validation Loss: 0.4955, Training Accuracy: 0.9200, Validation Accuracy: 0.8202\n",
      "Epoch [361/500], Training Loss: 0.1807, Validation Loss: 0.5587, Training Accuracy: 0.9163, Validation Accuracy: 0.8315\n",
      "Epoch [362/500], Training Loss: 0.1909, Validation Loss: 0.5655, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [363/500], Training Loss: 0.2174, Validation Loss: 0.5495, Training Accuracy: 0.9038, Validation Accuracy: 0.8427\n",
      "Epoch [364/500], Training Loss: 0.1892, Validation Loss: 0.6495, Training Accuracy: 0.9200, Validation Accuracy: 0.8539\n",
      "Epoch [365/500], Training Loss: 0.2698, Validation Loss: 0.4054, Training Accuracy: 0.9075, Validation Accuracy: 0.8427\n",
      "Epoch [366/500], Training Loss: 0.1990, Validation Loss: 0.5364, Training Accuracy: 0.9062, Validation Accuracy: 0.8427\n",
      "Epoch [367/500], Training Loss: 0.2797, Validation Loss: 0.3836, Training Accuracy: 0.8962, Validation Accuracy: 0.8090\n",
      "Epoch [368/500], Training Loss: 0.2122, Validation Loss: 0.4083, Training Accuracy: 0.9275, Validation Accuracy: 0.8427\n",
      "Epoch [369/500], Training Loss: 0.2973, Validation Loss: 0.4596, Training Accuracy: 0.9113, Validation Accuracy: 0.8315\n",
      "Epoch [370/500], Training Loss: 0.2737, Validation Loss: 0.3818, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [371/500], Training Loss: 0.2917, Validation Loss: 0.4315, Training Accuracy: 0.9025, Validation Accuracy: 0.8315\n",
      "Epoch [372/500], Training Loss: 0.2038, Validation Loss: 0.4435, Training Accuracy: 0.9175, Validation Accuracy: 0.8427\n",
      "Epoch [373/500], Training Loss: 0.2242, Validation Loss: 0.5023, Training Accuracy: 0.9200, Validation Accuracy: 0.8427\n",
      "Epoch [374/500], Training Loss: 0.2015, Validation Loss: 0.4393, Training Accuracy: 0.9263, Validation Accuracy: 0.8315\n",
      "Epoch [375/500], Training Loss: 0.3089, Validation Loss: 0.5051, Training Accuracy: 0.9150, Validation Accuracy: 0.8202\n",
      "Epoch [376/500], Training Loss: 0.2206, Validation Loss: 0.5100, Training Accuracy: 0.9150, Validation Accuracy: 0.8202\n",
      "Epoch [377/500], Training Loss: 0.3073, Validation Loss: 0.6395, Training Accuracy: 0.9150, Validation Accuracy: 0.8090\n",
      "Epoch [378/500], Training Loss: 0.1948, Validation Loss: 0.4289, Training Accuracy: 0.9225, Validation Accuracy: 0.8090\n",
      "Epoch [379/500], Training Loss: 0.1792, Validation Loss: 0.7684, Training Accuracy: 0.9263, Validation Accuracy: 0.7978\n",
      "Epoch [380/500], Training Loss: 0.2342, Validation Loss: 0.4415, Training Accuracy: 0.9225, Validation Accuracy: 0.8202\n",
      "Epoch [381/500], Training Loss: 0.2221, Validation Loss: 0.4836, Training Accuracy: 0.9187, Validation Accuracy: 0.8315\n",
      "Epoch [382/500], Training Loss: 0.2159, Validation Loss: 0.4037, Training Accuracy: 0.9137, Validation Accuracy: 0.8315\n",
      "Epoch [383/500], Training Loss: 0.2247, Validation Loss: 0.5013, Training Accuracy: 0.9213, Validation Accuracy: 0.8539\n",
      "Epoch [384/500], Training Loss: 0.1979, Validation Loss: 0.4603, Training Accuracy: 0.9087, Validation Accuracy: 0.8315\n",
      "Epoch [385/500], Training Loss: 0.1863, Validation Loss: 0.5441, Training Accuracy: 0.9175, Validation Accuracy: 0.8427\n",
      "Epoch [386/500], Training Loss: 0.3576, Validation Loss: 0.4330, Training Accuracy: 0.9100, Validation Accuracy: 0.8315\n",
      "Epoch [387/500], Training Loss: 0.1884, Validation Loss: 0.5928, Training Accuracy: 0.9175, Validation Accuracy: 0.8539\n",
      "Epoch [388/500], Training Loss: 0.2064, Validation Loss: 0.5077, Training Accuracy: 0.9087, Validation Accuracy: 0.8090\n",
      "Epoch [389/500], Training Loss: 0.2305, Validation Loss: 0.4430, Training Accuracy: 0.9100, Validation Accuracy: 0.7978\n",
      "Epoch [390/500], Training Loss: 0.3140, Validation Loss: 0.6151, Training Accuracy: 0.9200, Validation Accuracy: 0.8202\n",
      "Epoch [391/500], Training Loss: 0.2564, Validation Loss: 0.4693, Training Accuracy: 0.9237, Validation Accuracy: 0.8315\n",
      "Epoch [392/500], Training Loss: 0.3339, Validation Loss: 0.3981, Training Accuracy: 0.9200, Validation Accuracy: 0.8427\n",
      "Epoch [393/500], Training Loss: 0.1832, Validation Loss: 0.5670, Training Accuracy: 0.9200, Validation Accuracy: 0.8315\n",
      "Epoch [394/500], Training Loss: 0.2485, Validation Loss: 0.3711, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [395/500], Training Loss: 0.1757, Validation Loss: 0.5680, Training Accuracy: 0.9263, Validation Accuracy: 0.8539\n",
      "Epoch [396/500], Training Loss: 0.3888, Validation Loss: 0.5691, Training Accuracy: 0.8950, Validation Accuracy: 0.8427\n",
      "Epoch [397/500], Training Loss: 0.2355, Validation Loss: 0.3881, Training Accuracy: 0.8975, Validation Accuracy: 0.8539\n",
      "Epoch [398/500], Training Loss: 0.2077, Validation Loss: 0.5447, Training Accuracy: 0.9163, Validation Accuracy: 0.8090\n",
      "Epoch [399/500], Training Loss: 0.1998, Validation Loss: 0.4676, Training Accuracy: 0.9175, Validation Accuracy: 0.8090\n",
      "Epoch [400/500], Training Loss: 0.2327, Validation Loss: 0.5250, Training Accuracy: 0.9025, Validation Accuracy: 0.8202\n",
      "Epoch [401/500], Training Loss: 0.2064, Validation Loss: 0.4099, Training Accuracy: 0.9087, Validation Accuracy: 0.8315\n",
      "Epoch [402/500], Training Loss: 0.1883, Validation Loss: 0.5821, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [403/500], Training Loss: 0.2824, Validation Loss: 0.4102, Training Accuracy: 0.9025, Validation Accuracy: 0.8427\n",
      "Epoch [404/500], Training Loss: 0.3384, Validation Loss: 0.5201, Training Accuracy: 0.9100, Validation Accuracy: 0.8427\n",
      "Epoch [405/500], Training Loss: 0.3275, Validation Loss: 0.5025, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [406/500], Training Loss: 0.1844, Validation Loss: 0.5872, Training Accuracy: 0.9275, Validation Accuracy: 0.8427\n",
      "Epoch [407/500], Training Loss: 0.2115, Validation Loss: 0.5115, Training Accuracy: 0.9175, Validation Accuracy: 0.8427\n",
      "Epoch [408/500], Training Loss: 0.1837, Validation Loss: 0.7565, Training Accuracy: 0.9287, Validation Accuracy: 0.8427\n",
      "Epoch [409/500], Training Loss: 0.2891, Validation Loss: 1.5716, Training Accuracy: 0.9325, Validation Accuracy: 0.8427\n",
      "Epoch [410/500], Training Loss: 0.2083, Validation Loss: 0.4477, Training Accuracy: 0.9213, Validation Accuracy: 0.8427\n",
      "Epoch [411/500], Training Loss: 0.2082, Validation Loss: 0.4565, Training Accuracy: 0.9150, Validation Accuracy: 0.8539\n",
      "Epoch [412/500], Training Loss: 0.2261, Validation Loss: 0.4589, Training Accuracy: 0.9250, Validation Accuracy: 0.8539\n",
      "Epoch [413/500], Training Loss: 0.1809, Validation Loss: 0.5846, Training Accuracy: 0.9237, Validation Accuracy: 0.8539\n",
      "Epoch [414/500], Training Loss: 0.1913, Validation Loss: 0.7184, Training Accuracy: 0.9237, Validation Accuracy: 0.8315\n",
      "Epoch [415/500], Training Loss: 0.1980, Validation Loss: 0.5086, Training Accuracy: 0.9225, Validation Accuracy: 0.8202\n",
      "Epoch [416/500], Training Loss: 0.2132, Validation Loss: 0.4968, Training Accuracy: 0.9250, Validation Accuracy: 0.8652\n",
      "Epoch [417/500], Training Loss: 0.2230, Validation Loss: 0.5045, Training Accuracy: 0.9175, Validation Accuracy: 0.8427\n",
      "Epoch [418/500], Training Loss: 0.1964, Validation Loss: 1.4519, Training Accuracy: 0.9187, Validation Accuracy: 0.8539\n",
      "Epoch [419/500], Training Loss: 0.1980, Validation Loss: 1.4153, Training Accuracy: 0.9187, Validation Accuracy: 0.8539\n",
      "Epoch [420/500], Training Loss: 0.1588, Validation Loss: 1.5153, Training Accuracy: 0.9375, Validation Accuracy: 0.8539\n",
      "Epoch [421/500], Training Loss: 0.1754, Validation Loss: 1.5151, Training Accuracy: 0.9237, Validation Accuracy: 0.8427\n",
      "Epoch [422/500], Training Loss: 0.1811, Validation Loss: 1.5398, Training Accuracy: 0.9350, Validation Accuracy: 0.8315\n",
      "Epoch [423/500], Training Loss: 0.2006, Validation Loss: 0.4944, Training Accuracy: 0.9163, Validation Accuracy: 0.8202\n",
      "Epoch [424/500], Training Loss: 0.4262, Validation Loss: 1.6042, Training Accuracy: 0.9125, Validation Accuracy: 0.8427\n",
      "Epoch [425/500], Training Loss: 0.2203, Validation Loss: 1.5582, Training Accuracy: 0.9113, Validation Accuracy: 0.8315\n",
      "Epoch [426/500], Training Loss: 0.2106, Validation Loss: 0.5138, Training Accuracy: 0.9137, Validation Accuracy: 0.8315\n",
      "Epoch [427/500], Training Loss: 0.2203, Validation Loss: 2.6489, Training Accuracy: 0.9038, Validation Accuracy: 0.8427\n",
      "Epoch [428/500], Training Loss: 0.2011, Validation Loss: 0.5786, Training Accuracy: 0.9125, Validation Accuracy: 0.8539\n",
      "Epoch [429/500], Training Loss: 0.2016, Validation Loss: 0.5233, Training Accuracy: 0.9075, Validation Accuracy: 0.8427\n",
      "Epoch [430/500], Training Loss: 0.1809, Validation Loss: 0.5255, Training Accuracy: 0.9213, Validation Accuracy: 0.8539\n",
      "Epoch [431/500], Training Loss: 0.3798, Validation Loss: 0.4525, Training Accuracy: 0.9012, Validation Accuracy: 0.8764\n",
      "Epoch [432/500], Training Loss: 0.2044, Validation Loss: 0.4799, Training Accuracy: 0.9187, Validation Accuracy: 0.8427\n",
      "Epoch [433/500], Training Loss: 0.2242, Validation Loss: 0.3878, Training Accuracy: 0.9163, Validation Accuracy: 0.8539\n",
      "Epoch [434/500], Training Loss: 0.3040, Validation Loss: 0.4301, Training Accuracy: 0.8850, Validation Accuracy: 0.8652\n",
      "Epoch [435/500], Training Loss: 0.1995, Validation Loss: 0.5294, Training Accuracy: 0.9200, Validation Accuracy: 0.8764\n",
      "Epoch [436/500], Training Loss: 0.1787, Validation Loss: 0.5914, Training Accuracy: 0.9225, Validation Accuracy: 0.8539\n",
      "Epoch [437/500], Training Loss: 0.1681, Validation Loss: 0.5397, Training Accuracy: 0.9300, Validation Accuracy: 0.8539\n",
      "Epoch [438/500], Training Loss: 0.1770, Validation Loss: 0.6762, Training Accuracy: 0.9300, Validation Accuracy: 0.8427\n",
      "Epoch [439/500], Training Loss: 0.1970, Validation Loss: 0.6592, Training Accuracy: 0.9087, Validation Accuracy: 0.8315\n",
      "Epoch [440/500], Training Loss: 0.4347, Validation Loss: 2.5951, Training Accuracy: 0.9163, Validation Accuracy: 0.8652\n",
      "Epoch [441/500], Training Loss: 0.2162, Validation Loss: 0.6646, Training Accuracy: 0.9175, Validation Accuracy: 0.8315\n",
      "Epoch [442/500], Training Loss: 0.2516, Validation Loss: 0.4699, Training Accuracy: 0.9012, Validation Accuracy: 0.8315\n",
      "Epoch [443/500], Training Loss: 0.2093, Validation Loss: 1.6382, Training Accuracy: 0.9100, Validation Accuracy: 0.8539\n",
      "Epoch [444/500], Training Loss: 0.2276, Validation Loss: 0.6989, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [445/500], Training Loss: 0.1892, Validation Loss: 1.6952, Training Accuracy: 0.9187, Validation Accuracy: 0.8427\n",
      "Epoch [446/500], Training Loss: 0.2161, Validation Loss: 0.6415, Training Accuracy: 0.9038, Validation Accuracy: 0.8427\n",
      "Epoch [447/500], Training Loss: 0.2032, Validation Loss: 0.6557, Training Accuracy: 0.9187, Validation Accuracy: 0.8315\n",
      "Epoch [448/500], Training Loss: 0.3713, Validation Loss: 0.5376, Training Accuracy: 0.9137, Validation Accuracy: 0.8427\n",
      "Epoch [449/500], Training Loss: 0.2012, Validation Loss: 0.5311, Training Accuracy: 0.9175, Validation Accuracy: 0.8539\n",
      "Epoch [450/500], Training Loss: 0.2132, Validation Loss: 0.5229, Training Accuracy: 0.9225, Validation Accuracy: 0.8427\n",
      "Epoch [451/500], Training Loss: 0.1829, Validation Loss: 1.5982, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [452/500], Training Loss: 0.1773, Validation Loss: 1.6614, Training Accuracy: 0.9275, Validation Accuracy: 0.8315\n",
      "Epoch [453/500], Training Loss: 0.2093, Validation Loss: 0.6668, Training Accuracy: 0.9237, Validation Accuracy: 0.8427\n",
      "Epoch [454/500], Training Loss: 0.2071, Validation Loss: 0.5751, Training Accuracy: 0.9213, Validation Accuracy: 0.8427\n",
      "Epoch [455/500], Training Loss: 0.1979, Validation Loss: 0.4620, Training Accuracy: 0.9250, Validation Accuracy: 0.8539\n",
      "Epoch [456/500], Training Loss: 0.1851, Validation Loss: 0.5814, Training Accuracy: 0.9213, Validation Accuracy: 0.8539\n",
      "Epoch [457/500], Training Loss: 0.1927, Validation Loss: 0.5540, Training Accuracy: 0.9137, Validation Accuracy: 0.8427\n",
      "Epoch [458/500], Training Loss: 0.1965, Validation Loss: 0.6513, Training Accuracy: 0.9200, Validation Accuracy: 0.8427\n",
      "Epoch [459/500], Training Loss: 0.1908, Validation Loss: 0.5270, Training Accuracy: 0.9287, Validation Accuracy: 0.8652\n",
      "Epoch [460/500], Training Loss: 0.2294, Validation Loss: 0.8013, Training Accuracy: 0.9075, Validation Accuracy: 0.8090\n",
      "Epoch [461/500], Training Loss: 0.2982, Validation Loss: 0.7521, Training Accuracy: 0.9125, Validation Accuracy: 0.8202\n",
      "Epoch [462/500], Training Loss: 0.1895, Validation Loss: 0.7060, Training Accuracy: 0.9225, Validation Accuracy: 0.8427\n",
      "Epoch [463/500], Training Loss: 0.2117, Validation Loss: 0.8562, Training Accuracy: 0.9175, Validation Accuracy: 0.8427\n",
      "Epoch [464/500], Training Loss: 0.2140, Validation Loss: 0.5937, Training Accuracy: 0.9012, Validation Accuracy: 0.8652\n",
      "Epoch [465/500], Training Loss: 0.1788, Validation Loss: 1.5841, Training Accuracy: 0.9213, Validation Accuracy: 0.8315\n",
      "Epoch [466/500], Training Loss: 0.3353, Validation Loss: 0.5234, Training Accuracy: 0.9187, Validation Accuracy: 0.8539\n",
      "Epoch [467/500], Training Loss: 0.2043, Validation Loss: 0.5898, Training Accuracy: 0.9187, Validation Accuracy: 0.8539\n",
      "Epoch [468/500], Training Loss: 0.3418, Validation Loss: 0.6171, Training Accuracy: 0.9137, Validation Accuracy: 0.8315\n",
      "Epoch [469/500], Training Loss: 0.1832, Validation Loss: 0.6296, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [470/500], Training Loss: 0.1808, Validation Loss: 0.5187, Training Accuracy: 0.9187, Validation Accuracy: 0.8427\n",
      "Epoch [471/500], Training Loss: 0.2018, Validation Loss: 0.6209, Training Accuracy: 0.9137, Validation Accuracy: 0.8427\n",
      "Epoch [472/500], Training Loss: 0.2209, Validation Loss: 0.4512, Training Accuracy: 0.9025, Validation Accuracy: 0.8539\n",
      "Epoch [473/500], Training Loss: 0.1828, Validation Loss: 1.4180, Training Accuracy: 0.9225, Validation Accuracy: 0.8539\n",
      "Epoch [474/500], Training Loss: 0.1959, Validation Loss: 0.5082, Training Accuracy: 0.9175, Validation Accuracy: 0.8315\n",
      "Epoch [475/500], Training Loss: 0.1656, Validation Loss: 1.5952, Training Accuracy: 0.9237, Validation Accuracy: 0.8427\n",
      "Epoch [476/500], Training Loss: 0.1737, Validation Loss: 0.6134, Training Accuracy: 0.9250, Validation Accuracy: 0.8202\n",
      "Epoch [477/500], Training Loss: 0.1901, Validation Loss: 0.5940, Training Accuracy: 0.9113, Validation Accuracy: 0.8315\n",
      "Epoch [478/500], Training Loss: 0.2231, Validation Loss: 0.4653, Training Accuracy: 0.9062, Validation Accuracy: 0.8427\n",
      "Epoch [479/500], Training Loss: 0.1793, Validation Loss: 0.8364, Training Accuracy: 0.9213, Validation Accuracy: 0.8427\n",
      "Epoch [480/500], Training Loss: 0.1846, Validation Loss: 0.6777, Training Accuracy: 0.9225, Validation Accuracy: 0.8090\n",
      "Epoch [481/500], Training Loss: 0.1857, Validation Loss: 0.5601, Training Accuracy: 0.9275, Validation Accuracy: 0.8315\n",
      "Epoch [482/500], Training Loss: 0.1755, Validation Loss: 0.6595, Training Accuracy: 0.9200, Validation Accuracy: 0.8202\n",
      "Epoch [483/500], Training Loss: 0.3407, Validation Loss: 0.4351, Training Accuracy: 0.9237, Validation Accuracy: 0.8090\n",
      "Epoch [484/500], Training Loss: 0.2175, Validation Loss: 0.6213, Training Accuracy: 0.9187, Validation Accuracy: 0.8315\n",
      "Epoch [485/500], Training Loss: 0.1734, Validation Loss: 0.5864, Training Accuracy: 0.9100, Validation Accuracy: 0.8539\n",
      "Epoch [486/500], Training Loss: 0.2216, Validation Loss: 0.3949, Training Accuracy: 0.9062, Validation Accuracy: 0.8427\n",
      "Epoch [487/500], Training Loss: 0.1824, Validation Loss: 1.4986, Training Accuracy: 0.9225, Validation Accuracy: 0.8539\n",
      "Epoch [488/500], Training Loss: 0.2216, Validation Loss: 1.4724, Training Accuracy: 0.9050, Validation Accuracy: 0.8427\n",
      "Epoch [489/500], Training Loss: 0.2024, Validation Loss: 1.5955, Training Accuracy: 0.9075, Validation Accuracy: 0.8427\n",
      "Epoch [490/500], Training Loss: 0.1982, Validation Loss: 1.5273, Training Accuracy: 0.9163, Validation Accuracy: 0.8315\n",
      "Epoch [491/500], Training Loss: 0.2181, Validation Loss: 1.5489, Training Accuracy: 0.9187, Validation Accuracy: 0.8315\n",
      "Epoch [492/500], Training Loss: 0.2872, Validation Loss: 1.4873, Training Accuracy: 0.9237, Validation Accuracy: 0.8315\n",
      "Epoch [493/500], Training Loss: 0.2338, Validation Loss: 0.4406, Training Accuracy: 0.9163, Validation Accuracy: 0.8202\n",
      "Epoch [494/500], Training Loss: 0.2017, Validation Loss: 0.6652, Training Accuracy: 0.9087, Validation Accuracy: 0.8315\n",
      "Epoch [495/500], Training Loss: 0.1910, Validation Loss: 1.4705, Training Accuracy: 0.9125, Validation Accuracy: 0.8315\n",
      "Epoch [496/500], Training Loss: 0.1832, Validation Loss: 0.4269, Training Accuracy: 0.9275, Validation Accuracy: 0.8315\n",
      "Epoch [497/500], Training Loss: 0.1916, Validation Loss: 1.4258, Training Accuracy: 0.9163, Validation Accuracy: 0.8427\n",
      "Epoch [498/500], Training Loss: 0.2158, Validation Loss: 1.4028, Training Accuracy: 0.9100, Validation Accuracy: 0.8202\n",
      "Epoch [499/500], Training Loss: 0.1965, Validation Loss: 1.4837, Training Accuracy: 0.9175, Validation Accuracy: 0.8427\n",
      "Epoch [500/500], Training Loss: 0.3220, Validation Loss: 0.4684, Training Accuracy: 0.9187, Validation Accuracy: 0.8315\n",
      "Training Time: 6.81 seconds\n",
      "Epoch [1/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [2/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [3/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [4/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [5/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [6/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [7/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [8/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [9/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [10/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [11/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [12/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [13/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [14/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [15/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [16/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [17/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [18/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [19/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [20/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [21/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [22/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [23/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [24/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [25/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [26/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [27/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [28/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [29/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [30/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [31/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [32/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [33/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [34/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [35/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [36/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [37/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [38/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [39/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [40/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [41/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [42/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [43/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [44/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [45/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [46/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [47/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [48/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [49/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [50/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [51/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [52/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [53/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [54/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [55/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [56/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [57/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [58/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [59/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [60/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [61/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [62/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [63/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [64/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [65/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [66/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [67/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [68/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [69/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [70/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [71/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [72/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [73/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [74/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [75/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [76/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [77/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [78/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [79/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [80/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [81/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [82/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [83/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [84/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [85/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [86/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [87/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [88/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [89/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [90/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [91/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [92/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [93/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [94/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [95/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [96/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [97/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [98/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [99/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [100/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [101/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [102/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [103/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [104/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [105/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [106/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [107/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [108/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [109/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [110/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [111/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [112/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [113/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [114/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [115/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [116/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [117/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [118/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [119/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [120/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [121/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [122/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [123/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [124/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [125/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [126/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [127/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [128/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [129/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [130/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [131/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [132/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [133/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [134/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [135/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [136/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [137/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [138/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [139/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [140/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [141/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [142/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [143/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [144/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [145/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [146/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [147/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [148/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [149/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [150/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [151/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [152/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [153/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [154/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [155/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [156/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [157/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [158/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [159/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [160/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [161/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [162/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [163/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [164/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [165/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [166/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [167/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [168/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [169/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [170/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [171/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [172/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [173/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [174/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [175/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [176/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [177/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [178/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [179/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [180/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [181/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [182/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [183/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [184/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [185/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [186/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [187/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [188/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [189/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [190/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [191/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [192/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [193/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [194/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [195/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [196/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [197/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [198/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [199/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [200/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [201/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [202/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [203/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [204/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [205/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [206/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [207/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [208/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [209/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [210/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [211/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [212/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [213/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [214/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [215/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [216/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [217/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [218/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [219/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [220/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [221/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [222/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [223/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [224/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [225/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [226/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [227/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [228/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [229/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [230/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [231/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [232/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [233/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [234/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [235/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [236/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [237/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [238/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [239/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [240/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [241/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [242/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [243/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [244/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [245/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [246/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [247/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [248/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [249/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [250/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [251/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [252/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [253/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [254/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [255/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [256/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [257/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [258/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [259/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [260/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [261/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [262/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [263/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [264/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [265/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [266/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [267/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [268/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [269/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [270/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [271/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [272/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [273/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [274/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [275/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [276/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [277/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [278/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [279/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [280/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [281/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [282/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [283/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [284/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [285/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [286/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [287/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [288/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [289/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [290/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [291/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [292/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [293/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [294/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [295/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [296/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [297/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [298/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [299/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [300/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [301/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [302/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [303/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [304/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [305/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [306/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [307/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [308/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [309/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [310/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [311/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [312/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [313/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [314/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [315/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [316/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [317/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [318/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [319/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [320/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [321/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [322/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [323/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [324/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [325/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [326/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [327/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [328/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [329/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [330/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [331/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [332/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [333/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [334/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [335/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [336/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [337/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [338/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [339/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [340/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [341/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [342/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [343/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [344/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [345/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [346/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [347/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [348/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [349/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [350/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [351/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [352/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [353/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [354/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [355/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [356/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [357/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [358/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [359/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [360/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [361/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [362/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [363/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [364/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [365/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [366/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [367/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [368/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [369/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [370/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [371/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [372/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [373/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [374/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [375/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [376/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [377/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [378/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [379/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [380/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [381/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [382/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [383/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [384/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [385/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [386/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [387/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [388/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [389/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [390/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [391/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [392/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [393/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [394/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [395/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [396/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [397/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [398/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [399/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [400/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [401/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [402/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [403/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [404/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [405/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [406/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [407/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [408/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [409/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [410/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [411/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [412/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [413/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [414/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [415/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [416/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [417/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [418/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [419/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [420/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [421/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [422/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [423/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [424/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [425/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [426/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [427/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [428/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [429/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [430/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [431/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [432/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [433/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [434/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [435/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [436/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [437/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [438/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [439/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [440/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [441/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [442/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [443/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [444/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [445/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [446/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [447/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [448/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [449/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [450/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [451/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [452/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [453/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [454/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [455/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [456/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [457/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [458/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [459/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [460/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [461/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [462/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [463/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [464/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [465/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [466/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [467/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [468/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [469/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [470/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [471/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [472/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [473/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [474/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [475/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [476/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [477/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [478/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [479/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [480/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [481/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [482/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [483/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [484/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [485/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [486/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [487/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [488/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [489/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [490/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [491/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [492/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [493/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [494/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [495/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [496/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [497/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [498/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [499/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [500/500], Test Loss: 1.4864, Testing Accuracy: 0.7980\n",
      "Epoch [1/500], Training Loss: 0.6742, Validation Loss: 0.6094, Training Accuracy: 0.5775, Validation Accuracy: 0.6966\n",
      "Epoch [2/500], Training Loss: 0.5684, Validation Loss: 0.4989, Training Accuracy: 0.7212, Validation Accuracy: 0.7528\n",
      "Epoch [3/500], Training Loss: 0.5170, Validation Loss: 0.4831, Training Accuracy: 0.7525, Validation Accuracy: 0.7528\n",
      "Epoch [4/500], Training Loss: 0.5317, Validation Loss: 0.4848, Training Accuracy: 0.7512, Validation Accuracy: 0.7416\n",
      "Epoch [5/500], Training Loss: 0.5113, Validation Loss: 0.4745, Training Accuracy: 0.7488, Validation Accuracy: 0.7528\n",
      "Epoch [6/500], Training Loss: 0.5060, Validation Loss: 0.4896, Training Accuracy: 0.7450, Validation Accuracy: 0.7416\n",
      "Epoch [7/500], Training Loss: 0.5085, Validation Loss: 0.4727, Training Accuracy: 0.7562, Validation Accuracy: 0.7528\n",
      "Epoch [8/500], Training Loss: 0.5071, Validation Loss: 0.4748, Training Accuracy: 0.7600, Validation Accuracy: 0.7753\n",
      "Epoch [9/500], Training Loss: 0.4949, Validation Loss: 0.4809, Training Accuracy: 0.7612, Validation Accuracy: 0.7528\n",
      "Epoch [10/500], Training Loss: 0.4807, Validation Loss: 0.4784, Training Accuracy: 0.7638, Validation Accuracy: 0.7753\n",
      "Epoch [11/500], Training Loss: 0.4945, Validation Loss: 0.4822, Training Accuracy: 0.7512, Validation Accuracy: 0.7640\n",
      "Epoch [12/500], Training Loss: 0.4881, Validation Loss: 0.4807, Training Accuracy: 0.7700, Validation Accuracy: 0.7640\n",
      "Epoch [13/500], Training Loss: 0.4811, Validation Loss: 0.4870, Training Accuracy: 0.7688, Validation Accuracy: 0.7640\n",
      "Epoch [14/500], Training Loss: 0.4758, Validation Loss: 0.4757, Training Accuracy: 0.7750, Validation Accuracy: 0.7865\n",
      "Epoch [15/500], Training Loss: 0.4784, Validation Loss: 0.4873, Training Accuracy: 0.7775, Validation Accuracy: 0.7640\n",
      "Epoch [16/500], Training Loss: 0.4629, Validation Loss: 0.4775, Training Accuracy: 0.7913, Validation Accuracy: 0.7865\n",
      "Epoch [17/500], Training Loss: 0.4532, Validation Loss: 0.4818, Training Accuracy: 0.7850, Validation Accuracy: 0.7640\n",
      "Epoch [18/500], Training Loss: 0.4455, Validation Loss: 0.4764, Training Accuracy: 0.7900, Validation Accuracy: 0.7528\n",
      "Epoch [19/500], Training Loss: 0.4489, Validation Loss: 0.4896, Training Accuracy: 0.7837, Validation Accuracy: 0.7865\n",
      "Epoch [20/500], Training Loss: 0.4463, Validation Loss: 0.4938, Training Accuracy: 0.7913, Validation Accuracy: 0.7640\n",
      "Epoch [21/500], Training Loss: 0.4557, Validation Loss: 0.4948, Training Accuracy: 0.7725, Validation Accuracy: 0.7416\n",
      "Epoch [22/500], Training Loss: 0.4524, Validation Loss: 0.4817, Training Accuracy: 0.7863, Validation Accuracy: 0.7753\n",
      "Epoch [23/500], Training Loss: 0.4358, Validation Loss: 0.4910, Training Accuracy: 0.7825, Validation Accuracy: 0.7191\n",
      "Epoch [24/500], Training Loss: 0.4295, Validation Loss: 0.4841, Training Accuracy: 0.7963, Validation Accuracy: 0.7528\n",
      "Epoch [25/500], Training Loss: 0.4272, Validation Loss: 0.4915, Training Accuracy: 0.7925, Validation Accuracy: 0.7191\n",
      "Epoch [26/500], Training Loss: 0.4204, Validation Loss: 0.4928, Training Accuracy: 0.8087, Validation Accuracy: 0.7640\n",
      "Epoch [27/500], Training Loss: 0.4225, Validation Loss: 0.5064, Training Accuracy: 0.7925, Validation Accuracy: 0.7640\n",
      "Epoch [28/500], Training Loss: 0.4073, Validation Loss: 0.5105, Training Accuracy: 0.8050, Validation Accuracy: 0.7528\n",
      "Epoch [29/500], Training Loss: 0.4105, Validation Loss: 0.4841, Training Accuracy: 0.8037, Validation Accuracy: 0.7528\n",
      "Epoch [30/500], Training Loss: 0.3911, Validation Loss: 0.5079, Training Accuracy: 0.8050, Validation Accuracy: 0.7416\n",
      "Epoch [31/500], Training Loss: 0.3978, Validation Loss: 0.5024, Training Accuracy: 0.8163, Validation Accuracy: 0.7528\n",
      "Epoch [32/500], Training Loss: 0.4169, Validation Loss: 0.5182, Training Accuracy: 0.8050, Validation Accuracy: 0.7303\n",
      "Epoch [33/500], Training Loss: 0.3910, Validation Loss: 0.5216, Training Accuracy: 0.8150, Validation Accuracy: 0.7303\n",
      "Epoch [34/500], Training Loss: 0.3857, Validation Loss: 0.5002, Training Accuracy: 0.8137, Validation Accuracy: 0.7865\n",
      "Epoch [35/500], Training Loss: 0.4047, Validation Loss: 0.4922, Training Accuracy: 0.8087, Validation Accuracy: 0.7640\n",
      "Epoch [36/500], Training Loss: 0.3788, Validation Loss: 0.5164, Training Accuracy: 0.8263, Validation Accuracy: 0.7978\n",
      "Epoch [37/500], Training Loss: 0.3968, Validation Loss: 0.4877, Training Accuracy: 0.8075, Validation Accuracy: 0.7640\n",
      "Epoch [38/500], Training Loss: 0.3778, Validation Loss: 0.5113, Training Accuracy: 0.8263, Validation Accuracy: 0.7640\n",
      "Epoch [39/500], Training Loss: 0.3787, Validation Loss: 0.5136, Training Accuracy: 0.8337, Validation Accuracy: 0.7978\n",
      "Epoch [40/500], Training Loss: 0.3575, Validation Loss: 0.5013, Training Accuracy: 0.8488, Validation Accuracy: 0.7753\n",
      "Epoch [41/500], Training Loss: 0.3580, Validation Loss: 0.5097, Training Accuracy: 0.8488, Validation Accuracy: 0.7865\n",
      "Epoch [42/500], Training Loss: 0.3816, Validation Loss: 0.4909, Training Accuracy: 0.8375, Validation Accuracy: 0.7753\n",
      "Epoch [43/500], Training Loss: 0.3466, Validation Loss: 0.5057, Training Accuracy: 0.8337, Validation Accuracy: 0.7753\n",
      "Epoch [44/500], Training Loss: 0.3622, Validation Loss: 0.5002, Training Accuracy: 0.8413, Validation Accuracy: 0.7978\n",
      "Epoch [45/500], Training Loss: 0.3622, Validation Loss: 0.4777, Training Accuracy: 0.8425, Validation Accuracy: 0.8090\n",
      "Epoch [46/500], Training Loss: 0.3293, Validation Loss: 0.5028, Training Accuracy: 0.8512, Validation Accuracy: 0.7978\n",
      "Epoch [47/500], Training Loss: 0.3848, Validation Loss: 0.4765, Training Accuracy: 0.8263, Validation Accuracy: 0.7865\n",
      "Epoch [48/500], Training Loss: 0.3581, Validation Loss: 0.4692, Training Accuracy: 0.8325, Validation Accuracy: 0.8202\n",
      "Epoch [49/500], Training Loss: 0.3370, Validation Loss: 0.4806, Training Accuracy: 0.8650, Validation Accuracy: 0.7865\n",
      "Epoch [50/500], Training Loss: 0.3278, Validation Loss: 0.4966, Training Accuracy: 0.8575, Validation Accuracy: 0.7865\n",
      "Epoch [51/500], Training Loss: 0.3502, Validation Loss: 0.4730, Training Accuracy: 0.8400, Validation Accuracy: 0.8202\n",
      "Epoch [52/500], Training Loss: 0.3255, Validation Loss: 0.5263, Training Accuracy: 0.8512, Validation Accuracy: 0.8202\n",
      "Epoch [53/500], Training Loss: 0.3364, Validation Loss: 0.4750, Training Accuracy: 0.8475, Validation Accuracy: 0.8090\n",
      "Epoch [54/500], Training Loss: 0.3332, Validation Loss: 0.5004, Training Accuracy: 0.8488, Validation Accuracy: 0.7978\n",
      "Epoch [55/500], Training Loss: 0.3218, Validation Loss: 0.5257, Training Accuracy: 0.8525, Validation Accuracy: 0.7978\n",
      "Epoch [56/500], Training Loss: 0.2991, Validation Loss: 0.4844, Training Accuracy: 0.8738, Validation Accuracy: 0.7978\n",
      "Epoch [57/500], Training Loss: 0.3127, Validation Loss: 0.4915, Training Accuracy: 0.8662, Validation Accuracy: 0.7978\n",
      "Epoch [58/500], Training Loss: 0.3189, Validation Loss: 0.5078, Training Accuracy: 0.8625, Validation Accuracy: 0.7865\n",
      "Epoch [59/500], Training Loss: 0.2869, Validation Loss: 0.5165, Training Accuracy: 0.8800, Validation Accuracy: 0.7753\n",
      "Epoch [60/500], Training Loss: 0.2974, Validation Loss: 0.5162, Training Accuracy: 0.8650, Validation Accuracy: 0.8090\n",
      "Epoch [61/500], Training Loss: 0.3070, Validation Loss: 0.4841, Training Accuracy: 0.8638, Validation Accuracy: 0.8202\n",
      "Epoch [62/500], Training Loss: 0.3046, Validation Loss: 0.5221, Training Accuracy: 0.8725, Validation Accuracy: 0.7865\n",
      "Epoch [63/500], Training Loss: 0.2967, Validation Loss: 0.5132, Training Accuracy: 0.8688, Validation Accuracy: 0.7753\n",
      "Epoch [64/500], Training Loss: 0.2880, Validation Loss: 0.5415, Training Accuracy: 0.8812, Validation Accuracy: 0.7865\n",
      "Epoch [65/500], Training Loss: 0.2866, Validation Loss: 0.5456, Training Accuracy: 0.8650, Validation Accuracy: 0.7978\n",
      "Epoch [66/500], Training Loss: 0.2764, Validation Loss: 0.5040, Training Accuracy: 0.8875, Validation Accuracy: 0.7753\n",
      "Epoch [67/500], Training Loss: 0.2910, Validation Loss: 0.5365, Training Accuracy: 0.8850, Validation Accuracy: 0.8202\n",
      "Epoch [68/500], Training Loss: 0.3116, Validation Loss: 0.5419, Training Accuracy: 0.8725, Validation Accuracy: 0.7528\n",
      "Epoch [69/500], Training Loss: 0.2608, Validation Loss: 0.5283, Training Accuracy: 0.8938, Validation Accuracy: 0.7865\n",
      "Epoch [70/500], Training Loss: 0.2770, Validation Loss: 0.5622, Training Accuracy: 0.8800, Validation Accuracy: 0.7640\n",
      "Epoch [71/500], Training Loss: 0.2873, Validation Loss: 0.5272, Training Accuracy: 0.8788, Validation Accuracy: 0.7753\n",
      "Epoch [72/500], Training Loss: 0.2743, Validation Loss: 0.5408, Training Accuracy: 0.8900, Validation Accuracy: 0.7978\n",
      "Epoch [73/500], Training Loss: 0.2946, Validation Loss: 0.5595, Training Accuracy: 0.8612, Validation Accuracy: 0.7753\n",
      "Epoch [74/500], Training Loss: 0.2412, Validation Loss: 0.5412, Training Accuracy: 0.8938, Validation Accuracy: 0.7753\n",
      "Epoch [75/500], Training Loss: 0.2783, Validation Loss: 0.5519, Training Accuracy: 0.8938, Validation Accuracy: 0.7528\n",
      "Epoch [76/500], Training Loss: 0.2473, Validation Loss: 0.5656, Training Accuracy: 0.8938, Validation Accuracy: 0.7640\n",
      "Epoch [77/500], Training Loss: 0.2539, Validation Loss: 0.5376, Training Accuracy: 0.9062, Validation Accuracy: 0.7865\n",
      "Epoch [78/500], Training Loss: 0.2427, Validation Loss: 0.5017, Training Accuracy: 0.8950, Validation Accuracy: 0.8090\n",
      "Epoch [79/500], Training Loss: 0.2541, Validation Loss: 0.5267, Training Accuracy: 0.8925, Validation Accuracy: 0.7753\n",
      "Epoch [80/500], Training Loss: 0.2542, Validation Loss: 0.5298, Training Accuracy: 0.8988, Validation Accuracy: 0.7978\n",
      "Epoch [81/500], Training Loss: 0.2563, Validation Loss: 0.5128, Training Accuracy: 0.8988, Validation Accuracy: 0.7865\n",
      "Epoch [82/500], Training Loss: 0.2417, Validation Loss: 0.5522, Training Accuracy: 0.9025, Validation Accuracy: 0.7865\n",
      "Epoch [83/500], Training Loss: 0.2314, Validation Loss: 0.5839, Training Accuracy: 0.9075, Validation Accuracy: 0.7753\n",
      "Epoch [84/500], Training Loss: 0.2549, Validation Loss: 0.5560, Training Accuracy: 0.8925, Validation Accuracy: 0.8090\n",
      "Epoch [85/500], Training Loss: 0.2142, Validation Loss: 0.6140, Training Accuracy: 0.9200, Validation Accuracy: 0.7865\n",
      "Epoch [86/500], Training Loss: 0.2329, Validation Loss: 0.5749, Training Accuracy: 0.9075, Validation Accuracy: 0.7978\n",
      "Epoch [87/500], Training Loss: 0.2117, Validation Loss: 0.5465, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [88/500], Training Loss: 0.2186, Validation Loss: 0.5607, Training Accuracy: 0.9050, Validation Accuracy: 0.7640\n",
      "Epoch [89/500], Training Loss: 0.2263, Validation Loss: 0.5694, Training Accuracy: 0.9050, Validation Accuracy: 0.8090\n",
      "Epoch [90/500], Training Loss: 0.2449, Validation Loss: 0.5502, Training Accuracy: 0.9025, Validation Accuracy: 0.7865\n",
      "Epoch [91/500], Training Loss: 0.2313, Validation Loss: 0.5686, Training Accuracy: 0.9137, Validation Accuracy: 0.8090\n",
      "Epoch [92/500], Training Loss: 0.2242, Validation Loss: 0.5678, Training Accuracy: 0.9150, Validation Accuracy: 0.7865\n",
      "Epoch [93/500], Training Loss: 0.2445, Validation Loss: 0.5587, Training Accuracy: 0.9038, Validation Accuracy: 0.7753\n",
      "Epoch [94/500], Training Loss: 0.2127, Validation Loss: 0.5642, Training Accuracy: 0.9150, Validation Accuracy: 0.7865\n",
      "Epoch [95/500], Training Loss: 0.2101, Validation Loss: 0.5738, Training Accuracy: 0.9075, Validation Accuracy: 0.7640\n",
      "Epoch [96/500], Training Loss: 0.2134, Validation Loss: 0.5635, Training Accuracy: 0.9163, Validation Accuracy: 0.7753\n",
      "Epoch [97/500], Training Loss: 0.2054, Validation Loss: 0.5300, Training Accuracy: 0.9213, Validation Accuracy: 0.7978\n",
      "Epoch [98/500], Training Loss: 0.2226, Validation Loss: 0.5469, Training Accuracy: 0.9087, Validation Accuracy: 0.8090\n",
      "Epoch [99/500], Training Loss: 0.2423, Validation Loss: 0.4880, Training Accuracy: 0.9000, Validation Accuracy: 0.8090\n",
      "Epoch [100/500], Training Loss: 0.2088, Validation Loss: 0.5670, Training Accuracy: 0.9150, Validation Accuracy: 0.8090\n",
      "Epoch [101/500], Training Loss: 0.1906, Validation Loss: 0.5881, Training Accuracy: 0.9187, Validation Accuracy: 0.7978\n",
      "Epoch [102/500], Training Loss: 0.2313, Validation Loss: 0.5389, Training Accuracy: 0.9075, Validation Accuracy: 0.8202\n",
      "Epoch [103/500], Training Loss: 0.2335, Validation Loss: 0.5504, Training Accuracy: 0.9137, Validation Accuracy: 0.7978\n",
      "Epoch [104/500], Training Loss: 0.2044, Validation Loss: 0.5740, Training Accuracy: 0.9113, Validation Accuracy: 0.7865\n",
      "Epoch [105/500], Training Loss: 0.1895, Validation Loss: 0.6317, Training Accuracy: 0.9237, Validation Accuracy: 0.8202\n",
      "Epoch [106/500], Training Loss: 0.2033, Validation Loss: 0.6417, Training Accuracy: 0.9213, Validation Accuracy: 0.7640\n",
      "Epoch [107/500], Training Loss: 0.1906, Validation Loss: 0.5944, Training Accuracy: 0.9337, Validation Accuracy: 0.7753\n",
      "Epoch [108/500], Training Loss: 0.1792, Validation Loss: 0.5854, Training Accuracy: 0.9300, Validation Accuracy: 0.7978\n",
      "Epoch [109/500], Training Loss: 0.1998, Validation Loss: 0.6399, Training Accuracy: 0.9137, Validation Accuracy: 0.7865\n",
      "Epoch [110/500], Training Loss: 0.1981, Validation Loss: 0.5988, Training Accuracy: 0.9250, Validation Accuracy: 0.7753\n",
      "Epoch [111/500], Training Loss: 0.2009, Validation Loss: 0.5068, Training Accuracy: 0.9150, Validation Accuracy: 0.8090\n",
      "Epoch [112/500], Training Loss: 0.1740, Validation Loss: 0.5970, Training Accuracy: 0.9250, Validation Accuracy: 0.8090\n",
      "Epoch [113/500], Training Loss: 0.2070, Validation Loss: 0.5781, Training Accuracy: 0.9125, Validation Accuracy: 0.7865\n",
      "Epoch [114/500], Training Loss: 0.2076, Validation Loss: 0.6034, Training Accuracy: 0.9175, Validation Accuracy: 0.7978\n",
      "Epoch [115/500], Training Loss: 0.1916, Validation Loss: 0.5969, Training Accuracy: 0.9150, Validation Accuracy: 0.7640\n",
      "Epoch [116/500], Training Loss: 0.1875, Validation Loss: 0.5921, Training Accuracy: 0.9237, Validation Accuracy: 0.7753\n",
      "Epoch [117/500], Training Loss: 0.2114, Validation Loss: 0.6060, Training Accuracy: 0.9150, Validation Accuracy: 0.7753\n",
      "Epoch [118/500], Training Loss: 0.1748, Validation Loss: 0.6225, Training Accuracy: 0.9337, Validation Accuracy: 0.7978\n",
      "Epoch [119/500], Training Loss: 0.1767, Validation Loss: 0.6265, Training Accuracy: 0.9287, Validation Accuracy: 0.7978\n",
      "Epoch [120/500], Training Loss: 0.1793, Validation Loss: 0.6024, Training Accuracy: 0.9263, Validation Accuracy: 0.7978\n",
      "Epoch [121/500], Training Loss: 0.1496, Validation Loss: 0.6360, Training Accuracy: 0.9413, Validation Accuracy: 0.7978\n",
      "Epoch [122/500], Training Loss: 0.2088, Validation Loss: 0.6319, Training Accuracy: 0.9125, Validation Accuracy: 0.7865\n",
      "Epoch [123/500], Training Loss: 0.1778, Validation Loss: 0.6363, Training Accuracy: 0.9213, Validation Accuracy: 0.7753\n",
      "Epoch [124/500], Training Loss: 0.1776, Validation Loss: 0.7254, Training Accuracy: 0.9313, Validation Accuracy: 0.7528\n",
      "Epoch [125/500], Training Loss: 0.1747, Validation Loss: 0.6703, Training Accuracy: 0.9313, Validation Accuracy: 0.7978\n",
      "Epoch [126/500], Training Loss: 0.1546, Validation Loss: 0.6731, Training Accuracy: 0.9413, Validation Accuracy: 0.8090\n",
      "Epoch [127/500], Training Loss: 0.1658, Validation Loss: 0.6749, Training Accuracy: 0.9300, Validation Accuracy: 0.7865\n",
      "Epoch [128/500], Training Loss: 0.1934, Validation Loss: 0.7153, Training Accuracy: 0.9163, Validation Accuracy: 0.7528\n",
      "Epoch [129/500], Training Loss: 0.1518, Validation Loss: 0.6832, Training Accuracy: 0.9425, Validation Accuracy: 0.7753\n",
      "Epoch [130/500], Training Loss: 0.1730, Validation Loss: 0.6863, Training Accuracy: 0.9375, Validation Accuracy: 0.7978\n",
      "Epoch [131/500], Training Loss: 0.1874, Validation Loss: 0.6521, Training Accuracy: 0.9250, Validation Accuracy: 0.7865\n",
      "Epoch [132/500], Training Loss: 0.1596, Validation Loss: 0.6803, Training Accuracy: 0.9375, Validation Accuracy: 0.8090\n",
      "Epoch [133/500], Training Loss: 0.1379, Validation Loss: 0.7483, Training Accuracy: 0.9487, Validation Accuracy: 0.7753\n",
      "Epoch [134/500], Training Loss: 0.1786, Validation Loss: 0.7149, Training Accuracy: 0.9250, Validation Accuracy: 0.8090\n",
      "Epoch [135/500], Training Loss: 0.1399, Validation Loss: 1.6068, Training Accuracy: 0.9463, Validation Accuracy: 0.8090\n",
      "Epoch [136/500], Training Loss: 0.1402, Validation Loss: 0.7137, Training Accuracy: 0.9475, Validation Accuracy: 0.8315\n",
      "Epoch [137/500], Training Loss: 0.1566, Validation Loss: 0.6843, Training Accuracy: 0.9437, Validation Accuracy: 0.7978\n",
      "Epoch [138/500], Training Loss: 0.1408, Validation Loss: 0.6319, Training Accuracy: 0.9463, Validation Accuracy: 0.8090\n",
      "Epoch [139/500], Training Loss: 0.1727, Validation Loss: 0.6411, Training Accuracy: 0.9313, Validation Accuracy: 0.8202\n",
      "Epoch [140/500], Training Loss: 0.1578, Validation Loss: 0.6410, Training Accuracy: 0.9350, Validation Accuracy: 0.7978\n",
      "Epoch [141/500], Training Loss: 0.1474, Validation Loss: 0.6303, Training Accuracy: 0.9425, Validation Accuracy: 0.7753\n",
      "Epoch [142/500], Training Loss: 0.1576, Validation Loss: 0.6553, Training Accuracy: 0.9437, Validation Accuracy: 0.8090\n",
      "Epoch [143/500], Training Loss: 0.1551, Validation Loss: 0.7094, Training Accuracy: 0.9413, Validation Accuracy: 0.7978\n",
      "Epoch [144/500], Training Loss: 0.1600, Validation Loss: 0.6434, Training Accuracy: 0.9363, Validation Accuracy: 0.7640\n",
      "Epoch [145/500], Training Loss: 0.1606, Validation Loss: 0.6161, Training Accuracy: 0.9350, Validation Accuracy: 0.7865\n",
      "Epoch [146/500], Training Loss: 0.1521, Validation Loss: 0.6586, Training Accuracy: 0.9375, Validation Accuracy: 0.8202\n",
      "Epoch [147/500], Training Loss: 0.1611, Validation Loss: 0.6557, Training Accuracy: 0.9375, Validation Accuracy: 0.7865\n",
      "Epoch [148/500], Training Loss: 0.1558, Validation Loss: 0.6925, Training Accuracy: 0.9387, Validation Accuracy: 0.7640\n",
      "Epoch [149/500], Training Loss: 0.1732, Validation Loss: 0.6763, Training Accuracy: 0.9275, Validation Accuracy: 0.8202\n",
      "Epoch [150/500], Training Loss: 0.1458, Validation Loss: 0.6822, Training Accuracy: 0.9425, Validation Accuracy: 0.7978\n",
      "Epoch [151/500], Training Loss: 0.1548, Validation Loss: 0.6421, Training Accuracy: 0.9475, Validation Accuracy: 0.8427\n",
      "Epoch [152/500], Training Loss: 0.1604, Validation Loss: 0.7121, Training Accuracy: 0.9350, Validation Accuracy: 0.8202\n",
      "Epoch [153/500], Training Loss: 0.1412, Validation Loss: 0.6763, Training Accuracy: 0.9387, Validation Accuracy: 0.8090\n",
      "Epoch [154/500], Training Loss: 0.1253, Validation Loss: 0.6633, Training Accuracy: 0.9600, Validation Accuracy: 0.8202\n",
      "Epoch [155/500], Training Loss: 0.1356, Validation Loss: 0.7101, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [156/500], Training Loss: 0.1791, Validation Loss: 0.6841, Training Accuracy: 0.9250, Validation Accuracy: 0.8090\n",
      "Epoch [157/500], Training Loss: 0.1533, Validation Loss: 0.6660, Training Accuracy: 0.9350, Validation Accuracy: 0.8090\n",
      "Epoch [158/500], Training Loss: 0.1311, Validation Loss: 0.7372, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [159/500], Training Loss: 0.1389, Validation Loss: 0.6656, Training Accuracy: 0.9525, Validation Accuracy: 0.7865\n",
      "Epoch [160/500], Training Loss: 0.1103, Validation Loss: 0.6927, Training Accuracy: 0.9650, Validation Accuracy: 0.8202\n",
      "Epoch [161/500], Training Loss: 0.1568, Validation Loss: 0.6578, Training Accuracy: 0.9387, Validation Accuracy: 0.7978\n",
      "Epoch [162/500], Training Loss: 0.1368, Validation Loss: 0.7260, Training Accuracy: 0.9437, Validation Accuracy: 0.8090\n",
      "Epoch [163/500], Training Loss: 0.1333, Validation Loss: 1.6142, Training Accuracy: 0.9513, Validation Accuracy: 0.8090\n",
      "Epoch [164/500], Training Loss: 0.1178, Validation Loss: 1.5882, Training Accuracy: 0.9563, Validation Accuracy: 0.8202\n",
      "Epoch [165/500], Training Loss: 0.1504, Validation Loss: 0.7194, Training Accuracy: 0.9350, Validation Accuracy: 0.7753\n",
      "Epoch [166/500], Training Loss: 0.1431, Validation Loss: 0.6707, Training Accuracy: 0.9437, Validation Accuracy: 0.7978\n",
      "Epoch [167/500], Training Loss: 0.1508, Validation Loss: 1.5994, Training Accuracy: 0.9413, Validation Accuracy: 0.7640\n",
      "Epoch [168/500], Training Loss: 0.1482, Validation Loss: 0.6983, Training Accuracy: 0.9413, Validation Accuracy: 0.7978\n",
      "Epoch [169/500], Training Loss: 0.1339, Validation Loss: 0.7244, Training Accuracy: 0.9537, Validation Accuracy: 0.8090\n",
      "Epoch [170/500], Training Loss: 0.1406, Validation Loss: 0.7069, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [171/500], Training Loss: 0.1396, Validation Loss: 0.6941, Training Accuracy: 0.9475, Validation Accuracy: 0.8090\n",
      "Epoch [172/500], Training Loss: 0.1382, Validation Loss: 0.6280, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [173/500], Training Loss: 0.1115, Validation Loss: 0.7374, Training Accuracy: 0.9613, Validation Accuracy: 0.8202\n",
      "Epoch [174/500], Training Loss: 0.1272, Validation Loss: 0.6518, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [175/500], Training Loss: 0.1337, Validation Loss: 0.6619, Training Accuracy: 0.9500, Validation Accuracy: 0.8202\n",
      "Epoch [176/500], Training Loss: 0.1210, Validation Loss: 0.6147, Training Accuracy: 0.9513, Validation Accuracy: 0.8202\n",
      "Epoch [177/500], Training Loss: 0.1335, Validation Loss: 0.6417, Training Accuracy: 0.9500, Validation Accuracy: 0.8090\n",
      "Epoch [178/500], Training Loss: 0.1249, Validation Loss: 0.7352, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [179/500], Training Loss: 0.1048, Validation Loss: 0.7430, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [180/500], Training Loss: 0.1121, Validation Loss: 0.7478, Training Accuracy: 0.9563, Validation Accuracy: 0.8090\n",
      "Epoch [181/500], Training Loss: 0.1151, Validation Loss: 0.7540, Training Accuracy: 0.9500, Validation Accuracy: 0.7753\n",
      "Epoch [182/500], Training Loss: 0.0996, Validation Loss: 0.7274, Training Accuracy: 0.9688, Validation Accuracy: 0.8090\n",
      "Epoch [183/500], Training Loss: 0.1087, Validation Loss: 0.7007, Training Accuracy: 0.9600, Validation Accuracy: 0.8090\n",
      "Epoch [184/500], Training Loss: 0.1089, Validation Loss: 0.7657, Training Accuracy: 0.9575, Validation Accuracy: 0.8090\n",
      "Epoch [185/500], Training Loss: 0.1105, Validation Loss: 0.7784, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [186/500], Training Loss: 0.1160, Validation Loss: 0.7067, Training Accuracy: 0.9550, Validation Accuracy: 0.7865\n",
      "Epoch [187/500], Training Loss: 0.1417, Validation Loss: 0.7076, Training Accuracy: 0.9437, Validation Accuracy: 0.8090\n",
      "Epoch [188/500], Training Loss: 0.1057, Validation Loss: 0.7296, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [189/500], Training Loss: 0.1188, Validation Loss: 0.7418, Training Accuracy: 0.9563, Validation Accuracy: 0.8090\n",
      "Epoch [190/500], Training Loss: 0.1253, Validation Loss: 0.7459, Training Accuracy: 0.9537, Validation Accuracy: 0.8315\n",
      "Epoch [191/500], Training Loss: 0.1228, Validation Loss: 0.6900, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [192/500], Training Loss: 0.1345, Validation Loss: 0.6372, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [193/500], Training Loss: 0.1220, Validation Loss: 0.6920, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [194/500], Training Loss: 0.1173, Validation Loss: 0.6993, Training Accuracy: 0.9525, Validation Accuracy: 0.8315\n",
      "Epoch [195/500], Training Loss: 0.1090, Validation Loss: 0.7186, Training Accuracy: 0.9600, Validation Accuracy: 0.8090\n",
      "Epoch [196/500], Training Loss: 0.1155, Validation Loss: 0.6527, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [197/500], Training Loss: 0.0998, Validation Loss: 0.7056, Training Accuracy: 0.9688, Validation Accuracy: 0.8202\n",
      "Epoch [198/500], Training Loss: 0.1272, Validation Loss: 0.7892, Training Accuracy: 0.9613, Validation Accuracy: 0.7640\n",
      "Epoch [199/500], Training Loss: 0.1093, Validation Loss: 0.8048, Training Accuracy: 0.9587, Validation Accuracy: 0.7640\n",
      "Epoch [200/500], Training Loss: 0.1182, Validation Loss: 0.7249, Training Accuracy: 0.9475, Validation Accuracy: 0.7865\n",
      "Epoch [201/500], Training Loss: 0.1224, Validation Loss: 0.7138, Training Accuracy: 0.9537, Validation Accuracy: 0.7640\n",
      "Epoch [202/500], Training Loss: 0.1149, Validation Loss: 0.6994, Training Accuracy: 0.9450, Validation Accuracy: 0.8202\n",
      "Epoch [203/500], Training Loss: 0.1173, Validation Loss: 0.6346, Training Accuracy: 0.9500, Validation Accuracy: 0.7865\n",
      "Epoch [204/500], Training Loss: 0.0998, Validation Loss: 0.7236, Training Accuracy: 0.9637, Validation Accuracy: 0.8090\n",
      "Epoch [205/500], Training Loss: 0.1105, Validation Loss: 0.7271, Training Accuracy: 0.9575, Validation Accuracy: 0.7753\n",
      "Epoch [206/500], Training Loss: 0.1114, Validation Loss: 1.5753, Training Accuracy: 0.9550, Validation Accuracy: 0.8202\n",
      "Epoch [207/500], Training Loss: 0.1071, Validation Loss: 0.6834, Training Accuracy: 0.9587, Validation Accuracy: 0.7865\n",
      "Epoch [208/500], Training Loss: 0.0999, Validation Loss: 0.7831, Training Accuracy: 0.9663, Validation Accuracy: 0.7640\n",
      "Epoch [209/500], Training Loss: 0.1102, Validation Loss: 0.7585, Training Accuracy: 0.9613, Validation Accuracy: 0.8090\n",
      "Epoch [210/500], Training Loss: 0.1014, Validation Loss: 1.6433, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [211/500], Training Loss: 0.1038, Validation Loss: 1.6063, Training Accuracy: 0.9625, Validation Accuracy: 0.8315\n",
      "Epoch [212/500], Training Loss: 0.0978, Validation Loss: 0.7075, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [213/500], Training Loss: 0.0878, Validation Loss: 0.7367, Training Accuracy: 0.9675, Validation Accuracy: 0.8202\n",
      "Epoch [214/500], Training Loss: 0.1124, Validation Loss: 1.5979, Training Accuracy: 0.9563, Validation Accuracy: 0.8202\n",
      "Epoch [215/500], Training Loss: 0.1255, Validation Loss: 0.7433, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [216/500], Training Loss: 0.0997, Validation Loss: 0.6710, Training Accuracy: 0.9625, Validation Accuracy: 0.8202\n",
      "Epoch [217/500], Training Loss: 0.1045, Validation Loss: 1.6482, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [218/500], Training Loss: 0.1028, Validation Loss: 0.8192, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [219/500], Training Loss: 0.1149, Validation Loss: 1.6477, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [220/500], Training Loss: 0.1148, Validation Loss: 1.6795, Training Accuracy: 0.9587, Validation Accuracy: 0.7753\n",
      "Epoch [221/500], Training Loss: 0.1029, Validation Loss: 0.7914, Training Accuracy: 0.9563, Validation Accuracy: 0.7865\n",
      "Epoch [222/500], Training Loss: 0.1298, Validation Loss: 0.7886, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [223/500], Training Loss: 0.1023, Validation Loss: 1.6369, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [224/500], Training Loss: 0.1012, Validation Loss: 1.7020, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [225/500], Training Loss: 0.1267, Validation Loss: 0.7470, Training Accuracy: 0.9513, Validation Accuracy: 0.7978\n",
      "Epoch [226/500], Training Loss: 0.0995, Validation Loss: 0.7355, Training Accuracy: 0.9637, Validation Accuracy: 0.7753\n",
      "Epoch [227/500], Training Loss: 0.0933, Validation Loss: 0.8058, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [228/500], Training Loss: 0.1311, Validation Loss: 0.8090, Training Accuracy: 0.9463, Validation Accuracy: 0.7640\n",
      "Epoch [229/500], Training Loss: 0.0959, Validation Loss: 0.7774, Training Accuracy: 0.9650, Validation Accuracy: 0.7753\n",
      "Epoch [230/500], Training Loss: 0.0902, Validation Loss: 0.8219, Training Accuracy: 0.9613, Validation Accuracy: 0.7753\n",
      "Epoch [231/500], Training Loss: 0.0963, Validation Loss: 0.7558, Training Accuracy: 0.9650, Validation Accuracy: 0.7753\n",
      "Epoch [232/500], Training Loss: 0.1058, Validation Loss: 1.6351, Training Accuracy: 0.9637, Validation Accuracy: 0.7753\n",
      "Epoch [233/500], Training Loss: 0.1052, Validation Loss: 0.7706, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [234/500], Training Loss: 0.0723, Validation Loss: 0.8446, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [235/500], Training Loss: 0.1124, Validation Loss: 1.7308, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [236/500], Training Loss: 0.0978, Validation Loss: 1.7515, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [237/500], Training Loss: 0.0975, Validation Loss: 1.8073, Training Accuracy: 0.9637, Validation Accuracy: 0.7753\n",
      "Epoch [238/500], Training Loss: 0.0988, Validation Loss: 1.7348, Training Accuracy: 0.9613, Validation Accuracy: 0.7865\n",
      "Epoch [239/500], Training Loss: 0.0894, Validation Loss: 1.7621, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [240/500], Training Loss: 0.0815, Validation Loss: 1.7193, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [241/500], Training Loss: 0.0953, Validation Loss: 1.7604, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [242/500], Training Loss: 0.1102, Validation Loss: 1.7151, Training Accuracy: 0.9613, Validation Accuracy: 0.8090\n",
      "Epoch [243/500], Training Loss: 0.0932, Validation Loss: 1.7513, Training Accuracy: 0.9637, Validation Accuracy: 0.7753\n",
      "Epoch [244/500], Training Loss: 0.0871, Validation Loss: 1.7708, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [245/500], Training Loss: 0.0861, Validation Loss: 1.8120, Training Accuracy: 0.9688, Validation Accuracy: 0.7640\n",
      "Epoch [246/500], Training Loss: 0.0746, Validation Loss: 1.7635, Training Accuracy: 0.9775, Validation Accuracy: 0.8090\n",
      "Epoch [247/500], Training Loss: 0.0764, Validation Loss: 1.8298, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [248/500], Training Loss: 0.1045, Validation Loss: 1.7604, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [249/500], Training Loss: 0.0646, Validation Loss: 1.7334, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [250/500], Training Loss: 0.1337, Validation Loss: 1.7083, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [251/500], Training Loss: 0.1073, Validation Loss: 1.7350, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [252/500], Training Loss: 0.1000, Validation Loss: 1.7620, Training Accuracy: 0.9637, Validation Accuracy: 0.7640\n",
      "Epoch [253/500], Training Loss: 0.1016, Validation Loss: 1.7274, Training Accuracy: 0.9663, Validation Accuracy: 0.7753\n",
      "Epoch [254/500], Training Loss: 0.1141, Validation Loss: 1.7462, Training Accuracy: 0.9587, Validation Accuracy: 0.7640\n",
      "Epoch [255/500], Training Loss: 0.0935, Validation Loss: 1.7234, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [256/500], Training Loss: 0.0711, Validation Loss: 1.7528, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [257/500], Training Loss: 0.0923, Validation Loss: 1.7296, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [258/500], Training Loss: 0.0890, Validation Loss: 1.7322, Training Accuracy: 0.9700, Validation Accuracy: 0.8090\n",
      "Epoch [259/500], Training Loss: 0.0717, Validation Loss: 1.7247, Training Accuracy: 0.9700, Validation Accuracy: 0.8315\n",
      "Epoch [260/500], Training Loss: 0.0916, Validation Loss: 0.9042, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [261/500], Training Loss: 0.1148, Validation Loss: 1.8090, Training Accuracy: 0.9587, Validation Accuracy: 0.7753\n",
      "Epoch [262/500], Training Loss: 0.1064, Validation Loss: 1.7160, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [263/500], Training Loss: 0.0976, Validation Loss: 1.6684, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [264/500], Training Loss: 0.0967, Validation Loss: 1.6517, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [265/500], Training Loss: 0.0894, Validation Loss: 1.6953, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [266/500], Training Loss: 0.0681, Validation Loss: 1.6967, Training Accuracy: 0.9775, Validation Accuracy: 0.7865\n",
      "Epoch [267/500], Training Loss: 0.1170, Validation Loss: 0.8074, Training Accuracy: 0.9563, Validation Accuracy: 0.8090\n",
      "Epoch [268/500], Training Loss: 0.0701, Validation Loss: 0.8507, Training Accuracy: 0.9750, Validation Accuracy: 0.8202\n",
      "Epoch [269/500], Training Loss: 0.0740, Validation Loss: 0.8528, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [270/500], Training Loss: 0.0666, Validation Loss: 1.7726, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [271/500], Training Loss: 0.1009, Validation Loss: 0.8806, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [272/500], Training Loss: 0.0792, Validation Loss: 1.7575, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [273/500], Training Loss: 0.0854, Validation Loss: 1.7711, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [274/500], Training Loss: 0.1027, Validation Loss: 1.7690, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [275/500], Training Loss: 0.0916, Validation Loss: 1.7318, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [276/500], Training Loss: 0.0962, Validation Loss: 1.7840, Training Accuracy: 0.9600, Validation Accuracy: 0.7865\n",
      "Epoch [277/500], Training Loss: 0.0851, Validation Loss: 1.8039, Training Accuracy: 0.9675, Validation Accuracy: 0.7753\n",
      "Epoch [278/500], Training Loss: 0.0720, Validation Loss: 1.8316, Training Accuracy: 0.9725, Validation Accuracy: 0.7640\n",
      "Epoch [279/500], Training Loss: 0.0868, Validation Loss: 1.7740, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [280/500], Training Loss: 0.0842, Validation Loss: 1.8518, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [281/500], Training Loss: 0.0882, Validation Loss: 1.8477, Training Accuracy: 0.9675, Validation Accuracy: 0.7753\n",
      "Epoch [282/500], Training Loss: 0.0787, Validation Loss: 1.8311, Training Accuracy: 0.9663, Validation Accuracy: 0.7640\n",
      "Epoch [283/500], Training Loss: 0.0949, Validation Loss: 1.7838, Training Accuracy: 0.9637, Validation Accuracy: 0.8090\n",
      "Epoch [284/500], Training Loss: 0.0915, Validation Loss: 1.7581, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [285/500], Training Loss: 0.0621, Validation Loss: 1.8114, Training Accuracy: 0.9788, Validation Accuracy: 0.7640\n",
      "Epoch [286/500], Training Loss: 0.0884, Validation Loss: 1.8262, Training Accuracy: 0.9725, Validation Accuracy: 0.7753\n",
      "Epoch [287/500], Training Loss: 0.1096, Validation Loss: 1.8086, Training Accuracy: 0.9613, Validation Accuracy: 0.7640\n",
      "Epoch [288/500], Training Loss: 0.0738, Validation Loss: 1.7869, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [289/500], Training Loss: 0.0677, Validation Loss: 1.8647, Training Accuracy: 0.9762, Validation Accuracy: 0.7528\n",
      "Epoch [290/500], Training Loss: 0.0768, Validation Loss: 1.8614, Training Accuracy: 0.9725, Validation Accuracy: 0.7753\n",
      "Epoch [291/500], Training Loss: 0.0604, Validation Loss: 1.8505, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [292/500], Training Loss: 0.0963, Validation Loss: 1.8036, Training Accuracy: 0.9650, Validation Accuracy: 0.7640\n",
      "Epoch [293/500], Training Loss: 0.0977, Validation Loss: 1.7948, Training Accuracy: 0.9563, Validation Accuracy: 0.7640\n",
      "Epoch [294/500], Training Loss: 0.0754, Validation Loss: 1.7994, Training Accuracy: 0.9725, Validation Accuracy: 0.7640\n",
      "Epoch [295/500], Training Loss: 0.0899, Validation Loss: 1.8544, Training Accuracy: 0.9663, Validation Accuracy: 0.7753\n",
      "Epoch [296/500], Training Loss: 0.0989, Validation Loss: 1.8514, Training Accuracy: 0.9613, Validation Accuracy: 0.7753\n",
      "Epoch [297/500], Training Loss: 0.0690, Validation Loss: 0.9318, Training Accuracy: 0.9775, Validation Accuracy: 0.7865\n",
      "Epoch [298/500], Training Loss: 0.0833, Validation Loss: 1.8205, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [299/500], Training Loss: 0.0939, Validation Loss: 1.8356, Training Accuracy: 0.9663, Validation Accuracy: 0.7865\n",
      "Epoch [300/500], Training Loss: 0.0866, Validation Loss: 1.8350, Training Accuracy: 0.9700, Validation Accuracy: 0.7753\n",
      "Epoch [301/500], Training Loss: 0.0685, Validation Loss: 1.8181, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [302/500], Training Loss: 0.0774, Validation Loss: 1.8031, Training Accuracy: 0.9725, Validation Accuracy: 0.7753\n",
      "Epoch [303/500], Training Loss: 0.0735, Validation Loss: 1.8328, Training Accuracy: 0.9762, Validation Accuracy: 0.7640\n",
      "Epoch [304/500], Training Loss: 0.0643, Validation Loss: 1.8186, Training Accuracy: 0.9775, Validation Accuracy: 0.7528\n",
      "Epoch [305/500], Training Loss: 0.0536, Validation Loss: 1.9030, Training Accuracy: 0.9800, Validation Accuracy: 0.7640\n",
      "Epoch [306/500], Training Loss: 0.0952, Validation Loss: 1.8354, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [307/500], Training Loss: 0.0908, Validation Loss: 1.7763, Training Accuracy: 0.9675, Validation Accuracy: 0.7640\n",
      "Epoch [308/500], Training Loss: 0.1064, Validation Loss: 1.6743, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [309/500], Training Loss: 0.1017, Validation Loss: 1.7437, Training Accuracy: 0.9587, Validation Accuracy: 0.7753\n",
      "Epoch [310/500], Training Loss: 0.0788, Validation Loss: 1.7854, Training Accuracy: 0.9725, Validation Accuracy: 0.7528\n",
      "Epoch [311/500], Training Loss: 0.0579, Validation Loss: 1.7630, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [312/500], Training Loss: 0.0748, Validation Loss: 1.7677, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [313/500], Training Loss: 0.0844, Validation Loss: 1.7982, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [314/500], Training Loss: 0.0673, Validation Loss: 1.8155, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [315/500], Training Loss: 0.0710, Validation Loss: 1.7884, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [316/500], Training Loss: 0.0644, Validation Loss: 1.7378, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [317/500], Training Loss: 0.0862, Validation Loss: 1.7830, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [318/500], Training Loss: 0.0559, Validation Loss: 1.7863, Training Accuracy: 0.9838, Validation Accuracy: 0.7865\n",
      "Epoch [319/500], Training Loss: 0.0840, Validation Loss: 1.8757, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [320/500], Training Loss: 0.0565, Validation Loss: 1.9296, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [321/500], Training Loss: 0.0684, Validation Loss: 1.9327, Training Accuracy: 0.9775, Validation Accuracy: 0.7640\n",
      "Epoch [322/500], Training Loss: 0.0708, Validation Loss: 1.8618, Training Accuracy: 0.9712, Validation Accuracy: 0.7753\n",
      "Epoch [323/500], Training Loss: 0.0713, Validation Loss: 1.8053, Training Accuracy: 0.9725, Validation Accuracy: 0.7753\n",
      "Epoch [324/500], Training Loss: 0.0698, Validation Loss: 1.8018, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [325/500], Training Loss: 0.0657, Validation Loss: 1.8798, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [326/500], Training Loss: 0.0557, Validation Loss: 1.8874, Training Accuracy: 0.9812, Validation Accuracy: 0.7640\n",
      "Epoch [327/500], Training Loss: 0.0695, Validation Loss: 1.8633, Training Accuracy: 0.9775, Validation Accuracy: 0.7865\n",
      "Epoch [328/500], Training Loss: 0.0680, Validation Loss: 1.8335, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [329/500], Training Loss: 0.0836, Validation Loss: 1.8708, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [330/500], Training Loss: 0.0848, Validation Loss: 1.8522, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [331/500], Training Loss: 0.0681, Validation Loss: 1.7950, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [332/500], Training Loss: 0.0738, Validation Loss: 1.8369, Training Accuracy: 0.9738, Validation Accuracy: 0.7640\n",
      "Epoch [333/500], Training Loss: 0.0780, Validation Loss: 1.8572, Training Accuracy: 0.9738, Validation Accuracy: 0.7753\n",
      "Epoch [334/500], Training Loss: 0.0581, Validation Loss: 1.8815, Training Accuracy: 0.9812, Validation Accuracy: 0.7528\n",
      "Epoch [335/500], Training Loss: 0.0466, Validation Loss: 1.9328, Training Accuracy: 0.9850, Validation Accuracy: 0.7753\n",
      "Epoch [336/500], Training Loss: 0.0689, Validation Loss: 1.9133, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [337/500], Training Loss: 0.0609, Validation Loss: 1.8981, Training Accuracy: 0.9750, Validation Accuracy: 0.7416\n",
      "Epoch [338/500], Training Loss: 0.0839, Validation Loss: 1.9238, Training Accuracy: 0.9700, Validation Accuracy: 0.7416\n",
      "Epoch [339/500], Training Loss: 0.0617, Validation Loss: 1.8802, Training Accuracy: 0.9838, Validation Accuracy: 0.7865\n",
      "Epoch [340/500], Training Loss: 0.0926, Validation Loss: 1.9094, Training Accuracy: 0.9712, Validation Accuracy: 0.7640\n",
      "Epoch [341/500], Training Loss: 0.0977, Validation Loss: 1.8370, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [342/500], Training Loss: 0.0534, Validation Loss: 1.7872, Training Accuracy: 0.9838, Validation Accuracy: 0.7865\n",
      "Epoch [343/500], Training Loss: 0.0661, Validation Loss: 1.8212, Training Accuracy: 0.9738, Validation Accuracy: 0.7753\n",
      "Epoch [344/500], Training Loss: 0.0660, Validation Loss: 1.8503, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [345/500], Training Loss: 0.0594, Validation Loss: 1.8308, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [346/500], Training Loss: 0.0732, Validation Loss: 1.8738, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [347/500], Training Loss: 0.0614, Validation Loss: 1.8061, Training Accuracy: 0.9775, Validation Accuracy: 0.7753\n",
      "Epoch [348/500], Training Loss: 0.0626, Validation Loss: 1.8375, Training Accuracy: 0.9788, Validation Accuracy: 0.7640\n",
      "Epoch [349/500], Training Loss: 0.0705, Validation Loss: 1.7219, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [350/500], Training Loss: 0.0614, Validation Loss: 1.8113, Training Accuracy: 0.9825, Validation Accuracy: 0.7528\n",
      "Epoch [351/500], Training Loss: 0.0734, Validation Loss: 1.7508, Training Accuracy: 0.9750, Validation Accuracy: 0.7640\n",
      "Epoch [352/500], Training Loss: 0.0644, Validation Loss: 1.7500, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [353/500], Training Loss: 0.0431, Validation Loss: 1.7784, Training Accuracy: 0.9862, Validation Accuracy: 0.8090\n",
      "Epoch [354/500], Training Loss: 0.0627, Validation Loss: 1.7776, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [355/500], Training Loss: 0.0742, Validation Loss: 1.8197, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [356/500], Training Loss: 0.0835, Validation Loss: 1.7426, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [357/500], Training Loss: 0.0726, Validation Loss: 1.8390, Training Accuracy: 0.9762, Validation Accuracy: 0.7640\n",
      "Epoch [358/500], Training Loss: 0.0833, Validation Loss: 1.9467, Training Accuracy: 0.9750, Validation Accuracy: 0.7640\n",
      "Epoch [359/500], Training Loss: 0.0603, Validation Loss: 1.9152, Training Accuracy: 0.9800, Validation Accuracy: 0.7640\n",
      "Epoch [360/500], Training Loss: 0.0607, Validation Loss: 1.8872, Training Accuracy: 0.9762, Validation Accuracy: 0.7753\n",
      "Epoch [361/500], Training Loss: 0.0701, Validation Loss: 1.8327, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [362/500], Training Loss: 0.0699, Validation Loss: 1.8757, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [363/500], Training Loss: 0.0746, Validation Loss: 1.9964, Training Accuracy: 0.9800, Validation Accuracy: 0.7640\n",
      "Epoch [364/500], Training Loss: 0.0576, Validation Loss: 1.9971, Training Accuracy: 0.9750, Validation Accuracy: 0.7640\n",
      "Epoch [365/500], Training Loss: 0.0603, Validation Loss: 2.0223, Training Accuracy: 0.9788, Validation Accuracy: 0.7640\n",
      "Epoch [366/500], Training Loss: 0.0863, Validation Loss: 1.9332, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [367/500], Training Loss: 0.0521, Validation Loss: 1.9462, Training Accuracy: 0.9862, Validation Accuracy: 0.7640\n",
      "Epoch [368/500], Training Loss: 0.0647, Validation Loss: 1.9103, Training Accuracy: 0.9738, Validation Accuracy: 0.7640\n",
      "Epoch [369/500], Training Loss: 0.0558, Validation Loss: 1.9851, Training Accuracy: 0.9850, Validation Accuracy: 0.7640\n",
      "Epoch [370/500], Training Loss: 0.0708, Validation Loss: 2.0061, Training Accuracy: 0.9762, Validation Accuracy: 0.7640\n",
      "Epoch [371/500], Training Loss: 0.0783, Validation Loss: 1.9907, Training Accuracy: 0.9700, Validation Accuracy: 0.7640\n",
      "Epoch [372/500], Training Loss: 0.0693, Validation Loss: 1.9486, Training Accuracy: 0.9762, Validation Accuracy: 0.7753\n",
      "Epoch [373/500], Training Loss: 0.0674, Validation Loss: 1.9879, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [374/500], Training Loss: 0.0799, Validation Loss: 1.8979, Training Accuracy: 0.9725, Validation Accuracy: 0.7640\n",
      "Epoch [375/500], Training Loss: 0.0576, Validation Loss: 1.8977, Training Accuracy: 0.9825, Validation Accuracy: 0.7753\n",
      "Epoch [376/500], Training Loss: 0.0689, Validation Loss: 1.8876, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [377/500], Training Loss: 0.0657, Validation Loss: 1.8521, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [378/500], Training Loss: 0.0751, Validation Loss: 1.7831, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [379/500], Training Loss: 0.0825, Validation Loss: 1.8312, Training Accuracy: 0.9775, Validation Accuracy: 0.7753\n",
      "Epoch [380/500], Training Loss: 0.0648, Validation Loss: 1.8138, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [381/500], Training Loss: 0.0452, Validation Loss: 1.8138, Training Accuracy: 0.9862, Validation Accuracy: 0.7978\n",
      "Epoch [382/500], Training Loss: 0.0483, Validation Loss: 1.8321, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [383/500], Training Loss: 0.0581, Validation Loss: 1.8747, Training Accuracy: 0.9825, Validation Accuracy: 0.7865\n",
      "Epoch [384/500], Training Loss: 0.0560, Validation Loss: 1.8658, Training Accuracy: 0.9775, Validation Accuracy: 0.7865\n",
      "Epoch [385/500], Training Loss: 0.0717, Validation Loss: 1.9922, Training Accuracy: 0.9788, Validation Accuracy: 0.7640\n",
      "Epoch [386/500], Training Loss: 0.0524, Validation Loss: 1.9405, Training Accuracy: 0.9775, Validation Accuracy: 0.7753\n",
      "Epoch [387/500], Training Loss: 0.0648, Validation Loss: 1.8674, Training Accuracy: 0.9762, Validation Accuracy: 0.7753\n",
      "Epoch [388/500], Training Loss: 0.0889, Validation Loss: 1.8719, Training Accuracy: 0.9675, Validation Accuracy: 0.7640\n",
      "Epoch [389/500], Training Loss: 0.0529, Validation Loss: 1.9444, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [390/500], Training Loss: 0.0693, Validation Loss: 1.9211, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [391/500], Training Loss: 0.0812, Validation Loss: 1.9162, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [392/500], Training Loss: 0.0638, Validation Loss: 1.8326, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [393/500], Training Loss: 0.0778, Validation Loss: 1.8697, Training Accuracy: 0.9775, Validation Accuracy: 0.7640\n",
      "Epoch [394/500], Training Loss: 0.0669, Validation Loss: 1.8645, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [395/500], Training Loss: 0.0816, Validation Loss: 1.8506, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [396/500], Training Loss: 0.0605, Validation Loss: 1.8227, Training Accuracy: 0.9775, Validation Accuracy: 0.7753\n",
      "Epoch [397/500], Training Loss: 0.0801, Validation Loss: 1.7814, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [398/500], Training Loss: 0.0358, Validation Loss: 1.8862, Training Accuracy: 0.9862, Validation Accuracy: 0.7640\n",
      "Epoch [399/500], Training Loss: 0.0550, Validation Loss: 1.9829, Training Accuracy: 0.9800, Validation Accuracy: 0.7640\n",
      "Epoch [400/500], Training Loss: 0.0705, Validation Loss: 1.9623, Training Accuracy: 0.9712, Validation Accuracy: 0.7528\n",
      "Epoch [401/500], Training Loss: 0.0405, Validation Loss: 1.9667, Training Accuracy: 0.9850, Validation Accuracy: 0.7640\n",
      "Epoch [402/500], Training Loss: 0.0482, Validation Loss: 1.9680, Training Accuracy: 0.9812, Validation Accuracy: 0.7640\n",
      "Epoch [403/500], Training Loss: 0.0485, Validation Loss: 1.9431, Training Accuracy: 0.9850, Validation Accuracy: 0.7753\n",
      "Epoch [404/500], Training Loss: 0.0690, Validation Loss: 1.9257, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [405/500], Training Loss: 0.0518, Validation Loss: 1.9677, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [406/500], Training Loss: 0.0625, Validation Loss: 1.9816, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [407/500], Training Loss: 0.0639, Validation Loss: 1.9236, Training Accuracy: 0.9788, Validation Accuracy: 0.7640\n",
      "Epoch [408/500], Training Loss: 0.0487, Validation Loss: 1.9459, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [409/500], Training Loss: 0.0538, Validation Loss: 1.9220, Training Accuracy: 0.9800, Validation Accuracy: 0.7640\n",
      "Epoch [410/500], Training Loss: 0.0538, Validation Loss: 1.9520, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [411/500], Training Loss: 0.0542, Validation Loss: 1.9416, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [412/500], Training Loss: 0.0480, Validation Loss: 2.0043, Training Accuracy: 0.9862, Validation Accuracy: 0.7753\n",
      "Epoch [413/500], Training Loss: 0.0469, Validation Loss: 2.0000, Training Accuracy: 0.9838, Validation Accuracy: 0.7640\n",
      "Epoch [414/500], Training Loss: 0.0539, Validation Loss: 1.9484, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [415/500], Training Loss: 0.0434, Validation Loss: 1.9464, Training Accuracy: 0.9900, Validation Accuracy: 0.7865\n",
      "Epoch [416/500], Training Loss: 0.0647, Validation Loss: 1.9468, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [417/500], Training Loss: 0.0699, Validation Loss: 1.8949, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [418/500], Training Loss: 0.0277, Validation Loss: 1.8688, Training Accuracy: 0.9925, Validation Accuracy: 0.7865\n",
      "Epoch [419/500], Training Loss: 0.0611, Validation Loss: 1.8994, Training Accuracy: 0.9762, Validation Accuracy: 0.7528\n",
      "Epoch [420/500], Training Loss: 0.0473, Validation Loss: 1.9761, Training Accuracy: 0.9838, Validation Accuracy: 0.7753\n",
      "Epoch [421/500], Training Loss: 0.0513, Validation Loss: 2.0330, Training Accuracy: 0.9788, Validation Accuracy: 0.7640\n",
      "Epoch [422/500], Training Loss: 0.0703, Validation Loss: 2.0104, Training Accuracy: 0.9775, Validation Accuracy: 0.7416\n",
      "Epoch [423/500], Training Loss: 0.0766, Validation Loss: 1.9100, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [424/500], Training Loss: 0.0682, Validation Loss: 1.9159, Training Accuracy: 0.9775, Validation Accuracy: 0.7865\n",
      "Epoch [425/500], Training Loss: 0.0660, Validation Loss: 1.9501, Training Accuracy: 0.9750, Validation Accuracy: 0.7640\n",
      "Epoch [426/500], Training Loss: 0.0442, Validation Loss: 1.9336, Training Accuracy: 0.9850, Validation Accuracy: 0.7865\n",
      "Epoch [427/500], Training Loss: 0.0690, Validation Loss: 1.8516, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [428/500], Training Loss: 0.0640, Validation Loss: 1.8205, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [429/500], Training Loss: 0.0440, Validation Loss: 1.8322, Training Accuracy: 0.9838, Validation Accuracy: 0.7865\n",
      "Epoch [430/500], Training Loss: 0.0612, Validation Loss: 1.8604, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [431/500], Training Loss: 0.0567, Validation Loss: 1.8921, Training Accuracy: 0.9850, Validation Accuracy: 0.7640\n",
      "Epoch [432/500], Training Loss: 0.0484, Validation Loss: 1.9040, Training Accuracy: 0.9800, Validation Accuracy: 0.7640\n",
      "Epoch [433/500], Training Loss: 0.0570, Validation Loss: 1.9838, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [434/500], Training Loss: 0.0675, Validation Loss: 1.9500, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [435/500], Training Loss: 0.0963, Validation Loss: 1.9276, Training Accuracy: 0.9663, Validation Accuracy: 0.7753\n",
      "Epoch [436/500], Training Loss: 0.0598, Validation Loss: 1.8997, Training Accuracy: 0.9825, Validation Accuracy: 0.7528\n",
      "Epoch [437/500], Training Loss: 0.0475, Validation Loss: 1.9000, Training Accuracy: 0.9862, Validation Accuracy: 0.7640\n",
      "Epoch [438/500], Training Loss: 0.0477, Validation Loss: 1.8954, Training Accuracy: 0.9850, Validation Accuracy: 0.7640\n",
      "Epoch [439/500], Training Loss: 0.0283, Validation Loss: 1.9378, Training Accuracy: 0.9912, Validation Accuracy: 0.7640\n",
      "Epoch [440/500], Training Loss: 0.0696, Validation Loss: 1.8905, Training Accuracy: 0.9750, Validation Accuracy: 0.7640\n",
      "Epoch [441/500], Training Loss: 0.0719, Validation Loss: 1.8693, Training Accuracy: 0.9712, Validation Accuracy: 0.7640\n",
      "Epoch [442/500], Training Loss: 0.0683, Validation Loss: 1.8906, Training Accuracy: 0.9762, Validation Accuracy: 0.7753\n",
      "Epoch [443/500], Training Loss: 0.0448, Validation Loss: 1.8972, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [444/500], Training Loss: 0.0556, Validation Loss: 1.8795, Training Accuracy: 0.9725, Validation Accuracy: 0.7865\n",
      "Epoch [445/500], Training Loss: 0.0564, Validation Loss: 1.8834, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [446/500], Training Loss: 0.0587, Validation Loss: 1.8824, Training Accuracy: 0.9838, Validation Accuracy: 0.7753\n",
      "Epoch [447/500], Training Loss: 0.0571, Validation Loss: 1.9478, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [448/500], Training Loss: 0.0610, Validation Loss: 1.9126, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [449/500], Training Loss: 0.0705, Validation Loss: 1.9278, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [450/500], Training Loss: 0.0386, Validation Loss: 1.9570, Training Accuracy: 0.9838, Validation Accuracy: 0.7865\n",
      "Epoch [451/500], Training Loss: 0.0408, Validation Loss: 1.9590, Training Accuracy: 0.9812, Validation Accuracy: 0.7865\n",
      "Epoch [452/500], Training Loss: 0.0338, Validation Loss: 2.0005, Training Accuracy: 0.9900, Validation Accuracy: 0.7865\n",
      "Epoch [453/500], Training Loss: 0.0449, Validation Loss: 2.1044, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [454/500], Training Loss: 0.0538, Validation Loss: 1.9959, Training Accuracy: 0.9800, Validation Accuracy: 0.7640\n",
      "Epoch [455/500], Training Loss: 0.0801, Validation Loss: 2.0279, Training Accuracy: 0.9775, Validation Accuracy: 0.7753\n",
      "Epoch [456/500], Training Loss: 0.0610, Validation Loss: 1.9213, Training Accuracy: 0.9825, Validation Accuracy: 0.7865\n",
      "Epoch [457/500], Training Loss: 0.0649, Validation Loss: 1.8491, Training Accuracy: 0.9775, Validation Accuracy: 0.8315\n",
      "Epoch [458/500], Training Loss: 0.0428, Validation Loss: 1.8931, Training Accuracy: 0.9875, Validation Accuracy: 0.8315\n",
      "Epoch [459/500], Training Loss: 0.0485, Validation Loss: 1.9035, Training Accuracy: 0.9838, Validation Accuracy: 0.8202\n",
      "Epoch [460/500], Training Loss: 0.0718, Validation Loss: 1.8949, Training Accuracy: 0.9775, Validation Accuracy: 0.8315\n",
      "Epoch [461/500], Training Loss: 0.0474, Validation Loss: 1.8599, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [462/500], Training Loss: 0.0650, Validation Loss: 1.9039, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [463/500], Training Loss: 0.0697, Validation Loss: 1.9881, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [464/500], Training Loss: 0.0512, Validation Loss: 1.8921, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [465/500], Training Loss: 0.0453, Validation Loss: 1.8303, Training Accuracy: 0.9838, Validation Accuracy: 0.8090\n",
      "Epoch [466/500], Training Loss: 0.0389, Validation Loss: 1.8610, Training Accuracy: 0.9888, Validation Accuracy: 0.8202\n",
      "Epoch [467/500], Training Loss: 0.0548, Validation Loss: 1.8861, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [468/500], Training Loss: 0.0481, Validation Loss: 1.9947, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [469/500], Training Loss: 0.0619, Validation Loss: 1.8805, Training Accuracy: 0.9812, Validation Accuracy: 0.8090\n",
      "Epoch [470/500], Training Loss: 0.0630, Validation Loss: 1.8203, Training Accuracy: 0.9762, Validation Accuracy: 0.8202\n",
      "Epoch [471/500], Training Loss: 0.0601, Validation Loss: 1.8428, Training Accuracy: 0.9800, Validation Accuracy: 0.8090\n",
      "Epoch [472/500], Training Loss: 0.0371, Validation Loss: 1.9161, Training Accuracy: 0.9875, Validation Accuracy: 0.7978\n",
      "Epoch [473/500], Training Loss: 0.0363, Validation Loss: 1.9897, Training Accuracy: 0.9912, Validation Accuracy: 0.7978\n",
      "Epoch [474/500], Training Loss: 0.0632, Validation Loss: 1.9658, Training Accuracy: 0.9800, Validation Accuracy: 0.8090\n",
      "Epoch [475/500], Training Loss: 0.0414, Validation Loss: 1.9151, Training Accuracy: 0.9812, Validation Accuracy: 0.8202\n",
      "Epoch [476/500], Training Loss: 0.0673, Validation Loss: 1.8243, Training Accuracy: 0.9738, Validation Accuracy: 0.8202\n",
      "Epoch [477/500], Training Loss: 0.0584, Validation Loss: 1.9039, Training Accuracy: 0.9788, Validation Accuracy: 0.8202\n",
      "Epoch [478/500], Training Loss: 0.0503, Validation Loss: 1.9589, Training Accuracy: 0.9850, Validation Accuracy: 0.8090\n",
      "Epoch [479/500], Training Loss: 0.0507, Validation Loss: 1.9989, Training Accuracy: 0.9788, Validation Accuracy: 0.8202\n",
      "Epoch [480/500], Training Loss: 0.0785, Validation Loss: 2.0383, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [481/500], Training Loss: 0.0804, Validation Loss: 1.9135, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [482/500], Training Loss: 0.0394, Validation Loss: 1.8762, Training Accuracy: 0.9862, Validation Accuracy: 0.7865\n",
      "Epoch [483/500], Training Loss: 0.0556, Validation Loss: 1.8972, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [484/500], Training Loss: 0.0856, Validation Loss: 1.8981, Training Accuracy: 0.9725, Validation Accuracy: 0.7640\n",
      "Epoch [485/500], Training Loss: 0.0426, Validation Loss: 1.9390, Training Accuracy: 0.9812, Validation Accuracy: 0.7640\n",
      "Epoch [486/500], Training Loss: 0.0638, Validation Loss: 1.8684, Training Accuracy: 0.9775, Validation Accuracy: 0.8090\n",
      "Epoch [487/500], Training Loss: 0.0209, Validation Loss: 1.8717, Training Accuracy: 0.9950, Validation Accuracy: 0.8090\n",
      "Epoch [488/500], Training Loss: 0.0463, Validation Loss: 1.9491, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Epoch [489/500], Training Loss: 0.0567, Validation Loss: 1.9428, Training Accuracy: 0.9812, Validation Accuracy: 0.7640\n",
      "Epoch [490/500], Training Loss: 0.0409, Validation Loss: 1.9959, Training Accuracy: 0.9875, Validation Accuracy: 0.7640\n",
      "Epoch [491/500], Training Loss: 0.0422, Validation Loss: 2.0100, Training Accuracy: 0.9875, Validation Accuracy: 0.7528\n",
      "Epoch [492/500], Training Loss: 0.0447, Validation Loss: 2.0375, Training Accuracy: 0.9825, Validation Accuracy: 0.7528\n",
      "Epoch [493/500], Training Loss: 0.0464, Validation Loss: 1.9004, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [494/500], Training Loss: 0.0465, Validation Loss: 1.8970, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [495/500], Training Loss: 0.0525, Validation Loss: 1.9608, Training Accuracy: 0.9825, Validation Accuracy: 0.7753\n",
      "Epoch [496/500], Training Loss: 0.0465, Validation Loss: 1.9613, Training Accuracy: 0.9838, Validation Accuracy: 0.8090\n",
      "Epoch [497/500], Training Loss: 0.0399, Validation Loss: 1.9094, Training Accuracy: 0.9888, Validation Accuracy: 0.8202\n",
      "Epoch [498/500], Training Loss: 0.0391, Validation Loss: 1.9448, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [499/500], Training Loss: 0.0544, Validation Loss: 1.9888, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [500/500], Training Loss: 0.0567, Validation Loss: 1.9732, Training Accuracy: 0.9850, Validation Accuracy: 0.7865\n",
      "Training Time: 6.84 seconds\n",
      "Epoch [1/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [2/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [3/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [4/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [5/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [6/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [7/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [8/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [9/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [10/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [11/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [12/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [13/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [14/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [15/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [16/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [17/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [18/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [19/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [20/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [21/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [22/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [23/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [24/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [25/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [26/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [27/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [28/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [29/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [30/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [31/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [32/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [33/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [34/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [35/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [36/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [37/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [38/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [39/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [40/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [41/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [42/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [43/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [44/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [45/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [46/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [47/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [48/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [49/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [50/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [51/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [52/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [53/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [54/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [55/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [56/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [57/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [58/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [59/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [60/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [61/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [62/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [63/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [64/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [65/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [66/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [67/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [68/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [69/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [70/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [71/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [72/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [73/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [74/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [75/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [76/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [77/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [78/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [79/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [80/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [81/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [82/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [83/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [84/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [85/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [86/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [87/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [88/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [89/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [90/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [91/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [92/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [93/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [94/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [95/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [96/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [97/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [98/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [99/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [100/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [101/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [102/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [103/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [104/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [105/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [106/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [107/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [108/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [109/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [110/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [111/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [112/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [113/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [114/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [115/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [116/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [117/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [118/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [119/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [120/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [121/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [122/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [123/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [124/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [125/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [126/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [127/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [128/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [129/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [130/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [131/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [132/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [133/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [134/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [135/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [136/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [137/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [138/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [139/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [140/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [141/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [142/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [143/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [144/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [145/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [146/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [147/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [148/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [149/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [150/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [151/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [152/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [153/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [154/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [155/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [156/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [157/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [158/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [159/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [160/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [161/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [162/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [163/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [164/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [165/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [166/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [167/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [168/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [169/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [170/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [171/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [172/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [173/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [174/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [175/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [176/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [177/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [178/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [179/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [180/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [181/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [182/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [183/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [184/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [185/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [186/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [187/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [188/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [189/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [190/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [191/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [192/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [193/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [194/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [195/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [196/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [197/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [198/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [199/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [200/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [201/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [202/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [203/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [204/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [205/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [206/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [207/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [208/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [209/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [210/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [211/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [212/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [213/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [214/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [215/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [216/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [217/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [218/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [219/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [220/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [221/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [222/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [223/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [224/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [225/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [226/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [227/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [228/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [229/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [230/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [231/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [232/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [233/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [234/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [235/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [236/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [237/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [238/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [239/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [240/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [241/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [242/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [243/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [244/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [245/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [246/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [247/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [248/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [249/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [250/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [251/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [252/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [253/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [254/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [255/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [256/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [257/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [258/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [259/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [260/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [261/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [262/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [263/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [264/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [265/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [266/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [267/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [268/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [269/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [270/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [271/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [272/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [273/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [274/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [275/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [276/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [277/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [278/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [279/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [280/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [281/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [282/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [283/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [284/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [285/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [286/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [287/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [288/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [289/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [290/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [291/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [292/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [293/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [294/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [295/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [296/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [297/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [298/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [299/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [300/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [301/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [302/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [303/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [304/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [305/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [306/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [307/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [308/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [309/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [310/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [311/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [312/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [313/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [314/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [315/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [316/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [317/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [318/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [319/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [320/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [321/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [322/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [323/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [324/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [325/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [326/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [327/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [328/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [329/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [330/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [331/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [332/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [333/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [334/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [335/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [336/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [337/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [338/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [339/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [340/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [341/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [342/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [343/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [344/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [345/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [346/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [347/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [348/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [349/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [350/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [351/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [352/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [353/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [354/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [355/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [356/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [357/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [358/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [359/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [360/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [361/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [362/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [363/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [364/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [365/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [366/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [367/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [368/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [369/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [370/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [371/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [372/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [373/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [374/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [375/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [376/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [377/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [378/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [379/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [380/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [381/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [382/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [383/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [384/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [385/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [386/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [387/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [388/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [389/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [390/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [391/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [392/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [393/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [394/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [395/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [396/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [397/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [398/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [399/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [400/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [401/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [402/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [403/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [404/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [405/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [406/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [407/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [408/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [409/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [410/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [411/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [412/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [413/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [414/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [415/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [416/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [417/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [418/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [419/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [420/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [421/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [422/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [423/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [424/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [425/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [426/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [427/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [428/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [429/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [430/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [431/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [432/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [433/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [434/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [435/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [436/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [437/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [438/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [439/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [440/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [441/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [442/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [443/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [444/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [445/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [446/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [447/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [448/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [449/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [450/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [451/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [452/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [453/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [454/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [455/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [456/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [457/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [458/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [459/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [460/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [461/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [462/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [463/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [464/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [465/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [466/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [467/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [468/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [469/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [470/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [471/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [472/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [473/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [474/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [475/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [476/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [477/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [478/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [479/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [480/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [481/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [482/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [483/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [484/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [485/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [486/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [487/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [488/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [489/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [490/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [491/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [492/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [493/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [494/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [495/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [496/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [497/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [498/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [499/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Epoch [500/500], Test Loss: 0.6545, Testing Accuracy: 0.7879\n",
      "Learning Rate: 0.1, Training Accuracy: 0.4963, Validation Accuracy: 0.4944, Testing Accuracy: 0.5455\n",
      "Learning Rate: 0.01, Training Accuracy: 0.9187, Validation Accuracy: 0.8315, Testing Accuracy: 0.7980\n",
      "Learning Rate: 0.001, Training Accuracy: 0.9850, Validation Accuracy: 0.7865, Testing Accuracy: 0.7879\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(7, 256)  # Input layer\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)  # Hidden layers\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc5 = nn.Linear(32, 1)  # Output layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Using sigmoid because of Binary Target\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "#Different learning rates\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "results_learning_rate = []\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "batch_size = 16\n",
    "num_epochs = 500\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = NeuralNetwork()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    summary(model, input_size=(1, 7))\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        training_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = loss_function(outputs, labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss += loss.item()\n",
    "            predicted = torch.round(outputs)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "        train_losses.append(training_loss / len(train_loader))\n",
    "        train_accuracies.append(correct_predictions / total_predictions)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_predictions = 0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_outputs = model(val_inputs).squeeze()\n",
    "                val_outputs = val_outputs.view(-1)  \n",
    "                val_loss += loss_function(val_outputs, val_labels.float()).item()\n",
    "                predicted = torch.round(val_outputs)\n",
    "                val_correct_predictions += (predicted == val_labels).sum().item()\n",
    "                val_total_predictions += val_labels.size(0)\n",
    "\n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            val_accuracies.append(val_correct_predictions / val_total_predictions)\n",
    "\n",
    "        average_training_loss = training_loss / len(train_loader)\n",
    "        average_validation_loss = val_loss / len(val_loader)\n",
    "        training_accuracy = correct_predictions / total_predictions\n",
    "        validation_accuracy = val_correct_predictions / val_total_predictions\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "              f'Training Loss: {average_training_loss:.4f}, '\n",
    "              f'Validation Loss: {average_validation_loss:.4f}, '\n",
    "              f'Training Accuracy: {training_accuracy:.4f}, '\n",
    "              f'Validation Accuracy: {validation_accuracy:.4f}')\n",
    "\n",
    "        if average_validation_loss < best_val_loss:\n",
    "            best_val_loss = average_validation_loss\n",
    "            torch.save(model.state_dict(), 'best_model_weights.pth')\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'Training Time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "    # Testing the model\n",
    "    model.load_state_dict(torch.load('best_model_weights.pth'))\n",
    "\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct_predictions = 0\n",
    "        test_total_predictions = 0\n",
    "\n",
    "        confusion_predictions = []\n",
    "        confusion_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_inputs, test_labels in test_loader:\n",
    "                test_outputs = model(test_inputs).squeeze()\n",
    "                test_outputs = test_outputs.view(-1)  \n",
    "                test_loss += loss_function(test_outputs, test_labels.float()).item()\n",
    "                \n",
    "                predicted = torch.round(test_outputs)\n",
    "                test_correct_predictions += (predicted == test_labels.float()).sum().item()\n",
    "                test_total_predictions += test_labels.size(0)\n",
    "            \n",
    "                confusion_predictions.extend(predicted.numpy())\n",
    "                confusion_labels.extend(test_labels.numpy())\n",
    "\n",
    "            test_losses.append(test_loss / len(test_loader))\n",
    "            test_accuracies.append(test_correct_predictions / test_total_predictions)\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        test_accuracy = test_correct_predictions / test_total_predictions\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "              f'Test Loss: {avg_test_loss:.4f}, '\n",
    "              f'Testing Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    results_learning_rate.append({\n",
    "        'learning_rate': lr,\n",
    "        'train_accuracy': training_accuracy,\n",
    "        'val_accuracy': validation_accuracy,\n",
    "        'test_accuracy': test_accuracy\n",
    "    })\n",
    "\n",
    "# Print or save the results\n",
    "for result in results_learning_rate:\n",
    "    print(f\"Learning Rate: {result['learning_rate']}, \"\n",
    "          f\"Training Accuracy: {result['train_accuracy']:.4f}, \"\n",
    "          f\"Validation Accuracy: {result['val_accuracy']:.4f}, \"\n",
    "          f\"Testing Accuracy: {result['test_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rates = [result['learning_rate'] for result in results_learning_rate]\n",
    "test_accuracies = [result['test_accuracy'] for result in results_learning_rate]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(learning_rates, test_accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('Testing Accuracies vs Learning Rates')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.xticks(learning_rates)\n",
    "plt.grid()\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1568,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "best_val_loss = float('inf')\n",
    "num_epochs = 500\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing Early Stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 0.3470, Validation Loss: 0.4597, Training Accuracy: 0.8450, Validation Accuracy: 0.8315\n",
      "Epoch [2/500], Training Loss: 0.3259, Validation Loss: 0.5044, Training Accuracy: 0.8600, Validation Accuracy: 0.7865\n",
      "Epoch [3/500], Training Loss: 0.3316, Validation Loss: 0.4709, Training Accuracy: 0.8337, Validation Accuracy: 0.8202\n",
      "Epoch [4/500], Training Loss: 0.3300, Validation Loss: 0.4960, Training Accuracy: 0.8488, Validation Accuracy: 0.7978\n",
      "Epoch [5/500], Training Loss: 0.3171, Validation Loss: 0.4644, Training Accuracy: 0.8650, Validation Accuracy: 0.7978\n",
      "Epoch [6/500], Training Loss: 0.3246, Validation Loss: 0.4897, Training Accuracy: 0.8550, Validation Accuracy: 0.7753\n",
      "Epoch [7/500], Training Loss: 0.3003, Validation Loss: 0.5255, Training Accuracy: 0.8588, Validation Accuracy: 0.8202\n",
      "Epoch [8/500], Training Loss: 0.2921, Validation Loss: 0.5067, Training Accuracy: 0.8750, Validation Accuracy: 0.7640\n",
      "Epoch [9/500], Training Loss: 0.3177, Validation Loss: 0.4950, Training Accuracy: 0.8550, Validation Accuracy: 0.7978\n",
      "Epoch [10/500], Training Loss: 0.2810, Validation Loss: 0.4943, Training Accuracy: 0.8800, Validation Accuracy: 0.7753\n",
      "Epoch [11/500], Training Loss: 0.2857, Validation Loss: 0.5385, Training Accuracy: 0.8788, Validation Accuracy: 0.7753\n",
      "Epoch [12/500], Training Loss: 0.3085, Validation Loss: 0.5011, Training Accuracy: 0.8625, Validation Accuracy: 0.7978\n",
      "Epoch [13/500], Training Loss: 0.3010, Validation Loss: 0.5237, Training Accuracy: 0.8725, Validation Accuracy: 0.7640\n",
      "Epoch [14/500], Training Loss: 0.2968, Validation Loss: 0.4723, Training Accuracy: 0.8675, Validation Accuracy: 0.8090\n",
      "Epoch [15/500], Training Loss: 0.2906, Validation Loss: 0.5061, Training Accuracy: 0.8712, Validation Accuracy: 0.8202\n",
      "Epoch [16/500], Training Loss: 0.2976, Validation Loss: 0.4917, Training Accuracy: 0.8612, Validation Accuracy: 0.7978\n",
      "Epoch [17/500], Training Loss: 0.2884, Validation Loss: 0.4851, Training Accuracy: 0.8638, Validation Accuracy: 0.7978\n",
      "Epoch [18/500], Training Loss: 0.3037, Validation Loss: 0.4991, Training Accuracy: 0.8788, Validation Accuracy: 0.8090\n",
      "Epoch [19/500], Training Loss: 0.2893, Validation Loss: 0.4705, Training Accuracy: 0.8650, Validation Accuracy: 0.7978\n",
      "Epoch [20/500], Training Loss: 0.2776, Validation Loss: 0.5174, Training Accuracy: 0.8838, Validation Accuracy: 0.7865\n",
      "Epoch [21/500], Training Loss: 0.2949, Validation Loss: 0.5173, Training Accuracy: 0.8812, Validation Accuracy: 0.7640\n",
      "Epoch [22/500], Training Loss: 0.2674, Validation Loss: 0.5174, Training Accuracy: 0.8900, Validation Accuracy: 0.7865\n",
      "Epoch [23/500], Training Loss: 0.3014, Validation Loss: 0.4863, Training Accuracy: 0.8762, Validation Accuracy: 0.7978\n",
      "Epoch [24/500], Training Loss: 0.2697, Validation Loss: 0.4408, Training Accuracy: 0.8800, Validation Accuracy: 0.8202\n",
      "Epoch [25/500], Training Loss: 0.2629, Validation Loss: 0.5487, Training Accuracy: 0.8850, Validation Accuracy: 0.8202\n",
      "Epoch [26/500], Training Loss: 0.2622, Validation Loss: 0.5194, Training Accuracy: 0.8875, Validation Accuracy: 0.7753\n",
      "Epoch [27/500], Training Loss: 0.2495, Validation Loss: 0.5188, Training Accuracy: 0.8925, Validation Accuracy: 0.8090\n",
      "Epoch [28/500], Training Loss: 0.2646, Validation Loss: 0.5297, Training Accuracy: 0.8738, Validation Accuracy: 0.8202\n",
      "Epoch [29/500], Training Loss: 0.2880, Validation Loss: 0.4724, Training Accuracy: 0.8850, Validation Accuracy: 0.8202\n",
      "Epoch [30/500], Training Loss: 0.2529, Validation Loss: 0.4898, Training Accuracy: 0.8838, Validation Accuracy: 0.8090\n",
      "Epoch [31/500], Training Loss: 0.2679, Validation Loss: 0.4886, Training Accuracy: 0.8875, Validation Accuracy: 0.8090\n",
      "Epoch [32/500], Training Loss: 0.2308, Validation Loss: 0.5241, Training Accuracy: 0.9038, Validation Accuracy: 0.7865\n",
      "Epoch [33/500], Training Loss: 0.2520, Validation Loss: 0.5162, Training Accuracy: 0.8925, Validation Accuracy: 0.8202\n",
      "Epoch [34/500], Training Loss: 0.2680, Validation Loss: 0.5288, Training Accuracy: 0.8962, Validation Accuracy: 0.7865\n",
      "Epoch [35/500], Training Loss: 0.2339, Validation Loss: 0.5104, Training Accuracy: 0.8988, Validation Accuracy: 0.7865\n",
      "Epoch [36/500], Training Loss: 0.2337, Validation Loss: 0.5915, Training Accuracy: 0.9012, Validation Accuracy: 0.7865\n",
      "Epoch [37/500], Training Loss: 0.2590, Validation Loss: 0.5538, Training Accuracy: 0.8912, Validation Accuracy: 0.7640\n",
      "Epoch [38/500], Training Loss: 0.2522, Validation Loss: 0.5389, Training Accuracy: 0.9012, Validation Accuracy: 0.7753\n",
      "Epoch [39/500], Training Loss: 0.2654, Validation Loss: 0.4941, Training Accuracy: 0.8775, Validation Accuracy: 0.7865\n",
      "Epoch [40/500], Training Loss: 0.2304, Validation Loss: 0.5502, Training Accuracy: 0.9062, Validation Accuracy: 0.7753\n",
      "Epoch [41/500], Training Loss: 0.2471, Validation Loss: 0.5545, Training Accuracy: 0.9062, Validation Accuracy: 0.7865\n",
      "Epoch [42/500], Training Loss: 0.2368, Validation Loss: 0.5265, Training Accuracy: 0.9000, Validation Accuracy: 0.7978\n",
      "Epoch [43/500], Training Loss: 0.2404, Validation Loss: 0.5165, Training Accuracy: 0.8950, Validation Accuracy: 0.7528\n",
      "Epoch [44/500], Training Loss: 0.2391, Validation Loss: 0.5728, Training Accuracy: 0.9038, Validation Accuracy: 0.8090\n",
      "Epoch [45/500], Training Loss: 0.2360, Validation Loss: 0.5509, Training Accuracy: 0.8950, Validation Accuracy: 0.7865\n",
      "Epoch [46/500], Training Loss: 0.2377, Validation Loss: 0.5166, Training Accuracy: 0.9075, Validation Accuracy: 0.7978\n",
      "Epoch [47/500], Training Loss: 0.2319, Validation Loss: 0.5049, Training Accuracy: 0.9025, Validation Accuracy: 0.7865\n",
      "Epoch [48/500], Training Loss: 0.2085, Validation Loss: 0.5517, Training Accuracy: 0.9175, Validation Accuracy: 0.8202\n",
      "Epoch [49/500], Training Loss: 0.2141, Validation Loss: 0.5909, Training Accuracy: 0.9087, Validation Accuracy: 0.7978\n",
      "Epoch [50/500], Training Loss: 0.2055, Validation Loss: 0.5814, Training Accuracy: 0.9087, Validation Accuracy: 0.8090\n",
      "Epoch [51/500], Training Loss: 0.1983, Validation Loss: 0.6113, Training Accuracy: 0.9213, Validation Accuracy: 0.7528\n",
      "Epoch [52/500], Training Loss: 0.2183, Validation Loss: 0.6674, Training Accuracy: 0.9113, Validation Accuracy: 0.7640\n",
      "Epoch [53/500], Training Loss: 0.2186, Validation Loss: 0.5824, Training Accuracy: 0.8988, Validation Accuracy: 0.7865\n",
      "Epoch [54/500], Training Loss: 0.2055, Validation Loss: 0.5981, Training Accuracy: 0.9175, Validation Accuracy: 0.7865\n",
      "Epoch [55/500], Training Loss: 0.2108, Validation Loss: 0.5517, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [56/500], Training Loss: 0.2064, Validation Loss: 0.6020, Training Accuracy: 0.9038, Validation Accuracy: 0.8202\n",
      "Epoch [57/500], Training Loss: 0.2360, Validation Loss: 0.5727, Training Accuracy: 0.9000, Validation Accuracy: 0.7753\n",
      "Epoch [58/500], Training Loss: 0.2187, Validation Loss: 0.5644, Training Accuracy: 0.9187, Validation Accuracy: 0.7865\n",
      "Epoch [59/500], Training Loss: 0.2220, Validation Loss: 0.5695, Training Accuracy: 0.9113, Validation Accuracy: 0.7753\n",
      "Epoch [60/500], Training Loss: 0.2169, Validation Loss: 0.5842, Training Accuracy: 0.9000, Validation Accuracy: 0.7865\n",
      "Epoch [61/500], Training Loss: 0.2402, Validation Loss: 0.5268, Training Accuracy: 0.9100, Validation Accuracy: 0.8315\n",
      "Epoch [62/500], Training Loss: 0.2291, Validation Loss: 0.5330, Training Accuracy: 0.9075, Validation Accuracy: 0.7865\n",
      "Epoch [63/500], Training Loss: 0.2044, Validation Loss: 0.5577, Training Accuracy: 0.9213, Validation Accuracy: 0.7753\n",
      "Epoch [64/500], Training Loss: 0.2087, Validation Loss: 0.5303, Training Accuracy: 0.9087, Validation Accuracy: 0.8202\n",
      "Epoch [65/500], Training Loss: 0.1959, Validation Loss: 0.5568, Training Accuracy: 0.9150, Validation Accuracy: 0.8090\n",
      "Epoch [66/500], Training Loss: 0.2283, Validation Loss: 0.5186, Training Accuracy: 0.9012, Validation Accuracy: 0.7978\n",
      "Epoch [67/500], Training Loss: 0.2080, Validation Loss: 0.5740, Training Accuracy: 0.9100, Validation Accuracy: 0.8090\n",
      "Epoch [68/500], Training Loss: 0.2015, Validation Loss: 0.5946, Training Accuracy: 0.9213, Validation Accuracy: 0.7978\n",
      "Epoch [69/500], Training Loss: 0.1757, Validation Loss: 0.6237, Training Accuracy: 0.9337, Validation Accuracy: 0.7978\n",
      "Epoch [70/500], Training Loss: 0.1945, Validation Loss: 0.6264, Training Accuracy: 0.9275, Validation Accuracy: 0.7978\n",
      "Epoch [71/500], Training Loss: 0.2101, Validation Loss: 0.5911, Training Accuracy: 0.9100, Validation Accuracy: 0.7978\n",
      "Epoch [72/500], Training Loss: 0.1902, Validation Loss: 0.5633, Training Accuracy: 0.9225, Validation Accuracy: 0.7978\n",
      "Epoch [73/500], Training Loss: 0.2032, Validation Loss: 0.5947, Training Accuracy: 0.9213, Validation Accuracy: 0.8202\n",
      "Epoch [74/500], Training Loss: 0.1702, Validation Loss: 0.6040, Training Accuracy: 0.9375, Validation Accuracy: 0.8090\n",
      "Early stopping at epoch 74. No improvement in validation loss for 50 epochs.\n",
      "Epoch [1/1], Test Loss: 0.7229, Testing Accuracy: 0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/v5ysl19s0hbdkdprhb3xqd4r0000gn/T/ipykernel_34536/1621870245.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_weights.pth'))\n"
     ]
    }
   ],
   "source": [
    "patience = 50\n",
    "no_improvement_count = 0\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = loss_function(outputs, labels.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "        predicted = torch.round(outputs)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    train_losses.append(training_loss / len(train_loader))\n",
    "    train_accuracies.append(correct_predictions / total_predictions)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_outputs = model(val_inputs).squeeze()\n",
    "            val_loss += loss_function(val_outputs, val_labels.float()).item()\n",
    "            predicted = torch.round(val_outputs)\n",
    "            val_correct_predictions += (predicted == val_labels).sum().item()\n",
    "            val_total_predictions += val_labels.size(0)\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(val_correct_predictions / val_total_predictions)\n",
    "\n",
    "    average_training_loss = training_loss / len(train_loader)\n",
    "    average_validation_loss = val_loss / len(val_loader)\n",
    "    training_accuracy = correct_predictions / total_predictions\n",
    "    validation_accuracy = val_correct_predictions / val_total_predictions\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Training Loss: {average_training_loss:.4f}, '\n",
    "          f'Validation Loss: {average_validation_loss:.4f}, '\n",
    "          f'Training Accuracy: {training_accuracy:.4f}, '\n",
    "          f'Validation Accuracy: {validation_accuracy:.4f}')\n",
    "\n",
    "    if average_validation_loss < best_val_loss:\n",
    "        best_val_loss = average_validation_loss\n",
    "        no_improvement_count = 0  \n",
    "        torch.save(model.state_dict(), 'best_model_weights.pth')  \n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "\n",
    "    if no_improvement_count >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}. No improvement in validation loss for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_weights.pth'))\n",
    "\n",
    "\n",
    "num_test_epochs = 1\n",
    "for epoch in range(num_test_epochs):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct_predictions = 0\n",
    "    test_total_predictions = 0\n",
    "\n",
    "    confusion_predictions = []\n",
    "    confusion_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in test_loader:\n",
    "            test_outputs = model(test_inputs).squeeze()\n",
    "            test_loss += loss_function(test_outputs, test_labels.float()).item()\n",
    "\n",
    "            predicted = torch.round(test_outputs)\n",
    "            test_correct_predictions += (predicted == test_labels.float()).sum().item()\n",
    "            test_total_predictions += test_labels.size(0)\n",
    "\n",
    "            confusion_predictions.extend(predicted.cpu().numpy())\n",
    "            confusion_labels.extend(test_labels.cpu().numpy()) \n",
    "\n",
    "        test_losses.append(test_loss / len(test_loader)) \n",
    "        test_accuracies.append(test_correct_predictions / test_total_predictions) \n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = test_correct_predictions / test_total_predictions\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_test_epochs}], '\n",
    "          f'Test Loss: {avg_test_loss:.4f}, '\n",
    "          f'Testing Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(train_accuracies) + 1)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training, Validation, and Test Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing Learning Rate Scheduler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 0.2504, Validation Loss: 0.4921, Training Accuracy: 0.8912, Validation Accuracy: 0.7865\n",
      "Epoch [2/500], Training Loss: 0.2417, Validation Loss: 0.4659, Training Accuracy: 0.8962, Validation Accuracy: 0.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/500], Training Loss: 0.2529, Validation Loss: 0.5206, Training Accuracy: 0.8962, Validation Accuracy: 0.7865\n",
      "Epoch [4/500], Training Loss: 0.2675, Validation Loss: 0.5012, Training Accuracy: 0.8825, Validation Accuracy: 0.7978\n",
      "Epoch [5/500], Training Loss: 0.2618, Validation Loss: 0.4998, Training Accuracy: 0.8900, Validation Accuracy: 0.7978\n",
      "Epoch [6/500], Training Loss: 0.2417, Validation Loss: 0.5081, Training Accuracy: 0.8950, Validation Accuracy: 0.7865\n",
      "Epoch [7/500], Training Loss: 0.2446, Validation Loss: 0.5095, Training Accuracy: 0.8975, Validation Accuracy: 0.7865\n",
      "Epoch [8/500], Training Loss: 0.2467, Validation Loss: 0.5280, Training Accuracy: 0.8988, Validation Accuracy: 0.7640\n",
      "Epoch [9/500], Training Loss: 0.2489, Validation Loss: 0.5310, Training Accuracy: 0.9050, Validation Accuracy: 0.7753\n",
      "Epoch [10/500], Training Loss: 0.2341, Validation Loss: 0.5522, Training Accuracy: 0.9062, Validation Accuracy: 0.7865\n",
      "Epoch [11/500], Training Loss: 0.2482, Validation Loss: 0.5266, Training Accuracy: 0.8788, Validation Accuracy: 0.8090\n",
      "Epoch [12/500], Training Loss: 0.2299, Validation Loss: 0.5470, Training Accuracy: 0.9137, Validation Accuracy: 0.7978\n",
      "Epoch [13/500], Training Loss: 0.2750, Validation Loss: 0.4774, Training Accuracy: 0.8912, Validation Accuracy: 0.7978\n",
      "Epoch [14/500], Training Loss: 0.2344, Validation Loss: 0.5288, Training Accuracy: 0.9025, Validation Accuracy: 0.7865\n",
      "Epoch [15/500], Training Loss: 0.2374, Validation Loss: 0.5078, Training Accuracy: 0.8938, Validation Accuracy: 0.7865\n",
      "Epoch [16/500], Training Loss: 0.2275, Validation Loss: 0.5297, Training Accuracy: 0.9000, Validation Accuracy: 0.8202\n",
      "Epoch [17/500], Training Loss: 0.2281, Validation Loss: 0.5690, Training Accuracy: 0.9012, Validation Accuracy: 0.8090\n",
      "Epoch [18/500], Training Loss: 0.2547, Validation Loss: 0.5690, Training Accuracy: 0.8975, Validation Accuracy: 0.8090\n",
      "Epoch [19/500], Training Loss: 0.2559, Validation Loss: 0.5218, Training Accuracy: 0.8862, Validation Accuracy: 0.7753\n",
      "Epoch [20/500], Training Loss: 0.2146, Validation Loss: 0.5441, Training Accuracy: 0.9100, Validation Accuracy: 0.7865\n",
      "Epoch [21/500], Training Loss: 0.2445, Validation Loss: 0.5215, Training Accuracy: 0.8812, Validation Accuracy: 0.7640\n",
      "Epoch [22/500], Training Loss: 0.2223, Validation Loss: 0.5650, Training Accuracy: 0.9062, Validation Accuracy: 0.7753\n",
      "Epoch [23/500], Training Loss: 0.2485, Validation Loss: 0.5559, Training Accuracy: 0.8912, Validation Accuracy: 0.8090\n",
      "Epoch [24/500], Training Loss: 0.2151, Validation Loss: 0.5338, Training Accuracy: 0.9100, Validation Accuracy: 0.7978\n",
      "Epoch [25/500], Training Loss: 0.2383, Validation Loss: 0.5806, Training Accuracy: 0.9025, Validation Accuracy: 0.8090\n",
      "Epoch [26/500], Training Loss: 0.2352, Validation Loss: 0.5067, Training Accuracy: 0.8950, Validation Accuracy: 0.7978\n",
      "Epoch [27/500], Training Loss: 0.2168, Validation Loss: 0.5637, Training Accuracy: 0.9062, Validation Accuracy: 0.7978\n",
      "Epoch [28/500], Training Loss: 0.2409, Validation Loss: 0.5189, Training Accuracy: 0.9012, Validation Accuracy: 0.8315\n",
      "Epoch [29/500], Training Loss: 0.2232, Validation Loss: 0.5085, Training Accuracy: 0.9012, Validation Accuracy: 0.8315\n",
      "Epoch [30/500], Training Loss: 0.2230, Validation Loss: 0.5383, Training Accuracy: 0.9038, Validation Accuracy: 0.8090\n",
      "Epoch [31/500], Training Loss: 0.2246, Validation Loss: 0.5715, Training Accuracy: 0.9038, Validation Accuracy: 0.8090\n",
      "Epoch [32/500], Training Loss: 0.2138, Validation Loss: 0.5743, Training Accuracy: 0.9100, Validation Accuracy: 0.7865\n",
      "Epoch [33/500], Training Loss: 0.2080, Validation Loss: 0.5454, Training Accuracy: 0.9200, Validation Accuracy: 0.8202\n",
      "Epoch [34/500], Training Loss: 0.2344, Validation Loss: 0.5394, Training Accuracy: 0.8975, Validation Accuracy: 0.8090\n",
      "Epoch [35/500], Training Loss: 0.1997, Validation Loss: 0.6071, Training Accuracy: 0.9075, Validation Accuracy: 0.7865\n",
      "Epoch [36/500], Training Loss: 0.2357, Validation Loss: 0.5756, Training Accuracy: 0.8862, Validation Accuracy: 0.8090\n",
      "Epoch [37/500], Training Loss: 0.1973, Validation Loss: 0.6216, Training Accuracy: 0.9250, Validation Accuracy: 0.7865\n",
      "Epoch [38/500], Training Loss: 0.2189, Validation Loss: 0.5826, Training Accuracy: 0.9137, Validation Accuracy: 0.8315\n",
      "Epoch [39/500], Training Loss: 0.1982, Validation Loss: 0.6001, Training Accuracy: 0.9137, Validation Accuracy: 0.8202\n",
      "Epoch [40/500], Training Loss: 0.1919, Validation Loss: 0.5879, Training Accuracy: 0.9113, Validation Accuracy: 0.8090\n",
      "Epoch [41/500], Training Loss: 0.1914, Validation Loss: 0.6306, Training Accuracy: 0.9250, Validation Accuracy: 0.8090\n",
      "Epoch [42/500], Training Loss: 0.2059, Validation Loss: 0.6515, Training Accuracy: 0.9187, Validation Accuracy: 0.7753\n",
      "Epoch [43/500], Training Loss: 0.2041, Validation Loss: 0.6422, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [44/500], Training Loss: 0.1938, Validation Loss: 0.6815, Training Accuracy: 0.9237, Validation Accuracy: 0.7978\n",
      "Epoch [45/500], Training Loss: 0.2101, Validation Loss: 0.6685, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [46/500], Training Loss: 0.1743, Validation Loss: 0.6402, Training Accuracy: 0.9337, Validation Accuracy: 0.8202\n",
      "Epoch [47/500], Training Loss: 0.2278, Validation Loss: 0.6036, Training Accuracy: 0.9075, Validation Accuracy: 0.7753\n",
      "Epoch [48/500], Training Loss: 0.1789, Validation Loss: 0.6550, Training Accuracy: 0.9263, Validation Accuracy: 0.7753\n",
      "Epoch [49/500], Training Loss: 0.2220, Validation Loss: 0.5775, Training Accuracy: 0.9062, Validation Accuracy: 0.7978\n",
      "Epoch [50/500], Training Loss: 0.1948, Validation Loss: 0.5726, Training Accuracy: 0.9150, Validation Accuracy: 0.8090\n",
      "Epoch [51/500], Training Loss: 0.2288, Validation Loss: 0.5161, Training Accuracy: 0.9050, Validation Accuracy: 0.8315\n",
      "Epoch [52/500], Training Loss: 0.1739, Validation Loss: 0.5686, Training Accuracy: 0.9363, Validation Accuracy: 0.8202\n",
      "Epoch [53/500], Training Loss: 0.1969, Validation Loss: 0.5140, Training Accuracy: 0.9237, Validation Accuracy: 0.8315\n",
      "Epoch [54/500], Training Loss: 0.1860, Validation Loss: 0.5873, Training Accuracy: 0.9187, Validation Accuracy: 0.7753\n",
      "Epoch [55/500], Training Loss: 0.1777, Validation Loss: 0.6264, Training Accuracy: 0.9287, Validation Accuracy: 0.7753\n",
      "Epoch [56/500], Training Loss: 0.1973, Validation Loss: 0.5951, Training Accuracy: 0.9100, Validation Accuracy: 0.7753\n",
      "Epoch [57/500], Training Loss: 0.1900, Validation Loss: 0.5720, Training Accuracy: 0.9225, Validation Accuracy: 0.8202\n",
      "Epoch [58/500], Training Loss: 0.2064, Validation Loss: 0.5856, Training Accuracy: 0.9175, Validation Accuracy: 0.7978\n",
      "Epoch [59/500], Training Loss: 0.1841, Validation Loss: 0.5642, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [60/500], Training Loss: 0.1903, Validation Loss: 0.5903, Training Accuracy: 0.9137, Validation Accuracy: 0.8202\n",
      "Epoch [61/500], Training Loss: 0.1927, Validation Loss: 0.6319, Training Accuracy: 0.9263, Validation Accuracy: 0.7978\n",
      "Epoch [62/500], Training Loss: 0.1976, Validation Loss: 0.5860, Training Accuracy: 0.9300, Validation Accuracy: 0.7978\n",
      "Epoch [63/500], Training Loss: 0.1583, Validation Loss: 0.6774, Training Accuracy: 0.9425, Validation Accuracy: 0.7978\n",
      "Epoch [64/500], Training Loss: 0.1682, Validation Loss: 0.5922, Training Accuracy: 0.9275, Validation Accuracy: 0.8202\n",
      "Epoch [65/500], Training Loss: 0.1574, Validation Loss: 0.6747, Training Accuracy: 0.9237, Validation Accuracy: 0.8202\n",
      "Epoch [66/500], Training Loss: 0.1710, Validation Loss: 0.6767, Training Accuracy: 0.9387, Validation Accuracy: 0.7865\n",
      "Epoch [67/500], Training Loss: 0.1628, Validation Loss: 0.6653, Training Accuracy: 0.9300, Validation Accuracy: 0.8090\n",
      "Epoch [68/500], Training Loss: 0.1568, Validation Loss: 0.6672, Training Accuracy: 0.9437, Validation Accuracy: 0.8427\n",
      "Epoch [69/500], Training Loss: 0.1809, Validation Loss: 0.6082, Training Accuracy: 0.9287, Validation Accuracy: 0.7865\n",
      "Epoch [70/500], Training Loss: 0.1553, Validation Loss: 1.5877, Training Accuracy: 0.9387, Validation Accuracy: 0.8315\n",
      "Epoch [71/500], Training Loss: 0.1950, Validation Loss: 0.6790, Training Accuracy: 0.9325, Validation Accuracy: 0.8090\n",
      "Epoch [72/500], Training Loss: 0.1865, Validation Loss: 0.6289, Training Accuracy: 0.9250, Validation Accuracy: 0.8090\n",
      "Epoch [73/500], Training Loss: 0.1740, Validation Loss: 0.6698, Training Accuracy: 0.9237, Validation Accuracy: 0.7753\n",
      "Epoch [74/500], Training Loss: 0.1777, Validation Loss: 0.6860, Training Accuracy: 0.9250, Validation Accuracy: 0.7978\n",
      "Epoch [75/500], Training Loss: 0.1752, Validation Loss: 0.6364, Training Accuracy: 0.9300, Validation Accuracy: 0.8202\n",
      "Epoch [76/500], Training Loss: 0.1442, Validation Loss: 0.6896, Training Accuracy: 0.9413, Validation Accuracy: 0.7978\n",
      "Epoch [77/500], Training Loss: 0.1607, Validation Loss: 0.7236, Training Accuracy: 0.9350, Validation Accuracy: 0.7753\n",
      "Epoch [78/500], Training Loss: 0.1909, Validation Loss: 0.6440, Training Accuracy: 0.9250, Validation Accuracy: 0.7640\n",
      "Epoch [79/500], Training Loss: 0.1723, Validation Loss: 0.6548, Training Accuracy: 0.9363, Validation Accuracy: 0.8090\n",
      "Epoch [80/500], Training Loss: 0.1656, Validation Loss: 0.6476, Training Accuracy: 0.9363, Validation Accuracy: 0.7865\n",
      "Epoch [81/500], Training Loss: 0.1371, Validation Loss: 0.7108, Training Accuracy: 0.9450, Validation Accuracy: 0.7528\n",
      "Epoch [82/500], Training Loss: 0.1670, Validation Loss: 0.6596, Training Accuracy: 0.9363, Validation Accuracy: 0.8315\n",
      "Epoch [83/500], Training Loss: 0.1662, Validation Loss: 0.6692, Training Accuracy: 0.9400, Validation Accuracy: 0.8315\n",
      "Epoch [84/500], Training Loss: 0.1455, Validation Loss: 0.7014, Training Accuracy: 0.9437, Validation Accuracy: 0.7865\n",
      "Epoch [85/500], Training Loss: 0.1418, Validation Loss: 0.6903, Training Accuracy: 0.9500, Validation Accuracy: 0.7865\n",
      "Epoch [86/500], Training Loss: 0.1586, Validation Loss: 0.6306, Training Accuracy: 0.9337, Validation Accuracy: 0.8090\n",
      "Epoch [87/500], Training Loss: 0.1539, Validation Loss: 0.6793, Training Accuracy: 0.9325, Validation Accuracy: 0.7978\n",
      "Epoch [88/500], Training Loss: 0.1642, Validation Loss: 0.6802, Training Accuracy: 0.9300, Validation Accuracy: 0.8090\n",
      "Epoch [89/500], Training Loss: 0.1532, Validation Loss: 0.7036, Training Accuracy: 0.9413, Validation Accuracy: 0.8090\n",
      "Epoch [90/500], Training Loss: 0.1550, Validation Loss: 0.7062, Training Accuracy: 0.9475, Validation Accuracy: 0.8090\n",
      "Epoch [91/500], Training Loss: 0.1401, Validation Loss: 0.6997, Training Accuracy: 0.9437, Validation Accuracy: 0.7978\n",
      "Epoch [92/500], Training Loss: 0.1566, Validation Loss: 0.6844, Training Accuracy: 0.9400, Validation Accuracy: 0.8202\n",
      "Epoch [93/500], Training Loss: 0.1575, Validation Loss: 0.7043, Training Accuracy: 0.9350, Validation Accuracy: 0.8090\n",
      "Epoch [94/500], Training Loss: 0.1634, Validation Loss: 0.6359, Training Accuracy: 0.9387, Validation Accuracy: 0.7865\n",
      "Epoch [95/500], Training Loss: 0.1525, Validation Loss: 0.6397, Training Accuracy: 0.9425, Validation Accuracy: 0.7865\n",
      "Epoch [96/500], Training Loss: 0.1463, Validation Loss: 0.8075, Training Accuracy: 0.9413, Validation Accuracy: 0.7528\n",
      "Epoch [97/500], Training Loss: 0.1498, Validation Loss: 0.6686, Training Accuracy: 0.9475, Validation Accuracy: 0.8202\n",
      "Epoch [98/500], Training Loss: 0.1195, Validation Loss: 0.7565, Training Accuracy: 0.9487, Validation Accuracy: 0.7753\n",
      "Epoch [99/500], Training Loss: 0.1416, Validation Loss: 0.7505, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [100/500], Training Loss: 0.1340, Validation Loss: 0.6816, Training Accuracy: 0.9487, Validation Accuracy: 0.8315\n",
      "Epoch [101/500], Training Loss: 0.1427, Validation Loss: 1.5529, Training Accuracy: 0.9537, Validation Accuracy: 0.8427\n",
      "Epoch [102/500], Training Loss: 0.1629, Validation Loss: 1.5695, Training Accuracy: 0.9313, Validation Accuracy: 0.7978\n",
      "Epoch [103/500], Training Loss: 0.1505, Validation Loss: 0.6533, Training Accuracy: 0.9450, Validation Accuracy: 0.8202\n",
      "Epoch [104/500], Training Loss: 0.1429, Validation Loss: 0.6480, Training Accuracy: 0.9450, Validation Accuracy: 0.8315\n",
      "Epoch [105/500], Training Loss: 0.1454, Validation Loss: 1.5764, Training Accuracy: 0.9513, Validation Accuracy: 0.8090\n",
      "Epoch [106/500], Training Loss: 0.1483, Validation Loss: 0.7701, Training Accuracy: 0.9387, Validation Accuracy: 0.7640\n",
      "Epoch [107/500], Training Loss: 0.1595, Validation Loss: 1.5946, Training Accuracy: 0.9425, Validation Accuracy: 0.7865\n",
      "Epoch [108/500], Training Loss: 0.1443, Validation Loss: 1.6138, Training Accuracy: 0.9525, Validation Accuracy: 0.8202\n",
      "Epoch [109/500], Training Loss: 0.1623, Validation Loss: 1.5685, Training Accuracy: 0.9363, Validation Accuracy: 0.7865\n",
      "Epoch [110/500], Training Loss: 0.1466, Validation Loss: 1.6527, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [111/500], Training Loss: 0.1268, Validation Loss: 0.7275, Training Accuracy: 0.9537, Validation Accuracy: 0.7865\n",
      "Epoch [112/500], Training Loss: 0.1455, Validation Loss: 0.7279, Training Accuracy: 0.9413, Validation Accuracy: 0.7978\n",
      "Epoch [113/500], Training Loss: 0.1174, Validation Loss: 1.6649, Training Accuracy: 0.9537, Validation Accuracy: 0.7640\n",
      "Epoch [114/500], Training Loss: 0.1339, Validation Loss: 0.7490, Training Accuracy: 0.9400, Validation Accuracy: 0.7865\n",
      "Epoch [115/500], Training Loss: 0.1272, Validation Loss: 0.7417, Training Accuracy: 0.9500, Validation Accuracy: 0.7865\n",
      "Epoch [116/500], Training Loss: 0.1735, Validation Loss: 0.6869, Training Accuracy: 0.9375, Validation Accuracy: 0.8090\n",
      "Epoch [117/500], Training Loss: 0.1334, Validation Loss: 1.6180, Training Accuracy: 0.9475, Validation Accuracy: 0.8090\n",
      "Epoch [118/500], Training Loss: 0.1661, Validation Loss: 0.6849, Training Accuracy: 0.9350, Validation Accuracy: 0.7978\n",
      "Epoch [119/500], Training Loss: 0.1284, Validation Loss: 0.6625, Training Accuracy: 0.9487, Validation Accuracy: 0.8090\n",
      "Epoch [120/500], Training Loss: 0.1085, Validation Loss: 0.6970, Training Accuracy: 0.9600, Validation Accuracy: 0.8202\n",
      "Epoch [121/500], Training Loss: 0.1044, Validation Loss: 1.6185, Training Accuracy: 0.9625, Validation Accuracy: 0.7978\n",
      "Epoch [122/500], Training Loss: 0.1197, Validation Loss: 1.6960, Training Accuracy: 0.9613, Validation Accuracy: 0.7753\n",
      "Epoch [123/500], Training Loss: 0.1270, Validation Loss: 1.6446, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [124/500], Training Loss: 0.1629, Validation Loss: 0.7129, Training Accuracy: 0.9387, Validation Accuracy: 0.8090\n",
      "Epoch [125/500], Training Loss: 0.1215, Validation Loss: 0.7490, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [126/500], Training Loss: 0.1367, Validation Loss: 1.6031, Training Accuracy: 0.9500, Validation Accuracy: 0.8090\n",
      "Epoch [127/500], Training Loss: 0.1293, Validation Loss: 1.6982, Training Accuracy: 0.9537, Validation Accuracy: 0.7978\n",
      "Epoch [128/500], Training Loss: 0.1358, Validation Loss: 0.7441, Training Accuracy: 0.9475, Validation Accuracy: 0.8090\n",
      "Epoch [129/500], Training Loss: 0.1413, Validation Loss: 0.7476, Training Accuracy: 0.9525, Validation Accuracy: 0.7865\n",
      "Epoch [130/500], Training Loss: 0.1246, Validation Loss: 0.7651, Training Accuracy: 0.9537, Validation Accuracy: 0.7978\n",
      "Epoch [131/500], Training Loss: 0.1069, Validation Loss: 0.7807, Training Accuracy: 0.9625, Validation Accuracy: 0.8202\n",
      "Epoch [132/500], Training Loss: 0.1206, Validation Loss: 0.6944, Training Accuracy: 0.9487, Validation Accuracy: 0.7978\n",
      "Epoch [133/500], Training Loss: 0.1199, Validation Loss: 0.7484, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [134/500], Training Loss: 0.1190, Validation Loss: 0.8294, Training Accuracy: 0.9513, Validation Accuracy: 0.7978\n",
      "Epoch [135/500], Training Loss: 0.0981, Validation Loss: 0.8259, Training Accuracy: 0.9650, Validation Accuracy: 0.7753\n",
      "Epoch [136/500], Training Loss: 0.1253, Validation Loss: 1.6721, Training Accuracy: 0.9537, Validation Accuracy: 0.7865\n",
      "Epoch [137/500], Training Loss: 0.1369, Validation Loss: 1.6759, Training Accuracy: 0.9487, Validation Accuracy: 0.7753\n",
      "Epoch [138/500], Training Loss: 0.1078, Validation Loss: 1.6555, Training Accuracy: 0.9575, Validation Accuracy: 0.7865\n",
      "Epoch [139/500], Training Loss: 0.1250, Validation Loss: 1.7815, Training Accuracy: 0.9550, Validation Accuracy: 0.7528\n",
      "Epoch [140/500], Training Loss: 0.1014, Validation Loss: 1.6879, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [141/500], Training Loss: 0.1159, Validation Loss: 1.6812, Training Accuracy: 0.9537, Validation Accuracy: 0.7528\n",
      "Epoch [142/500], Training Loss: 0.0922, Validation Loss: 1.7239, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [143/500], Training Loss: 0.1114, Validation Loss: 1.6869, Training Accuracy: 0.9550, Validation Accuracy: 0.7865\n",
      "Epoch [144/500], Training Loss: 0.1349, Validation Loss: 0.8316, Training Accuracy: 0.9525, Validation Accuracy: 0.7865\n",
      "Epoch [145/500], Training Loss: 0.1311, Validation Loss: 0.8241, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [146/500], Training Loss: 0.1568, Validation Loss: 0.7601, Training Accuracy: 0.9375, Validation Accuracy: 0.7865\n",
      "Epoch [147/500], Training Loss: 0.1194, Validation Loss: 0.7924, Training Accuracy: 0.9563, Validation Accuracy: 0.7865\n",
      "Epoch [148/500], Training Loss: 0.1185, Validation Loss: 0.8225, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [149/500], Training Loss: 0.0995, Validation Loss: 0.8466, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [150/500], Training Loss: 0.1430, Validation Loss: 0.8294, Training Accuracy: 0.9500, Validation Accuracy: 0.7865\n",
      "Epoch [151/500], Training Loss: 0.1376, Validation Loss: 0.7858, Training Accuracy: 0.9525, Validation Accuracy: 0.7528\n",
      "Epoch [152/500], Training Loss: 0.1228, Validation Loss: 0.7595, Training Accuracy: 0.9525, Validation Accuracy: 0.7753\n",
      "Epoch [153/500], Training Loss: 0.0878, Validation Loss: 0.7527, Training Accuracy: 0.9688, Validation Accuracy: 0.8090\n",
      "Epoch [154/500], Training Loss: 0.1252, Validation Loss: 0.8475, Training Accuracy: 0.9575, Validation Accuracy: 0.7753\n",
      "Epoch [155/500], Training Loss: 0.1449, Validation Loss: 0.7163, Training Accuracy: 0.9400, Validation Accuracy: 0.7978\n",
      "Epoch [156/500], Training Loss: 0.1347, Validation Loss: 0.7846, Training Accuracy: 0.9450, Validation Accuracy: 0.7640\n",
      "Epoch [157/500], Training Loss: 0.1026, Validation Loss: 0.8421, Training Accuracy: 0.9575, Validation Accuracy: 0.7753\n",
      "Epoch [158/500], Training Loss: 0.1125, Validation Loss: 0.7408, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [159/500], Training Loss: 0.1138, Validation Loss: 0.7880, Training Accuracy: 0.9600, Validation Accuracy: 0.8202\n",
      "Epoch [160/500], Training Loss: 0.1286, Validation Loss: 0.7515, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [161/500], Training Loss: 0.1028, Validation Loss: 1.7224, Training Accuracy: 0.9613, Validation Accuracy: 0.7753\n",
      "Epoch [162/500], Training Loss: 0.1034, Validation Loss: 0.8101, Training Accuracy: 0.9613, Validation Accuracy: 0.7753\n",
      "Epoch [163/500], Training Loss: 0.0897, Validation Loss: 0.8182, Training Accuracy: 0.9663, Validation Accuracy: 0.7640\n",
      "Epoch [164/500], Training Loss: 0.0921, Validation Loss: 1.7264, Training Accuracy: 0.9675, Validation Accuracy: 0.7640\n",
      "Epoch [165/500], Training Loss: 0.1196, Validation Loss: 0.8387, Training Accuracy: 0.9513, Validation Accuracy: 0.7416\n",
      "Epoch [166/500], Training Loss: 0.0976, Validation Loss: 1.7960, Training Accuracy: 0.9613, Validation Accuracy: 0.7753\n",
      "Epoch [167/500], Training Loss: 0.1012, Validation Loss: 1.7180, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [168/500], Training Loss: 0.0751, Validation Loss: 1.7631, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [169/500], Training Loss: 0.0751, Validation Loss: 1.8474, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [170/500], Training Loss: 0.1288, Validation Loss: 1.8006, Training Accuracy: 0.9537, Validation Accuracy: 0.7978\n",
      "Epoch [171/500], Training Loss: 0.1051, Validation Loss: 0.8040, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [172/500], Training Loss: 0.0999, Validation Loss: 0.8233, Training Accuracy: 0.9625, Validation Accuracy: 0.7640\n",
      "Epoch [173/500], Training Loss: 0.0985, Validation Loss: 0.8126, Training Accuracy: 0.9537, Validation Accuracy: 0.8090\n",
      "Epoch [174/500], Training Loss: 0.0912, Validation Loss: 1.7379, Training Accuracy: 0.9663, Validation Accuracy: 0.8090\n",
      "Epoch [175/500], Training Loss: 0.0907, Validation Loss: 1.7789, Training Accuracy: 0.9650, Validation Accuracy: 0.8315\n",
      "Epoch [176/500], Training Loss: 0.0927, Validation Loss: 1.7678, Training Accuracy: 0.9637, Validation Accuracy: 0.8090\n",
      "Epoch [177/500], Training Loss: 0.0984, Validation Loss: 0.9261, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [178/500], Training Loss: 0.1124, Validation Loss: 0.8724, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [179/500], Training Loss: 0.0803, Validation Loss: 1.7911, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [180/500], Training Loss: 0.1163, Validation Loss: 0.7381, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [181/500], Training Loss: 0.1028, Validation Loss: 0.7899, Training Accuracy: 0.9637, Validation Accuracy: 0.7753\n",
      "Epoch [182/500], Training Loss: 0.1240, Validation Loss: 1.7118, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [183/500], Training Loss: 0.0894, Validation Loss: 1.7060, Training Accuracy: 0.9625, Validation Accuracy: 0.7753\n",
      "Epoch [184/500], Training Loss: 0.0962, Validation Loss: 1.7985, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [185/500], Training Loss: 0.1092, Validation Loss: 1.7645, Training Accuracy: 0.9587, Validation Accuracy: 0.7865\n",
      "Epoch [186/500], Training Loss: 0.0992, Validation Loss: 1.7504, Training Accuracy: 0.9550, Validation Accuracy: 0.7865\n",
      "Epoch [187/500], Training Loss: 0.1030, Validation Loss: 0.8116, Training Accuracy: 0.9600, Validation Accuracy: 0.7753\n",
      "Epoch [188/500], Training Loss: 0.1068, Validation Loss: 0.7920, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [189/500], Training Loss: 0.0875, Validation Loss: 0.8418, Training Accuracy: 0.9675, Validation Accuracy: 0.7753\n",
      "Epoch [190/500], Training Loss: 0.0747, Validation Loss: 1.7109, Training Accuracy: 0.9762, Validation Accuracy: 0.8202\n",
      "Epoch [191/500], Training Loss: 0.1142, Validation Loss: 0.8779, Training Accuracy: 0.9600, Validation Accuracy: 0.8090\n",
      "Epoch [192/500], Training Loss: 0.0711, Validation Loss: 0.8265, Training Accuracy: 0.9700, Validation Accuracy: 0.8090\n",
      "Epoch [193/500], Training Loss: 0.0582, Validation Loss: 0.8309, Training Accuracy: 0.9775, Validation Accuracy: 0.8090\n",
      "Epoch [194/500], Training Loss: 0.0801, Validation Loss: 1.7752, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [195/500], Training Loss: 0.0941, Validation Loss: 1.7960, Training Accuracy: 0.9663, Validation Accuracy: 0.7865\n",
      "Epoch [196/500], Training Loss: 0.0827, Validation Loss: 1.7354, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [197/500], Training Loss: 0.1015, Validation Loss: 0.8078, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [198/500], Training Loss: 0.1119, Validation Loss: 1.6970, Training Accuracy: 0.9637, Validation Accuracy: 0.8090\n",
      "Epoch [199/500], Training Loss: 0.0761, Validation Loss: 0.8325, Training Accuracy: 0.9725, Validation Accuracy: 0.8090\n",
      "Epoch [200/500], Training Loss: 0.0989, Validation Loss: 1.7824, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [201/500], Training Loss: 0.0826, Validation Loss: 1.7389, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [202/500], Training Loss: 0.0866, Validation Loss: 0.8549, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [203/500], Training Loss: 0.0875, Validation Loss: 0.8868, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [204/500], Training Loss: 0.1047, Validation Loss: 1.8866, Training Accuracy: 0.9613, Validation Accuracy: 0.7865\n",
      "Epoch [205/500], Training Loss: 0.1061, Validation Loss: 1.7207, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [206/500], Training Loss: 0.1105, Validation Loss: 0.8312, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [207/500], Training Loss: 0.0883, Validation Loss: 1.7089, Training Accuracy: 0.9625, Validation Accuracy: 0.8202\n",
      "Epoch [208/500], Training Loss: 0.0892, Validation Loss: 1.7440, Training Accuracy: 0.9663, Validation Accuracy: 0.8090\n",
      "Epoch [209/500], Training Loss: 0.0768, Validation Loss: 1.7481, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [210/500], Training Loss: 0.0834, Validation Loss: 1.7555, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [211/500], Training Loss: 0.0855, Validation Loss: 1.7434, Training Accuracy: 0.9675, Validation Accuracy: 0.7978\n",
      "Epoch [212/500], Training Loss: 0.1139, Validation Loss: 1.6775, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [213/500], Training Loss: 0.0939, Validation Loss: 1.7460, Training Accuracy: 0.9637, Validation Accuracy: 0.7978\n",
      "Epoch [214/500], Training Loss: 0.0568, Validation Loss: 1.7940, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [215/500], Training Loss: 0.0953, Validation Loss: 1.7903, Training Accuracy: 0.9613, Validation Accuracy: 0.7865\n",
      "Epoch [216/500], Training Loss: 0.0915, Validation Loss: 1.7510, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [217/500], Training Loss: 0.0896, Validation Loss: 1.7560, Training Accuracy: 0.9788, Validation Accuracy: 0.7753\n",
      "Epoch [218/500], Training Loss: 0.0905, Validation Loss: 1.7908, Training Accuracy: 0.9675, Validation Accuracy: 0.7753\n",
      "Epoch [219/500], Training Loss: 0.0750, Validation Loss: 1.8086, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [220/500], Training Loss: 0.0790, Validation Loss: 1.8688, Training Accuracy: 0.9712, Validation Accuracy: 0.7303\n",
      "Epoch [221/500], Training Loss: 0.0856, Validation Loss: 1.7942, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [222/500], Training Loss: 0.0943, Validation Loss: 1.8134, Training Accuracy: 0.9613, Validation Accuracy: 0.7753\n",
      "Epoch [223/500], Training Loss: 0.0814, Validation Loss: 1.8960, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [224/500], Training Loss: 0.0732, Validation Loss: 1.8920, Training Accuracy: 0.9775, Validation Accuracy: 0.7753\n",
      "Epoch [225/500], Training Loss: 0.1058, Validation Loss: 1.8006, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [226/500], Training Loss: 0.1029, Validation Loss: 1.8313, Training Accuracy: 0.9650, Validation Accuracy: 0.7753\n",
      "Epoch [227/500], Training Loss: 0.0886, Validation Loss: 1.8355, Training Accuracy: 0.9700, Validation Accuracy: 0.7640\n",
      "Epoch [228/500], Training Loss: 0.0778, Validation Loss: 1.8459, Training Accuracy: 0.9725, Validation Accuracy: 0.7640\n",
      "Epoch [229/500], Training Loss: 0.0946, Validation Loss: 1.8009, Training Accuracy: 0.9663, Validation Accuracy: 0.7865\n",
      "Epoch [230/500], Training Loss: 0.0881, Validation Loss: 1.8202, Training Accuracy: 0.9637, Validation Accuracy: 0.7640\n",
      "Epoch [231/500], Training Loss: 0.0855, Validation Loss: 1.8737, Training Accuracy: 0.9637, Validation Accuracy: 0.7978\n",
      "Epoch [232/500], Training Loss: 0.0852, Validation Loss: 1.8447, Training Accuracy: 0.9700, Validation Accuracy: 0.7640\n",
      "Epoch [233/500], Training Loss: 0.0866, Validation Loss: 1.8760, Training Accuracy: 0.9675, Validation Accuracy: 0.7640\n",
      "Epoch [234/500], Training Loss: 0.0926, Validation Loss: 1.8983, Training Accuracy: 0.9650, Validation Accuracy: 0.7640\n",
      "Epoch [235/500], Training Loss: 0.0782, Validation Loss: 1.8448, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [236/500], Training Loss: 0.0743, Validation Loss: 1.7584, Training Accuracy: 0.9725, Validation Accuracy: 0.8202\n",
      "Epoch [237/500], Training Loss: 0.1051, Validation Loss: 1.7941, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [238/500], Training Loss: 0.0823, Validation Loss: 1.7282, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [239/500], Training Loss: 0.0955, Validation Loss: 1.7536, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [240/500], Training Loss: 0.0841, Validation Loss: 1.7210, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [241/500], Training Loss: 0.1084, Validation Loss: 1.8165, Training Accuracy: 0.9600, Validation Accuracy: 0.7528\n",
      "Epoch [242/500], Training Loss: 0.0751, Validation Loss: 1.7862, Training Accuracy: 0.9762, Validation Accuracy: 0.7753\n",
      "Epoch [243/500], Training Loss: 0.0764, Validation Loss: 1.7678, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [244/500], Training Loss: 0.0690, Validation Loss: 1.7597, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [245/500], Training Loss: 0.0631, Validation Loss: 1.7975, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [246/500], Training Loss: 0.0825, Validation Loss: 1.7797, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [247/500], Training Loss: 0.0715, Validation Loss: 1.7384, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [248/500], Training Loss: 0.0854, Validation Loss: 1.9141, Training Accuracy: 0.9650, Validation Accuracy: 0.7640\n",
      "Epoch [249/500], Training Loss: 0.0777, Validation Loss: 1.7991, Training Accuracy: 0.9775, Validation Accuracy: 0.8090\n",
      "Epoch [250/500], Training Loss: 0.0615, Validation Loss: 1.8617, Training Accuracy: 0.9775, Validation Accuracy: 0.7753\n",
      "Epoch [251/500], Training Loss: 0.0817, Validation Loss: 1.8144, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [252/500], Training Loss: 0.0689, Validation Loss: 1.7862, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [253/500], Training Loss: 0.0646, Validation Loss: 1.8300, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [254/500], Training Loss: 0.0862, Validation Loss: 1.8383, Training Accuracy: 0.9700, Validation Accuracy: 0.7753\n",
      "Epoch [255/500], Training Loss: 0.0686, Validation Loss: 1.8571, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [256/500], Training Loss: 0.0706, Validation Loss: 1.8444, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [257/500], Training Loss: 0.0960, Validation Loss: 1.8432, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [258/500], Training Loss: 0.1013, Validation Loss: 1.7972, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [259/500], Training Loss: 0.1289, Validation Loss: 1.7521, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [260/500], Training Loss: 0.0902, Validation Loss: 1.6953, Training Accuracy: 0.9700, Validation Accuracy: 0.8315\n",
      "Epoch [261/500], Training Loss: 0.1241, Validation Loss: 1.7084, Training Accuracy: 0.9637, Validation Accuracy: 0.8315\n",
      "Epoch [262/500], Training Loss: 0.0718, Validation Loss: 1.6773, Training Accuracy: 0.9762, Validation Accuracy: 0.8315\n",
      "Epoch [263/500], Training Loss: 0.0665, Validation Loss: 1.6858, Training Accuracy: 0.9775, Validation Accuracy: 0.8202\n",
      "Epoch [264/500], Training Loss: 0.0710, Validation Loss: 1.7608, Training Accuracy: 0.9663, Validation Accuracy: 0.8315\n",
      "Epoch [265/500], Training Loss: 0.0836, Validation Loss: 1.7676, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [266/500], Training Loss: 0.0936, Validation Loss: 1.7011, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [267/500], Training Loss: 0.0858, Validation Loss: 1.7604, Training Accuracy: 0.9663, Validation Accuracy: 0.7865\n",
      "Epoch [268/500], Training Loss: 0.0704, Validation Loss: 1.8151, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [269/500], Training Loss: 0.0803, Validation Loss: 1.8301, Training Accuracy: 0.9725, Validation Accuracy: 0.8202\n",
      "Epoch [270/500], Training Loss: 0.0721, Validation Loss: 1.8134, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [271/500], Training Loss: 0.0543, Validation Loss: 1.8661, Training Accuracy: 0.9812, Validation Accuracy: 0.8090\n",
      "Epoch [272/500], Training Loss: 0.0915, Validation Loss: 0.9002, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [273/500], Training Loss: 0.0706, Validation Loss: 1.8518, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [274/500], Training Loss: 0.0722, Validation Loss: 1.8390, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [275/500], Training Loss: 0.0769, Validation Loss: 1.0051, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [276/500], Training Loss: 0.0613, Validation Loss: 1.9048, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [277/500], Training Loss: 0.0731, Validation Loss: 1.8050, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [278/500], Training Loss: 0.0705, Validation Loss: 1.7714, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [279/500], Training Loss: 0.0746, Validation Loss: 1.8433, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [280/500], Training Loss: 0.0682, Validation Loss: 1.8841, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [281/500], Training Loss: 0.0707, Validation Loss: 1.8762, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [282/500], Training Loss: 0.0588, Validation Loss: 1.8664, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [283/500], Training Loss: 0.0978, Validation Loss: 1.8392, Training Accuracy: 0.9625, Validation Accuracy: 0.7978\n",
      "Epoch [284/500], Training Loss: 0.0556, Validation Loss: 1.8293, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [285/500], Training Loss: 0.0579, Validation Loss: 1.8762, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [286/500], Training Loss: 0.0453, Validation Loss: 1.9107, Training Accuracy: 0.9850, Validation Accuracy: 0.7865\n",
      "Epoch [287/500], Training Loss: 0.0459, Validation Loss: 1.8745, Training Accuracy: 0.9825, Validation Accuracy: 0.7865\n",
      "Epoch [288/500], Training Loss: 0.0481, Validation Loss: 1.9169, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [289/500], Training Loss: 0.0619, Validation Loss: 1.9761, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [290/500], Training Loss: 0.0886, Validation Loss: 1.9144, Training Accuracy: 0.9663, Validation Accuracy: 0.7528\n",
      "Epoch [291/500], Training Loss: 0.0704, Validation Loss: 1.9625, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [292/500], Training Loss: 0.0576, Validation Loss: 1.9526, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [293/500], Training Loss: 0.0628, Validation Loss: 1.0676, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Epoch [294/500], Training Loss: 0.0739, Validation Loss: 1.0225, Training Accuracy: 0.9738, Validation Accuracy: 0.7753\n",
      "Epoch [295/500], Training Loss: 0.0522, Validation Loss: 1.9321, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [296/500], Training Loss: 0.0848, Validation Loss: 1.8653, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [297/500], Training Loss: 0.0861, Validation Loss: 1.9551, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [298/500], Training Loss: 0.0765, Validation Loss: 1.9367, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [299/500], Training Loss: 0.0637, Validation Loss: 1.9859, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [300/500], Training Loss: 0.0415, Validation Loss: 1.9637, Training Accuracy: 0.9900, Validation Accuracy: 0.7753\n",
      "Epoch [301/500], Training Loss: 0.0537, Validation Loss: 1.9782, Training Accuracy: 0.9775, Validation Accuracy: 0.7640\n",
      "Epoch [302/500], Training Loss: 0.0483, Validation Loss: 1.9338, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [303/500], Training Loss: 0.0649, Validation Loss: 1.9189, Training Accuracy: 0.9788, Validation Accuracy: 0.7753\n",
      "Epoch [304/500], Training Loss: 0.0816, Validation Loss: 1.9370, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [305/500], Training Loss: 0.0580, Validation Loss: 2.0030, Training Accuracy: 0.9850, Validation Accuracy: 0.7528\n",
      "Epoch [306/500], Training Loss: 0.0771, Validation Loss: 1.9515, Training Accuracy: 0.9788, Validation Accuracy: 0.7528\n",
      "Epoch [307/500], Training Loss: 0.0809, Validation Loss: 2.0011, Training Accuracy: 0.9663, Validation Accuracy: 0.7528\n",
      "Epoch [308/500], Training Loss: 0.0855, Validation Loss: 1.8784, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [309/500], Training Loss: 0.0564, Validation Loss: 1.9369, Training Accuracy: 0.9812, Validation Accuracy: 0.7865\n",
      "Epoch [310/500], Training Loss: 0.0581, Validation Loss: 1.9966, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [311/500], Training Loss: 0.0403, Validation Loss: 1.9791, Training Accuracy: 0.9888, Validation Accuracy: 0.7865\n",
      "Epoch [312/500], Training Loss: 0.0692, Validation Loss: 1.9610, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [313/500], Training Loss: 0.0770, Validation Loss: 2.0561, Training Accuracy: 0.9738, Validation Accuracy: 0.7191\n",
      "Epoch [314/500], Training Loss: 0.0564, Validation Loss: 2.1065, Training Accuracy: 0.9775, Validation Accuracy: 0.7528\n",
      "Epoch [315/500], Training Loss: 0.0821, Validation Loss: 2.1368, Training Accuracy: 0.9688, Validation Accuracy: 0.7528\n",
      "Epoch [316/500], Training Loss: 0.0771, Validation Loss: 2.1098, Training Accuracy: 0.9712, Validation Accuracy: 0.7753\n",
      "Epoch [317/500], Training Loss: 0.1191, Validation Loss: 1.8591, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [318/500], Training Loss: 0.0792, Validation Loss: 1.9207, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [319/500], Training Loss: 0.0594, Validation Loss: 1.9198, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [320/500], Training Loss: 0.0649, Validation Loss: 1.8553, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [321/500], Training Loss: 0.0680, Validation Loss: 2.0133, Training Accuracy: 0.9788, Validation Accuracy: 0.7753\n",
      "Epoch [322/500], Training Loss: 0.0650, Validation Loss: 2.0234, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [323/500], Training Loss: 0.0621, Validation Loss: 2.0420, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [324/500], Training Loss: 0.0597, Validation Loss: 2.1226, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [325/500], Training Loss: 0.0386, Validation Loss: 2.1351, Training Accuracy: 0.9888, Validation Accuracy: 0.7865\n",
      "Epoch [326/500], Training Loss: 0.0806, Validation Loss: 2.0181, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [327/500], Training Loss: 0.0787, Validation Loss: 1.9121, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [328/500], Training Loss: 0.0429, Validation Loss: 1.8586, Training Accuracy: 0.9825, Validation Accuracy: 0.7640\n",
      "Epoch [329/500], Training Loss: 0.0771, Validation Loss: 1.8353, Training Accuracy: 0.9762, Validation Accuracy: 0.7753\n",
      "Epoch [330/500], Training Loss: 0.0899, Validation Loss: 1.8309, Training Accuracy: 0.9762, Validation Accuracy: 0.7753\n",
      "Epoch [331/500], Training Loss: 0.0868, Validation Loss: 1.8837, Training Accuracy: 0.9675, Validation Accuracy: 0.7528\n",
      "Epoch [332/500], Training Loss: 0.0508, Validation Loss: 1.8467, Training Accuracy: 0.9838, Validation Accuracy: 0.7753\n",
      "Epoch [333/500], Training Loss: 0.0838, Validation Loss: 1.9045, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [334/500], Training Loss: 0.0799, Validation Loss: 1.9295, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [335/500], Training Loss: 0.0435, Validation Loss: 1.9597, Training Accuracy: 0.9912, Validation Accuracy: 0.7865\n",
      "Epoch [336/500], Training Loss: 0.0493, Validation Loss: 1.9459, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [337/500], Training Loss: 0.0863, Validation Loss: 1.9305, Training Accuracy: 0.9712, Validation Accuracy: 0.8090\n",
      "Epoch [338/500], Training Loss: 0.0608, Validation Loss: 1.9174, Training Accuracy: 0.9788, Validation Accuracy: 0.7640\n",
      "Epoch [339/500], Training Loss: 0.0511, Validation Loss: 1.9212, Training Accuracy: 0.9838, Validation Accuracy: 0.7640\n",
      "Epoch [340/500], Training Loss: 0.0788, Validation Loss: 1.8373, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [341/500], Training Loss: 0.0668, Validation Loss: 1.9105, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [342/500], Training Loss: 0.0436, Validation Loss: 1.9686, Training Accuracy: 0.9825, Validation Accuracy: 0.7753\n",
      "Epoch [343/500], Training Loss: 0.0445, Validation Loss: 1.9586, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [344/500], Training Loss: 0.0504, Validation Loss: 2.0225, Training Accuracy: 0.9912, Validation Accuracy: 0.7753\n",
      "Epoch [345/500], Training Loss: 0.0581, Validation Loss: 2.0666, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [346/500], Training Loss: 0.0720, Validation Loss: 2.0989, Training Accuracy: 0.9788, Validation Accuracy: 0.7753\n",
      "Epoch [347/500], Training Loss: 0.0682, Validation Loss: 2.0639, Training Accuracy: 0.9825, Validation Accuracy: 0.7865\n",
      "Epoch [348/500], Training Loss: 0.0899, Validation Loss: 2.1507, Training Accuracy: 0.9650, Validation Accuracy: 0.7865\n",
      "Epoch [349/500], Training Loss: 0.0976, Validation Loss: 1.9543, Training Accuracy: 0.9712, Validation Accuracy: 0.8090\n",
      "Epoch [350/500], Training Loss: 0.0594, Validation Loss: 1.9978, Training Accuracy: 0.9788, Validation Accuracy: 0.7753\n",
      "Epoch [351/500], Training Loss: 0.0623, Validation Loss: 2.0380, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [352/500], Training Loss: 0.0670, Validation Loss: 1.9566, Training Accuracy: 0.9725, Validation Accuracy: 0.8090\n",
      "Epoch [353/500], Training Loss: 0.0642, Validation Loss: 1.9017, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [354/500], Training Loss: 0.0579, Validation Loss: 1.9902, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [355/500], Training Loss: 0.0556, Validation Loss: 1.9543, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [356/500], Training Loss: 0.0759, Validation Loss: 1.9123, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [357/500], Training Loss: 0.0544, Validation Loss: 2.0141, Training Accuracy: 0.9812, Validation Accuracy: 0.7416\n",
      "Epoch [358/500], Training Loss: 0.0596, Validation Loss: 1.9510, Training Accuracy: 0.9775, Validation Accuracy: 0.7640\n",
      "Epoch [359/500], Training Loss: 0.0583, Validation Loss: 2.0528, Training Accuracy: 0.9775, Validation Accuracy: 0.7640\n",
      "Epoch [360/500], Training Loss: 0.0397, Validation Loss: 2.1074, Training Accuracy: 0.9875, Validation Accuracy: 0.7640\n",
      "Epoch [361/500], Training Loss: 0.0648, Validation Loss: 2.1129, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [362/500], Training Loss: 0.0601, Validation Loss: 2.0306, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [363/500], Training Loss: 0.0546, Validation Loss: 2.0084, Training Accuracy: 0.9800, Validation Accuracy: 0.8315\n",
      "Epoch [364/500], Training Loss: 0.0925, Validation Loss: 1.9506, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [365/500], Training Loss: 0.0721, Validation Loss: 1.9416, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [366/500], Training Loss: 0.0532, Validation Loss: 1.8824, Training Accuracy: 0.9825, Validation Accuracy: 0.8202\n",
      "Epoch [367/500], Training Loss: 0.0705, Validation Loss: 1.8657, Training Accuracy: 0.9800, Validation Accuracy: 0.8090\n",
      "Epoch [368/500], Training Loss: 0.0468, Validation Loss: 1.8679, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Epoch [369/500], Training Loss: 0.0741, Validation Loss: 1.9183, Training Accuracy: 0.9788, Validation Accuracy: 0.7753\n",
      "Epoch [370/500], Training Loss: 0.0690, Validation Loss: 1.9465, Training Accuracy: 0.9775, Validation Accuracy: 0.7753\n",
      "Epoch [371/500], Training Loss: 0.0541, Validation Loss: 1.9884, Training Accuracy: 0.9875, Validation Accuracy: 0.7865\n",
      "Epoch [372/500], Training Loss: 0.0583, Validation Loss: 2.0132, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [373/500], Training Loss: 0.0585, Validation Loss: 1.9322, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [374/500], Training Loss: 0.0576, Validation Loss: 1.9495, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [375/500], Training Loss: 0.0561, Validation Loss: 1.9602, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [376/500], Training Loss: 0.0789, Validation Loss: 1.9229, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [377/500], Training Loss: 0.0513, Validation Loss: 1.8985, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [378/500], Training Loss: 0.0623, Validation Loss: 1.9059, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [379/500], Training Loss: 0.0519, Validation Loss: 1.8470, Training Accuracy: 0.9838, Validation Accuracy: 0.7978\n",
      "Epoch [380/500], Training Loss: 0.0541, Validation Loss: 1.9090, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [381/500], Training Loss: 0.0607, Validation Loss: 2.0021, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [382/500], Training Loss: 0.0592, Validation Loss: 1.9465, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [383/500], Training Loss: 0.0512, Validation Loss: 2.0688, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [384/500], Training Loss: 0.0395, Validation Loss: 2.0944, Training Accuracy: 0.9875, Validation Accuracy: 0.7865\n",
      "Epoch [385/500], Training Loss: 0.0414, Validation Loss: 2.1189, Training Accuracy: 0.9862, Validation Accuracy: 0.7753\n",
      "Epoch [386/500], Training Loss: 0.0565, Validation Loss: 1.9935, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [387/500], Training Loss: 0.0443, Validation Loss: 2.0768, Training Accuracy: 0.9838, Validation Accuracy: 0.7865\n",
      "Epoch [388/500], Training Loss: 0.1967, Validation Loss: 2.0606, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [389/500], Training Loss: 0.0567, Validation Loss: 2.0231, Training Accuracy: 0.9812, Validation Accuracy: 0.7528\n",
      "Epoch [390/500], Training Loss: 0.0509, Validation Loss: 2.0363, Training Accuracy: 0.9825, Validation Accuracy: 0.7865\n",
      "Epoch [391/500], Training Loss: 0.0491, Validation Loss: 2.0388, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [392/500], Training Loss: 0.0404, Validation Loss: 1.9926, Training Accuracy: 0.9888, Validation Accuracy: 0.7753\n",
      "Epoch [393/500], Training Loss: 0.0601, Validation Loss: 2.0181, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [394/500], Training Loss: 0.0576, Validation Loss: 2.0814, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [395/500], Training Loss: 0.0586, Validation Loss: 2.0670, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [396/500], Training Loss: 0.0579, Validation Loss: 1.9994, Training Accuracy: 0.9862, Validation Accuracy: 0.7865\n",
      "Epoch [397/500], Training Loss: 0.0538, Validation Loss: 2.0714, Training Accuracy: 0.9912, Validation Accuracy: 0.7753\n",
      "Epoch [398/500], Training Loss: 0.0462, Validation Loss: 2.0505, Training Accuracy: 0.9812, Validation Accuracy: 0.7865\n",
      "Epoch [399/500], Training Loss: 0.0498, Validation Loss: 2.0933, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [400/500], Training Loss: 0.0543, Validation Loss: 2.0483, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [401/500], Training Loss: 0.0594, Validation Loss: 1.8876, Training Accuracy: 0.9838, Validation Accuracy: 0.8090\n",
      "Epoch [402/500], Training Loss: 0.0465, Validation Loss: 2.0605, Training Accuracy: 0.9862, Validation Accuracy: 0.7753\n",
      "Epoch [403/500], Training Loss: 0.0670, Validation Loss: 2.1002, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [404/500], Training Loss: 0.0412, Validation Loss: 2.0390, Training Accuracy: 0.9838, Validation Accuracy: 0.7978\n",
      "Epoch [405/500], Training Loss: 0.0867, Validation Loss: 1.9415, Training Accuracy: 0.9675, Validation Accuracy: 0.7978\n",
      "Epoch [406/500], Training Loss: 0.0573, Validation Loss: 1.9703, Training Accuracy: 0.9812, Validation Accuracy: 0.7865\n",
      "Epoch [407/500], Training Loss: 0.0536, Validation Loss: 1.9995, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [408/500], Training Loss: 0.0616, Validation Loss: 2.0176, Training Accuracy: 0.9738, Validation Accuracy: 0.7753\n",
      "Epoch [409/500], Training Loss: 0.0431, Validation Loss: 2.0480, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [410/500], Training Loss: 0.0595, Validation Loss: 2.0663, Training Accuracy: 0.9812, Validation Accuracy: 0.7865\n",
      "Epoch [411/500], Training Loss: 0.0411, Validation Loss: 2.0113, Training Accuracy: 0.9888, Validation Accuracy: 0.7865\n",
      "Epoch [412/500], Training Loss: 0.0508, Validation Loss: 2.0428, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [413/500], Training Loss: 0.0522, Validation Loss: 2.0647, Training Accuracy: 0.9825, Validation Accuracy: 0.7640\n",
      "Epoch [414/500], Training Loss: 0.0592, Validation Loss: 2.0113, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [415/500], Training Loss: 0.0406, Validation Loss: 2.0400, Training Accuracy: 0.9825, Validation Accuracy: 0.7753\n",
      "Epoch [416/500], Training Loss: 0.0618, Validation Loss: 1.9887, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [417/500], Training Loss: 0.0480, Validation Loss: 1.9889, Training Accuracy: 0.9825, Validation Accuracy: 0.7865\n",
      "Epoch [418/500], Training Loss: 0.0741, Validation Loss: 1.9286, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [419/500], Training Loss: 0.0723, Validation Loss: 1.9380, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [420/500], Training Loss: 0.0720, Validation Loss: 1.8914, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [421/500], Training Loss: 0.0777, Validation Loss: 1.9156, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [422/500], Training Loss: 0.0689, Validation Loss: 1.9167, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [423/500], Training Loss: 0.0592, Validation Loss: 1.9621, Training Accuracy: 0.9862, Validation Accuracy: 0.7865\n",
      "Epoch [424/500], Training Loss: 0.0370, Validation Loss: 2.0100, Training Accuracy: 0.9888, Validation Accuracy: 0.7865\n",
      "Epoch [425/500], Training Loss: 0.0461, Validation Loss: 2.0639, Training Accuracy: 0.9862, Validation Accuracy: 0.7865\n",
      "Epoch [426/500], Training Loss: 0.0465, Validation Loss: 2.0334, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [427/500], Training Loss: 0.0566, Validation Loss: 2.0314, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [428/500], Training Loss: 0.0511, Validation Loss: 2.1340, Training Accuracy: 0.9900, Validation Accuracy: 0.7978\n",
      "Epoch [429/500], Training Loss: 0.0574, Validation Loss: 2.1288, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [430/500], Training Loss: 0.0492, Validation Loss: 2.0556, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [431/500], Training Loss: 0.0342, Validation Loss: 2.0959, Training Accuracy: 0.9875, Validation Accuracy: 0.7865\n",
      "Epoch [432/500], Training Loss: 0.0689, Validation Loss: 1.9820, Training Accuracy: 0.9725, Validation Accuracy: 0.8090\n",
      "Epoch [433/500], Training Loss: 0.0499, Validation Loss: 1.9606, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [434/500], Training Loss: 0.0593, Validation Loss: 2.0294, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [435/500], Training Loss: 0.0437, Validation Loss: 2.0886, Training Accuracy: 0.9825, Validation Accuracy: 0.7865\n",
      "Epoch [436/500], Training Loss: 0.0555, Validation Loss: 2.0928, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [437/500], Training Loss: 0.0425, Validation Loss: 2.1007, Training Accuracy: 0.9862, Validation Accuracy: 0.7865\n",
      "Epoch [438/500], Training Loss: 0.0262, Validation Loss: 2.1398, Training Accuracy: 0.9925, Validation Accuracy: 0.7978\n",
      "Epoch [439/500], Training Loss: 0.0363, Validation Loss: 2.1418, Training Accuracy: 0.9862, Validation Accuracy: 0.7865\n",
      "Epoch [440/500], Training Loss: 0.0372, Validation Loss: 2.0793, Training Accuracy: 0.9862, Validation Accuracy: 0.7753\n",
      "Epoch [441/500], Training Loss: 0.0472, Validation Loss: 2.0251, Training Accuracy: 0.9875, Validation Accuracy: 0.8090\n",
      "Epoch [442/500], Training Loss: 0.0642, Validation Loss: 2.0503, Training Accuracy: 0.9850, Validation Accuracy: 0.8202\n",
      "Epoch [443/500], Training Loss: 0.0602, Validation Loss: 2.1139, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [444/500], Training Loss: 0.0552, Validation Loss: 2.0792, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Epoch [445/500], Training Loss: 0.0380, Validation Loss: 2.0430, Training Accuracy: 0.9862, Validation Accuracy: 0.7978\n",
      "Epoch [446/500], Training Loss: 0.0448, Validation Loss: 2.0122, Training Accuracy: 0.9838, Validation Accuracy: 0.7978\n",
      "Epoch [447/500], Training Loss: 0.0485, Validation Loss: 1.9934, Training Accuracy: 0.9862, Validation Accuracy: 0.7753\n",
      "Epoch [448/500], Training Loss: 0.0508, Validation Loss: 2.0544, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [449/500], Training Loss: 0.0380, Validation Loss: 2.1418, Training Accuracy: 0.9850, Validation Accuracy: 0.7865\n",
      "Epoch [450/500], Training Loss: 0.0461, Validation Loss: 2.1083, Training Accuracy: 0.9812, Validation Accuracy: 0.7640\n",
      "Epoch [451/500], Training Loss: 0.0479, Validation Loss: 2.0519, Training Accuracy: 0.9838, Validation Accuracy: 0.7865\n",
      "Epoch [452/500], Training Loss: 0.0337, Validation Loss: 2.0552, Training Accuracy: 0.9875, Validation Accuracy: 0.7640\n",
      "Epoch [453/500], Training Loss: 0.0811, Validation Loss: 2.0148, Training Accuracy: 0.9762, Validation Accuracy: 0.7753\n",
      "Epoch [454/500], Training Loss: 0.0735, Validation Loss: 1.9730, Training Accuracy: 0.9775, Validation Accuracy: 0.7865\n",
      "Epoch [455/500], Training Loss: 0.0543, Validation Loss: 1.9478, Training Accuracy: 0.9838, Validation Accuracy: 0.7640\n",
      "Epoch [456/500], Training Loss: 0.0417, Validation Loss: 2.0907, Training Accuracy: 0.9862, Validation Accuracy: 0.7865\n",
      "Epoch [457/500], Training Loss: 0.0514, Validation Loss: 2.0806, Training Accuracy: 0.9775, Validation Accuracy: 0.7753\n",
      "Epoch [458/500], Training Loss: 0.0350, Validation Loss: 2.1004, Training Accuracy: 0.9862, Validation Accuracy: 0.7978\n",
      "Epoch [459/500], Training Loss: 0.0423, Validation Loss: 2.1843, Training Accuracy: 0.9875, Validation Accuracy: 0.7753\n",
      "Epoch [460/500], Training Loss: 0.0668, Validation Loss: 2.2484, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [461/500], Training Loss: 0.0529, Validation Loss: 2.1902, Training Accuracy: 0.9838, Validation Accuracy: 0.7528\n",
      "Epoch [462/500], Training Loss: 0.0451, Validation Loss: 2.2153, Training Accuracy: 0.9875, Validation Accuracy: 0.7865\n",
      "Epoch [463/500], Training Loss: 0.0475, Validation Loss: 2.1981, Training Accuracy: 0.9850, Validation Accuracy: 0.7865\n",
      "Epoch [464/500], Training Loss: 0.0514, Validation Loss: 2.1053, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Epoch [465/500], Training Loss: 0.0673, Validation Loss: 1.9121, Training Accuracy: 0.9800, Validation Accuracy: 0.8202\n",
      "Epoch [466/500], Training Loss: 0.0667, Validation Loss: 1.9926, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [467/500], Training Loss: 0.0508, Validation Loss: 2.0256, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [468/500], Training Loss: 0.0303, Validation Loss: 1.9652, Training Accuracy: 0.9888, Validation Accuracy: 0.8090\n",
      "Epoch [469/500], Training Loss: 0.0367, Validation Loss: 2.0830, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Epoch [470/500], Training Loss: 0.0470, Validation Loss: 2.0949, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Epoch [471/500], Training Loss: 0.0483, Validation Loss: 2.0230, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [472/500], Training Loss: 0.0331, Validation Loss: 1.9799, Training Accuracy: 0.9888, Validation Accuracy: 0.7978\n",
      "Epoch [473/500], Training Loss: 0.0397, Validation Loss: 2.0261, Training Accuracy: 0.9900, Validation Accuracy: 0.7978\n",
      "Epoch [474/500], Training Loss: 0.0410, Validation Loss: 2.1029, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Epoch [475/500], Training Loss: 0.0306, Validation Loss: 2.1569, Training Accuracy: 0.9875, Validation Accuracy: 0.8202\n",
      "Epoch [476/500], Training Loss: 0.0450, Validation Loss: 2.1626, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Epoch [477/500], Training Loss: 0.0473, Validation Loss: 2.1731, Training Accuracy: 0.9825, Validation Accuracy: 0.7865\n",
      "Epoch [478/500], Training Loss: 0.0533, Validation Loss: 2.1268, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [479/500], Training Loss: 0.0450, Validation Loss: 2.0860, Training Accuracy: 0.9875, Validation Accuracy: 0.7865\n",
      "Epoch [480/500], Training Loss: 0.0668, Validation Loss: 2.1003, Training Accuracy: 0.9788, Validation Accuracy: 0.7640\n",
      "Epoch [481/500], Training Loss: 0.0478, Validation Loss: 2.0429, Training Accuracy: 0.9862, Validation Accuracy: 0.7753\n",
      "Epoch [482/500], Training Loss: 0.0513, Validation Loss: 2.0317, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [483/500], Training Loss: 0.0296, Validation Loss: 2.0920, Training Accuracy: 0.9888, Validation Accuracy: 0.7640\n",
      "Epoch [484/500], Training Loss: 0.0523, Validation Loss: 2.0572, Training Accuracy: 0.9825, Validation Accuracy: 0.7753\n",
      "Epoch [485/500], Training Loss: 0.0481, Validation Loss: 2.1181, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [486/500], Training Loss: 0.0289, Validation Loss: 2.1364, Training Accuracy: 0.9912, Validation Accuracy: 0.7865\n",
      "Epoch [487/500], Training Loss: 0.0542, Validation Loss: 2.1530, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [488/500], Training Loss: 0.0429, Validation Loss: 2.2120, Training Accuracy: 0.9838, Validation Accuracy: 0.7865\n",
      "Epoch [489/500], Training Loss: 0.0511, Validation Loss: 2.1465, Training Accuracy: 0.9850, Validation Accuracy: 0.7865\n",
      "Epoch [490/500], Training Loss: 0.0644, Validation Loss: 2.0831, Training Accuracy: 0.9712, Validation Accuracy: 0.7640\n",
      "Epoch [491/500], Training Loss: 0.0555, Validation Loss: 2.0500, Training Accuracy: 0.9800, Validation Accuracy: 0.7640\n",
      "Epoch [492/500], Training Loss: 0.0328, Validation Loss: 2.0433, Training Accuracy: 0.9850, Validation Accuracy: 0.7753\n",
      "Epoch [493/500], Training Loss: 0.0491, Validation Loss: 2.0766, Training Accuracy: 0.9775, Validation Accuracy: 0.7865\n",
      "Epoch [494/500], Training Loss: 0.0461, Validation Loss: 2.1430, Training Accuracy: 0.9812, Validation Accuracy: 0.7640\n",
      "Epoch [495/500], Training Loss: 0.0519, Validation Loss: 2.0912, Training Accuracy: 0.9825, Validation Accuracy: 0.7753\n",
      "Epoch [496/500], Training Loss: 0.0590, Validation Loss: 1.9695, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [497/500], Training Loss: 0.0233, Validation Loss: 2.0229, Training Accuracy: 0.9912, Validation Accuracy: 0.8090\n",
      "Epoch [498/500], Training Loss: 0.0543, Validation Loss: 2.1773, Training Accuracy: 0.9800, Validation Accuracy: 0.8090\n",
      "Epoch [499/500], Training Loss: 0.0525, Validation Loss: 2.2515, Training Accuracy: 0.9875, Validation Accuracy: 0.7978\n",
      "Epoch [500/500], Training Loss: 0.0384, Validation Loss: 2.2487, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Training Time: 6.85 seconds\n",
      "Test Loss: 0.7229, Testing Accuracy: 0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/v5ysl19s0hbdkdprhb3xqd4r0000gn/T/ipykernel_34536/1268722804.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_weights.pth'))\n"
     ]
    }
   ],
   "source": [
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=20, verbose=True)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = loss_function(outputs, labels.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "        predicted = torch.round(outputs)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    train_losses.append(training_loss / len(train_loader))\n",
    "    train_accuracies.append(correct_predictions / total_predictions)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_outputs = model(val_inputs).squeeze()\n",
    "            val_loss += loss_function(val_outputs, val_labels.float()).item()\n",
    "            predicted = torch.round(val_outputs)\n",
    "            val_correct_predictions += (predicted == val_labels).sum().item()\n",
    "            val_total_predictions += val_labels.size(0)\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(val_correct_predictions / val_total_predictions)\n",
    "\n",
    "    average_training_loss = training_loss / len(train_loader)\n",
    "    average_validation_loss = val_loss / len(val_loader)\n",
    "    training_accuracy = correct_predictions / total_predictions\n",
    "    validation_accuracy = val_correct_predictions / val_total_predictions\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Training Loss: {average_training_loss:.4f}, '\n",
    "          f'Validation Loss: {average_validation_loss:.4f}, '\n",
    "          f'Training Accuracy: {training_accuracy:.4f}, '\n",
    "          f'Validation Accuracy: {validation_accuracy:.4f}')\n",
    "\n",
    "    if average_validation_loss < best_val_loss:\n",
    "        best_val_loss = average_validation_loss\n",
    "        torch.save(model.state_dict(), 'best_model_weights.pth')\n",
    "\n",
    "    scheduler.step(validation_accuracy)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Training Time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_weights.pth'))\n",
    "\n",
    "# Testing the model\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct_predictions = 0\n",
    "test_total_predictions = 0\n",
    "\n",
    "confusion_predictions = []\n",
    "confusion_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_outputs = model(test_inputs).squeeze()\n",
    "        test_loss += loss_function(test_outputs, test_labels.float()).item()\n",
    "        \n",
    "        predicted = torch.round(test_outputs)\n",
    "        test_correct_predictions += (predicted == test_labels.float()).sum().item()\n",
    "        test_total_predictions += test_labels.size(0)\n",
    "    \n",
    "       \n",
    "        confusion_predictions.extend(predicted.cpu().numpy())\n",
    "        confusion_labels.extend(test_labels.cpu().numpy())\n",
    "\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_accuracies.append(test_correct_predictions / test_total_predictions)\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = test_correct_predictions / test_total_predictions\n",
    "\n",
    "print(f'Test Loss: {avg_test_loss:.4f}, '\n",
    "      f'Testing Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(train_accuracies) + 1)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training, Validation, and Test Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing Gradient Accumulation method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 0.2685, Validation Loss: 0.4622, Training Accuracy: 0.8862, Validation Accuracy: 0.7978\n",
      "Epoch [2/500], Training Loss: 0.2440, Validation Loss: 0.4899, Training Accuracy: 0.9038, Validation Accuracy: 0.7865\n",
      "Epoch [3/500], Training Loss: 0.2382, Validation Loss: 0.5130, Training Accuracy: 0.9012, Validation Accuracy: 0.7978\n",
      "Epoch [4/500], Training Loss: 0.2429, Validation Loss: 0.5126, Training Accuracy: 0.8900, Validation Accuracy: 0.7978\n",
      "Epoch [5/500], Training Loss: 0.2399, Validation Loss: 0.5095, Training Accuracy: 0.8962, Validation Accuracy: 0.7978\n",
      "Epoch [6/500], Training Loss: 0.2428, Validation Loss: 0.5096, Training Accuracy: 0.9038, Validation Accuracy: 0.7978\n",
      "Epoch [7/500], Training Loss: 0.2715, Validation Loss: 0.4900, Training Accuracy: 0.8875, Validation Accuracy: 0.7865\n",
      "Epoch [8/500], Training Loss: 0.2453, Validation Loss: 0.4832, Training Accuracy: 0.8862, Validation Accuracy: 0.7753\n",
      "Epoch [9/500], Training Loss: 0.2425, Validation Loss: 0.4964, Training Accuracy: 0.9038, Validation Accuracy: 0.7753\n",
      "Epoch [10/500], Training Loss: 0.2399, Validation Loss: 0.5166, Training Accuracy: 0.8938, Validation Accuracy: 0.7978\n",
      "Epoch [11/500], Training Loss: 0.2475, Validation Loss: 0.5349, Training Accuracy: 0.8938, Validation Accuracy: 0.8090\n",
      "Epoch [12/500], Training Loss: 0.2385, Validation Loss: 0.5318, Training Accuracy: 0.9062, Validation Accuracy: 0.8090\n",
      "Epoch [13/500], Training Loss: 0.2370, Validation Loss: 0.5154, Training Accuracy: 0.9062, Validation Accuracy: 0.7978\n",
      "Epoch [14/500], Training Loss: 0.2445, Validation Loss: 0.5150, Training Accuracy: 0.8950, Validation Accuracy: 0.7865\n",
      "Epoch [15/500], Training Loss: 0.2545, Validation Loss: 0.5152, Training Accuracy: 0.8975, Validation Accuracy: 0.7978\n",
      "Epoch [16/500], Training Loss: 0.2225, Validation Loss: 0.5292, Training Accuracy: 0.9050, Validation Accuracy: 0.8090\n",
      "Epoch [17/500], Training Loss: 0.2140, Validation Loss: 0.5389, Training Accuracy: 0.9175, Validation Accuracy: 0.7865\n",
      "Epoch [18/500], Training Loss: 0.2456, Validation Loss: 0.5489, Training Accuracy: 0.8825, Validation Accuracy: 0.7978\n",
      "Epoch [19/500], Training Loss: 0.2108, Validation Loss: 0.5455, Training Accuracy: 0.9163, Validation Accuracy: 0.7978\n",
      "Epoch [20/500], Training Loss: 0.2068, Validation Loss: 0.5458, Training Accuracy: 0.9075, Validation Accuracy: 0.8202\n",
      "Epoch [21/500], Training Loss: 0.2342, Validation Loss: 0.5516, Training Accuracy: 0.9025, Validation Accuracy: 0.7753\n",
      "Epoch [22/500], Training Loss: 0.2038, Validation Loss: 0.5597, Training Accuracy: 0.9163, Validation Accuracy: 0.7753\n",
      "Epoch [23/500], Training Loss: 0.2262, Validation Loss: 0.5411, Training Accuracy: 0.9075, Validation Accuracy: 0.7753\n",
      "Epoch [24/500], Training Loss: 0.2306, Validation Loss: 0.5300, Training Accuracy: 0.9075, Validation Accuracy: 0.7978\n",
      "Epoch [25/500], Training Loss: 0.2146, Validation Loss: 0.5352, Training Accuracy: 0.9050, Validation Accuracy: 0.7753\n",
      "Epoch [26/500], Training Loss: 0.2421, Validation Loss: 0.5501, Training Accuracy: 0.9050, Validation Accuracy: 0.7640\n",
      "Epoch [27/500], Training Loss: 0.2176, Validation Loss: 0.5476, Training Accuracy: 0.9038, Validation Accuracy: 0.7640\n",
      "Epoch [28/500], Training Loss: 0.2246, Validation Loss: 0.5515, Training Accuracy: 0.9087, Validation Accuracy: 0.7753\n",
      "Epoch [29/500], Training Loss: 0.2522, Validation Loss: 0.5454, Training Accuracy: 0.8862, Validation Accuracy: 0.7753\n",
      "Epoch [30/500], Training Loss: 0.2448, Validation Loss: 0.5474, Training Accuracy: 0.8988, Validation Accuracy: 0.7640\n",
      "Epoch [31/500], Training Loss: 0.2105, Validation Loss: 0.5637, Training Accuracy: 0.9175, Validation Accuracy: 0.7753\n",
      "Epoch [32/500], Training Loss: 0.2241, Validation Loss: 0.5651, Training Accuracy: 0.8988, Validation Accuracy: 0.7640\n",
      "Epoch [33/500], Training Loss: 0.1862, Validation Loss: 0.5637, Training Accuracy: 0.9187, Validation Accuracy: 0.7640\n",
      "Epoch [34/500], Training Loss: 0.2203, Validation Loss: 0.5676, Training Accuracy: 0.9137, Validation Accuracy: 0.7753\n",
      "Epoch [35/500], Training Loss: 0.1988, Validation Loss: 0.5691, Training Accuracy: 0.9137, Validation Accuracy: 0.7865\n",
      "Epoch [36/500], Training Loss: 0.2135, Validation Loss: 0.5648, Training Accuracy: 0.9137, Validation Accuracy: 0.8090\n",
      "Epoch [37/500], Training Loss: 0.2020, Validation Loss: 0.5978, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [38/500], Training Loss: 0.2116, Validation Loss: 0.5942, Training Accuracy: 0.9137, Validation Accuracy: 0.8090\n",
      "Epoch [39/500], Training Loss: 0.1816, Validation Loss: 0.5800, Training Accuracy: 0.9137, Validation Accuracy: 0.7978\n",
      "Epoch [40/500], Training Loss: 0.2150, Validation Loss: 0.6109, Training Accuracy: 0.9025, Validation Accuracy: 0.8090\n",
      "Epoch [41/500], Training Loss: 0.1974, Validation Loss: 0.6264, Training Accuracy: 0.9225, Validation Accuracy: 0.7978\n",
      "Epoch [42/500], Training Loss: 0.1921, Validation Loss: 0.6420, Training Accuracy: 0.9175, Validation Accuracy: 0.7978\n",
      "Epoch [43/500], Training Loss: 0.2159, Validation Loss: 0.6259, Training Accuracy: 0.9087, Validation Accuracy: 0.7978\n",
      "Epoch [44/500], Training Loss: 0.2023, Validation Loss: 0.6054, Training Accuracy: 0.9137, Validation Accuracy: 0.7865\n",
      "Epoch [45/500], Training Loss: 0.2173, Validation Loss: 0.6118, Training Accuracy: 0.9050, Validation Accuracy: 0.7978\n",
      "Epoch [46/500], Training Loss: 0.2001, Validation Loss: 0.6231, Training Accuracy: 0.9187, Validation Accuracy: 0.7865\n",
      "Epoch [47/500], Training Loss: 0.2333, Validation Loss: 0.6029, Training Accuracy: 0.9038, Validation Accuracy: 0.8090\n",
      "Epoch [48/500], Training Loss: 0.2000, Validation Loss: 0.5957, Training Accuracy: 0.9225, Validation Accuracy: 0.7865\n",
      "Epoch [49/500], Training Loss: 0.1939, Validation Loss: 0.5762, Training Accuracy: 0.9163, Validation Accuracy: 0.7865\n",
      "Epoch [50/500], Training Loss: 0.2000, Validation Loss: 0.5590, Training Accuracy: 0.9287, Validation Accuracy: 0.8202\n",
      "Epoch [51/500], Training Loss: 0.2084, Validation Loss: 0.5722, Training Accuracy: 0.9150, Validation Accuracy: 0.8202\n",
      "Epoch [52/500], Training Loss: 0.2035, Validation Loss: 0.5689, Training Accuracy: 0.9200, Validation Accuracy: 0.8315\n",
      "Epoch [53/500], Training Loss: 0.2035, Validation Loss: 0.5701, Training Accuracy: 0.9187, Validation Accuracy: 0.8315\n",
      "Epoch [54/500], Training Loss: 0.2122, Validation Loss: 0.5685, Training Accuracy: 0.9000, Validation Accuracy: 0.7978\n",
      "Epoch [55/500], Training Loss: 0.1973, Validation Loss: 0.5826, Training Accuracy: 0.9250, Validation Accuracy: 0.8090\n",
      "Epoch [56/500], Training Loss: 0.2003, Validation Loss: 0.5845, Training Accuracy: 0.9087, Validation Accuracy: 0.7865\n",
      "Epoch [57/500], Training Loss: 0.2108, Validation Loss: 0.5658, Training Accuracy: 0.9050, Validation Accuracy: 0.8090\n",
      "Epoch [58/500], Training Loss: 0.1995, Validation Loss: 0.5661, Training Accuracy: 0.9213, Validation Accuracy: 0.8090\n",
      "Epoch [59/500], Training Loss: 0.1923, Validation Loss: 0.5659, Training Accuracy: 0.9313, Validation Accuracy: 0.8315\n",
      "Epoch [60/500], Training Loss: 0.2087, Validation Loss: 0.5940, Training Accuracy: 0.9113, Validation Accuracy: 0.7978\n",
      "Epoch [61/500], Training Loss: 0.2058, Validation Loss: 0.6157, Training Accuracy: 0.9187, Validation Accuracy: 0.7978\n",
      "Epoch [62/500], Training Loss: 0.2173, Validation Loss: 0.5842, Training Accuracy: 0.9150, Validation Accuracy: 0.8090\n",
      "Epoch [63/500], Training Loss: 0.1954, Validation Loss: 0.5617, Training Accuracy: 0.9113, Validation Accuracy: 0.8090\n",
      "Epoch [64/500], Training Loss: 0.2017, Validation Loss: 0.5672, Training Accuracy: 0.9163, Validation Accuracy: 0.8090\n",
      "Epoch [65/500], Training Loss: 0.1975, Validation Loss: 0.5894, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [66/500], Training Loss: 0.2041, Validation Loss: 0.5897, Training Accuracy: 0.9213, Validation Accuracy: 0.7978\n",
      "Epoch [67/500], Training Loss: 0.2001, Validation Loss: 0.6016, Training Accuracy: 0.9137, Validation Accuracy: 0.8090\n",
      "Epoch [68/500], Training Loss: 0.2060, Validation Loss: 0.6067, Training Accuracy: 0.9062, Validation Accuracy: 0.8090\n",
      "Epoch [69/500], Training Loss: 0.1832, Validation Loss: 0.6158, Training Accuracy: 0.9237, Validation Accuracy: 0.7978\n",
      "Epoch [70/500], Training Loss: 0.1826, Validation Loss: 0.6186, Training Accuracy: 0.9250, Validation Accuracy: 0.8090\n",
      "Epoch [71/500], Training Loss: 0.1811, Validation Loss: 0.6202, Training Accuracy: 0.9250, Validation Accuracy: 0.7978\n",
      "Epoch [72/500], Training Loss: 0.1969, Validation Loss: 0.6189, Training Accuracy: 0.9237, Validation Accuracy: 0.7978\n",
      "Epoch [73/500], Training Loss: 0.1730, Validation Loss: 0.6067, Training Accuracy: 0.9300, Validation Accuracy: 0.8202\n",
      "Epoch [74/500], Training Loss: 0.1934, Validation Loss: 0.6113, Training Accuracy: 0.9287, Validation Accuracy: 0.7865\n",
      "Epoch [75/500], Training Loss: 0.1953, Validation Loss: 0.6152, Training Accuracy: 0.9225, Validation Accuracy: 0.7978\n",
      "Epoch [76/500], Training Loss: 0.1895, Validation Loss: 0.6102, Training Accuracy: 0.9250, Validation Accuracy: 0.7978\n",
      "Epoch [77/500], Training Loss: 0.1947, Validation Loss: 0.5920, Training Accuracy: 0.9287, Validation Accuracy: 0.7978\n",
      "Epoch [78/500], Training Loss: 0.1892, Validation Loss: 0.5811, Training Accuracy: 0.9313, Validation Accuracy: 0.8090\n",
      "Epoch [79/500], Training Loss: 0.1824, Validation Loss: 0.5787, Training Accuracy: 0.9237, Validation Accuracy: 0.8090\n",
      "Epoch [80/500], Training Loss: 0.1753, Validation Loss: 0.5711, Training Accuracy: 0.9287, Validation Accuracy: 0.8202\n",
      "Epoch [81/500], Training Loss: 0.1753, Validation Loss: 0.5634, Training Accuracy: 0.9325, Validation Accuracy: 0.8202\n",
      "Epoch [82/500], Training Loss: 0.1721, Validation Loss: 0.5764, Training Accuracy: 0.9400, Validation Accuracy: 0.7753\n",
      "Epoch [83/500], Training Loss: 0.1895, Validation Loss: 0.5750, Training Accuracy: 0.9225, Validation Accuracy: 0.7865\n",
      "Epoch [84/500], Training Loss: 0.1602, Validation Loss: 0.5707, Training Accuracy: 0.9375, Validation Accuracy: 0.7978\n",
      "Epoch [85/500], Training Loss: 0.1993, Validation Loss: 0.5740, Training Accuracy: 0.9275, Validation Accuracy: 0.7978\n",
      "Epoch [86/500], Training Loss: 0.1765, Validation Loss: 0.5765, Training Accuracy: 0.9263, Validation Accuracy: 0.8090\n",
      "Epoch [87/500], Training Loss: 0.1649, Validation Loss: 0.5828, Training Accuracy: 0.9375, Validation Accuracy: 0.8315\n",
      "Epoch [88/500], Training Loss: 0.1768, Validation Loss: 0.5891, Training Accuracy: 0.9313, Validation Accuracy: 0.8090\n",
      "Epoch [89/500], Training Loss: 0.1813, Validation Loss: 0.6118, Training Accuracy: 0.9350, Validation Accuracy: 0.7978\n",
      "Epoch [90/500], Training Loss: 0.1941, Validation Loss: 0.6111, Training Accuracy: 0.9175, Validation Accuracy: 0.8090\n",
      "Epoch [91/500], Training Loss: 0.1561, Validation Loss: 0.6133, Training Accuracy: 0.9337, Validation Accuracy: 0.8090\n",
      "Epoch [92/500], Training Loss: 0.1944, Validation Loss: 0.6199, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [93/500], Training Loss: 0.1633, Validation Loss: 0.6271, Training Accuracy: 0.9387, Validation Accuracy: 0.8090\n",
      "Epoch [94/500], Training Loss: 0.1743, Validation Loss: 0.6240, Training Accuracy: 0.9287, Validation Accuracy: 0.8202\n",
      "Epoch [95/500], Training Loss: 0.2022, Validation Loss: 0.6106, Training Accuracy: 0.9237, Validation Accuracy: 0.8202\n",
      "Epoch [96/500], Training Loss: 0.1794, Validation Loss: 0.6015, Training Accuracy: 0.9287, Validation Accuracy: 0.8090\n",
      "Epoch [97/500], Training Loss: 0.1699, Validation Loss: 0.6225, Training Accuracy: 0.9387, Validation Accuracy: 0.7978\n",
      "Epoch [98/500], Training Loss: 0.1963, Validation Loss: 0.6309, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [99/500], Training Loss: 0.1574, Validation Loss: 0.6233, Training Accuracy: 0.9425, Validation Accuracy: 0.8090\n",
      "Epoch [100/500], Training Loss: 0.1597, Validation Loss: 0.6375, Training Accuracy: 0.9375, Validation Accuracy: 0.8202\n",
      "Epoch [101/500], Training Loss: 0.1724, Validation Loss: 0.6490, Training Accuracy: 0.9337, Validation Accuracy: 0.7978\n",
      "Epoch [102/500], Training Loss: 0.1621, Validation Loss: 0.6561, Training Accuracy: 0.9287, Validation Accuracy: 0.7978\n",
      "Epoch [103/500], Training Loss: 0.1656, Validation Loss: 0.6335, Training Accuracy: 0.9287, Validation Accuracy: 0.7978\n",
      "Epoch [104/500], Training Loss: 0.1480, Validation Loss: 0.6236, Training Accuracy: 0.9475, Validation Accuracy: 0.7978\n",
      "Epoch [105/500], Training Loss: 0.1568, Validation Loss: 0.6281, Training Accuracy: 0.9387, Validation Accuracy: 0.8315\n",
      "Epoch [106/500], Training Loss: 0.1828, Validation Loss: 0.6291, Training Accuracy: 0.9250, Validation Accuracy: 0.8090\n",
      "Epoch [107/500], Training Loss: 0.1774, Validation Loss: 0.6459, Training Accuracy: 0.9337, Validation Accuracy: 0.8090\n",
      "Epoch [108/500], Training Loss: 0.1871, Validation Loss: 0.6594, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [109/500], Training Loss: 0.1554, Validation Loss: 0.6390, Training Accuracy: 0.9313, Validation Accuracy: 0.7640\n",
      "Epoch [110/500], Training Loss: 0.1908, Validation Loss: 0.6401, Training Accuracy: 0.9163, Validation Accuracy: 0.7640\n",
      "Epoch [111/500], Training Loss: 0.1666, Validation Loss: 0.6119, Training Accuracy: 0.9225, Validation Accuracy: 0.7865\n",
      "Epoch [112/500], Training Loss: 0.1748, Validation Loss: 0.6110, Training Accuracy: 0.9300, Validation Accuracy: 0.7978\n",
      "Epoch [113/500], Training Loss: 0.1370, Validation Loss: 0.6106, Training Accuracy: 0.9487, Validation Accuracy: 0.8202\n",
      "Epoch [114/500], Training Loss: 0.1693, Validation Loss: 0.6278, Training Accuracy: 0.9263, Validation Accuracy: 0.8090\n",
      "Epoch [115/500], Training Loss: 0.1675, Validation Loss: 0.6428, Training Accuracy: 0.9375, Validation Accuracy: 0.7865\n",
      "Epoch [116/500], Training Loss: 0.1678, Validation Loss: 0.6290, Training Accuracy: 0.9313, Validation Accuracy: 0.7753\n",
      "Epoch [117/500], Training Loss: 0.1620, Validation Loss: 0.6325, Training Accuracy: 0.9387, Validation Accuracy: 0.7865\n",
      "Epoch [118/500], Training Loss: 0.1730, Validation Loss: 0.6551, Training Accuracy: 0.9275, Validation Accuracy: 0.7978\n",
      "Epoch [119/500], Training Loss: 0.1711, Validation Loss: 0.6454, Training Accuracy: 0.9300, Validation Accuracy: 0.7978\n",
      "Epoch [120/500], Training Loss: 0.1614, Validation Loss: 0.6396, Training Accuracy: 0.9387, Validation Accuracy: 0.8090\n",
      "Epoch [121/500], Training Loss: 0.1582, Validation Loss: 0.6202, Training Accuracy: 0.9350, Validation Accuracy: 0.7978\n",
      "Epoch [122/500], Training Loss: 0.1587, Validation Loss: 0.5998, Training Accuracy: 0.9325, Validation Accuracy: 0.8090\n",
      "Epoch [123/500], Training Loss: 0.1478, Validation Loss: 0.6289, Training Accuracy: 0.9487, Validation Accuracy: 0.7978\n",
      "Epoch [124/500], Training Loss: 0.1469, Validation Loss: 0.6598, Training Accuracy: 0.9413, Validation Accuracy: 0.8315\n",
      "Epoch [125/500], Training Loss: 0.1603, Validation Loss: 0.6647, Training Accuracy: 0.9413, Validation Accuracy: 0.8315\n",
      "Epoch [126/500], Training Loss: 0.1500, Validation Loss: 0.6711, Training Accuracy: 0.9387, Validation Accuracy: 0.7978\n",
      "Epoch [127/500], Training Loss: 0.1710, Validation Loss: 0.6922, Training Accuracy: 0.9300, Validation Accuracy: 0.7865\n",
      "Epoch [128/500], Training Loss: 0.1646, Validation Loss: 0.6849, Training Accuracy: 0.9375, Validation Accuracy: 0.8090\n",
      "Epoch [129/500], Training Loss: 0.1829, Validation Loss: 0.6466, Training Accuracy: 0.9287, Validation Accuracy: 0.7753\n",
      "Epoch [130/500], Training Loss: 0.1528, Validation Loss: 0.6394, Training Accuracy: 0.9400, Validation Accuracy: 0.7753\n",
      "Epoch [131/500], Training Loss: 0.1585, Validation Loss: 0.6478, Training Accuracy: 0.9325, Validation Accuracy: 0.7865\n",
      "Epoch [132/500], Training Loss: 0.1438, Validation Loss: 0.6811, Training Accuracy: 0.9437, Validation Accuracy: 0.7865\n",
      "Epoch [133/500], Training Loss: 0.1524, Validation Loss: 0.6707, Training Accuracy: 0.9387, Validation Accuracy: 0.7753\n",
      "Epoch [134/500], Training Loss: 0.1294, Validation Loss: 0.6794, Training Accuracy: 0.9475, Validation Accuracy: 0.7640\n",
      "Epoch [135/500], Training Loss: 0.1442, Validation Loss: 0.7125, Training Accuracy: 0.9375, Validation Accuracy: 0.7753\n",
      "Epoch [136/500], Training Loss: 0.1463, Validation Loss: 0.7230, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [137/500], Training Loss: 0.1870, Validation Loss: 0.6779, Training Accuracy: 0.9325, Validation Accuracy: 0.8090\n",
      "Epoch [138/500], Training Loss: 0.1580, Validation Loss: 0.6649, Training Accuracy: 0.9437, Validation Accuracy: 0.7865\n",
      "Epoch [139/500], Training Loss: 0.1314, Validation Loss: 0.6685, Training Accuracy: 0.9475, Validation Accuracy: 0.7978\n",
      "Epoch [140/500], Training Loss: 0.1704, Validation Loss: 0.6743, Training Accuracy: 0.9375, Validation Accuracy: 0.7978\n",
      "Epoch [141/500], Training Loss: 0.1509, Validation Loss: 0.6790, Training Accuracy: 0.9400, Validation Accuracy: 0.7978\n",
      "Epoch [142/500], Training Loss: 0.1500, Validation Loss: 0.6707, Training Accuracy: 0.9387, Validation Accuracy: 0.7978\n",
      "Epoch [143/500], Training Loss: 0.1305, Validation Loss: 0.7041, Training Accuracy: 0.9450, Validation Accuracy: 0.7978\n",
      "Epoch [144/500], Training Loss: 0.1400, Validation Loss: 0.7121, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [145/500], Training Loss: 0.1252, Validation Loss: 0.6876, Training Accuracy: 0.9475, Validation Accuracy: 0.8090\n",
      "Epoch [146/500], Training Loss: 0.1531, Validation Loss: 0.6783, Training Accuracy: 0.9425, Validation Accuracy: 0.8090\n",
      "Epoch [147/500], Training Loss: 0.1570, Validation Loss: 0.6833, Training Accuracy: 0.9500, Validation Accuracy: 0.8090\n",
      "Epoch [148/500], Training Loss: 0.1534, Validation Loss: 0.6724, Training Accuracy: 0.9275, Validation Accuracy: 0.8090\n",
      "Epoch [149/500], Training Loss: 0.1415, Validation Loss: 0.6588, Training Accuracy: 0.9375, Validation Accuracy: 0.8315\n",
      "Epoch [150/500], Training Loss: 0.1547, Validation Loss: 0.6703, Training Accuracy: 0.9413, Validation Accuracy: 0.8090\n",
      "Epoch [151/500], Training Loss: 0.1478, Validation Loss: 0.6730, Training Accuracy: 0.9437, Validation Accuracy: 0.7978\n",
      "Epoch [152/500], Training Loss: 0.1371, Validation Loss: 0.6956, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [153/500], Training Loss: 0.1623, Validation Loss: 0.6890, Training Accuracy: 0.9425, Validation Accuracy: 0.7865\n",
      "Epoch [154/500], Training Loss: 0.1474, Validation Loss: 0.6724, Training Accuracy: 0.9500, Validation Accuracy: 0.7753\n",
      "Epoch [155/500], Training Loss: 0.1438, Validation Loss: 0.6747, Training Accuracy: 0.9537, Validation Accuracy: 0.7978\n",
      "Epoch [156/500], Training Loss: 0.1529, Validation Loss: 0.6810, Training Accuracy: 0.9450, Validation Accuracy: 0.7865\n",
      "Epoch [157/500], Training Loss: 0.1449, Validation Loss: 0.6891, Training Accuracy: 0.9425, Validation Accuracy: 0.8315\n",
      "Epoch [158/500], Training Loss: 0.1423, Validation Loss: 0.6985, Training Accuracy: 0.9387, Validation Accuracy: 0.8315\n",
      "Epoch [159/500], Training Loss: 0.1517, Validation Loss: 0.6805, Training Accuracy: 0.9500, Validation Accuracy: 0.8090\n",
      "Epoch [160/500], Training Loss: 0.1620, Validation Loss: 0.6814, Training Accuracy: 0.9287, Validation Accuracy: 0.7978\n",
      "Epoch [161/500], Training Loss: 0.1372, Validation Loss: 0.7096, Training Accuracy: 0.9525, Validation Accuracy: 0.8090\n",
      "Epoch [162/500], Training Loss: 0.1677, Validation Loss: 0.6888, Training Accuracy: 0.9375, Validation Accuracy: 0.8090\n",
      "Epoch [163/500], Training Loss: 0.1419, Validation Loss: 0.6591, Training Accuracy: 0.9450, Validation Accuracy: 0.8202\n",
      "Epoch [164/500], Training Loss: 0.1595, Validation Loss: 0.6435, Training Accuracy: 0.9437, Validation Accuracy: 0.8202\n",
      "Epoch [165/500], Training Loss: 0.1471, Validation Loss: 0.6556, Training Accuracy: 0.9463, Validation Accuracy: 0.8090\n",
      "Epoch [166/500], Training Loss: 0.1613, Validation Loss: 0.6749, Training Accuracy: 0.9413, Validation Accuracy: 0.7978\n",
      "Epoch [167/500], Training Loss: 0.1339, Validation Loss: 0.7078, Training Accuracy: 0.9513, Validation Accuracy: 0.8090\n",
      "Epoch [168/500], Training Loss: 0.1520, Validation Loss: 0.6796, Training Accuracy: 0.9463, Validation Accuracy: 0.7753\n",
      "Epoch [169/500], Training Loss: 0.1246, Validation Loss: 0.6706, Training Accuracy: 0.9563, Validation Accuracy: 0.7865\n",
      "Epoch [170/500], Training Loss: 0.1460, Validation Loss: 0.7132, Training Accuracy: 0.9425, Validation Accuracy: 0.7978\n",
      "Epoch [171/500], Training Loss: 0.1584, Validation Loss: 0.6751, Training Accuracy: 0.9350, Validation Accuracy: 0.7978\n",
      "Epoch [172/500], Training Loss: 0.1451, Validation Loss: 0.6382, Training Accuracy: 0.9400, Validation Accuracy: 0.7865\n",
      "Epoch [173/500], Training Loss: 0.1633, Validation Loss: 0.6707, Training Accuracy: 0.9425, Validation Accuracy: 0.7865\n",
      "Epoch [174/500], Training Loss: 0.1448, Validation Loss: 0.6821, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [175/500], Training Loss: 0.1433, Validation Loss: 0.6927, Training Accuracy: 0.9463, Validation Accuracy: 0.7865\n",
      "Epoch [176/500], Training Loss: 0.1366, Validation Loss: 0.7136, Training Accuracy: 0.9437, Validation Accuracy: 0.7978\n",
      "Epoch [177/500], Training Loss: 0.1374, Validation Loss: 0.7499, Training Accuracy: 0.9487, Validation Accuracy: 0.8090\n",
      "Epoch [178/500], Training Loss: 0.1435, Validation Loss: 0.7464, Training Accuracy: 0.9337, Validation Accuracy: 0.8090\n",
      "Epoch [179/500], Training Loss: 0.1267, Validation Loss: 0.7695, Training Accuracy: 0.9487, Validation Accuracy: 0.7978\n",
      "Epoch [180/500], Training Loss: 0.1520, Validation Loss: 0.8047, Training Accuracy: 0.9375, Validation Accuracy: 0.7753\n",
      "Epoch [181/500], Training Loss: 0.1340, Validation Loss: 0.8174, Training Accuracy: 0.9513, Validation Accuracy: 0.7978\n",
      "Epoch [182/500], Training Loss: 0.1485, Validation Loss: 0.8019, Training Accuracy: 0.9425, Validation Accuracy: 0.7865\n",
      "Epoch [183/500], Training Loss: 0.1347, Validation Loss: 0.7686, Training Accuracy: 0.9537, Validation Accuracy: 0.8090\n",
      "Epoch [184/500], Training Loss: 0.1303, Validation Loss: 1.6447, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [185/500], Training Loss: 0.1281, Validation Loss: 1.6551, Training Accuracy: 0.9550, Validation Accuracy: 0.7865\n",
      "Epoch [186/500], Training Loss: 0.1364, Validation Loss: 1.6623, Training Accuracy: 0.9550, Validation Accuracy: 0.7753\n",
      "Epoch [187/500], Training Loss: 0.1442, Validation Loss: 1.6542, Training Accuracy: 0.9400, Validation Accuracy: 0.8090\n",
      "Epoch [188/500], Training Loss: 0.1364, Validation Loss: 1.6309, Training Accuracy: 0.9450, Validation Accuracy: 0.8202\n",
      "Epoch [189/500], Training Loss: 0.1510, Validation Loss: 0.7262, Training Accuracy: 0.9425, Validation Accuracy: 0.8202\n",
      "Epoch [190/500], Training Loss: 0.1272, Validation Loss: 0.7343, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [191/500], Training Loss: 0.1237, Validation Loss: 0.7351, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [192/500], Training Loss: 0.1410, Validation Loss: 0.7225, Training Accuracy: 0.9437, Validation Accuracy: 0.8090\n",
      "Epoch [193/500], Training Loss: 0.1242, Validation Loss: 0.7607, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [194/500], Training Loss: 0.1271, Validation Loss: 0.7800, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [195/500], Training Loss: 0.1050, Validation Loss: 0.7911, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [196/500], Training Loss: 0.1210, Validation Loss: 0.8032, Training Accuracy: 0.9450, Validation Accuracy: 0.7978\n",
      "Epoch [197/500], Training Loss: 0.1147, Validation Loss: 0.8190, Training Accuracy: 0.9550, Validation Accuracy: 0.7865\n",
      "Epoch [198/500], Training Loss: 0.1419, Validation Loss: 0.8362, Training Accuracy: 0.9437, Validation Accuracy: 0.7753\n",
      "Epoch [199/500], Training Loss: 0.1320, Validation Loss: 0.8306, Training Accuracy: 0.9437, Validation Accuracy: 0.7753\n",
      "Epoch [200/500], Training Loss: 0.1225, Validation Loss: 0.8009, Training Accuracy: 0.9537, Validation Accuracy: 0.7753\n",
      "Epoch [201/500], Training Loss: 0.1177, Validation Loss: 1.6818, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [202/500], Training Loss: 0.1253, Validation Loss: 1.6977, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [203/500], Training Loss: 0.1149, Validation Loss: 1.6920, Training Accuracy: 0.9487, Validation Accuracy: 0.8202\n",
      "Epoch [204/500], Training Loss: 0.1127, Validation Loss: 1.6708, Training Accuracy: 0.9487, Validation Accuracy: 0.8090\n",
      "Epoch [205/500], Training Loss: 0.1530, Validation Loss: 1.6688, Training Accuracy: 0.9400, Validation Accuracy: 0.7978\n",
      "Epoch [206/500], Training Loss: 0.1210, Validation Loss: 1.6576, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [207/500], Training Loss: 0.1123, Validation Loss: 1.6532, Training Accuracy: 0.9600, Validation Accuracy: 0.7753\n",
      "Epoch [208/500], Training Loss: 0.1293, Validation Loss: 1.6600, Training Accuracy: 0.9475, Validation Accuracy: 0.7865\n",
      "Epoch [209/500], Training Loss: 0.1259, Validation Loss: 1.6770, Training Accuracy: 0.9487, Validation Accuracy: 0.7865\n",
      "Epoch [210/500], Training Loss: 0.1253, Validation Loss: 1.6695, Training Accuracy: 0.9537, Validation Accuracy: 0.7640\n",
      "Epoch [211/500], Training Loss: 0.1120, Validation Loss: 1.6684, Training Accuracy: 0.9537, Validation Accuracy: 0.7640\n",
      "Epoch [212/500], Training Loss: 0.1377, Validation Loss: 1.6523, Training Accuracy: 0.9475, Validation Accuracy: 0.7978\n",
      "Epoch [213/500], Training Loss: 0.1219, Validation Loss: 1.6681, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [214/500], Training Loss: 0.1466, Validation Loss: 1.6907, Training Accuracy: 0.9475, Validation Accuracy: 0.7753\n",
      "Epoch [215/500], Training Loss: 0.1224, Validation Loss: 1.6855, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [216/500], Training Loss: 0.1290, Validation Loss: 1.7062, Training Accuracy: 0.9475, Validation Accuracy: 0.7753\n",
      "Epoch [217/500], Training Loss: 0.1385, Validation Loss: 1.7253, Training Accuracy: 0.9475, Validation Accuracy: 0.7753\n",
      "Epoch [218/500], Training Loss: 0.1159, Validation Loss: 1.7200, Training Accuracy: 0.9500, Validation Accuracy: 0.7753\n",
      "Epoch [219/500], Training Loss: 0.1209, Validation Loss: 1.6997, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [220/500], Training Loss: 0.1373, Validation Loss: 1.6923, Training Accuracy: 0.9500, Validation Accuracy: 0.7865\n",
      "Epoch [221/500], Training Loss: 0.1167, Validation Loss: 1.7153, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [222/500], Training Loss: 0.1256, Validation Loss: 1.7388, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [223/500], Training Loss: 0.1125, Validation Loss: 1.7378, Training Accuracy: 0.9563, Validation Accuracy: 0.7753\n",
      "Epoch [224/500], Training Loss: 0.1276, Validation Loss: 1.7346, Training Accuracy: 0.9537, Validation Accuracy: 0.7865\n",
      "Epoch [225/500], Training Loss: 0.0999, Validation Loss: 1.7309, Training Accuracy: 0.9587, Validation Accuracy: 0.7753\n",
      "Epoch [226/500], Training Loss: 0.1305, Validation Loss: 1.7241, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [227/500], Training Loss: 0.1288, Validation Loss: 1.7265, Training Accuracy: 0.9537, Validation Accuracy: 0.7640\n",
      "Epoch [228/500], Training Loss: 0.1348, Validation Loss: 1.7437, Training Accuracy: 0.9425, Validation Accuracy: 0.7753\n",
      "Epoch [229/500], Training Loss: 0.1248, Validation Loss: 0.8297, Training Accuracy: 0.9487, Validation Accuracy: 0.7978\n",
      "Epoch [230/500], Training Loss: 0.1146, Validation Loss: 0.8100, Training Accuracy: 0.9563, Validation Accuracy: 0.8090\n",
      "Epoch [231/500], Training Loss: 0.1118, Validation Loss: 0.7873, Training Accuracy: 0.9613, Validation Accuracy: 0.8090\n",
      "Epoch [232/500], Training Loss: 0.1069, Validation Loss: 0.8019, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [233/500], Training Loss: 0.1004, Validation Loss: 1.7040, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [234/500], Training Loss: 0.1061, Validation Loss: 1.7024, Training Accuracy: 0.9575, Validation Accuracy: 0.8090\n",
      "Epoch [235/500], Training Loss: 0.1204, Validation Loss: 0.8010, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [236/500], Training Loss: 0.1239, Validation Loss: 0.8048, Training Accuracy: 0.9563, Validation Accuracy: 0.8090\n",
      "Epoch [237/500], Training Loss: 0.1091, Validation Loss: 1.6782, Training Accuracy: 0.9637, Validation Accuracy: 0.8202\n",
      "Epoch [238/500], Training Loss: 0.1135, Validation Loss: 1.6841, Training Accuracy: 0.9537, Validation Accuracy: 0.8427\n",
      "Epoch [239/500], Training Loss: 0.1114, Validation Loss: 1.6658, Training Accuracy: 0.9550, Validation Accuracy: 0.8315\n",
      "Epoch [240/500], Training Loss: 0.1010, Validation Loss: 1.6744, Training Accuracy: 0.9613, Validation Accuracy: 0.8202\n",
      "Epoch [241/500], Training Loss: 0.1192, Validation Loss: 1.6927, Training Accuracy: 0.9525, Validation Accuracy: 0.8202\n",
      "Epoch [242/500], Training Loss: 0.1068, Validation Loss: 1.6866, Training Accuracy: 0.9650, Validation Accuracy: 0.8202\n",
      "Epoch [243/500], Training Loss: 0.1404, Validation Loss: 0.7785, Training Accuracy: 0.9537, Validation Accuracy: 0.8090\n",
      "Epoch [244/500], Training Loss: 0.1070, Validation Loss: 0.7421, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [245/500], Training Loss: 0.1117, Validation Loss: 0.7541, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [246/500], Training Loss: 0.1161, Validation Loss: 0.7730, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [247/500], Training Loss: 0.1274, Validation Loss: 0.7863, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [248/500], Training Loss: 0.1277, Validation Loss: 1.6749, Training Accuracy: 0.9575, Validation Accuracy: 0.8090\n",
      "Epoch [249/500], Training Loss: 0.1348, Validation Loss: 1.6734, Training Accuracy: 0.9537, Validation Accuracy: 0.8090\n",
      "Epoch [250/500], Training Loss: 0.1066, Validation Loss: 1.6875, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [251/500], Training Loss: 0.1287, Validation Loss: 1.7149, Training Accuracy: 0.9500, Validation Accuracy: 0.7753\n",
      "Epoch [252/500], Training Loss: 0.1500, Validation Loss: 0.8500, Training Accuracy: 0.9500, Validation Accuracy: 0.7753\n",
      "Epoch [253/500], Training Loss: 0.1114, Validation Loss: 1.7268, Training Accuracy: 0.9600, Validation Accuracy: 0.7865\n",
      "Epoch [254/500], Training Loss: 0.1122, Validation Loss: 1.7090, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [255/500], Training Loss: 0.1035, Validation Loss: 1.7000, Training Accuracy: 0.9637, Validation Accuracy: 0.8202\n",
      "Epoch [256/500], Training Loss: 0.1077, Validation Loss: 1.6913, Training Accuracy: 0.9650, Validation Accuracy: 0.8202\n",
      "Epoch [257/500], Training Loss: 0.1287, Validation Loss: 1.6931, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [258/500], Training Loss: 0.1059, Validation Loss: 1.6914, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [259/500], Training Loss: 0.1093, Validation Loss: 0.8186, Training Accuracy: 0.9663, Validation Accuracy: 0.7865\n",
      "Epoch [260/500], Training Loss: 0.1076, Validation Loss: 0.8199, Training Accuracy: 0.9650, Validation Accuracy: 0.7865\n",
      "Epoch [261/500], Training Loss: 0.1122, Validation Loss: 0.8324, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [262/500], Training Loss: 0.1041, Validation Loss: 1.7075, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [263/500], Training Loss: 0.1156, Validation Loss: 1.7031, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [264/500], Training Loss: 0.1349, Validation Loss: 1.6908, Training Accuracy: 0.9537, Validation Accuracy: 0.8202\n",
      "Epoch [265/500], Training Loss: 0.1223, Validation Loss: 1.6915, Training Accuracy: 0.9475, Validation Accuracy: 0.7978\n",
      "Epoch [266/500], Training Loss: 0.1033, Validation Loss: 1.7134, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [267/500], Training Loss: 0.0988, Validation Loss: 1.7378, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [268/500], Training Loss: 0.0979, Validation Loss: 1.7141, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [269/500], Training Loss: 0.0991, Validation Loss: 1.6753, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [270/500], Training Loss: 0.1223, Validation Loss: 1.6653, Training Accuracy: 0.9513, Validation Accuracy: 0.8315\n",
      "Epoch [271/500], Training Loss: 0.1059, Validation Loss: 1.6819, Training Accuracy: 0.9637, Validation Accuracy: 0.8315\n",
      "Epoch [272/500], Training Loss: 0.0986, Validation Loss: 1.6814, Training Accuracy: 0.9587, Validation Accuracy: 0.8427\n",
      "Epoch [273/500], Training Loss: 0.1083, Validation Loss: 1.6669, Training Accuracy: 0.9613, Validation Accuracy: 0.8202\n",
      "Epoch [274/500], Training Loss: 0.0870, Validation Loss: 1.6797, Training Accuracy: 0.9650, Validation Accuracy: 0.8202\n",
      "Epoch [275/500], Training Loss: 0.1078, Validation Loss: 1.6942, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [276/500], Training Loss: 0.1066, Validation Loss: 1.6992, Training Accuracy: 0.9650, Validation Accuracy: 0.8202\n",
      "Epoch [277/500], Training Loss: 0.0870, Validation Loss: 1.6953, Training Accuracy: 0.9637, Validation Accuracy: 0.8090\n",
      "Epoch [278/500], Training Loss: 0.1114, Validation Loss: 1.6946, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [279/500], Training Loss: 0.0908, Validation Loss: 1.7033, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [280/500], Training Loss: 0.1072, Validation Loss: 1.7123, Training Accuracy: 0.9500, Validation Accuracy: 0.7865\n",
      "Epoch [281/500], Training Loss: 0.0872, Validation Loss: 1.7093, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [282/500], Training Loss: 0.0989, Validation Loss: 0.8154, Training Accuracy: 0.9587, Validation Accuracy: 0.7865\n",
      "Epoch [283/500], Training Loss: 0.1320, Validation Loss: 0.7812, Training Accuracy: 0.9463, Validation Accuracy: 0.7865\n",
      "Epoch [284/500], Training Loss: 0.1082, Validation Loss: 0.7439, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [285/500], Training Loss: 0.1089, Validation Loss: 0.7790, Training Accuracy: 0.9600, Validation Accuracy: 0.7865\n",
      "Epoch [286/500], Training Loss: 0.0912, Validation Loss: 0.8142, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [287/500], Training Loss: 0.0963, Validation Loss: 0.8184, Training Accuracy: 0.9650, Validation Accuracy: 0.7865\n",
      "Epoch [288/500], Training Loss: 0.1081, Validation Loss: 1.7261, Training Accuracy: 0.9537, Validation Accuracy: 0.7753\n",
      "Epoch [289/500], Training Loss: 0.0920, Validation Loss: 1.7397, Training Accuracy: 0.9712, Validation Accuracy: 0.7640\n",
      "Epoch [290/500], Training Loss: 0.0984, Validation Loss: 1.7315, Training Accuracy: 0.9600, Validation Accuracy: 0.7753\n",
      "Epoch [291/500], Training Loss: 0.1106, Validation Loss: 1.7529, Training Accuracy: 0.9575, Validation Accuracy: 0.7865\n",
      "Epoch [292/500], Training Loss: 0.1481, Validation Loss: 1.7286, Training Accuracy: 0.9475, Validation Accuracy: 0.7865\n",
      "Epoch [293/500], Training Loss: 0.1208, Validation Loss: 0.7989, Training Accuracy: 0.9650, Validation Accuracy: 0.7865\n",
      "Epoch [294/500], Training Loss: 0.1192, Validation Loss: 0.8164, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [295/500], Training Loss: 0.1226, Validation Loss: 0.8377, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [296/500], Training Loss: 0.1066, Validation Loss: 0.8472, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [297/500], Training Loss: 0.0838, Validation Loss: 0.8424, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [298/500], Training Loss: 0.0998, Validation Loss: 1.7154, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [299/500], Training Loss: 0.0843, Validation Loss: 1.7275, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [300/500], Training Loss: 0.1004, Validation Loss: 1.7251, Training Accuracy: 0.9563, Validation Accuracy: 0.7865\n",
      "Epoch [301/500], Training Loss: 0.0849, Validation Loss: 1.7329, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [302/500], Training Loss: 0.1085, Validation Loss: 1.7072, Training Accuracy: 0.9600, Validation Accuracy: 0.7865\n",
      "Epoch [303/500], Training Loss: 0.1068, Validation Loss: 0.7884, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [304/500], Training Loss: 0.0875, Validation Loss: 1.6562, Training Accuracy: 0.9700, Validation Accuracy: 0.8090\n",
      "Epoch [305/500], Training Loss: 0.0992, Validation Loss: 1.6542, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [306/500], Training Loss: 0.1028, Validation Loss: 0.7740, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [307/500], Training Loss: 0.1100, Validation Loss: 0.7789, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [308/500], Training Loss: 0.1177, Validation Loss: 0.7902, Training Accuracy: 0.9525, Validation Accuracy: 0.8090\n",
      "Epoch [309/500], Training Loss: 0.0825, Validation Loss: 0.7863, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [310/500], Training Loss: 0.1031, Validation Loss: 0.8177, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [311/500], Training Loss: 0.0996, Validation Loss: 1.7277, Training Accuracy: 0.9688, Validation Accuracy: 0.8202\n",
      "Epoch [312/500], Training Loss: 0.1266, Validation Loss: 1.7333, Training Accuracy: 0.9513, Validation Accuracy: 0.8090\n",
      "Epoch [313/500], Training Loss: 0.0974, Validation Loss: 0.8491, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [314/500], Training Loss: 0.1079, Validation Loss: 0.8559, Training Accuracy: 0.9513, Validation Accuracy: 0.8090\n",
      "Epoch [315/500], Training Loss: 0.1015, Validation Loss: 0.8539, Training Accuracy: 0.9637, Validation Accuracy: 0.7978\n",
      "Epoch [316/500], Training Loss: 0.0968, Validation Loss: 0.8535, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [317/500], Training Loss: 0.0966, Validation Loss: 1.7205, Training Accuracy: 0.9600, Validation Accuracy: 0.7865\n",
      "Epoch [318/500], Training Loss: 0.0836, Validation Loss: 1.7111, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [319/500], Training Loss: 0.0942, Validation Loss: 1.7119, Training Accuracy: 0.9625, Validation Accuracy: 0.7978\n",
      "Epoch [320/500], Training Loss: 0.0993, Validation Loss: 1.7192, Training Accuracy: 0.9663, Validation Accuracy: 0.8090\n",
      "Epoch [321/500], Training Loss: 0.0924, Validation Loss: 1.7309, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [322/500], Training Loss: 0.1062, Validation Loss: 1.7182, Training Accuracy: 0.9650, Validation Accuracy: 0.7640\n",
      "Epoch [323/500], Training Loss: 0.0651, Validation Loss: 1.7334, Training Accuracy: 0.9850, Validation Accuracy: 0.7640\n",
      "Epoch [324/500], Training Loss: 0.0951, Validation Loss: 1.7640, Training Accuracy: 0.9613, Validation Accuracy: 0.7753\n",
      "Epoch [325/500], Training Loss: 0.1090, Validation Loss: 1.8004, Training Accuracy: 0.9625, Validation Accuracy: 0.7640\n",
      "Epoch [326/500], Training Loss: 0.1135, Validation Loss: 1.8027, Training Accuracy: 0.9625, Validation Accuracy: 0.7753\n",
      "Epoch [327/500], Training Loss: 0.0889, Validation Loss: 1.8217, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [328/500], Training Loss: 0.1032, Validation Loss: 1.8015, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [329/500], Training Loss: 0.0853, Validation Loss: 1.7921, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [330/500], Training Loss: 0.0957, Validation Loss: 1.7715, Training Accuracy: 0.9663, Validation Accuracy: 0.7865\n",
      "Epoch [331/500], Training Loss: 0.0681, Validation Loss: 1.7505, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [332/500], Training Loss: 0.1024, Validation Loss: 1.7442, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [333/500], Training Loss: 0.0843, Validation Loss: 1.7513, Training Accuracy: 0.9675, Validation Accuracy: 0.7978\n",
      "Epoch [334/500], Training Loss: 0.1145, Validation Loss: 1.7669, Training Accuracy: 0.9525, Validation Accuracy: 0.7865\n",
      "Epoch [335/500], Training Loss: 0.0666, Validation Loss: 1.7788, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [336/500], Training Loss: 0.0971, Validation Loss: 0.9132, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [337/500], Training Loss: 0.1156, Validation Loss: 0.8611, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [338/500], Training Loss: 0.0850, Validation Loss: 0.8631, Training Accuracy: 0.9650, Validation Accuracy: 0.7865\n",
      "Epoch [339/500], Training Loss: 0.0865, Validation Loss: 1.7795, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [340/500], Training Loss: 0.0822, Validation Loss: 1.8087, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [341/500], Training Loss: 0.0949, Validation Loss: 1.7824, Training Accuracy: 0.9637, Validation Accuracy: 0.8090\n",
      "Epoch [342/500], Training Loss: 0.0970, Validation Loss: 1.7557, Training Accuracy: 0.9663, Validation Accuracy: 0.8090\n",
      "Epoch [343/500], Training Loss: 0.0717, Validation Loss: 1.7621, Training Accuracy: 0.9750, Validation Accuracy: 0.8202\n",
      "Epoch [344/500], Training Loss: 0.0938, Validation Loss: 1.7847, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [345/500], Training Loss: 0.0773, Validation Loss: 1.8039, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [346/500], Training Loss: 0.1033, Validation Loss: 1.8007, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [347/500], Training Loss: 0.0931, Validation Loss: 1.7974, Training Accuracy: 0.9663, Validation Accuracy: 0.7865\n",
      "Epoch [348/500], Training Loss: 0.0691, Validation Loss: 1.8158, Training Accuracy: 0.9812, Validation Accuracy: 0.7865\n",
      "Epoch [349/500], Training Loss: 0.0930, Validation Loss: 1.8105, Training Accuracy: 0.9663, Validation Accuracy: 0.7865\n",
      "Epoch [350/500], Training Loss: 0.0739, Validation Loss: 1.7982, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [351/500], Training Loss: 0.1018, Validation Loss: 1.7785, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [352/500], Training Loss: 0.0770, Validation Loss: 1.7643, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [353/500], Training Loss: 0.0920, Validation Loss: 1.7396, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [354/500], Training Loss: 0.1013, Validation Loss: 1.7338, Training Accuracy: 0.9637, Validation Accuracy: 0.8202\n",
      "Epoch [355/500], Training Loss: 0.0879, Validation Loss: 1.7245, Training Accuracy: 0.9625, Validation Accuracy: 0.8202\n",
      "Epoch [356/500], Training Loss: 0.0917, Validation Loss: 1.7123, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [357/500], Training Loss: 0.0764, Validation Loss: 1.7133, Training Accuracy: 0.9750, Validation Accuracy: 0.7753\n",
      "Epoch [358/500], Training Loss: 0.0955, Validation Loss: 1.7353, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [359/500], Training Loss: 0.0963, Validation Loss: 1.7521, Training Accuracy: 0.9587, Validation Accuracy: 0.7865\n",
      "Epoch [360/500], Training Loss: 0.0907, Validation Loss: 1.7322, Training Accuracy: 0.9675, Validation Accuracy: 0.7640\n",
      "Epoch [361/500], Training Loss: 0.0775, Validation Loss: 1.7476, Training Accuracy: 0.9688, Validation Accuracy: 0.7753\n",
      "Epoch [362/500], Training Loss: 0.0923, Validation Loss: 1.7694, Training Accuracy: 0.9675, Validation Accuracy: 0.7416\n",
      "Epoch [363/500], Training Loss: 0.0979, Validation Loss: 1.8142, Training Accuracy: 0.9663, Validation Accuracy: 0.7640\n",
      "Epoch [364/500], Training Loss: 0.0895, Validation Loss: 1.8175, Training Accuracy: 0.9600, Validation Accuracy: 0.7865\n",
      "Epoch [365/500], Training Loss: 0.1055, Validation Loss: 1.7763, Training Accuracy: 0.9637, Validation Accuracy: 0.8090\n",
      "Epoch [366/500], Training Loss: 0.0892, Validation Loss: 1.7564, Training Accuracy: 0.9688, Validation Accuracy: 0.8202\n",
      "Epoch [367/500], Training Loss: 0.0997, Validation Loss: 1.7524, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [368/500], Training Loss: 0.0772, Validation Loss: 1.7759, Training Accuracy: 0.9675, Validation Accuracy: 0.7978\n",
      "Epoch [369/500], Training Loss: 0.1012, Validation Loss: 1.7792, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [370/500], Training Loss: 0.0924, Validation Loss: 1.7954, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [371/500], Training Loss: 0.0792, Validation Loss: 1.8144, Training Accuracy: 0.9725, Validation Accuracy: 0.7753\n",
      "Epoch [372/500], Training Loss: 0.0820, Validation Loss: 1.8117, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [373/500], Training Loss: 0.1036, Validation Loss: 1.8134, Training Accuracy: 0.9600, Validation Accuracy: 0.7865\n",
      "Epoch [374/500], Training Loss: 0.0769, Validation Loss: 1.8025, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [375/500], Training Loss: 0.0808, Validation Loss: 1.8169, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [376/500], Training Loss: 0.0855, Validation Loss: 1.8310, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [377/500], Training Loss: 0.0903, Validation Loss: 1.8008, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [378/500], Training Loss: 0.0639, Validation Loss: 1.8008, Training Accuracy: 0.9725, Validation Accuracy: 0.8090\n",
      "Epoch [379/500], Training Loss: 0.0927, Validation Loss: 1.8080, Training Accuracy: 0.9650, Validation Accuracy: 0.8202\n",
      "Epoch [380/500], Training Loss: 0.0866, Validation Loss: 1.8028, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [381/500], Training Loss: 0.0703, Validation Loss: 1.7903, Training Accuracy: 0.9688, Validation Accuracy: 0.8202\n",
      "Epoch [382/500], Training Loss: 0.0799, Validation Loss: 1.8175, Training Accuracy: 0.9725, Validation Accuracy: 0.8090\n",
      "Epoch [383/500], Training Loss: 0.0691, Validation Loss: 1.8057, Training Accuracy: 0.9750, Validation Accuracy: 0.8315\n",
      "Epoch [384/500], Training Loss: 0.0833, Validation Loss: 1.8001, Training Accuracy: 0.9663, Validation Accuracy: 0.8427\n",
      "Epoch [385/500], Training Loss: 0.0779, Validation Loss: 1.7898, Training Accuracy: 0.9725, Validation Accuracy: 0.8427\n",
      "Epoch [386/500], Training Loss: 0.0608, Validation Loss: 1.7941, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [387/500], Training Loss: 0.0881, Validation Loss: 1.8088, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [388/500], Training Loss: 0.0835, Validation Loss: 1.8100, Training Accuracy: 0.9700, Validation Accuracy: 0.8202\n",
      "Epoch [389/500], Training Loss: 0.0991, Validation Loss: 1.8060, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [390/500], Training Loss: 0.0780, Validation Loss: 1.8508, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [391/500], Training Loss: 0.1049, Validation Loss: 1.8513, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [392/500], Training Loss: 0.0793, Validation Loss: 1.8202, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [393/500], Training Loss: 0.0814, Validation Loss: 1.8005, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [394/500], Training Loss: 0.0860, Validation Loss: 1.7895, Training Accuracy: 0.9637, Validation Accuracy: 0.7978\n",
      "Epoch [395/500], Training Loss: 0.0908, Validation Loss: 1.7910, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [396/500], Training Loss: 0.0733, Validation Loss: 1.8138, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [397/500], Training Loss: 0.0707, Validation Loss: 1.8168, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [398/500], Training Loss: 0.0755, Validation Loss: 1.8070, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [399/500], Training Loss: 0.0736, Validation Loss: 1.8279, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [400/500], Training Loss: 0.0896, Validation Loss: 1.8284, Training Accuracy: 0.9650, Validation Accuracy: 0.7753\n",
      "Epoch [401/500], Training Loss: 0.0967, Validation Loss: 1.8110, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [402/500], Training Loss: 0.0765, Validation Loss: 1.7804, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [403/500], Training Loss: 0.0939, Validation Loss: 1.7625, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [404/500], Training Loss: 0.0790, Validation Loss: 1.7580, Training Accuracy: 0.9725, Validation Accuracy: 0.8090\n",
      "Epoch [405/500], Training Loss: 0.0589, Validation Loss: 1.7802, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [406/500], Training Loss: 0.0784, Validation Loss: 1.8048, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [407/500], Training Loss: 0.0920, Validation Loss: 1.7901, Training Accuracy: 0.9725, Validation Accuracy: 0.8202\n",
      "Epoch [408/500], Training Loss: 0.0672, Validation Loss: 1.7731, Training Accuracy: 0.9775, Validation Accuracy: 0.8090\n",
      "Epoch [409/500], Training Loss: 0.0687, Validation Loss: 1.7994, Training Accuracy: 0.9725, Validation Accuracy: 0.8202\n",
      "Epoch [410/500], Training Loss: 0.1016, Validation Loss: 1.8308, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [411/500], Training Loss: 0.0863, Validation Loss: 1.8650, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [412/500], Training Loss: 0.0824, Validation Loss: 1.8440, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [413/500], Training Loss: 0.0806, Validation Loss: 1.8309, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [414/500], Training Loss: 0.0801, Validation Loss: 0.9504, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [415/500], Training Loss: 0.0589, Validation Loss: 1.8260, Training Accuracy: 0.9862, Validation Accuracy: 0.7865\n",
      "Epoch [416/500], Training Loss: 0.0867, Validation Loss: 1.8543, Training Accuracy: 0.9613, Validation Accuracy: 0.7753\n",
      "Epoch [417/500], Training Loss: 0.0586, Validation Loss: 1.8396, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [418/500], Training Loss: 0.0994, Validation Loss: 1.8241, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [419/500], Training Loss: 0.0834, Validation Loss: 1.7844, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [420/500], Training Loss: 0.0636, Validation Loss: 1.8000, Training Accuracy: 0.9775, Validation Accuracy: 0.8090\n",
      "Epoch [421/500], Training Loss: 0.0911, Validation Loss: 1.8311, Training Accuracy: 0.9675, Validation Accuracy: 0.7865\n",
      "Epoch [422/500], Training Loss: 0.0812, Validation Loss: 1.8456, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [423/500], Training Loss: 0.0701, Validation Loss: 1.8289, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [424/500], Training Loss: 0.0790, Validation Loss: 1.8267, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [425/500], Training Loss: 0.0794, Validation Loss: 1.8176, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [426/500], Training Loss: 0.0888, Validation Loss: 1.8093, Training Accuracy: 0.9700, Validation Accuracy: 0.8090\n",
      "Epoch [427/500], Training Loss: 0.0834, Validation Loss: 1.8000, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [428/500], Training Loss: 0.0568, Validation Loss: 1.8133, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [429/500], Training Loss: 0.0888, Validation Loss: 1.7971, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [430/500], Training Loss: 0.0920, Validation Loss: 1.7647, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [431/500], Training Loss: 0.0784, Validation Loss: 1.7672, Training Accuracy: 0.9725, Validation Accuracy: 0.7865\n",
      "Epoch [432/500], Training Loss: 0.0746, Validation Loss: 1.7864, Training Accuracy: 0.9738, Validation Accuracy: 0.7753\n",
      "Epoch [433/500], Training Loss: 0.0605, Validation Loss: 1.8055, Training Accuracy: 0.9788, Validation Accuracy: 0.7753\n",
      "Epoch [434/500], Training Loss: 0.0741, Validation Loss: 1.8208, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [435/500], Training Loss: 0.0563, Validation Loss: 1.8266, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [436/500], Training Loss: 0.0793, Validation Loss: 1.8192, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [437/500], Training Loss: 0.0599, Validation Loss: 1.8403, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [438/500], Training Loss: 0.0816, Validation Loss: 1.8632, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [439/500], Training Loss: 0.0569, Validation Loss: 1.8843, Training Accuracy: 0.9800, Validation Accuracy: 0.7753\n",
      "Epoch [440/500], Training Loss: 0.0879, Validation Loss: 1.8670, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [441/500], Training Loss: 0.0723, Validation Loss: 1.8582, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [442/500], Training Loss: 0.0971, Validation Loss: 1.8545, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [443/500], Training Loss: 0.0537, Validation Loss: 1.8501, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [444/500], Training Loss: 0.0753, Validation Loss: 1.7989, Training Accuracy: 0.9712, Validation Accuracy: 0.8090\n",
      "Epoch [445/500], Training Loss: 0.0961, Validation Loss: 1.7725, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [446/500], Training Loss: 0.0774, Validation Loss: 1.7913, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [447/500], Training Loss: 0.0853, Validation Loss: 1.8229, Training Accuracy: 0.9650, Validation Accuracy: 0.7865\n",
      "Epoch [448/500], Training Loss: 0.0734, Validation Loss: 1.8540, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [449/500], Training Loss: 0.0825, Validation Loss: 1.8699, Training Accuracy: 0.9725, Validation Accuracy: 0.8090\n",
      "Epoch [450/500], Training Loss: 0.0601, Validation Loss: 1.8718, Training Accuracy: 0.9788, Validation Accuracy: 0.8202\n",
      "Epoch [451/500], Training Loss: 0.0971, Validation Loss: 1.8682, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [452/500], Training Loss: 0.0568, Validation Loss: 1.8520, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [453/500], Training Loss: 0.0694, Validation Loss: 1.8400, Training Accuracy: 0.9812, Validation Accuracy: 0.8090\n",
      "Epoch [454/500], Training Loss: 0.0846, Validation Loss: 0.9461, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [455/500], Training Loss: 0.0641, Validation Loss: 0.9596, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [456/500], Training Loss: 0.0475, Validation Loss: 0.9850, Training Accuracy: 0.9875, Validation Accuracy: 0.7978\n",
      "Epoch [457/500], Training Loss: 0.0483, Validation Loss: 1.8830, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [458/500], Training Loss: 0.0456, Validation Loss: 1.8648, Training Accuracy: 0.9888, Validation Accuracy: 0.8202\n",
      "Epoch [459/500], Training Loss: 0.0696, Validation Loss: 1.8422, Training Accuracy: 0.9800, Validation Accuracy: 0.8315\n",
      "Epoch [460/500], Training Loss: 0.0653, Validation Loss: 1.8449, Training Accuracy: 0.9762, Validation Accuracy: 0.8315\n",
      "Epoch [461/500], Training Loss: 0.0970, Validation Loss: 1.8437, Training Accuracy: 0.9650, Validation Accuracy: 0.8315\n",
      "Epoch [462/500], Training Loss: 0.0696, Validation Loss: 1.8689, Training Accuracy: 0.9800, Validation Accuracy: 0.8315\n",
      "Epoch [463/500], Training Loss: 0.0612, Validation Loss: 1.8866, Training Accuracy: 0.9850, Validation Accuracy: 0.8315\n",
      "Epoch [464/500], Training Loss: 0.0675, Validation Loss: 1.8846, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [465/500], Training Loss: 0.0637, Validation Loss: 1.8647, Training Accuracy: 0.9688, Validation Accuracy: 0.8090\n",
      "Epoch [466/500], Training Loss: 0.0589, Validation Loss: 1.8805, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [467/500], Training Loss: 0.0608, Validation Loss: 1.8924, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [468/500], Training Loss: 0.0514, Validation Loss: 1.8747, Training Accuracy: 0.9838, Validation Accuracy: 0.8090\n",
      "Epoch [469/500], Training Loss: 0.0682, Validation Loss: 1.8655, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [470/500], Training Loss: 0.0654, Validation Loss: 1.8690, Training Accuracy: 0.9712, Validation Accuracy: 0.8202\n",
      "Epoch [471/500], Training Loss: 0.0708, Validation Loss: 1.8681, Training Accuracy: 0.9675, Validation Accuracy: 0.8202\n",
      "Epoch [472/500], Training Loss: 0.0557, Validation Loss: 1.8187, Training Accuracy: 0.9788, Validation Accuracy: 0.8315\n",
      "Epoch [473/500], Training Loss: 0.0635, Validation Loss: 1.7998, Training Accuracy: 0.9712, Validation Accuracy: 0.8202\n",
      "Epoch [474/500], Training Loss: 0.0943, Validation Loss: 1.8055, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [475/500], Training Loss: 0.0906, Validation Loss: 1.8223, Training Accuracy: 0.9675, Validation Accuracy: 0.7978\n",
      "Epoch [476/500], Training Loss: 0.0650, Validation Loss: 1.8029, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [477/500], Training Loss: 0.0581, Validation Loss: 1.7975, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [478/500], Training Loss: 0.0739, Validation Loss: 1.8059, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [479/500], Training Loss: 0.0509, Validation Loss: 1.8274, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [480/500], Training Loss: 0.0773, Validation Loss: 1.8604, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [481/500], Training Loss: 0.0691, Validation Loss: 1.8762, Training Accuracy: 0.9775, Validation Accuracy: 0.7753\n",
      "Epoch [482/500], Training Loss: 0.0505, Validation Loss: 1.8879, Training Accuracy: 0.9850, Validation Accuracy: 0.7640\n",
      "Epoch [483/500], Training Loss: 0.0589, Validation Loss: 1.9140, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [484/500], Training Loss: 0.0568, Validation Loss: 1.9150, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [485/500], Training Loss: 0.0684, Validation Loss: 1.9205, Training Accuracy: 0.9762, Validation Accuracy: 0.8202\n",
      "Epoch [486/500], Training Loss: 0.0434, Validation Loss: 1.9151, Training Accuracy: 0.9888, Validation Accuracy: 0.8090\n",
      "Epoch [487/500], Training Loss: 0.0606, Validation Loss: 1.9206, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [488/500], Training Loss: 0.0711, Validation Loss: 1.9025, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [489/500], Training Loss: 0.0671, Validation Loss: 1.9102, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [490/500], Training Loss: 0.0567, Validation Loss: 1.9137, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [491/500], Training Loss: 0.0598, Validation Loss: 1.9039, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [492/500], Training Loss: 0.0658, Validation Loss: 1.8753, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [493/500], Training Loss: 0.0631, Validation Loss: 1.8381, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [494/500], Training Loss: 0.0624, Validation Loss: 1.8276, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [495/500], Training Loss: 0.0612, Validation Loss: 1.8283, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [496/500], Training Loss: 0.0841, Validation Loss: 1.8443, Training Accuracy: 0.9725, Validation Accuracy: 0.7865\n",
      "Epoch [497/500], Training Loss: 0.0750, Validation Loss: 1.8427, Training Accuracy: 0.9712, Validation Accuracy: 0.8090\n",
      "Epoch [498/500], Training Loss: 0.0762, Validation Loss: 1.8375, Training Accuracy: 0.9688, Validation Accuracy: 0.8090\n",
      "Epoch [499/500], Training Loss: 0.0790, Validation Loss: 1.8272, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [500/500], Training Loss: 0.0535, Validation Loss: 1.8158, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Training Time: 12.07 seconds\n",
      "Epoch [1/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/v5ysl19s0hbdkdprhb3xqd4r0000gn/T/ipykernel_34536/2037389910.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_weights.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [3/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [4/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [5/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [6/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [7/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [8/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [9/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [10/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [11/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [12/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [13/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [14/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [15/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [16/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [17/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [18/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [19/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [20/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [21/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [22/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [23/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [24/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [25/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [26/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [27/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [28/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [29/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [30/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [31/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [32/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [33/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [34/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [35/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [36/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [37/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [38/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [39/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [40/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [41/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [42/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [43/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [44/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [45/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [46/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [47/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [48/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [49/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [50/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [51/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [52/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [53/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [54/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [55/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [56/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [57/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [58/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [59/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [60/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [61/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [62/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [63/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [64/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [65/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [66/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [67/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [68/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [69/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [70/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [71/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [72/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [73/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [74/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [75/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [76/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [77/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [78/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [79/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [80/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [81/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [82/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [83/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [84/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [85/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [86/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [87/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [88/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [89/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [90/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [91/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [92/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [93/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [94/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [95/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [96/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [97/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [98/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [99/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [100/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [101/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [102/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [103/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [104/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [105/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [106/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [107/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [108/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [109/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [110/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [111/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [112/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [113/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [114/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [115/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [116/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [117/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [118/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [119/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [120/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [121/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [122/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [123/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [124/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [125/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [126/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [127/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [128/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [129/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [130/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [131/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [132/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [133/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [134/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [135/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [136/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [137/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [138/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [139/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [140/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [141/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [142/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [143/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [144/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [145/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [146/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [147/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [148/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [149/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [150/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [151/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [152/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [153/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [154/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [155/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [156/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [157/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [158/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [159/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [160/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [161/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [162/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [163/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [164/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [165/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [166/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [167/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [168/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [169/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [170/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [171/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [172/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [173/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [174/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [175/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [176/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [177/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [178/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [179/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [180/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [181/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [182/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [183/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [184/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [185/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [186/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [187/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [188/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [189/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [190/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [191/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [192/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [193/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [194/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [195/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [196/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [197/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [198/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [199/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [200/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [201/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [202/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [203/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [204/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [205/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [206/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [207/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [208/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [209/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [210/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [211/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [212/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [213/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [214/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [215/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [216/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [217/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [218/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [219/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [220/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [221/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [222/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [223/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [224/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [225/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [226/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [227/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [228/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [229/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [230/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [231/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [232/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [233/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [234/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [235/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [236/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [237/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [238/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [239/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [240/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [241/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [242/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [243/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [244/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [245/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [246/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [247/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [248/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [249/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [250/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [251/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [252/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [253/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [254/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [255/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [256/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [257/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [258/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [259/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [260/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [261/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [262/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [263/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [264/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [265/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [266/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [267/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [268/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [269/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [270/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [271/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [272/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [273/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [274/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [275/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [276/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [277/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [278/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [279/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [280/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [281/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [282/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [283/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [284/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [285/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [286/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [287/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [288/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [289/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [290/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [291/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [292/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [293/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [294/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [295/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [296/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [297/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [298/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [299/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [300/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [301/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [302/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [303/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [304/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [305/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [306/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [307/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [308/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [309/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [310/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [311/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [312/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [313/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [314/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [315/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [316/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [317/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [318/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [319/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [320/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [321/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [322/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [323/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [324/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [325/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [326/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [327/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [328/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [329/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [330/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [331/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [332/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [333/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [334/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [335/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [336/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [337/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [338/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [339/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [340/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [341/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [342/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [343/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [344/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [345/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [346/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [347/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [348/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [349/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [350/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [351/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [352/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [353/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [354/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [355/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [356/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [357/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [358/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [359/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [360/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [361/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [362/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [363/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [364/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [365/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [366/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [367/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [368/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [369/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [370/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [371/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [372/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [373/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [374/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [375/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [376/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [377/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [378/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [379/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [380/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [381/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [382/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [383/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [384/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [385/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [386/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [387/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [388/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [389/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [390/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [391/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [392/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [393/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [394/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [395/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [396/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [397/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [398/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [399/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [400/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [401/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [402/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [403/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [404/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [405/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [406/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [407/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [408/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [409/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [410/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [411/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [412/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [413/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [414/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [415/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [416/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [417/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [418/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [419/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [420/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [421/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [422/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [423/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [424/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [425/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [426/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [427/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [428/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [429/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [430/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [431/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [432/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [433/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [434/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [435/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [436/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [437/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [438/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [439/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [440/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [441/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [442/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [443/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [444/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [445/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [446/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [447/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [448/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [449/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [450/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [451/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [452/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [453/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [454/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [455/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [456/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [457/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [458/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [459/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [460/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [461/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [462/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [463/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [464/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [465/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [466/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [467/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [468/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [469/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [470/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [471/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [472/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [473/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [474/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [475/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [476/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [477/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [478/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [479/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [480/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [481/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [482/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [483/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [484/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [485/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [486/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [487/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [488/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [489/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [490/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [491/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [492/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [493/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [494/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [495/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [496/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [497/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [498/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [499/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [500/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [501/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [502/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [503/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [504/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [505/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [506/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [507/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [508/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [509/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [510/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [511/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [512/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [513/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [514/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [515/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [516/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [517/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [518/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [519/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [520/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [521/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [522/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [523/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [524/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [525/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [526/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [527/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [528/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [529/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [530/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [531/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [532/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [533/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [534/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [535/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [536/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [537/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [538/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [539/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [540/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [541/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [542/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [543/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [544/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [545/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [546/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [547/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [548/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [549/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [550/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [551/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [552/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [553/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [554/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [555/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [556/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [557/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [558/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [559/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [560/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [561/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [562/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [563/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [564/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [565/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [566/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [567/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [568/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [569/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [570/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [571/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [572/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [573/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [574/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [575/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [576/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [577/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [578/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [579/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [580/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [581/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [582/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [583/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [584/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [585/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [586/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [587/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [588/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [589/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [590/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [591/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [592/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [593/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [594/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [595/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [596/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [597/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [598/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [599/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [600/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n"
     ]
    }
   ],
   "source": [
    "accumulation_steps = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    optimizer.zero_grad()  \n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = loss_function(outputs, labels.float())\n",
    "        loss = loss / accumulation_steps  \n",
    "        loss.backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        training_loss += loss.item() * accumulation_steps \n",
    "        predicted = torch.round(outputs)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    train_losses.append(training_loss / len(train_loader))\n",
    "    train_accuracies.append(correct_predictions / total_predictions)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_outputs = model(val_inputs).squeeze()\n",
    "            val_loss += loss_function(val_outputs, val_labels.float()).item()\n",
    "            predicted = torch.round(val_outputs)\n",
    "            val_correct_predictions += (predicted == val_labels).sum().item()\n",
    "            val_total_predictions += val_labels.size(0)\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(val_correct_predictions / val_total_predictions)\n",
    "\n",
    "    average_training_loss = training_loss / len(train_loader)\n",
    "    average_validation_loss = val_loss / len(val_loader)\n",
    "    training_accuracy = correct_predictions / total_predictions\n",
    "    validation_accuracy = val_correct_predictions / val_total_predictions\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Training Loss: {average_training_loss:.4f}, '\n",
    "          f'Validation Loss: {average_validation_loss:.4f}, '\n",
    "          f'Training Accuracy: {training_accuracy:.4f}, '\n",
    "          f'Validation Accuracy: {validation_accuracy:.4f}')\n",
    "\n",
    "    if average_validation_loss < best_val_loss:\n",
    "        best_val_loss = average_validation_loss\n",
    "        torch.save(model.state_dict(), 'best_model_weights.pth')\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Training Time: {end_time - start_time:.2f} seconds')\n",
    "model.load_state_dict(torch.load('best_model_weights.pth'))\n",
    "\n",
    "num_epochss = 600\n",
    "for epoch in range(num_epochss):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct_predictions = 0\n",
    "    test_total_predictions = 0\n",
    "\n",
    "    confusion_predictions = []\n",
    "    confusion_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in test_loader:\n",
    "            test_outputs = model(test_inputs).squeeze()\n",
    "            test_loss += loss_function(test_outputs, test_labels.float()).item()\n",
    "            \n",
    "            predicted = torch.round(test_outputs)\n",
    "            test_correct_predictions += (predicted == test_labels.float()).sum().item()\n",
    "            test_total_predictions += test_labels.size(0)\n",
    "        \n",
    "            confusion_predictions.extend(predicted.numpy())  #for confusion matrix\n",
    "            confusion_labels.extend(test_labels.numpy())  #actual class labels\n",
    "\n",
    "        test_losses.append(test_loss / len(test_loader))  # Gives the average loss per batch\n",
    "        test_accuracies.append(test_correct_predictions / test_total_predictions)  # ratio of correct preds / total preds -> accuracy\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = test_correct_predictions / test_total_predictions\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochss}], '\n",
    "            f'Test Loss: {avg_test_loss:.4f}, '\n",
    "            f'Testing Accuracy: {test_accuracy:.4f}, ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(train_accuracies) + 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing Batch Normalization method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 0.2459, Validation Loss: 0.5279, Training Accuracy: 0.8912, Validation Accuracy: 0.7978\n",
      "Epoch [2/500], Training Loss: 0.2699, Validation Loss: 0.5111, Training Accuracy: 0.8875, Validation Accuracy: 0.7753\n",
      "Epoch [3/500], Training Loss: 0.2648, Validation Loss: 0.5691, Training Accuracy: 0.8900, Validation Accuracy: 0.7640\n",
      "Epoch [4/500], Training Loss: 0.2860, Validation Loss: 0.5245, Training Accuracy: 0.8838, Validation Accuracy: 0.7978\n",
      "Epoch [5/500], Training Loss: 0.2919, Validation Loss: 0.4715, Training Accuracy: 0.8738, Validation Accuracy: 0.8090\n",
      "Epoch [6/500], Training Loss: 0.2673, Validation Loss: 0.4956, Training Accuracy: 0.8862, Validation Accuracy: 0.7978\n",
      "Epoch [7/500], Training Loss: 0.2648, Validation Loss: 0.5116, Training Accuracy: 0.8812, Validation Accuracy: 0.8090\n",
      "Epoch [8/500], Training Loss: 0.2782, Validation Loss: 0.4926, Training Accuracy: 0.8825, Validation Accuracy: 0.7978\n",
      "Epoch [9/500], Training Loss: 0.2858, Validation Loss: 0.5122, Training Accuracy: 0.8762, Validation Accuracy: 0.7865\n",
      "Epoch [10/500], Training Loss: 0.2559, Validation Loss: 0.5318, Training Accuracy: 0.9038, Validation Accuracy: 0.7753\n",
      "Epoch [11/500], Training Loss: 0.2334, Validation Loss: 0.5607, Training Accuracy: 0.8988, Validation Accuracy: 0.7978\n",
      "Epoch [12/500], Training Loss: 0.2614, Validation Loss: 0.5315, Training Accuracy: 0.8800, Validation Accuracy: 0.8090\n",
      "Epoch [13/500], Training Loss: 0.2663, Validation Loss: 0.5190, Training Accuracy: 0.8962, Validation Accuracy: 0.7865\n",
      "Epoch [14/500], Training Loss: 0.2482, Validation Loss: 0.5658, Training Accuracy: 0.8925, Validation Accuracy: 0.8090\n",
      "Epoch [15/500], Training Loss: 0.2609, Validation Loss: 0.4658, Training Accuracy: 0.8912, Validation Accuracy: 0.8090\n",
      "Epoch [16/500], Training Loss: 0.2469, Validation Loss: 0.5362, Training Accuracy: 0.8912, Validation Accuracy: 0.8315\n",
      "Epoch [17/500], Training Loss: 0.2168, Validation Loss: 0.5080, Training Accuracy: 0.9075, Validation Accuracy: 0.7865\n",
      "Epoch [18/500], Training Loss: 0.2275, Validation Loss: 0.5785, Training Accuracy: 0.8912, Validation Accuracy: 0.8202\n",
      "Epoch [19/500], Training Loss: 0.2171, Validation Loss: 0.4797, Training Accuracy: 0.9113, Validation Accuracy: 0.8090\n",
      "Epoch [20/500], Training Loss: 0.2428, Validation Loss: 0.5499, Training Accuracy: 0.8950, Validation Accuracy: 0.7865\n",
      "Epoch [21/500], Training Loss: 0.2147, Validation Loss: 0.5209, Training Accuracy: 0.9125, Validation Accuracy: 0.7640\n",
      "Epoch [22/500], Training Loss: 0.2215, Validation Loss: 0.5317, Training Accuracy: 0.8988, Validation Accuracy: 0.7753\n",
      "Epoch [23/500], Training Loss: 0.2085, Validation Loss: 0.5606, Training Accuracy: 0.9100, Validation Accuracy: 0.7640\n",
      "Epoch [24/500], Training Loss: 0.2224, Validation Loss: 0.5778, Training Accuracy: 0.9187, Validation Accuracy: 0.7753\n",
      "Epoch [25/500], Training Loss: 0.2165, Validation Loss: 0.5665, Training Accuracy: 0.9012, Validation Accuracy: 0.8090\n",
      "Epoch [26/500], Training Loss: 0.2318, Validation Loss: 0.5727, Training Accuracy: 0.9062, Validation Accuracy: 0.7865\n",
      "Epoch [27/500], Training Loss: 0.2012, Validation Loss: 0.5720, Training Accuracy: 0.9237, Validation Accuracy: 0.7865\n",
      "Epoch [28/500], Training Loss: 0.1897, Validation Loss: 0.5770, Training Accuracy: 0.9275, Validation Accuracy: 0.7753\n",
      "Epoch [29/500], Training Loss: 0.1876, Validation Loss: 0.6026, Training Accuracy: 0.9187, Validation Accuracy: 0.7753\n",
      "Epoch [30/500], Training Loss: 0.1989, Validation Loss: 0.5924, Training Accuracy: 0.9187, Validation Accuracy: 0.7978\n",
      "Epoch [31/500], Training Loss: 0.2035, Validation Loss: 0.5940, Training Accuracy: 0.9163, Validation Accuracy: 0.8090\n",
      "Epoch [32/500], Training Loss: 0.1783, Validation Loss: 0.6105, Training Accuracy: 0.9287, Validation Accuracy: 0.7978\n",
      "Epoch [33/500], Training Loss: 0.2082, Validation Loss: 0.6179, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [34/500], Training Loss: 0.1806, Validation Loss: 0.6243, Training Accuracy: 0.9263, Validation Accuracy: 0.7753\n",
      "Epoch [35/500], Training Loss: 0.1742, Validation Loss: 0.6103, Training Accuracy: 0.9250, Validation Accuracy: 0.7978\n",
      "Epoch [36/500], Training Loss: 0.1863, Validation Loss: 0.5942, Training Accuracy: 0.9175, Validation Accuracy: 0.7978\n",
      "Epoch [37/500], Training Loss: 0.2022, Validation Loss: 0.5895, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [38/500], Training Loss: 0.1812, Validation Loss: 0.5826, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [39/500], Training Loss: 0.1854, Validation Loss: 0.5946, Training Accuracy: 0.9350, Validation Accuracy: 0.8090\n",
      "Epoch [40/500], Training Loss: 0.2008, Validation Loss: 0.5887, Training Accuracy: 0.9125, Validation Accuracy: 0.8090\n",
      "Epoch [41/500], Training Loss: 0.1877, Validation Loss: 0.5897, Training Accuracy: 0.9287, Validation Accuracy: 0.8090\n",
      "Epoch [42/500], Training Loss: 0.1685, Validation Loss: 0.5936, Training Accuracy: 0.9375, Validation Accuracy: 0.8090\n",
      "Epoch [43/500], Training Loss: 0.2019, Validation Loss: 0.5906, Training Accuracy: 0.9225, Validation Accuracy: 0.7978\n",
      "Epoch [44/500], Training Loss: 0.1999, Validation Loss: 0.5968, Training Accuracy: 0.9050, Validation Accuracy: 0.7978\n",
      "Epoch [45/500], Training Loss: 0.1812, Validation Loss: 0.6004, Training Accuracy: 0.9263, Validation Accuracy: 0.7865\n",
      "Epoch [46/500], Training Loss: 0.1718, Validation Loss: 0.6021, Training Accuracy: 0.9350, Validation Accuracy: 0.7865\n",
      "Epoch [47/500], Training Loss: 0.1787, Validation Loss: 0.6013, Training Accuracy: 0.9250, Validation Accuracy: 0.7865\n",
      "Epoch [48/500], Training Loss: 0.1630, Validation Loss: 0.6008, Training Accuracy: 0.9387, Validation Accuracy: 0.7753\n",
      "Epoch [49/500], Training Loss: 0.1753, Validation Loss: 0.6007, Training Accuracy: 0.9337, Validation Accuracy: 0.7753\n",
      "Epoch [50/500], Training Loss: 0.1835, Validation Loss: 0.6007, Training Accuracy: 0.9287, Validation Accuracy: 0.7753\n",
      "Epoch [51/500], Training Loss: 0.1568, Validation Loss: 0.6007, Training Accuracy: 0.9375, Validation Accuracy: 0.7753\n",
      "Epoch [52/500], Training Loss: 0.1742, Validation Loss: 0.6006, Training Accuracy: 0.9237, Validation Accuracy: 0.7753\n",
      "Epoch [53/500], Training Loss: 0.1861, Validation Loss: 0.6002, Training Accuracy: 0.9213, Validation Accuracy: 0.7753\n",
      "Epoch [54/500], Training Loss: 0.1663, Validation Loss: 0.5998, Training Accuracy: 0.9350, Validation Accuracy: 0.7753\n",
      "Epoch [55/500], Training Loss: 0.1688, Validation Loss: 0.6007, Training Accuracy: 0.9363, Validation Accuracy: 0.7753\n",
      "Epoch [56/500], Training Loss: 0.1956, Validation Loss: 0.6012, Training Accuracy: 0.9187, Validation Accuracy: 0.7865\n",
      "Epoch [57/500], Training Loss: 0.1863, Validation Loss: 0.5956, Training Accuracy: 0.9237, Validation Accuracy: 0.7865\n",
      "Epoch [58/500], Training Loss: 0.2021, Validation Loss: 0.5983, Training Accuracy: 0.9225, Validation Accuracy: 0.7865\n",
      "Epoch [59/500], Training Loss: 0.1775, Validation Loss: 0.5961, Training Accuracy: 0.9225, Validation Accuracy: 0.7978\n",
      "Epoch [60/500], Training Loss: 0.1680, Validation Loss: 0.5982, Training Accuracy: 0.9325, Validation Accuracy: 0.8090\n",
      "Epoch [61/500], Training Loss: 0.1634, Validation Loss: 0.5986, Training Accuracy: 0.9463, Validation Accuracy: 0.8090\n",
      "Epoch [62/500], Training Loss: 0.1657, Validation Loss: 0.5945, Training Accuracy: 0.9250, Validation Accuracy: 0.7978\n",
      "Epoch [63/500], Training Loss: 0.1605, Validation Loss: 0.6004, Training Accuracy: 0.9387, Validation Accuracy: 0.7978\n",
      "Epoch [64/500], Training Loss: 0.1973, Validation Loss: 0.5985, Training Accuracy: 0.9250, Validation Accuracy: 0.8090\n",
      "Epoch [65/500], Training Loss: 0.1811, Validation Loss: 0.6006, Training Accuracy: 0.9313, Validation Accuracy: 0.7865\n",
      "Epoch [66/500], Training Loss: 0.1771, Validation Loss: 0.5964, Training Accuracy: 0.9325, Validation Accuracy: 0.7978\n",
      "Epoch [67/500], Training Loss: 0.1838, Validation Loss: 0.5993, Training Accuracy: 0.9313, Validation Accuracy: 0.7865\n",
      "Epoch [68/500], Training Loss: 0.1972, Validation Loss: 0.5905, Training Accuracy: 0.9200, Validation Accuracy: 0.7865\n",
      "Epoch [69/500], Training Loss: 0.1820, Validation Loss: 0.5687, Training Accuracy: 0.9350, Validation Accuracy: 0.7978\n",
      "Epoch [70/500], Training Loss: 0.1713, Validation Loss: 0.5736, Training Accuracy: 0.9337, Validation Accuracy: 0.8202\n",
      "Epoch [71/500], Training Loss: 0.2158, Validation Loss: 0.5861, Training Accuracy: 0.9213, Validation Accuracy: 0.8090\n",
      "Epoch [72/500], Training Loss: 0.1825, Validation Loss: 0.5747, Training Accuracy: 0.9237, Validation Accuracy: 0.7978\n",
      "Epoch [73/500], Training Loss: 0.1627, Validation Loss: 0.6168, Training Accuracy: 0.9300, Validation Accuracy: 0.7865\n",
      "Epoch [74/500], Training Loss: 0.1800, Validation Loss: 0.5991, Training Accuracy: 0.9300, Validation Accuracy: 0.8090\n",
      "Epoch [75/500], Training Loss: 0.1825, Validation Loss: 0.5919, Training Accuracy: 0.9287, Validation Accuracy: 0.7865\n",
      "Epoch [76/500], Training Loss: 0.1748, Validation Loss: 0.5820, Training Accuracy: 0.9225, Validation Accuracy: 0.8090\n",
      "Epoch [77/500], Training Loss: 0.2057, Validation Loss: 0.5896, Training Accuracy: 0.9200, Validation Accuracy: 0.7978\n",
      "Epoch [78/500], Training Loss: 0.1647, Validation Loss: 0.5752, Training Accuracy: 0.9413, Validation Accuracy: 0.7978\n",
      "Epoch [79/500], Training Loss: 0.1748, Validation Loss: 0.5618, Training Accuracy: 0.9275, Validation Accuracy: 0.7978\n",
      "Epoch [80/500], Training Loss: 0.1834, Validation Loss: 0.6379, Training Accuracy: 0.9275, Validation Accuracy: 0.8090\n",
      "Epoch [81/500], Training Loss: 0.1584, Validation Loss: 0.6253, Training Accuracy: 0.9363, Validation Accuracy: 0.8090\n",
      "Epoch [82/500], Training Loss: 0.1907, Validation Loss: 0.6215, Training Accuracy: 0.9187, Validation Accuracy: 0.8202\n",
      "Epoch [83/500], Training Loss: 0.1846, Validation Loss: 0.6537, Training Accuracy: 0.9275, Validation Accuracy: 0.7865\n",
      "Epoch [84/500], Training Loss: 0.1958, Validation Loss: 0.5926, Training Accuracy: 0.9150, Validation Accuracy: 0.8202\n",
      "Epoch [85/500], Training Loss: 0.1822, Validation Loss: 0.6042, Training Accuracy: 0.9275, Validation Accuracy: 0.8090\n",
      "Epoch [86/500], Training Loss: 0.1850, Validation Loss: 0.6478, Training Accuracy: 0.9213, Validation Accuracy: 0.7865\n",
      "Epoch [87/500], Training Loss: 0.1885, Validation Loss: 0.5657, Training Accuracy: 0.9263, Validation Accuracy: 0.8090\n",
      "Epoch [88/500], Training Loss: 0.1784, Validation Loss: 0.6638, Training Accuracy: 0.9300, Validation Accuracy: 0.7978\n",
      "Epoch [89/500], Training Loss: 0.1995, Validation Loss: 0.5787, Training Accuracy: 0.9137, Validation Accuracy: 0.8202\n",
      "Epoch [90/500], Training Loss: 0.1737, Validation Loss: 0.5956, Training Accuracy: 0.9325, Validation Accuracy: 0.8090\n",
      "Epoch [91/500], Training Loss: 0.1785, Validation Loss: 0.6329, Training Accuracy: 0.9387, Validation Accuracy: 0.7640\n",
      "Epoch [92/500], Training Loss: 0.1916, Validation Loss: 0.6254, Training Accuracy: 0.9187, Validation Accuracy: 0.7978\n",
      "Epoch [93/500], Training Loss: 0.1717, Validation Loss: 0.6365, Training Accuracy: 0.9300, Validation Accuracy: 0.7978\n",
      "Epoch [94/500], Training Loss: 0.2044, Validation Loss: 0.6082, Training Accuracy: 0.9200, Validation Accuracy: 0.8090\n",
      "Epoch [95/500], Training Loss: 0.1876, Validation Loss: 0.5619, Training Accuracy: 0.9250, Validation Accuracy: 0.8315\n",
      "Epoch [96/500], Training Loss: 0.1926, Validation Loss: 0.5917, Training Accuracy: 0.9213, Validation Accuracy: 0.8427\n",
      "Epoch [97/500], Training Loss: 0.1672, Validation Loss: 0.6357, Training Accuracy: 0.9363, Validation Accuracy: 0.8090\n",
      "Epoch [98/500], Training Loss: 0.1917, Validation Loss: 0.6142, Training Accuracy: 0.9175, Validation Accuracy: 0.8090\n",
      "Epoch [99/500], Training Loss: 0.1883, Validation Loss: 0.6630, Training Accuracy: 0.9237, Validation Accuracy: 0.7753\n",
      "Epoch [100/500], Training Loss: 0.1861, Validation Loss: 0.6635, Training Accuracy: 0.9237, Validation Accuracy: 0.7753\n",
      "Epoch [101/500], Training Loss: 0.1934, Validation Loss: 0.6339, Training Accuracy: 0.9237, Validation Accuracy: 0.8090\n",
      "Epoch [102/500], Training Loss: 0.1788, Validation Loss: 0.6114, Training Accuracy: 0.9287, Validation Accuracy: 0.7978\n",
      "Epoch [103/500], Training Loss: 0.1843, Validation Loss: 0.5796, Training Accuracy: 0.9187, Validation Accuracy: 0.8090\n",
      "Epoch [104/500], Training Loss: 0.1626, Validation Loss: 0.6355, Training Accuracy: 0.9300, Validation Accuracy: 0.7640\n",
      "Epoch [105/500], Training Loss: 0.1727, Validation Loss: 0.6150, Training Accuracy: 0.9350, Validation Accuracy: 0.7753\n",
      "Epoch [106/500], Training Loss: 0.1953, Validation Loss: 0.5939, Training Accuracy: 0.9213, Validation Accuracy: 0.7753\n",
      "Epoch [107/500], Training Loss: 0.1911, Validation Loss: 0.5482, Training Accuracy: 0.9237, Validation Accuracy: 0.7753\n",
      "Epoch [108/500], Training Loss: 0.1863, Validation Loss: 0.5567, Training Accuracy: 0.9325, Validation Accuracy: 0.7865\n",
      "Epoch [109/500], Training Loss: 0.1784, Validation Loss: 0.6350, Training Accuracy: 0.9225, Validation Accuracy: 0.8090\n",
      "Epoch [110/500], Training Loss: 0.1448, Validation Loss: 0.6335, Training Accuracy: 0.9313, Validation Accuracy: 0.7978\n",
      "Epoch [111/500], Training Loss: 0.1393, Validation Loss: 0.6650, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [112/500], Training Loss: 0.1796, Validation Loss: 0.6392, Training Accuracy: 0.9413, Validation Accuracy: 0.8315\n",
      "Epoch [113/500], Training Loss: 0.1955, Validation Loss: 0.5836, Training Accuracy: 0.9163, Validation Accuracy: 0.7865\n",
      "Epoch [114/500], Training Loss: 0.1568, Validation Loss: 0.6269, Training Accuracy: 0.9425, Validation Accuracy: 0.7865\n",
      "Epoch [115/500], Training Loss: 0.1864, Validation Loss: 0.6893, Training Accuracy: 0.9225, Validation Accuracy: 0.7753\n",
      "Epoch [116/500], Training Loss: 0.1642, Validation Loss: 0.6845, Training Accuracy: 0.9350, Validation Accuracy: 0.7865\n",
      "Epoch [117/500], Training Loss: 0.2044, Validation Loss: 0.6360, Training Accuracy: 0.9263, Validation Accuracy: 0.8090\n",
      "Epoch [118/500], Training Loss: 0.1640, Validation Loss: 0.6885, Training Accuracy: 0.9350, Validation Accuracy: 0.7753\n",
      "Epoch [119/500], Training Loss: 0.1855, Validation Loss: 0.6215, Training Accuracy: 0.9313, Validation Accuracy: 0.7978\n",
      "Epoch [120/500], Training Loss: 0.1416, Validation Loss: 0.5986, Training Accuracy: 0.9537, Validation Accuracy: 0.7753\n",
      "Epoch [121/500], Training Loss: 0.1663, Validation Loss: 0.6185, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [122/500], Training Loss: 0.1625, Validation Loss: 0.6168, Training Accuracy: 0.9313, Validation Accuracy: 0.7978\n",
      "Epoch [123/500], Training Loss: 0.1506, Validation Loss: 0.6107, Training Accuracy: 0.9450, Validation Accuracy: 0.7978\n",
      "Epoch [124/500], Training Loss: 0.1325, Validation Loss: 0.6119, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [125/500], Training Loss: 0.1363, Validation Loss: 0.6180, Training Accuracy: 0.9500, Validation Accuracy: 0.7753\n",
      "Epoch [126/500], Training Loss: 0.1384, Validation Loss: 0.6327, Training Accuracy: 0.9463, Validation Accuracy: 0.7753\n",
      "Epoch [127/500], Training Loss: 0.1504, Validation Loss: 0.6038, Training Accuracy: 0.9400, Validation Accuracy: 0.7865\n",
      "Epoch [128/500], Training Loss: 0.1596, Validation Loss: 0.5780, Training Accuracy: 0.9387, Validation Accuracy: 0.8090\n",
      "Epoch [129/500], Training Loss: 0.1176, Validation Loss: 0.5830, Training Accuracy: 0.9500, Validation Accuracy: 0.8090\n",
      "Epoch [130/500], Training Loss: 0.1196, Validation Loss: 0.6151, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [131/500], Training Loss: 0.1328, Validation Loss: 0.5944, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [132/500], Training Loss: 0.1172, Validation Loss: 0.5898, Training Accuracy: 0.9587, Validation Accuracy: 0.7865\n",
      "Epoch [133/500], Training Loss: 0.1268, Validation Loss: 0.6321, Training Accuracy: 0.9463, Validation Accuracy: 0.7865\n",
      "Epoch [134/500], Training Loss: 0.1226, Validation Loss: 0.6414, Training Accuracy: 0.9437, Validation Accuracy: 0.7865\n",
      "Epoch [135/500], Training Loss: 0.1160, Validation Loss: 0.6491, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [136/500], Training Loss: 0.1430, Validation Loss: 0.6522, Training Accuracy: 0.9550, Validation Accuracy: 0.7753\n",
      "Epoch [137/500], Training Loss: 0.1135, Validation Loss: 0.6724, Training Accuracy: 0.9563, Validation Accuracy: 0.7865\n",
      "Epoch [138/500], Training Loss: 0.1173, Validation Loss: 0.6862, Training Accuracy: 0.9525, Validation Accuracy: 0.7865\n",
      "Epoch [139/500], Training Loss: 0.1456, Validation Loss: 0.6723, Training Accuracy: 0.9425, Validation Accuracy: 0.7978\n",
      "Epoch [140/500], Training Loss: 0.1353, Validation Loss: 0.6593, Training Accuracy: 0.9550, Validation Accuracy: 0.7865\n",
      "Epoch [141/500], Training Loss: 0.1267, Validation Loss: 0.6541, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [142/500], Training Loss: 0.1084, Validation Loss: 0.6582, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [143/500], Training Loss: 0.1155, Validation Loss: 0.6643, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [144/500], Training Loss: 0.1192, Validation Loss: 0.6612, Training Accuracy: 0.9625, Validation Accuracy: 0.7978\n",
      "Epoch [145/500], Training Loss: 0.1125, Validation Loss: 0.6635, Training Accuracy: 0.9537, Validation Accuracy: 0.7978\n",
      "Epoch [146/500], Training Loss: 0.1316, Validation Loss: 0.6645, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [147/500], Training Loss: 0.1393, Validation Loss: 0.6633, Training Accuracy: 0.9437, Validation Accuracy: 0.7978\n",
      "Epoch [148/500], Training Loss: 0.1222, Validation Loss: 0.6628, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [149/500], Training Loss: 0.1260, Validation Loss: 0.6628, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [150/500], Training Loss: 0.1118, Validation Loss: 0.6629, Training Accuracy: 0.9637, Validation Accuracy: 0.7978\n",
      "Epoch [151/500], Training Loss: 0.1197, Validation Loss: 0.6629, Training Accuracy: 0.9463, Validation Accuracy: 0.7978\n",
      "Epoch [152/500], Training Loss: 0.1090, Validation Loss: 0.6629, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [153/500], Training Loss: 0.1144, Validation Loss: 0.6637, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [154/500], Training Loss: 0.1028, Validation Loss: 0.6636, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [155/500], Training Loss: 0.1084, Validation Loss: 0.6645, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [156/500], Training Loss: 0.1096, Validation Loss: 0.6657, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [157/500], Training Loss: 0.1051, Validation Loss: 0.6622, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [158/500], Training Loss: 0.1153, Validation Loss: 0.6620, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [159/500], Training Loss: 0.1104, Validation Loss: 0.6633, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [160/500], Training Loss: 0.1170, Validation Loss: 0.6665, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [161/500], Training Loss: 0.1042, Validation Loss: 0.6694, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [162/500], Training Loss: 0.0927, Validation Loss: 0.6763, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [163/500], Training Loss: 0.1134, Validation Loss: 0.6891, Training Accuracy: 0.9500, Validation Accuracy: 0.7865\n",
      "Epoch [164/500], Training Loss: 0.0981, Validation Loss: 0.6986, Training Accuracy: 0.9613, Validation Accuracy: 0.7865\n",
      "Epoch [165/500], Training Loss: 0.1140, Validation Loss: 0.6856, Training Accuracy: 0.9537, Validation Accuracy: 0.7753\n",
      "Epoch [166/500], Training Loss: 0.1327, Validation Loss: 0.6736, Training Accuracy: 0.9475, Validation Accuracy: 0.7865\n",
      "Epoch [167/500], Training Loss: 0.1140, Validation Loss: 0.6628, Training Accuracy: 0.9587, Validation Accuracy: 0.7865\n",
      "Epoch [168/500], Training Loss: 0.1275, Validation Loss: 0.6643, Training Accuracy: 0.9487, Validation Accuracy: 0.7865\n",
      "Epoch [169/500], Training Loss: 0.1258, Validation Loss: 0.6573, Training Accuracy: 0.9487, Validation Accuracy: 0.7978\n",
      "Epoch [170/500], Training Loss: 0.1227, Validation Loss: 0.6717, Training Accuracy: 0.9550, Validation Accuracy: 0.7978\n",
      "Epoch [171/500], Training Loss: 0.1233, Validation Loss: 0.6872, Training Accuracy: 0.9475, Validation Accuracy: 0.8202\n",
      "Epoch [172/500], Training Loss: 0.1002, Validation Loss: 0.6948, Training Accuracy: 0.9675, Validation Accuracy: 0.7978\n",
      "Epoch [173/500], Training Loss: 0.1271, Validation Loss: 0.7268, Training Accuracy: 0.9475, Validation Accuracy: 0.7978\n",
      "Epoch [174/500], Training Loss: 0.1377, Validation Loss: 0.7358, Training Accuracy: 0.9400, Validation Accuracy: 0.7978\n",
      "Epoch [175/500], Training Loss: 0.1342, Validation Loss: 0.7304, Training Accuracy: 0.9500, Validation Accuracy: 0.7978\n",
      "Epoch [176/500], Training Loss: 0.1178, Validation Loss: 0.7347, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [177/500], Training Loss: 0.1212, Validation Loss: 0.7162, Training Accuracy: 0.9487, Validation Accuracy: 0.7978\n",
      "Epoch [178/500], Training Loss: 0.1414, Validation Loss: 0.7306, Training Accuracy: 0.9413, Validation Accuracy: 0.7753\n",
      "Epoch [179/500], Training Loss: 0.1332, Validation Loss: 0.6980, Training Accuracy: 0.9437, Validation Accuracy: 0.7865\n",
      "Epoch [180/500], Training Loss: 0.1248, Validation Loss: 0.6977, Training Accuracy: 0.9525, Validation Accuracy: 0.8090\n",
      "Epoch [181/500], Training Loss: 0.1375, Validation Loss: 0.6693, Training Accuracy: 0.9437, Validation Accuracy: 0.7640\n",
      "Epoch [182/500], Training Loss: 0.1272, Validation Loss: 0.6298, Training Accuracy: 0.9525, Validation Accuracy: 0.8202\n",
      "Epoch [183/500], Training Loss: 0.1247, Validation Loss: 0.6961, Training Accuracy: 0.9513, Validation Accuracy: 0.7978\n",
      "Epoch [184/500], Training Loss: 0.1341, Validation Loss: 0.7223, Training Accuracy: 0.9550, Validation Accuracy: 0.7640\n",
      "Epoch [185/500], Training Loss: 0.1422, Validation Loss: 0.6695, Training Accuracy: 0.9425, Validation Accuracy: 0.7978\n",
      "Epoch [186/500], Training Loss: 0.1219, Validation Loss: 0.6991, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [187/500], Training Loss: 0.1397, Validation Loss: 0.6523, Training Accuracy: 0.9525, Validation Accuracy: 0.8090\n",
      "Epoch [188/500], Training Loss: 0.1433, Validation Loss: 0.6341, Training Accuracy: 0.9437, Validation Accuracy: 0.8427\n",
      "Epoch [189/500], Training Loss: 0.1418, Validation Loss: 0.7637, Training Accuracy: 0.9425, Validation Accuracy: 0.8202\n",
      "Epoch [190/500], Training Loss: 0.1696, Validation Loss: 0.6700, Training Accuracy: 0.9425, Validation Accuracy: 0.7978\n",
      "Epoch [191/500], Training Loss: 0.1370, Validation Loss: 0.6925, Training Accuracy: 0.9513, Validation Accuracy: 0.7865\n",
      "Epoch [192/500], Training Loss: 0.1310, Validation Loss: 0.6967, Training Accuracy: 0.9387, Validation Accuracy: 0.7978\n",
      "Epoch [193/500], Training Loss: 0.1628, Validation Loss: 0.6652, Training Accuracy: 0.9387, Validation Accuracy: 0.8090\n",
      "Epoch [194/500], Training Loss: 0.1469, Validation Loss: 0.6750, Training Accuracy: 0.9450, Validation Accuracy: 0.8090\n",
      "Epoch [195/500], Training Loss: 0.1578, Validation Loss: 0.6667, Training Accuracy: 0.9363, Validation Accuracy: 0.7978\n",
      "Epoch [196/500], Training Loss: 0.1253, Validation Loss: 0.6781, Training Accuracy: 0.9463, Validation Accuracy: 0.8090\n",
      "Epoch [197/500], Training Loss: 0.1476, Validation Loss: 0.6647, Training Accuracy: 0.9437, Validation Accuracy: 0.7865\n",
      "Epoch [198/500], Training Loss: 0.1184, Validation Loss: 0.6723, Training Accuracy: 0.9537, Validation Accuracy: 0.7978\n",
      "Epoch [199/500], Training Loss: 0.1448, Validation Loss: 0.6859, Training Accuracy: 0.9463, Validation Accuracy: 0.8202\n",
      "Epoch [200/500], Training Loss: 0.1243, Validation Loss: 0.7240, Training Accuracy: 0.9500, Validation Accuracy: 0.8090\n",
      "Epoch [201/500], Training Loss: 0.1500, Validation Loss: 0.6788, Training Accuracy: 0.9425, Validation Accuracy: 0.8202\n",
      "Epoch [202/500], Training Loss: 0.1287, Validation Loss: 0.7009, Training Accuracy: 0.9550, Validation Accuracy: 0.8202\n",
      "Epoch [203/500], Training Loss: 0.1168, Validation Loss: 0.7215, Training Accuracy: 0.9537, Validation Accuracy: 0.8315\n",
      "Epoch [204/500], Training Loss: 0.1174, Validation Loss: 0.7983, Training Accuracy: 0.9537, Validation Accuracy: 0.8090\n",
      "Epoch [205/500], Training Loss: 0.1134, Validation Loss: 0.6963, Training Accuracy: 0.9637, Validation Accuracy: 0.8090\n",
      "Epoch [206/500], Training Loss: 0.2577, Validation Loss: 0.7777, Training Accuracy: 0.9463, Validation Accuracy: 0.7640\n",
      "Epoch [207/500], Training Loss: 0.1314, Validation Loss: 0.7248, Training Accuracy: 0.9463, Validation Accuracy: 0.8090\n",
      "Epoch [208/500], Training Loss: 0.1193, Validation Loss: 0.7022, Training Accuracy: 0.9563, Validation Accuracy: 0.8202\n",
      "Epoch [209/500], Training Loss: 0.1290, Validation Loss: 0.6421, Training Accuracy: 0.9437, Validation Accuracy: 0.8315\n",
      "Epoch [210/500], Training Loss: 0.1302, Validation Loss: 0.7420, Training Accuracy: 0.9437, Validation Accuracy: 0.7978\n",
      "Epoch [211/500], Training Loss: 0.1255, Validation Loss: 0.6983, Training Accuracy: 0.9537, Validation Accuracy: 0.8090\n",
      "Epoch [212/500], Training Loss: 0.0969, Validation Loss: 0.7933, Training Accuracy: 0.9613, Validation Accuracy: 0.7865\n",
      "Epoch [213/500], Training Loss: 0.1027, Validation Loss: 1.7121, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [214/500], Training Loss: 0.1299, Validation Loss: 0.7936, Training Accuracy: 0.9563, Validation Accuracy: 0.7978\n",
      "Epoch [215/500], Training Loss: 0.1366, Validation Loss: 0.8215, Training Accuracy: 0.9575, Validation Accuracy: 0.7865\n",
      "Epoch [216/500], Training Loss: 0.1077, Validation Loss: 0.7705, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [217/500], Training Loss: 0.1027, Validation Loss: 0.8360, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [218/500], Training Loss: 0.1080, Validation Loss: 0.7699, Training Accuracy: 0.9600, Validation Accuracy: 0.8090\n",
      "Epoch [219/500], Training Loss: 0.1321, Validation Loss: 0.7329, Training Accuracy: 0.9525, Validation Accuracy: 0.8202\n",
      "Epoch [220/500], Training Loss: 0.1167, Validation Loss: 0.7525, Training Accuracy: 0.9513, Validation Accuracy: 0.8202\n",
      "Epoch [221/500], Training Loss: 0.1271, Validation Loss: 0.7212, Training Accuracy: 0.9525, Validation Accuracy: 0.8090\n",
      "Epoch [222/500], Training Loss: 0.1254, Validation Loss: 0.7643, Training Accuracy: 0.9487, Validation Accuracy: 0.7865\n",
      "Epoch [223/500], Training Loss: 0.0954, Validation Loss: 0.8077, Training Accuracy: 0.9650, Validation Accuracy: 0.8202\n",
      "Epoch [224/500], Training Loss: 0.1053, Validation Loss: 0.7543, Training Accuracy: 0.9587, Validation Accuracy: 0.8090\n",
      "Epoch [225/500], Training Loss: 0.0978, Validation Loss: 0.7504, Training Accuracy: 0.9663, Validation Accuracy: 0.8315\n",
      "Epoch [226/500], Training Loss: 0.0885, Validation Loss: 0.7599, Training Accuracy: 0.9613, Validation Accuracy: 0.8202\n",
      "Epoch [227/500], Training Loss: 0.1053, Validation Loss: 0.7714, Training Accuracy: 0.9650, Validation Accuracy: 0.8315\n",
      "Epoch [228/500], Training Loss: 0.1035, Validation Loss: 0.7907, Training Accuracy: 0.9637, Validation Accuracy: 0.8315\n",
      "Epoch [229/500], Training Loss: 0.0984, Validation Loss: 0.7749, Training Accuracy: 0.9625, Validation Accuracy: 0.8090\n",
      "Epoch [230/500], Training Loss: 0.1239, Validation Loss: 0.7843, Training Accuracy: 0.9587, Validation Accuracy: 0.8202\n",
      "Epoch [231/500], Training Loss: 0.1183, Validation Loss: 0.7886, Training Accuracy: 0.9563, Validation Accuracy: 0.8315\n",
      "Epoch [232/500], Training Loss: 0.1062, Validation Loss: 0.8068, Training Accuracy: 0.9650, Validation Accuracy: 0.8315\n",
      "Epoch [233/500], Training Loss: 0.0840, Validation Loss: 0.8381, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [234/500], Training Loss: 0.1013, Validation Loss: 0.8191, Training Accuracy: 0.9575, Validation Accuracy: 0.8315\n",
      "Epoch [235/500], Training Loss: 0.0917, Validation Loss: 0.7912, Training Accuracy: 0.9663, Validation Accuracy: 0.8315\n",
      "Epoch [236/500], Training Loss: 0.0800, Validation Loss: 0.7995, Training Accuracy: 0.9700, Validation Accuracy: 0.8315\n",
      "Epoch [237/500], Training Loss: 0.0799, Validation Loss: 0.8086, Training Accuracy: 0.9688, Validation Accuracy: 0.8315\n",
      "Epoch [238/500], Training Loss: 0.0877, Validation Loss: 0.8175, Training Accuracy: 0.9688, Validation Accuracy: 0.8202\n",
      "Epoch [239/500], Training Loss: 0.0827, Validation Loss: 0.8062, Training Accuracy: 0.9738, Validation Accuracy: 0.8315\n",
      "Epoch [240/500], Training Loss: 0.0762, Validation Loss: 0.8160, Training Accuracy: 0.9712, Validation Accuracy: 0.8202\n",
      "Epoch [241/500], Training Loss: 0.1053, Validation Loss: 0.8143, Training Accuracy: 0.9613, Validation Accuracy: 0.8202\n",
      "Epoch [242/500], Training Loss: 0.0806, Validation Loss: 0.8157, Training Accuracy: 0.9688, Validation Accuracy: 0.8202\n",
      "Epoch [243/500], Training Loss: 0.0891, Validation Loss: 0.8186, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [244/500], Training Loss: 0.0707, Validation Loss: 0.8209, Training Accuracy: 0.9700, Validation Accuracy: 0.8202\n",
      "Epoch [245/500], Training Loss: 0.0750, Validation Loss: 0.8206, Training Accuracy: 0.9738, Validation Accuracy: 0.8202\n",
      "Epoch [246/500], Training Loss: 0.0896, Validation Loss: 0.8206, Training Accuracy: 0.9650, Validation Accuracy: 0.8202\n",
      "Epoch [247/500], Training Loss: 0.0768, Validation Loss: 0.8230, Training Accuracy: 0.9738, Validation Accuracy: 0.8202\n",
      "Epoch [248/500], Training Loss: 0.0898, Validation Loss: 0.8240, Training Accuracy: 0.9587, Validation Accuracy: 0.8202\n",
      "Epoch [249/500], Training Loss: 0.0722, Validation Loss: 0.8239, Training Accuracy: 0.9738, Validation Accuracy: 0.8202\n",
      "Epoch [250/500], Training Loss: 0.0647, Validation Loss: 0.8240, Training Accuracy: 0.9788, Validation Accuracy: 0.8202\n",
      "Epoch [251/500], Training Loss: 0.0649, Validation Loss: 0.8240, Training Accuracy: 0.9700, Validation Accuracy: 0.8202\n",
      "Epoch [252/500], Training Loss: 0.0885, Validation Loss: 0.8240, Training Accuracy: 0.9688, Validation Accuracy: 0.8202\n",
      "Epoch [253/500], Training Loss: 0.0881, Validation Loss: 0.8240, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [254/500], Training Loss: 0.0936, Validation Loss: 0.8235, Training Accuracy: 0.9700, Validation Accuracy: 0.8202\n",
      "Epoch [255/500], Training Loss: 0.0838, Validation Loss: 0.8232, Training Accuracy: 0.9725, Validation Accuracy: 0.8202\n",
      "Epoch [256/500], Training Loss: 0.0901, Validation Loss: 0.8216, Training Accuracy: 0.9637, Validation Accuracy: 0.8202\n",
      "Epoch [257/500], Training Loss: 0.0759, Validation Loss: 0.8226, Training Accuracy: 0.9712, Validation Accuracy: 0.8202\n",
      "Epoch [258/500], Training Loss: 0.0703, Validation Loss: 0.8218, Training Accuracy: 0.9688, Validation Accuracy: 0.8315\n",
      "Epoch [259/500], Training Loss: 0.0723, Validation Loss: 0.8281, Training Accuracy: 0.9738, Validation Accuracy: 0.8315\n",
      "Epoch [260/500], Training Loss: 0.0890, Validation Loss: 0.8248, Training Accuracy: 0.9688, Validation Accuracy: 0.8315\n",
      "Epoch [261/500], Training Loss: 0.0809, Validation Loss: 0.8241, Training Accuracy: 0.9675, Validation Accuracy: 0.8315\n",
      "Epoch [262/500], Training Loss: 0.0954, Validation Loss: 0.8294, Training Accuracy: 0.9675, Validation Accuracy: 0.8315\n",
      "Epoch [263/500], Training Loss: 0.0804, Validation Loss: 0.8257, Training Accuracy: 0.9688, Validation Accuracy: 0.8202\n",
      "Epoch [264/500], Training Loss: 0.0920, Validation Loss: 0.8228, Training Accuracy: 0.9712, Validation Accuracy: 0.8202\n",
      "Epoch [265/500], Training Loss: 0.0817, Validation Loss: 0.8311, Training Accuracy: 0.9750, Validation Accuracy: 0.8202\n",
      "Epoch [266/500], Training Loss: 0.0705, Validation Loss: 0.8462, Training Accuracy: 0.9663, Validation Accuracy: 0.8315\n",
      "Epoch [267/500], Training Loss: 0.0904, Validation Loss: 0.8336, Training Accuracy: 0.9637, Validation Accuracy: 0.8202\n",
      "Epoch [268/500], Training Loss: 0.0791, Validation Loss: 0.8401, Training Accuracy: 0.9725, Validation Accuracy: 0.8202\n",
      "Epoch [269/500], Training Loss: 0.0892, Validation Loss: 0.8312, Training Accuracy: 0.9712, Validation Accuracy: 0.8315\n",
      "Epoch [270/500], Training Loss: 0.0719, Validation Loss: 0.8285, Training Accuracy: 0.9725, Validation Accuracy: 0.8202\n",
      "Epoch [271/500], Training Loss: 0.0773, Validation Loss: 0.8235, Training Accuracy: 0.9738, Validation Accuracy: 0.8202\n",
      "Epoch [272/500], Training Loss: 0.0966, Validation Loss: 0.8402, Training Accuracy: 0.9675, Validation Accuracy: 0.8202\n",
      "Epoch [273/500], Training Loss: 0.0921, Validation Loss: 0.8505, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [274/500], Training Loss: 0.0787, Validation Loss: 1.7568, Training Accuracy: 0.9675, Validation Accuracy: 0.7978\n",
      "Epoch [275/500], Training Loss: 0.0756, Validation Loss: 0.8444, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [276/500], Training Loss: 0.0931, Validation Loss: 0.8158, Training Accuracy: 0.9637, Validation Accuracy: 0.8202\n",
      "Epoch [277/500], Training Loss: 0.0961, Validation Loss: 0.8135, Training Accuracy: 0.9650, Validation Accuracy: 0.8202\n",
      "Epoch [278/500], Training Loss: 0.0945, Validation Loss: 0.8658, Training Accuracy: 0.9575, Validation Accuracy: 0.8090\n",
      "Epoch [279/500], Training Loss: 0.0829, Validation Loss: 0.8257, Training Accuracy: 0.9762, Validation Accuracy: 0.8315\n",
      "Epoch [280/500], Training Loss: 0.0928, Validation Loss: 1.7285, Training Accuracy: 0.9613, Validation Accuracy: 0.7865\n",
      "Epoch [281/500], Training Loss: 0.1178, Validation Loss: 0.7617, Training Accuracy: 0.9537, Validation Accuracy: 0.8202\n",
      "Epoch [282/500], Training Loss: 0.0804, Validation Loss: 0.8034, Training Accuracy: 0.9750, Validation Accuracy: 0.8427\n",
      "Epoch [283/500], Training Loss: 0.0921, Validation Loss: 1.7483, Training Accuracy: 0.9663, Validation Accuracy: 0.8090\n",
      "Epoch [284/500], Training Loss: 0.1230, Validation Loss: 0.8196, Training Accuracy: 0.9525, Validation Accuracy: 0.8202\n",
      "Epoch [285/500], Training Loss: 0.1038, Validation Loss: 1.7567, Training Accuracy: 0.9625, Validation Accuracy: 0.7978\n",
      "Epoch [286/500], Training Loss: 0.0931, Validation Loss: 0.8349, Training Accuracy: 0.9637, Validation Accuracy: 0.8427\n",
      "Epoch [287/500], Training Loss: 0.1210, Validation Loss: 1.6983, Training Accuracy: 0.9575, Validation Accuracy: 0.7978\n",
      "Epoch [288/500], Training Loss: 0.0953, Validation Loss: 1.7328, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [289/500], Training Loss: 0.0812, Validation Loss: 1.7443, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [290/500], Training Loss: 0.0839, Validation Loss: 1.7361, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [291/500], Training Loss: 0.1026, Validation Loss: 1.7997, Training Accuracy: 0.9650, Validation Accuracy: 0.8315\n",
      "Epoch [292/500], Training Loss: 0.1022, Validation Loss: 1.7174, Training Accuracy: 0.9600, Validation Accuracy: 0.8202\n",
      "Epoch [293/500], Training Loss: 0.1397, Validation Loss: 1.7572, Training Accuracy: 0.9525, Validation Accuracy: 0.7978\n",
      "Epoch [294/500], Training Loss: 0.0969, Validation Loss: 1.7906, Training Accuracy: 0.9587, Validation Accuracy: 0.7978\n",
      "Epoch [295/500], Training Loss: 0.1104, Validation Loss: 0.8532, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [296/500], Training Loss: 0.0937, Validation Loss: 1.7280, Training Accuracy: 0.9663, Validation Accuracy: 0.8090\n",
      "Epoch [297/500], Training Loss: 0.1047, Validation Loss: 1.7265, Training Accuracy: 0.9637, Validation Accuracy: 0.8202\n",
      "Epoch [298/500], Training Loss: 0.1048, Validation Loss: 0.8159, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [299/500], Training Loss: 0.0953, Validation Loss: 0.7843, Training Accuracy: 0.9637, Validation Accuracy: 0.7978\n",
      "Epoch [300/500], Training Loss: 0.1419, Validation Loss: 0.8576, Training Accuracy: 0.9550, Validation Accuracy: 0.8090\n",
      "Epoch [301/500], Training Loss: 0.0993, Validation Loss: 1.6952, Training Accuracy: 0.9625, Validation Accuracy: 0.8202\n",
      "Epoch [302/500], Training Loss: 0.1033, Validation Loss: 1.7444, Training Accuracy: 0.9637, Validation Accuracy: 0.8202\n",
      "Epoch [303/500], Training Loss: 0.1152, Validation Loss: 1.7901, Training Accuracy: 0.9575, Validation Accuracy: 0.7865\n",
      "Epoch [304/500], Training Loss: 0.0946, Validation Loss: 0.8433, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [305/500], Training Loss: 0.0879, Validation Loss: 1.7657, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [306/500], Training Loss: 0.1033, Validation Loss: 1.7309, Training Accuracy: 0.9613, Validation Accuracy: 0.8202\n",
      "Epoch [307/500], Training Loss: 0.1277, Validation Loss: 1.6943, Training Accuracy: 0.9525, Validation Accuracy: 0.8090\n",
      "Epoch [308/500], Training Loss: 0.1118, Validation Loss: 1.5889, Training Accuracy: 0.9563, Validation Accuracy: 0.8090\n",
      "Epoch [309/500], Training Loss: 0.1039, Validation Loss: 1.6285, Training Accuracy: 0.9587, Validation Accuracy: 0.8202\n",
      "Epoch [310/500], Training Loss: 0.0811, Validation Loss: 1.6737, Training Accuracy: 0.9637, Validation Accuracy: 0.7865\n",
      "Epoch [311/500], Training Loss: 0.1000, Validation Loss: 0.7578, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [312/500], Training Loss: 0.1003, Validation Loss: 0.7737, Training Accuracy: 0.9637, Validation Accuracy: 0.8427\n",
      "Epoch [313/500], Training Loss: 0.1099, Validation Loss: 0.8112, Training Accuracy: 0.9513, Validation Accuracy: 0.8202\n",
      "Epoch [314/500], Training Loss: 0.0929, Validation Loss: 0.8033, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [315/500], Training Loss: 0.0931, Validation Loss: 1.7633, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [316/500], Training Loss: 0.1038, Validation Loss: 0.9248, Training Accuracy: 0.9650, Validation Accuracy: 0.7753\n",
      "Epoch [317/500], Training Loss: 0.1009, Validation Loss: 0.9374, Training Accuracy: 0.9600, Validation Accuracy: 0.7865\n",
      "Epoch [318/500], Training Loss: 0.1046, Validation Loss: 0.7971, Training Accuracy: 0.9650, Validation Accuracy: 0.7865\n",
      "Epoch [319/500], Training Loss: 0.0959, Validation Loss: 1.6893, Training Accuracy: 0.9663, Validation Accuracy: 0.7865\n",
      "Epoch [320/500], Training Loss: 0.0955, Validation Loss: 1.6870, Training Accuracy: 0.9688, Validation Accuracy: 0.7865\n",
      "Epoch [321/500], Training Loss: 0.0877, Validation Loss: 1.7263, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [322/500], Training Loss: 0.0826, Validation Loss: 1.7437, Training Accuracy: 0.9725, Validation Accuracy: 0.7753\n",
      "Epoch [323/500], Training Loss: 0.0706, Validation Loss: 1.7393, Training Accuracy: 0.9812, Validation Accuracy: 0.7865\n",
      "Epoch [324/500], Training Loss: 0.0758, Validation Loss: 1.7025, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [325/500], Training Loss: 0.0989, Validation Loss: 1.7042, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [326/500], Training Loss: 0.0894, Validation Loss: 1.6985, Training Accuracy: 0.9663, Validation Accuracy: 0.8202\n",
      "Epoch [327/500], Training Loss: 0.0800, Validation Loss: 1.7126, Training Accuracy: 0.9725, Validation Accuracy: 0.8315\n",
      "Epoch [328/500], Training Loss: 0.0623, Validation Loss: 1.7312, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [329/500], Training Loss: 0.0827, Validation Loss: 1.7626, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [330/500], Training Loss: 0.0790, Validation Loss: 1.7733, Training Accuracy: 0.9700, Validation Accuracy: 0.8090\n",
      "Epoch [331/500], Training Loss: 0.0635, Validation Loss: 1.7981, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [332/500], Training Loss: 0.0557, Validation Loss: 1.7935, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [333/500], Training Loss: 0.0797, Validation Loss: 1.7826, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [334/500], Training Loss: 0.0546, Validation Loss: 1.7815, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [335/500], Training Loss: 0.0491, Validation Loss: 1.7732, Training Accuracy: 0.9838, Validation Accuracy: 0.8090\n",
      "Epoch [336/500], Training Loss: 0.0638, Validation Loss: 1.7867, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [337/500], Training Loss: 0.0748, Validation Loss: 1.7790, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [338/500], Training Loss: 0.0814, Validation Loss: 1.7631, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [339/500], Training Loss: 0.0600, Validation Loss: 1.7711, Training Accuracy: 0.9788, Validation Accuracy: 0.7978\n",
      "Epoch [340/500], Training Loss: 0.0635, Validation Loss: 1.7842, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [341/500], Training Loss: 0.0566, Validation Loss: 1.7924, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [342/500], Training Loss: 0.0612, Validation Loss: 1.7994, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [343/500], Training Loss: 0.0700, Validation Loss: 1.8025, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [344/500], Training Loss: 0.0687, Validation Loss: 1.8068, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [345/500], Training Loss: 0.0798, Validation Loss: 1.8032, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [346/500], Training Loss: 0.0573, Validation Loss: 1.8008, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [347/500], Training Loss: 0.0659, Validation Loss: 1.8006, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [348/500], Training Loss: 0.0597, Validation Loss: 1.7999, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [349/500], Training Loss: 0.0814, Validation Loss: 1.7999, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [350/500], Training Loss: 0.0622, Validation Loss: 1.7998, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [351/500], Training Loss: 0.0555, Validation Loss: 1.7998, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [352/500], Training Loss: 0.0671, Validation Loss: 1.7999, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [353/500], Training Loss: 0.0529, Validation Loss: 1.7999, Training Accuracy: 0.9850, Validation Accuracy: 0.7978\n",
      "Epoch [354/500], Training Loss: 0.0531, Validation Loss: 1.8005, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [355/500], Training Loss: 0.0714, Validation Loss: 1.7991, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [356/500], Training Loss: 0.0788, Validation Loss: 1.8008, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [357/500], Training Loss: 0.0730, Validation Loss: 1.8012, Training Accuracy: 0.9675, Validation Accuracy: 0.7978\n",
      "Epoch [358/500], Training Loss: 0.0595, Validation Loss: 1.7998, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [359/500], Training Loss: 0.0560, Validation Loss: 1.8005, Training Accuracy: 0.9800, Validation Accuracy: 0.7978\n",
      "Epoch [360/500], Training Loss: 0.0611, Validation Loss: 1.7981, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [361/500], Training Loss: 0.0643, Validation Loss: 1.7866, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [362/500], Training Loss: 0.0745, Validation Loss: 1.7901, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [363/500], Training Loss: 0.0489, Validation Loss: 1.7846, Training Accuracy: 0.9812, Validation Accuracy: 0.7978\n",
      "Epoch [364/500], Training Loss: 0.0574, Validation Loss: 1.7964, Training Accuracy: 0.9775, Validation Accuracy: 0.8090\n",
      "Epoch [365/500], Training Loss: 0.0816, Validation Loss: 1.7912, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [366/500], Training Loss: 0.0588, Validation Loss: 1.8024, Training Accuracy: 0.9838, Validation Accuracy: 0.8090\n",
      "Epoch [367/500], Training Loss: 0.0617, Validation Loss: 1.8189, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [368/500], Training Loss: 0.0707, Validation Loss: 1.8041, Training Accuracy: 0.9688, Validation Accuracy: 0.8090\n",
      "Epoch [369/500], Training Loss: 0.0995, Validation Loss: 1.7853, Training Accuracy: 0.9688, Validation Accuracy: 0.8090\n",
      "Epoch [370/500], Training Loss: 0.0919, Validation Loss: 1.7858, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [371/500], Training Loss: 0.0609, Validation Loss: 1.8183, Training Accuracy: 0.9775, Validation Accuracy: 0.8090\n",
      "Epoch [372/500], Training Loss: 0.0625, Validation Loss: 1.7891, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [373/500], Training Loss: 0.0626, Validation Loss: 1.8188, Training Accuracy: 0.9775, Validation Accuracy: 0.7865\n",
      "Epoch [374/500], Training Loss: 0.0619, Validation Loss: 1.8003, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [375/500], Training Loss: 0.0632, Validation Loss: 1.8606, Training Accuracy: 0.9788, Validation Accuracy: 0.7640\n",
      "Epoch [376/500], Training Loss: 0.0725, Validation Loss: 1.8313, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [377/500], Training Loss: 0.0833, Validation Loss: 1.8026, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [378/500], Training Loss: 0.0602, Validation Loss: 1.8368, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [379/500], Training Loss: 0.0819, Validation Loss: 1.8030, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [380/500], Training Loss: 0.0845, Validation Loss: 1.8537, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [381/500], Training Loss: 0.0851, Validation Loss: 1.8612, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [382/500], Training Loss: 0.0707, Validation Loss: 1.8683, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [383/500], Training Loss: 0.0653, Validation Loss: 1.8208, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [384/500], Training Loss: 0.0819, Validation Loss: 1.8494, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [385/500], Training Loss: 0.0733, Validation Loss: 1.7938, Training Accuracy: 0.9750, Validation Accuracy: 0.7640\n",
      "Epoch [386/500], Training Loss: 0.0823, Validation Loss: 1.8604, Training Accuracy: 0.9712, Validation Accuracy: 0.7753\n",
      "Epoch [387/500], Training Loss: 0.0858, Validation Loss: 1.7539, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [388/500], Training Loss: 0.0811, Validation Loss: 1.8491, Training Accuracy: 0.9650, Validation Accuracy: 0.7865\n",
      "Epoch [389/500], Training Loss: 0.0880, Validation Loss: 1.7802, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [390/500], Training Loss: 0.0935, Validation Loss: 1.7291, Training Accuracy: 0.9637, Validation Accuracy: 0.7978\n",
      "Epoch [391/500], Training Loss: 0.0885, Validation Loss: 1.7342, Training Accuracy: 0.9750, Validation Accuracy: 0.8202\n",
      "Epoch [392/500], Training Loss: 0.0687, Validation Loss: 1.7661, Training Accuracy: 0.9775, Validation Accuracy: 0.7865\n",
      "Epoch [393/500], Training Loss: 0.0858, Validation Loss: 1.8070, Training Accuracy: 0.9738, Validation Accuracy: 0.7865\n",
      "Epoch [394/500], Training Loss: 0.0754, Validation Loss: 1.7903, Training Accuracy: 0.9725, Validation Accuracy: 0.7978\n",
      "Epoch [395/500], Training Loss: 0.0850, Validation Loss: 1.7921, Training Accuracy: 0.9712, Validation Accuracy: 0.8090\n",
      "Epoch [396/500], Training Loss: 0.0805, Validation Loss: 1.8312, Training Accuracy: 0.9750, Validation Accuracy: 0.8315\n",
      "Epoch [397/500], Training Loss: 0.0947, Validation Loss: 1.7979, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [398/500], Training Loss: 0.0732, Validation Loss: 1.8172, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [399/500], Training Loss: 0.0822, Validation Loss: 1.8327, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [400/500], Training Loss: 0.1115, Validation Loss: 0.9320, Training Accuracy: 0.9637, Validation Accuracy: 0.8090\n",
      "Epoch [401/500], Training Loss: 0.0895, Validation Loss: 1.7644, Training Accuracy: 0.9700, Validation Accuracy: 0.8202\n",
      "Epoch [402/500], Training Loss: 0.0890, Validation Loss: 0.9267, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [403/500], Training Loss: 0.1098, Validation Loss: 1.7086, Training Accuracy: 0.9537, Validation Accuracy: 0.7978\n",
      "Epoch [404/500], Training Loss: 0.0868, Validation Loss: 1.7280, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [405/500], Training Loss: 0.1048, Validation Loss: 1.6728, Training Accuracy: 0.9600, Validation Accuracy: 0.8202\n",
      "Epoch [406/500], Training Loss: 0.0976, Validation Loss: 1.6621, Training Accuracy: 0.9700, Validation Accuracy: 0.7978\n",
      "Epoch [407/500], Training Loss: 0.0878, Validation Loss: 1.6649, Training Accuracy: 0.9663, Validation Accuracy: 0.7978\n",
      "Epoch [408/500], Training Loss: 0.0812, Validation Loss: 1.7313, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [409/500], Training Loss: 0.2126, Validation Loss: 1.7819, Training Accuracy: 0.9613, Validation Accuracy: 0.7978\n",
      "Epoch [410/500], Training Loss: 0.0752, Validation Loss: 1.7449, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [411/500], Training Loss: 0.1098, Validation Loss: 1.7268, Training Accuracy: 0.9600, Validation Accuracy: 0.7978\n",
      "Epoch [412/500], Training Loss: 0.0827, Validation Loss: 1.6772, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [413/500], Training Loss: 0.0896, Validation Loss: 1.6894, Training Accuracy: 0.9637, Validation Accuracy: 0.7978\n",
      "Epoch [414/500], Training Loss: 0.0893, Validation Loss: 1.7401, Training Accuracy: 0.9650, Validation Accuracy: 0.8090\n",
      "Epoch [415/500], Training Loss: 0.0857, Validation Loss: 1.8042, Training Accuracy: 0.9700, Validation Accuracy: 0.8202\n",
      "Epoch [416/500], Training Loss: 0.0630, Validation Loss: 1.8043, Training Accuracy: 0.9812, Validation Accuracy: 0.7865\n",
      "Epoch [417/500], Training Loss: 0.0651, Validation Loss: 1.8394, Training Accuracy: 0.9750, Validation Accuracy: 0.7978\n",
      "Epoch [418/500], Training Loss: 0.0765, Validation Loss: 1.8125, Training Accuracy: 0.9712, Validation Accuracy: 0.8090\n",
      "Epoch [419/500], Training Loss: 0.0868, Validation Loss: 1.8352, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [420/500], Training Loss: 0.0721, Validation Loss: 1.8495, Training Accuracy: 0.9775, Validation Accuracy: 0.8202\n",
      "Epoch [421/500], Training Loss: 0.0838, Validation Loss: 1.8262, Training Accuracy: 0.9700, Validation Accuracy: 0.8090\n",
      "Epoch [422/500], Training Loss: 0.0696, Validation Loss: 1.8063, Training Accuracy: 0.9762, Validation Accuracy: 0.8202\n",
      "Epoch [423/500], Training Loss: 0.0996, Validation Loss: 1.7730, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [424/500], Training Loss: 0.0750, Validation Loss: 1.7409, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [425/500], Training Loss: 0.0713, Validation Loss: 1.7453, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [426/500], Training Loss: 0.0698, Validation Loss: 1.7421, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [427/500], Training Loss: 0.0687, Validation Loss: 1.7583, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [428/500], Training Loss: 0.0505, Validation Loss: 1.7617, Training Accuracy: 0.9825, Validation Accuracy: 0.8202\n",
      "Epoch [429/500], Training Loss: 0.0500, Validation Loss: 1.7957, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [430/500], Training Loss: 0.0755, Validation Loss: 1.8020, Training Accuracy: 0.9750, Validation Accuracy: 0.8202\n",
      "Epoch [431/500], Training Loss: 0.0535, Validation Loss: 1.7907, Training Accuracy: 0.9825, Validation Accuracy: 0.7978\n",
      "Epoch [432/500], Training Loss: 0.0559, Validation Loss: 1.7936, Training Accuracy: 0.9788, Validation Accuracy: 0.8202\n",
      "Epoch [433/500], Training Loss: 0.0712, Validation Loss: 1.7994, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [434/500], Training Loss: 0.0649, Validation Loss: 1.7968, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [435/500], Training Loss: 0.0685, Validation Loss: 1.7998, Training Accuracy: 0.9712, Validation Accuracy: 0.8090\n",
      "Epoch [436/500], Training Loss: 0.0511, Validation Loss: 1.7897, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [437/500], Training Loss: 0.0580, Validation Loss: 1.7948, Training Accuracy: 0.9800, Validation Accuracy: 0.8090\n",
      "Epoch [438/500], Training Loss: 0.0598, Validation Loss: 1.8013, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [439/500], Training Loss: 0.0547, Validation Loss: 1.8044, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [440/500], Training Loss: 0.0525, Validation Loss: 1.7979, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [441/500], Training Loss: 0.0544, Validation Loss: 1.8173, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [442/500], Training Loss: 0.0488, Validation Loss: 1.8157, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [443/500], Training Loss: 0.0582, Validation Loss: 1.8179, Training Accuracy: 0.9838, Validation Accuracy: 0.8090\n",
      "Epoch [444/500], Training Loss: 0.0468, Validation Loss: 1.8166, Training Accuracy: 0.9838, Validation Accuracy: 0.8090\n",
      "Epoch [445/500], Training Loss: 0.0522, Validation Loss: 1.8209, Training Accuracy: 0.9812, Validation Accuracy: 0.8090\n",
      "Epoch [446/500], Training Loss: 0.0416, Validation Loss: 1.8236, Training Accuracy: 0.9812, Validation Accuracy: 0.8090\n",
      "Epoch [447/500], Training Loss: 0.0598, Validation Loss: 1.8241, Training Accuracy: 0.9775, Validation Accuracy: 0.8090\n",
      "Epoch [448/500], Training Loss: 0.0485, Validation Loss: 1.8243, Training Accuracy: 0.9850, Validation Accuracy: 0.8090\n",
      "Epoch [449/500], Training Loss: 0.0559, Validation Loss: 1.8247, Training Accuracy: 0.9812, Validation Accuracy: 0.8090\n",
      "Epoch [450/500], Training Loss: 0.0577, Validation Loss: 1.8247, Training Accuracy: 0.9800, Validation Accuracy: 0.8090\n",
      "Epoch [451/500], Training Loss: 0.0405, Validation Loss: 1.8247, Training Accuracy: 0.9850, Validation Accuracy: 0.8090\n",
      "Epoch [452/500], Training Loss: 0.0639, Validation Loss: 1.8247, Training Accuracy: 0.9750, Validation Accuracy: 0.8090\n",
      "Epoch [453/500], Training Loss: 0.0522, Validation Loss: 1.8249, Training Accuracy: 0.9850, Validation Accuracy: 0.8090\n",
      "Epoch [454/500], Training Loss: 0.0686, Validation Loss: 1.8258, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [455/500], Training Loss: 0.0545, Validation Loss: 1.8262, Training Accuracy: 0.9812, Validation Accuracy: 0.8090\n",
      "Epoch [456/500], Training Loss: 0.0601, Validation Loss: 1.8276, Training Accuracy: 0.9775, Validation Accuracy: 0.8090\n",
      "Epoch [457/500], Training Loss: 0.0727, Validation Loss: 1.8306, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [458/500], Training Loss: 0.0692, Validation Loss: 1.8348, Training Accuracy: 0.9812, Validation Accuracy: 0.8090\n",
      "Epoch [459/500], Training Loss: 0.0548, Validation Loss: 1.8350, Training Accuracy: 0.9800, Validation Accuracy: 0.8090\n",
      "Epoch [460/500], Training Loss: 0.0469, Validation Loss: 1.8306, Training Accuracy: 0.9838, Validation Accuracy: 0.8090\n",
      "Epoch [461/500], Training Loss: 0.0412, Validation Loss: 1.8391, Training Accuracy: 0.9850, Validation Accuracy: 0.8090\n",
      "Epoch [462/500], Training Loss: 0.0644, Validation Loss: 1.8331, Training Accuracy: 0.9800, Validation Accuracy: 0.8090\n",
      "Epoch [463/500], Training Loss: 0.0345, Validation Loss: 1.8265, Training Accuracy: 0.9900, Validation Accuracy: 0.8090\n",
      "Epoch [464/500], Training Loss: 0.0444, Validation Loss: 1.8438, Training Accuracy: 0.9875, Validation Accuracy: 0.8090\n",
      "Epoch [465/500], Training Loss: 0.0497, Validation Loss: 1.8162, Training Accuracy: 0.9862, Validation Accuracy: 0.8090\n",
      "Epoch [466/500], Training Loss: 0.0478, Validation Loss: 1.8170, Training Accuracy: 0.9838, Validation Accuracy: 0.7978\n",
      "Epoch [467/500], Training Loss: 0.0378, Validation Loss: 1.8488, Training Accuracy: 0.9888, Validation Accuracy: 0.7865\n",
      "Epoch [468/500], Training Loss: 0.0441, Validation Loss: 1.8750, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [469/500], Training Loss: 0.0593, Validation Loss: 1.8480, Training Accuracy: 0.9738, Validation Accuracy: 0.8090\n",
      "Epoch [470/500], Training Loss: 0.0455, Validation Loss: 1.8542, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [471/500], Training Loss: 0.0545, Validation Loss: 1.8763, Training Accuracy: 0.9850, Validation Accuracy: 0.8202\n",
      "Epoch [472/500], Training Loss: 0.0553, Validation Loss: 1.8688, Training Accuracy: 0.9825, Validation Accuracy: 0.8090\n",
      "Epoch [473/500], Training Loss: 0.0427, Validation Loss: 1.8563, Training Accuracy: 0.9850, Validation Accuracy: 0.8202\n",
      "Epoch [474/500], Training Loss: 0.0520, Validation Loss: 1.8315, Training Accuracy: 0.9812, Validation Accuracy: 0.8202\n",
      "Epoch [475/500], Training Loss: 0.0546, Validation Loss: 1.8192, Training Accuracy: 0.9788, Validation Accuracy: 0.8090\n",
      "Epoch [476/500], Training Loss: 0.0690, Validation Loss: 1.9218, Training Accuracy: 0.9775, Validation Accuracy: 0.7978\n",
      "Epoch [477/500], Training Loss: 0.0784, Validation Loss: 1.8797, Training Accuracy: 0.9738, Validation Accuracy: 0.7978\n",
      "Epoch [478/500], Training Loss: 0.0558, Validation Loss: 1.8930, Training Accuracy: 0.9800, Validation Accuracy: 0.7865\n",
      "Epoch [479/500], Training Loss: 0.0734, Validation Loss: 1.8431, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [480/500], Training Loss: 0.0695, Validation Loss: 1.8291, Training Accuracy: 0.9725, Validation Accuracy: 0.8315\n",
      "Epoch [481/500], Training Loss: 0.0772, Validation Loss: 1.8114, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [482/500], Training Loss: 0.0624, Validation Loss: 1.8725, Training Accuracy: 0.9712, Validation Accuracy: 0.7978\n",
      "Epoch [483/500], Training Loss: 0.0735, Validation Loss: 1.8632, Training Accuracy: 0.9762, Validation Accuracy: 0.7978\n",
      "Epoch [484/500], Training Loss: 0.0640, Validation Loss: 1.8453, Training Accuracy: 0.9750, Validation Accuracy: 0.8202\n",
      "Epoch [485/500], Training Loss: 0.0725, Validation Loss: 1.8571, Training Accuracy: 0.9688, Validation Accuracy: 0.7640\n",
      "Epoch [486/500], Training Loss: 0.0704, Validation Loss: 1.8683, Training Accuracy: 0.9788, Validation Accuracy: 0.7865\n",
      "Epoch [487/500], Training Loss: 0.0766, Validation Loss: 1.7917, Training Accuracy: 0.9712, Validation Accuracy: 0.7865\n",
      "Epoch [488/500], Training Loss: 0.1049, Validation Loss: 1.8360, Training Accuracy: 0.9762, Validation Accuracy: 0.7865\n",
      "Epoch [489/500], Training Loss: 0.0704, Validation Loss: 1.8861, Training Accuracy: 0.9762, Validation Accuracy: 0.8090\n",
      "Epoch [490/500], Training Loss: 0.0849, Validation Loss: 1.9107, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [491/500], Training Loss: 0.0423, Validation Loss: 1.8425, Training Accuracy: 0.9812, Validation Accuracy: 0.7753\n",
      "Epoch [492/500], Training Loss: 0.0745, Validation Loss: 1.8640, Training Accuracy: 0.9750, Validation Accuracy: 0.7865\n",
      "Epoch [493/500], Training Loss: 0.0865, Validation Loss: 1.8361, Training Accuracy: 0.9650, Validation Accuracy: 0.7978\n",
      "Epoch [494/500], Training Loss: 0.0784, Validation Loss: 1.8059, Training Accuracy: 0.9700, Validation Accuracy: 0.7865\n",
      "Epoch [495/500], Training Loss: 0.0958, Validation Loss: 1.8603, Training Accuracy: 0.9625, Validation Accuracy: 0.7865\n",
      "Epoch [496/500], Training Loss: 0.0808, Validation Loss: 1.9043, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [497/500], Training Loss: 0.0637, Validation Loss: 1.8336, Training Accuracy: 0.9800, Validation Accuracy: 0.8090\n",
      "Epoch [498/500], Training Loss: 0.0869, Validation Loss: 1.7439, Training Accuracy: 0.9688, Validation Accuracy: 0.7978\n",
      "Epoch [499/500], Training Loss: 0.0783, Validation Loss: 1.7429, Training Accuracy: 0.9675, Validation Accuracy: 0.8090\n",
      "Epoch [500/500], Training Loss: 0.0817, Validation Loss: 0.8175, Training Accuracy: 0.9750, Validation Accuracy: 0.8202\n",
      "Training Time: 19.41 seconds\n",
      "Epoch [1/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [2/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [3/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [4/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [5/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [6/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [7/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [8/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [9/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [10/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [11/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [12/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [13/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [14/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [15/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [16/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [17/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [18/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [19/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [20/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [21/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [22/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [23/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [24/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [25/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [26/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [27/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [28/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [29/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [30/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [31/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [32/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [33/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [34/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [35/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [36/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [37/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [38/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [39/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [40/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [41/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [42/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [43/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [44/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [45/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [46/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [47/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [48/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [49/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [50/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [51/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [52/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [53/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [54/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [55/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [56/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [57/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [58/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [59/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [60/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [61/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [62/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [63/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [64/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [65/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [66/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [67/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [68/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [69/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [70/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [71/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [72/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [73/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [74/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [75/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [76/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [77/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [78/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [79/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [80/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [81/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [82/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [83/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [84/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [85/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [86/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [87/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [88/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [89/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [90/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [91/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [92/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [93/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [94/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [95/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [96/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [97/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [98/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [99/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [100/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [101/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [102/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [103/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [104/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [105/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [106/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [107/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [108/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [109/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [110/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [111/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [112/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [113/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [114/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [115/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [116/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [117/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [118/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [119/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [120/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [121/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [122/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [123/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [124/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [125/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [126/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [127/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [128/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [129/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [130/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [131/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [132/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [133/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [134/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [135/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [136/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [137/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [138/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [139/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [140/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [141/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [142/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [143/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [144/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [145/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [146/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [147/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [148/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [149/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [150/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [151/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [152/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [153/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [154/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [155/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [156/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [157/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [158/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [159/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [160/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [161/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [162/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [163/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [164/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [165/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [166/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [167/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [168/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [169/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [170/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [171/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [172/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [173/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [174/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [175/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [176/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [177/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [178/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [179/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [180/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [181/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [182/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [183/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [184/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [185/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [186/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [187/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [188/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [189/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [190/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [191/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [192/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [193/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [194/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [195/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [196/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [197/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [198/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [199/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [200/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [201/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [202/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [203/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [204/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [205/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [206/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [207/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [208/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [209/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [210/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [211/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [212/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [213/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [214/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [215/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [216/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [217/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [218/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [219/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [220/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [221/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [222/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [223/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [224/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [225/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [226/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [227/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [228/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [229/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [230/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [231/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [232/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [233/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [234/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [235/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [236/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [237/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [238/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [239/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [240/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [241/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [242/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [243/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [244/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [245/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [246/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [247/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [248/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [249/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [250/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [251/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [252/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [253/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [254/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [255/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [256/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [257/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [258/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [259/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [260/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [261/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [262/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [263/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [264/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [265/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [266/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [267/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [268/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [269/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [270/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [271/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [272/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [273/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [274/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [275/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [276/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [277/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [278/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [279/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [280/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [281/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [282/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [283/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [284/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [285/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [286/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [287/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [288/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [289/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [290/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [291/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [292/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [293/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [294/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [295/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [296/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [297/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [298/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [299/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [300/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [301/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [302/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [303/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [304/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [305/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [306/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [307/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [308/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [309/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [310/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [311/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [312/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [313/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [314/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [315/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [316/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [317/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [318/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [319/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [320/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [321/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [322/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [323/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [324/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [325/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [326/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [327/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [328/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [329/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [330/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [331/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [332/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [333/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [334/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [335/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [336/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [337/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [338/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [339/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [340/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [341/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [342/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [343/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [344/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [345/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [346/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [347/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [348/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [349/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [350/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [351/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [352/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [353/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [354/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [355/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [356/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [357/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [358/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [359/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [360/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [361/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [362/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [363/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [364/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [365/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/v5ysl19s0hbdkdprhb3xqd4r0000gn/T/ipykernel_34536/3941992981.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_weights.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [366/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [367/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [368/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [369/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [370/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [371/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [372/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [373/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [374/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [375/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [376/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [377/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [378/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [379/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [380/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [381/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [382/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [383/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [384/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [385/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [386/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [387/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [388/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [389/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [390/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [391/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [392/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [393/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [394/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [395/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [396/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [397/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [398/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [399/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [400/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [401/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [402/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [403/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [404/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [405/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [406/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [407/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [408/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [409/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [410/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [411/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [412/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [413/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [414/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [415/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [416/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [417/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [418/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [419/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [420/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [421/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [422/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [423/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [424/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [425/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [426/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [427/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [428/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [429/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [430/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [431/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [432/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [433/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [434/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [435/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [436/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [437/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [438/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [439/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [440/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [441/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [442/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [443/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [444/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [445/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [446/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [447/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [448/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [449/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [450/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [451/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [452/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [453/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [454/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [455/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [456/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [457/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [458/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [459/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [460/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [461/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [462/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [463/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [464/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [465/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [466/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [467/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [468/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [469/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [470/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [471/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [472/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [473/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [474/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [475/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [476/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [477/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [478/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [479/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [480/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [481/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [482/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [483/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [484/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [485/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [486/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [487/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [488/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [489/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [490/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [491/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [492/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [493/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [494/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [495/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [496/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [497/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [498/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [499/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [500/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [501/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [502/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [503/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [504/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [505/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [506/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [507/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [508/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [509/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [510/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [511/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [512/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [513/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [514/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [515/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [516/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [517/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [518/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [519/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [520/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [521/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [522/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [523/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [524/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [525/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [526/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [527/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [528/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [529/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [530/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [531/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [532/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [533/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [534/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [535/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [536/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [537/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [538/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [539/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [540/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [541/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [542/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [543/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [544/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [545/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [546/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [547/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [548/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [549/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [550/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [551/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [552/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [553/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [554/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [555/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [556/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [557/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [558/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [559/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [560/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [561/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [562/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [563/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [564/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [565/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [566/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [567/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [568/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [569/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [570/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [571/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [572/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [573/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [574/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [575/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [576/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [577/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [578/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [579/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [580/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [581/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [582/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [583/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [584/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [585/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [586/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [587/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [588/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [589/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [590/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [591/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [592/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [593/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [594/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [595/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [596/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [597/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [598/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [599/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n",
      "Epoch [600/600], Test Loss: 0.7229, Testing Accuracy: 0.7879, \n"
     ]
    }
   ],
   "source": [
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "for epoch in range(num_epochs): #defining the training loop\n",
    "    \n",
    "    model.train() #model in training mode\n",
    "    training_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0 \n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "        outputs = model(inputs).squeeze()  # output -> predictions   :   labels -> actual values [ 1 or 0 ]\n",
    "        loss = loss_function(outputs, labels.float())  # loss is calsulated between predicted and the actual values\n",
    "        optimizer.zero_grad()  # Before backpropagation, initialize all weights to zero \n",
    "        loss.backward()  # performs backward propagation\n",
    "        optimizer.step()  # updates the parameters learnt from backpropagation (weights)\n",
    "\n",
    "        training_loss += loss.item()  # .item() - extracts the scalar value of the loss tensor. Loss is calculated per batch\n",
    "\n",
    "        predicted = torch.round(outputs)  # Convert probabilities to binary predictions \n",
    "        correct_predictions += (predicted == labels).sum().item()  #creates a tensor oa maps how many actually match that conditon\n",
    "        total_predictions += labels.size(0)  #first dimension of the tensor\n",
    "\n",
    "    train_losses.append(training_loss / len(train_loader))  #for loss calculation\n",
    "    train_accuracies.append(correct_predictions / total_predictions)\n",
    "\n",
    "\n",
    "    model.eval()  #model in evaluation mode\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_outputs = model(val_inputs).squeeze()\n",
    "            val_loss += loss_function(val_outputs, val_labels.float()).item()\n",
    "\n",
    "            predicted = torch.round(val_outputs)\n",
    "            val_correct_predictions += (predicted == val_labels).sum().item()\n",
    "            val_total_predictions += val_labels.size(0)\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(val_correct_predictions / val_total_predictions)\n",
    "\n",
    "    average_training_loss = training_loss / len(train_loader)  #loss per batch\n",
    "    average_validation_loss = val_loss / len(val_loader)\n",
    "    training_accuracy = correct_predictions / total_predictions  \n",
    "    validation_accuracy = val_correct_predictions / val_total_predictions\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "            f'Training Loss: {average_training_loss:.4f}, '\n",
    "            f'Validation Loss: {average_validation_loss:.4f}, '\n",
    "            f'Training Accuracy: {training_accuracy:.4f}, '\n",
    "            f'Validation Accuracy: {validation_accuracy:.4f}')\n",
    "    \n",
    "    if average_validation_loss < best_val_loss:\n",
    "        best_val_loss = average_validation_loss\n",
    "        torch.save(model.state_dict(), 'best_model_weights.pth')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Training Time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_weights.pth'))\n",
    "\n",
    "num_epochss = 600\n",
    "for epoch in range(num_epochss):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct_predictions = 0\n",
    "    test_total_predictions = 0\n",
    "\n",
    "    confusion_predictions = []\n",
    "    confusion_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in test_loader:\n",
    "            test_outputs = model(test_inputs).squeeze()\n",
    "            test_loss += loss_function(test_outputs, test_labels.float()).item()\n",
    "            \n",
    "            predicted = torch.round(test_outputs)\n",
    "            test_correct_predictions += (predicted == test_labels.float()).sum().item()\n",
    "            test_total_predictions += test_labels.size(0)\n",
    "        \n",
    "            confusion_predictions.extend(predicted.numpy())  #for confusion matrix\n",
    "            confusion_labels.extend(test_labels.numpy())  #actual class labels\n",
    "\n",
    "        test_losses.append(test_loss / len(test_loader))  # Gives the average loss per batch\n",
    "        test_accuracies.append(test_correct_predictions / test_total_predictions)  # ratio of correct preds / total preds -> accuracy\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = test_correct_predictions / test_total_predictions\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochss}], '\n",
    "            f'Test Loss: {avg_test_loss:.4f}, '\n",
    "            f'Testing Accuracy: {test_accuracy:.4f}, ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(train_accuracies) + 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training, Validation, and Test Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph - comparing the test accuracy between the base model and the improved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "improved_test_acc = 0.7879\n",
    "base_test_acc = 0.7608\n",
    "\n",
    "models = [\"Base model\" , \"Batch_normalization\"]\n",
    "\n",
    "plt.bar(models, [base_test_acc,improved_test_acc ])\n",
    "plt.xlabel(\"Two models\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Comparison of two models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class lecture slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
